import sys
_module = sys.modules[__name__]
del sys
citation = _module
appnp = _module
arma = _module
cheb = _module
datasets = _module
gat = _module
gcn = _module
sgc = _module
statistics = _module
train_eval = _module
inference_benchmark = _module
kernel = _module
asap = _module
datasets = _module
diff_pool = _module
edge_pool = _module
gcn = _module
gin = _module
global_attention = _module
graclus = _module
graph_sage = _module
main = _module
main_performance = _module
sag_pool = _module
set2set = _module
sort_pool = _module
top_k = _module
train_eval = _module
neighbor_loader = _module
points = _module
edge_cnn = _module
mpnn = _module
point_cnn = _module
point_net = _module
spline_cnn = _module
train_eval = _module
runtime = _module
gat = _module
gcn = _module
hidden = _module
main = _module
rgcn = _module
train = _module
gat = _module
gcn = _module
main = _module
rgcn = _module
train = _module
setup = _module
training_benchmark = _module
utils = _module
hetero_gat = _module
hetero_sage = _module
utils = _module
conf = _module
agnn = _module
argva_node_clustering = _module
arma = _module
attentive_fp = _module
autoencoder = _module
captum_explainability = _module
cluster_gcn_ppi = _module
cluster_gcn_reddit = _module
colors_topk_pool = _module
cora = _module
correct_and_smooth = _module
save_model = _module
datapipe = _module
dgcnn_classification = _module
dgcnn_segmentation = _module
dna = _module
egc = _module
equilibrium_median = _module
faust = _module
film = _module
gat = _module
gcn = _module
gcn2_cora = _module
gcn2_ppi = _module
geniepath = _module
glnn = _module
gnn_explainer = _module
gnn_explainer_ba_shapes = _module
gnn_explainer_link_pred = _module
graph_sage_unsup = _module
graph_sage_unsup_ppi = _module
graph_saint = _module
graph_unet = _module
bipartite_sage = _module
dmgi_unsup = _module
han_imdb = _module
hetero_conv_dblp = _module
hetero_link_pred = _module
hgt_dblp = _module
load_csv = _module
metapath2vec = _module
to_hetero_mag = _module
infomax_inductive = _module
infomax_transductive = _module
gat = _module
gin = _module
label_prop = _module
link_pred = _module
linkx = _module
mem_pool = _module
mnist_graclus = _module
mnist_nn_conv = _module
mnist_voxel_grid = _module
data_parallel = _module
distributed_batching = _module
distributed_sampling = _module
mutag_gin = _module
node2vec = _module
ogbn_products_gat = _module
ogbn_products_sage = _module
ogbn_proteins_deepgcn = _module
pna = _module
point_transformer_classification = _module
point_transformer_segmentation = _module
pointnet2_classification = _module
pointnet2_segmentation = _module
ppi = _module
proteins_diff_pool = _module
proteins_dmon_pool = _module
proteins_gmt = _module
proteins_mincut_pool = _module
proteins_topk_pool = _module
gin = _module
gin = _module
graph_sage = _module
relational_gnn = _module
qm9_nn_conv = _module
qm9_pretrained_dimenet = _module
qm9_pretrained_schnet = _module
multi_gpu_quiver = _module
single_gpu_quiver = _module
randlanet_classification = _module
randlanet_segmentation = _module
rect = _module
reddit = _module
renet = _module
rev_gnn = _module
rgat = _module
rgcn = _module
rgcn_link_pred = _module
seal_link_pred = _module
sgc = _module
shadow = _module
sign = _module
signed_gcn = _module
super_gat = _module
tagcn = _module
tensorboard_logging = _module
tgn = _module
triangles_sag_pool = _module
unimp_arxiv = _module
upfd = _module
wl_kernel = _module
agg_batch = _module
configs_gen = _module
custom_graphgym = _module
act = _module
example = _module
config = _module
encoder = _module
example = _module
head = _module
example = _module
layer = _module
example = _module
loader = _module
loss = _module
example = _module
network = _module
example = _module
optimizer = _module
example = _module
pooling = _module
stage = _module
example = _module
example = _module
transform = _module
main = _module
conftest = _module
test_datamodule = _module
test_batch = _module
test_data = _module
test_dataset = _module
test_dataset_summary = _module
test_feature_store = _module
test_graph_store = _module
test_hetero_data = _module
test_inherit = _module
test_remote_backend_utils = _module
test_storage = _module
test_temporal = _module
test_ba_graph = _module
test_er_graph = _module
test_grid_graph = _module
test_custom_motif = _module
test_cycle_motif = _module
test_house_motif = _module
test_ba_shapes = _module
test_bzr = _module
test_elliptic = _module
test_enzymes = _module
test_explainer_dataset = _module
test_fake = _module
test_imdb_binary = _module
test_infection_dataset = _module
test_karate = _module
test_mutag = _module
test_planetoid = _module
test_snap_dataset = _module
test_suite_sparse = _module
test_attention_explainer = _module
test_explain_algorithm_utils = _module
test_gnn_explainer = _module
test_basic_metric = _module
test_faithfulness = _module
test_fidelity = _module
test_explain_config = _module
test_explainer = _module
test_explanation = _module
test_hetero_explainer = _module
test_hetero_explanation = _module
test_config = _module
test_config_store = _module
test_graphgym = _module
test_logger = _module
test_register = _module
test_off = _module
test_cluster = _module
test_dataloader = _module
test_dynamic_batch_sampler = _module
test_graph_saint = _module
test_hgt_loader = _module
test_imbalanced_sampler = _module
test_link_neighbor_loader = _module
test_neighbor_loader = _module
test_neighbor_sampler = _module
test_random_node_loader = _module
test_shadow = _module
test_temporal_dataloader = _module
test_attention = _module
test_basic = _module
test_equilibrium = _module
test_fused = _module
test_gmt = _module
test_lstm = _module
test_multi = _module
test_quantile = _module
test_scaler = _module
test_set2set = _module
test_sort = _module
test_agnn_conv = _module
test_appnp = _module
test_arma_conv = _module
test_cg_conv = _module
test_cheb_conv = _module
test_cluster_gcn_conv = _module
test_create_gnn = _module
test_dna_conv = _module
test_edge_conv = _module
test_eg_conv = _module
test_fa_conv = _module
test_feast_conv = _module
test_film_conv = _module
test_fused_gat_conv = _module
test_gat_conv = _module
test_gated_graph_conv = _module
test_gatv2_conv = _module
test_gcn2_conv = _module
test_gcn_conv = _module
test_gen_conv = _module
test_general_conv = _module
test_gin_conv = _module
test_gmm_conv = _module
test_graph_conv = _module
test_gravnet_conv = _module
test_han_conv = _module
test_heat_conv = _module
test_hetero_conv = _module
test_hgt_conv = _module
test_hypergraph_conv = _module
test_le_conv = _module
test_lg_conv = _module
test_message_passing = _module
test_mf_conv = _module
test_nn_conv = _module
test_pan_conv = _module
test_pdn_conv = _module
test_pna_conv = _module
test_point_conv = _module
test_point_gnn_conv = _module
test_point_transformer_conv = _module
test_ppf_conv = _module
test_res_gated_graph_conv = _module
test_rgat_conv = _module
test_rgcn_conv = _module
test_sage_conv = _module
test_sg_conv = _module
test_signed_conv = _module
test_spline_conv = _module
test_ssg_conv = _module
test_static_graph = _module
test_supergat_conv = _module
test_tag_conv = _module
test_transformer_conv = _module
test_wl_conv = _module
test_wl_conv_continuous = _module
test_x_conv = _module
test_dense_gcn_conv = _module
test_dense_gin_conv = _module
test_dense_graph_conv = _module
test_dense_sage_conv = _module
test_diff_pool = _module
test_dmon_pool = _module
test_linear = _module
test_mincut_pool = _module
test_bro = _module
test_gini = _module
test_attentive_fp = _module
test_autoencoder = _module
test_basic_gnn = _module
test_deep_graph_infomax = _module
test_deepgcn = _module
test_dimenet = _module
test_gnn_explainer_old_interface = _module
test_graph_unet = _module
test_hetero_explainer_old_interface = _module
test_jumping_knowledge = _module
test_lightgcn = _module
test_linkx = _module
test_mask_label = _module
test_metapath2vec = _module
test_mlp = _module
test_node2vec = _module
test_re_net = _module
test_rev_gnn = _module
test_schnet = _module
test_signed_gcn = _module
test_to_captum = _module
test_batch_norm = _module
test_diff_group_norm = _module
test_graph_norm = _module
test_graph_size_norm = _module
test_instance_norm = _module
test_layer_norm = _module
test_mean_subtraction_norm = _module
test_msg_norm = _module
test_pair_norm = _module
test_asap = _module
test_avg_pool = _module
test_consecutive = _module
test_decimation = _module
test_edge_pool = _module
test_glob = _module
test_graclus = _module
test_max_pool = _module
test_mem_pool = _module
test_pan_pool = _module
test_pool = _module
test_sag_pool = _module
test_topk_pool = _module
test_voxel_grid = _module
test_data_parallel = _module
test_encoding = _module
test_inits = _module
test_meta = _module
test_model_summary = _module
test_module_dict = _module
test_parameter_dict = _module
test_reshape = _module
test_resolver = _module
test_sequential = _module
test_to_fixed_size_transformer = _module
test_to_hetero_transformer = _module
test_to_hetero_with_bases_transformer = _module
test_knn_interpolate = _module
test_profile = _module
test_profile_utils = _module
test_debug = _module
test_experimental = _module
test_seed = _module
test_add_metapaths = _module
test_add_positional_encoding = _module
test_add_self_loops = _module
test_cartesian = _module
test_center = _module
test_compose = _module
test_constant = _module
test_delaunay = _module
test_distance = _module
test_face_to_edge = _module
test_feature_propagation = _module
test_fixed_points = _module
test_gdc = _module
test_generate_normals = _module
test_grid_sampling = _module
test_knn_graph = _module
test_laplacian_lambda_max = _module
test_largest_connected_components = _module
test_line_graph = _module
test_linear_transformation = _module
test_local_cartesian = _module
test_local_degree_profile = _module
test_mask_transform = _module
test_normalize_features = _module
test_normalize_rotation = _module
test_normalize_scale = _module
test_one_hot_degree = _module
test_point_pair_features = _module
test_polar = _module
test_radius_graph = _module
test_random_flip = _module
test_random_jitter = _module
test_random_link_split = _module
test_random_node_split = _module
test_random_rotate = _module
test_random_scale = _module
test_random_shear = _module
test_remove_isolated_nodes = _module
test_rooted_subgraph = _module
test_sample_points = _module
test_spherical = _module
test_target_indegree = _module
test_to_dense = _module
test_to_sparse_tensor = _module
test_to_superpixels = _module
test_to_undirected = _module
test_two_hop = _module
test_virtual_node = _module
test_assortativity = _module
test_augmentation = _module
test_convert = _module
test_degree = _module
test_dropout = _module
test_embedding = _module
test_geodesic = _module
test_get_laplacian = _module
test_get_mesh_laplacian = _module
test_grid = _module
test_homophily = _module
test_isolated = _module
test_loop = _module
test_mask = _module
test_negative_sampling = _module
test_normalized_cut = _module
test_random = _module
test_repeat = _module
test_scatter = _module
test_smiles = _module
test_softmax = _module
test_sort_edge_index = _module
test_sparse = _module
test_spmm = _module
test_subgraph = _module
test_to_dense_adj = _module
test_to_dense_batch = _module
test_train_test_split_edges = _module
test_unbatch = _module
test_undirected = _module
test_graph_visualization = _module
test_influence = _module
torch_geometric = _module
data = _module
batch = _module
collate = _module
data = _module
datapipes = _module
dataset = _module
download = _module
extract = _module
feature_store = _module
graph_store = _module
hetero_data = _module
in_memory_dataset = _module
lightning = _module
datamodule = _module
makedirs = _module
remote_backend_utils = _module
separate = _module
storage = _module
summary = _module
temporal = _module
view = _module
actor = _module
airfrans = _module
airports = _module
amazon = _module
amazon_products = _module
aminer = _module
aqsol = _module
attributed_graph_dataset = _module
ba2motif_dataset = _module
ba_shapes = _module
bitcoin_otc = _module
citation_full = _module
coauthor = _module
coma = _module
dblp = _module
dbp15k = _module
deezer_europe = _module
dgraph = _module
dynamic_faust = _module
elliptic = _module
email_eu_core = _module
entities = _module
explainer_dataset = _module
facebook = _module
fake = _module
faust = _module
flickr = _module
gdelt = _module
ged_dataset = _module
gemsec = _module
geometry = _module
github = _module
gnn_benchmark_dataset = _module
graph_generator = _module
ba_graph = _module
base = _module
er_graph = _module
grid_graph = _module
hgb_dataset = _module
hydro_net = _module
icews = _module
imdb = _module
infection_dataset = _module
jodie = _module
karate = _module
last_fm = _module
lastfm_asia = _module
linkx_dataset = _module
lrgb = _module
malnet_tiny = _module
md17 = _module
mixhop_synthetic_dataset = _module
mnist_superpixels = _module
modelnet = _module
molecule_net = _module
motif_generator = _module
custom = _module
cycle = _module
house = _module
movie_lens = _module
nell = _module
ogb_mag = _module
omdb = _module
particle = _module
pascal = _module
pascal_pf = _module
pcpnet_dataset = _module
planetoid = _module
polblogs = _module
ppi = _module
qm7 = _module
qm9 = _module
reddit = _module
reddit2 = _module
rel_link_pred_dataset = _module
s3dis = _module
sbm_dataset = _module
shapenet = _module
shrec2016 = _module
snap_dataset = _module
suite_sparse = _module
tosca = _module
tu_dataset = _module
twitch = _module
upfd = _module
cheatsheet = _module
webkb = _module
wikics = _module
wikipedia_network = _module
willow_object_class = _module
word_net = _module
yelp = _module
zinc = _module
debug = _module
deprecation = _module
experimental = _module
explain = _module
algorithm = _module
attention_explainer = _module
base = _module
dummy_explainer = _module
gnn_explainer = _module
utils = _module
explainer = _module
explanation = _module
metric = _module
basic = _module
faithfulness = _module
fidelity = _module
graphgym = _module
benchmark = _module
checkpoint = _module
cmd_args = _module
config_store = _module
contrib = _module
generalconv = _module
imports = _module
init = _module
loader = _module
logger = _module
loss = _module
model_builder = _module
models = _module
act = _module
encoder = _module
gnn = _module
head = _module
layer = _module
transform = _module
optim = _module
register = _module
train = _module
agg_runs = _module
comp_budget = _module
device = _module
epoch = _module
io = _module
plot = _module
tools = _module
home = _module
npz = _module
obj = _module
off = _module
planetoid = _module
ply = _module
sdf = _module
tu = _module
txt_array = _module
lazy_loader = _module
base = _module
cluster = _module
data_list_loader = _module
dataloader = _module
dense_data_loader = _module
dynamic_batch_sampler = _module
graph_saint = _module
hgt_loader = _module
imbalanced_sampler = _module
link_loader = _module
link_neighbor_loader = _module
neighbor_loader = _module
neighbor_sampler = _module
node_loader = _module
random_node_loader = _module
shadow = _module
temporal_dataloader = _module
utils = _module
logging = _module
nn = _module
aggr = _module
attention = _module
base = _module
basic = _module
equilibrium = _module
fused = _module
gmt = _module
lstm = _module
multi = _module
quantile = _module
scaler = _module
set2set = _module
sort = _module
conv = _module
agnn_conv = _module
appnp = _module
arma_conv = _module
cg_conv = _module
cheb_conv = _module
cluster_gcn_conv = _module
dna_conv = _module
edge_conv = _module
eg_conv = _module
fa_conv = _module
feast_conv = _module
film_conv = _module
fused_gat_conv = _module
gat_conv = _module
gated_graph_conv = _module
gatv2_conv = _module
gcn2_conv = _module
gcn_conv = _module
gen_conv = _module
general_conv = _module
gin_conv = _module
gmm_conv = _module
graph_conv = _module
gravnet_conv = _module
han_conv = _module
heat_conv = _module
hetero_conv = _module
hgt_conv = _module
hypergraph_conv = _module
le_conv = _module
lg_conv = _module
message_passing = _module
mf_conv = _module
nn_conv = _module
pan_conv = _module
pdn_conv = _module
pna_conv = _module
point_conv = _module
point_gnn_conv = _module
point_transformer_conv = _module
ppf_conv = _module
res_gated_graph_conv = _module
rgat_conv = _module
rgcn_conv = _module
sage_conv = _module
sg_conv = _module
signed_conv = _module
spline_conv = _module
ssg_conv = _module
supergat_conv = _module
tag_conv = _module
transformer_conv = _module
cheatsheet = _module
helpers = _module
inspector = _module
jit = _module
typing = _module
wl_conv = _module
wl_conv_continuous = _module
x_conv = _module
data_parallel = _module
dense = _module
dense_gcn_conv = _module
dense_gin_conv = _module
dense_graph_conv = _module
dense_sage_conv = _module
diff_pool = _module
dmon_pool = _module
linear = _module
mincut_pool = _module
encoding = _module
functional = _module
bro = _module
gini = _module
fx = _module
glob = _module
inits = _module
lr_scheduler = _module
meta = _module
attentive_fp = _module
autoencoder = _module
basic_gnn = _module
captum = _module
correct_and_smooth = _module
deep_graph_infomax = _module
deepgcn = _module
dimenet = _module
dimenet_utils = _module
graph_unet = _module
jumping_knowledge = _module
label_prop = _module
lightgcn = _module
linkx = _module
mask_label = _module
metapath2vec = _module
mlp = _module
node2vec = _module
re_net = _module
rect = _module
rev_gnn = _module
schnet = _module
signed_gcn = _module
tgn = _module
module_dict = _module
norm = _module
batch_norm = _module
diff_group_norm = _module
graph_norm = _module
graph_size_norm = _module
instance_norm = _module
layer_norm = _module
mean_subtraction_norm = _module
msg_norm = _module
pair_norm = _module
parameter_dict = _module
pool = _module
asap = _module
avg_pool = _module
consecutive = _module
decimation = _module
edge_pool = _module
glob = _module
graclus = _module
max_pool = _module
mem_pool = _module
pan_pool = _module
pool = _module
sag_pool = _module
topk_pool = _module
voxel_grid = _module
reshape = _module
resolver = _module
sequential = _module
summary = _module
to_fixed_size_transformer = _module
to_hetero_transformer = _module
to_hetero_with_bases_transformer = _module
unpool = _module
knn_interpolate = _module
profile = _module
profile = _module
profiler = _module
utils = _module
sampler = _module
base = _module
hgt_sampler = _module
neighbor_sampler = _module
utils = _module
seed = _module
testing = _module
decorators = _module
feature_store = _module
graph_store = _module
transforms = _module
add_metapaths = _module
add_positional_encoding = _module
add_self_loops = _module
base_transform = _module
cartesian = _module
center = _module
compose = _module
constant = _module
delaunay = _module
distance = _module
face_to_edge = _module
feature_propagation = _module
fixed_points = _module
gcn_norm = _module
gdc = _module
generate_mesh_normals = _module
grid_sampling = _module
knn_graph = _module
laplacian_lambda_max = _module
largest_connected_components = _module
line_graph = _module
linear_transformation = _module
local_cartesian = _module
local_degree_profile = _module
mask = _module
normalize_features = _module
normalize_rotation = _module
normalize_scale = _module
one_hot_degree = _module
point_pair_features = _module
polar = _module
radius_graph = _module
random_flip = _module
random_jitter = _module
random_link_split = _module
random_node_split = _module
random_rotate = _module
random_scale = _module
random_shear = _module
remove_isolated_nodes = _module
remove_training_classes = _module
rooted_subgraph = _module
sample_points = _module
sign = _module
spherical = _module
svd_feature_reduction = _module
target_indegree = _module
to_dense = _module
to_device = _module
to_sparse_tensor = _module
to_superpixels = _module
to_undirected = _module
two_hop = _module
virtual_node = _module
typing = _module
assortativity = _module
augmentation = _module
coalesce = _module
convert = _module
degree = _module
dropout = _module
embedding = _module
geodesic = _module
get_laplacian = _module
get_mesh_laplacian = _module
grid = _module
hetero = _module
homophily = _module
isolated = _module
loop = _module
mask = _module
mixin = _module
negative_sampling = _module
normalized_cut = _module
num_nodes = _module
random = _module
repeat = _module
scatter = _module
smiles = _module
softmax = _module
sort_edge_index = _module
sparse = _module
spmm = _module
subgraph = _module
to_dense_adj = _module
to_dense_batch = _module
train_test_split_edges = _module
tree_decomposition = _module
unbatch = _module
undirected = _module
visualization = _module
graph = _module
influence = _module

from _paritybench_helpers import _mock_config, patch_functional
from unittest.mock import mock_open, MagicMock
from torch.autograd import Function
from torch.nn import Module
import abc, collections, copy, enum, functools, inspect, itertools, logging, math, matplotlib, numbers, numpy, pandas, queue, random, re, scipy, sklearn, string, tensorflow, time, torch, torchaudio, torchtext, torchvision, types, typing, uuid, warnings
import numpy as np
from torch import Tensor
patch_functional()
open = mock_open()
yaml = logging = sys = argparse = MagicMock()
ArgumentParser = argparse.ArgumentParser
_global_config = args = argv = cfg = config = params = _mock_config()
argparse.ArgumentParser.return_value.parse_args.return_value = _global_config
yaml.load.return_value = _global_config
sys.argv = _global_config
__version__ = '1.0.0'
xrange = range
wraps = functools.wraps


import torch


import torch.nn.functional as F


from torch.nn import Linear


import time


from torch import tensor


from torch.optim import Adam


from math import ceil


from torch.nn import BatchNorm1d as BN


from torch.nn import ReLU


from torch.nn import Sequential


from itertools import product


from torch.nn import Conv1d


from sklearn.model_selection import StratifiedKFold


from torch.nn import Linear as Lin


from torch.nn import Sequential as Seq


from torch.nn import Parameter


from torch.nn import Parameter as Param


import matplotlib.pyplot as plt


from sklearn.cluster import KMeans


from sklearn.manifold import TSNE


from sklearn.metrics.cluster import completeness_score


from sklearn.metrics.cluster import homogeneity_score


from sklearn.metrics.cluster import v_measure_score


from math import sqrt


from sklearn.metrics import f1_score


from torch.nn import ModuleList


from typing import Optional


from torch import Tensor


from torch.nn import BatchNorm1d


from torch.optim.lr_scheduler import ReduceLROnPlateau


import numpy as np


from sklearn.metrics import roc_auc_score


from sklearn.model_selection import train_test_split


from sklearn.linear_model import LogisticRegression


from sklearn.linear_model import SGDClassifier


from sklearn.multioutput import MultiOutputClassifier


from torch.nn import Embedding


from typing import Dict


from typing import List


from typing import Union


from torch import nn


import pandas as pd


import torch.nn as nn


from torch.nn import BatchNorm1d as BatchNorm


from torch.nn import LeakyReLU


import torch.distributed as dist


import torch.multiprocessing as mp


from torch.nn.parallel import DistributedDataParallel


from torch.utils.data.distributed import DistributedSampler


from torch.nn import LayerNorm


from typing import Tuple


from torch.nn import GRU


import copy


import math


from itertools import chain


from scipy.sparse.csgraph import shortest_path


from torch.nn import BCEWithLogitsLoss


from torch.nn import MaxPool1d


from torch.utils.data import DataLoader


from torch.utils.tensorboard import SummaryWriter


from sklearn.metrics import average_precision_score


import warnings


from sklearn.exceptions import ConvergenceWarning


from sklearn.metrics import accuracy_score


from sklearn.svm import LinearSVC


from functools import partial


from typing import Iterator


from torch.optim import Adagrad


from torch.optim import Optimizer


import logging


import random


from typing import Any


from collections import namedtuple


from time import sleep


from torch.nn import Linear as PTLinear


from torch.nn.parameter import UninitializedParameter


from torch import Tensor as T


from typing import Mapping


from torch.nn import Module


from torch.optim.lr_scheduler import ConstantLR


from torch.optim.lr_scheduler import LambdaLR


from collections import OrderedDict


import torch.fx


from torch.nn import Dropout


from copy import copy


from math import pi as PI


import scipy.sparse


import inspect


from collections.abc import Sequence


from collections import defaultdict


from collections.abc import Mapping


from typing import Callable


from typing import Iterable


from typing import NamedTuple


import re


import torch.utils.data


from abc import abstractmethod


from enum import Enum


from collections.abc import MutableMapping


import scipy.sparse as sp


from collections import Counter


from functools import lru_cache


from torch.utils.data import ConcatDataset


from torch.utils.data import Subset


from torch.nn.parameter import Parameter


from torch.optim import SGD


from torch.optim.lr_scheduler import CosineAnnealingLR


from torch.optim.lr_scheduler import MultiStepLR


from torch.optim.lr_scheduler import StepLR


from torch._tensor_str import PRINT_OPTS


from torch._tensor_str import _tensor_str


from itertools import repeat


from torch.utils.data.dataloader import _BaseDataLoaderIter


from typing import Sequence


from torch.utils.data.dataloader import default_collate


from typing import Type


from torch.nn import LSTM


from torch.nn import MultiheadAttention


from math import log


from torch.nn import InstanceNorm1d


from inspect import Parameter


from typing import Set


from typing import get_type_hints


from uuid import uuid1


from torch.utils.hooks import RemovableHandle


from torch.nn import Sigmoid


from torch.nn import ELU


from torch.nn import Linear as L


from torch.nn import Sequential as S


from torch.nn import ModuleDict


import functools


from torch.nn import GRUCell


from inspect import signature


from torch.utils.checkpoint import checkpoint


from torch.nn.modules.loss import _Loss


from torch.nn import Identity


from abc import ABC


from torch.nn.modules.instancenorm import _InstanceNorm


from torch import LongTensor


from torch.nn import Conv2d


from torch.nn import KLDivLoss


from torch.optim.lr_scheduler import _LRScheduler


from torch.jit import ScriptModule


from collections import deque


from torch.profiler import ProfilerActivity


from torch.profiler import profile


import torch.profiler as torch_profiler


from typing import TypeVar


import scipy.spatial


from scipy.linalg import expm


import numbers


from torch.utils.dlpack import from_dlpack


from torch.utils.dlpack import to_dlpack


from scipy.sparse.csgraph import minimum_spanning_tree


from torch.autograd import grad


def expand_left(src: torch.Tensor, dim: int, dims: int) ->torch.Tensor:
    for _ in range(dims + dim if dim < 0 else dim):
        src = src.unsqueeze(0)
    return src


class Aggregation(torch.nn.Module):
    """An abstract base class for implementing custom aggregations.

    Aggregation can be either performed via an :obj:`index` vector, which
    defines the mapping from input elements to their location in the output:

    |

    .. image:: https://raw.githubusercontent.com/rusty1s/pytorch_scatter/
            master/docs/source/_figures/add.svg?sanitize=true
        :align: center
        :width: 400px

    |

    Notably, :obj:`index` does not have to be sorted:

    .. code-block::

       # Feature matrix holding 10 elements with 64 features each:
       x = torch.randn(10, 64)

       # Assign each element to one of three sets:
       index = torch.tensor([0, 0, 1, 0, 2, 0, 2, 1, 0, 2])

       output = aggr(x, index)  #  Output shape: [3, 64]

    Alternatively, aggregation can be achieved via a "compressed" index vector
    called :obj:`ptr`. Here, elements within the same set need to be grouped
    together in the input, and :obj:`ptr` defines their boundaries:

    .. code-block::

       # Feature matrix holding 10 elements with 64 features each:
       x = torch.randn(10, 64)

       # Define the boundary indices for three sets:
       ptr = torch.tensor([0, 4, 7, 10])

       output = aggr(x, ptr=ptr)  #  Output shape: [4, 64]

    Note that at least one of :obj:`index` or :obj:`ptr` must be defined.

    Shapes:
        - **input:**
          node features :math:`(|\\mathcal{V}|, F_{in})` or edge features
          :math:`(|\\mathcal{E}|, F_{in})`,
          index vector :math:`(|\\mathcal{V}|)` or :math:`(|\\mathcal{E}|)`,
        - **output:** graph features :math:`(|\\mathcal{G}|, F_{out})` or node
          features :math:`(|\\mathcal{V}|, F_{out})`
    """

    def forward(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2) ->Tensor:
        """
        Args:
            x (torch.Tensor): The source tensor.
            index (torch.LongTensor, optional): The indices of elements for
                applying the aggregation.
                One of :obj:`index` or :obj:`ptr` must be defined.
                (default: :obj:`None`)
            ptr (torch.LongTensor, optional): If given, computes the
                aggregation based on sorted inputs in CSR representation.
                One of :obj:`index` or :obj:`ptr` must be defined.
                (default: :obj:`None`)
            dim_size (int, optional): The size of the output tensor at
                dimension :obj:`dim` after aggregation. (default: :obj:`None`)
            dim (int, optional): The dimension in which to aggregate.
                (default: :obj:`-2`)
        """
        pass

    def reset_parameters(self):
        pass

    def __call__(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2, **kwargs) ->Tensor:
        if dim >= x.dim() or dim < -x.dim():
            raise ValueError(f"Encountered invalid dimension '{dim}' of source tensor with {x.dim()} dimensions")
        if index is None and ptr is None:
            index = x.new_zeros(x.size(dim), dtype=torch.long)
        if ptr is not None:
            if dim_size is None:
                dim_size = ptr.numel() - 1
            elif dim_size != ptr.numel() - 1:
                raise ValueError(f"Encountered invalid 'dim_size' (got '{dim_size}' but expected '{ptr.numel() - 1}')")
        if index is not None and dim_size is None:
            dim_size = int(index.max()) + 1 if index.numel() > 0 else 0
        try:
            return super().__call__(x, index, ptr, dim_size, dim, **kwargs)
        except (IndexError, RuntimeError) as e:
            if index is not None:
                if index.numel() > 0 and dim_size <= int(index.max()):
                    raise ValueError(f"Encountered invalid 'dim_size' (got '{dim_size}' but expected >= '{int(index.max()) + 1}')")
            raise e

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}()'

    def assert_index_present(self, index: Optional[Tensor]):
        if index is None:
            raise NotImplementedError("Aggregation requires 'index' to be specified")

    def assert_sorted_index(self, index: Optional[Tensor]):
        if index is not None and not torch.all(index[:-1] <= index[1:]):
            raise ValueError("Can not perform aggregation since the 'index' tensor is not sorted")

    def assert_two_dimensional_input(self, x: Tensor, dim: int):
        if x.dim() != 2:
            raise ValueError(f"Aggregation requires two-dimensional inputs (got '{x.dim()}')")
        if dim not in [-2, 0]:
            raise ValueError(f"Aggregation needs to perform aggregation in first dimension (got '{dim}')")

    def reduce(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2, reduce: str='sum') ->Tensor:
        if ptr is not None:
            ptr = expand_left(ptr, dim, dims=x.dim())
            return segment_csr(x, ptr, reduce=reduce)
        assert index is not None
        return scatter(x, index, dim, dim_size, reduce)

    def to_dense_batch(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2, fill_value: float=0.0) ->Tuple[Tensor, Tensor]:
        self.assert_index_present(index)
        self.assert_sorted_index(index)
        self.assert_two_dimensional_input(x, dim)
        return to_dense_batch(x, index, batch_size=dim_size, fill_value=fill_value)


FUSE_AGGRS = {'add', 'sum', 'mean', 'min', 'max'}


def sanitize(type_repr: str):
    type_repr = re.sub("<class \\'(.*)\\'>", '\\1', type_repr)
    type_repr = type_repr.replace('typing.', '')
    type_repr = type_repr.replace('torch_sparse.tensor.', '')
    type_repr = type_repr.replace('Adj', 'Union[Tensor, SparseTensor]')
    sexp = pp.nestedExpr(opener='[', closer=']')
    tree = sexp.parseString(f"[{type_repr.replace(',', ' ')}]").asList()[0]

    def union_to_optional_(tree):
        for i in range(len(tree)):
            e, n = tree[i], tree[i + 1] if i + 1 < len(tree) else []
            if e == 'Union' and n[-1] == 'NoneType':
                tree[i] = 'Optional'
                tree[i + 1] = tree[i + 1][:-1]
            elif e == 'Union' and 'NoneType' in n:
                idx = n.index('NoneType')
                n[idx] = [n[idx - 1]]
                n[idx - 1] = 'Optional'
            elif isinstance(e, list):
                tree[i] = union_to_optional_(e)
        return tree
    tree = union_to_optional_(tree)
    type_repr = re.sub('\\\'|\\"', '', str(tree)[1:-1]).replace(', [', '[')
    return type_repr


def param_type_repr(param) ->str:
    if param.annotation is inspect.Parameter.empty:
        return 'torch.Tensor'
    return sanitize(re.split(':|='.strip(), str(param))[1])


def return_type_repr(signature) ->str:
    return_type = signature.return_annotation
    if return_type is inspect.Parameter.empty:
        return 'torch.Tensor'
    elif str(return_type)[:6] != '<class':
        return sanitize(str(return_type))
    elif return_type.__module__ == 'builtins':
        return return_type.__name__
    else:
        return f'{return_type.__module__}.{return_type.__name__}'


def split_types_repr(types_repr: str) ->List[str]:
    out = []
    i = depth = 0
    for j, char in enumerate(types_repr):
        if char == '[':
            depth += 1
        elif char == ']':
            depth -= 1
        elif char == ',' and depth == 0:
            out.append(types_repr[i:j].strip())
            i = j + 1
    out.append(types_repr[i:].strip())
    return out


def parse_types(func: Callable) ->List[Tuple[Dict[str, str], str]]:
    source = inspect.getsource(func)
    signature = inspect.signature(func)
    iterator = re.finditer('#\\s*type:\\s*\\((.*)\\)\\s*->\\s*(.*)\\s*\\n', source)
    matches = list(iterator)
    if len(matches) > 0:
        out = []
        args = list(signature.parameters.keys())
        for match in matches:
            arg_types_repr, return_type = match.groups()
            arg_types = split_types_repr(arg_types_repr)
            arg_types = OrderedDict((k, v) for k, v in zip(args, arg_types))
            return_type = return_type.split('#')[0].strip()
            out.append((arg_types, return_type))
        return out
    else:
        ps = signature.parameters
        arg_types = OrderedDict((k, param_type_repr(v)) for k, v in ps.items())
        return [(arg_types, return_type_repr(signature))]


class Inspector(object):

    def __init__(self, base_class: Any):
        self.base_class: Any = base_class
        self.params: Dict[str, Dict[str, Any]] = {}

    def inspect(self, func: Callable, pop_first: bool=False) ->Dict[str, Any]:
        params = inspect.signature(func).parameters
        params = OrderedDict(params)
        if pop_first:
            params.popitem(last=False)
        self.params[func.__name__] = params

    def keys(self, func_names: Optional[List[str]]=None) ->Set[str]:
        keys = []
        for func in (func_names or list(self.params.keys())):
            keys += self.params[func].keys()
        return set(keys)

    def __implements__(self, cls, func_name: str) ->bool:
        if cls.__name__ == 'MessagePassing':
            return False
        if func_name in cls.__dict__.keys():
            return True
        return any(self.__implements__(c, func_name) for c in cls.__bases__)

    def implements(self, func_name: str) ->bool:
        return self.__implements__(self.base_class.__class__, func_name)

    def types(self, func_names: Optional[List[str]]=None) ->Dict[str, str]:
        out: Dict[str, str] = {}
        for func_name in (func_names or list(self.params.keys())):
            func = getattr(self.base_class, func_name)
            arg_types = parse_types(func)[0][0]
            for key in self.params[func_name].keys():
                if key in out and out[key] != arg_types[key]:
                    raise ValueError(f'Found inconsistent types for argument {key}. Expected type {out[key]} but found type {arg_types[key]}.')
                out[key] = arg_types[key]
        return out

    def distribute(self, func_name, kwargs: Dict[str, Any]):
        out = {}
        for key, param in self.params[func_name].items():
            data = kwargs.get(key, inspect.Parameter.empty)
            if data is inspect.Parameter.empty:
                if param.default is inspect.Parameter.empty:
                    raise TypeError(f'Required parameter {key} is empty.')
                data = param.default
            out[key] = data
        return out


class MaxAggregation(Aggregation):
    """An aggregation operator that takes the feature-wise maximum across a
    set of elements

    .. math::
        \\mathrm{max}(\\mathcal{X}) = \\max_{\\mathbf{x}_i \\in \\mathcal{X}}
        \\mathbf{x}_i.
    """

    def forward(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2) ->Tensor:
        return self.reduce(x, index, ptr, dim_size, dim, reduce='max')


class MeanAggregation(Aggregation):
    """An aggregation operator that averages features across a set of elements

    .. math::
        \\mathrm{mean}(\\mathcal{X}) = \\frac{1}{|\\mathcal{X}|}
        \\sum_{\\mathbf{x}_i \\in \\mathcal{X}} \\mathbf{x}_i.
    """

    def forward(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2) ->Tensor:
        return self.reduce(x, index, ptr, dim_size, dim, reduce='mean')


class MinAggregation(Aggregation):
    """An aggregation operator that takes the feature-wise minimum across a
    set of elements

    .. math::
        \\mathrm{min}(\\mathcal{X}) = \\min_{\\mathbf{x}_i \\in \\mathcal{X}}
        \\mathbf{x}_i.
    """

    def forward(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2) ->Tensor:
        return self.reduce(x, index, ptr, dim_size, dim, reduce='min')


class MulAggregation(Aggregation):
    """An aggregation operator that multiples features across a set of
    elements

    .. math::
        \\mathrm{mul}(\\mathcal{X}) = \\prod_{\\mathbf{x}_i \\in \\mathcal{X}}
        \\mathbf{x}_i.
    """

    def forward(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2) ->Tensor:
        self.assert_index_present(index)
        return self.reduce(x, index, None, dim_size, dim, reduce='mul')


class VarAggregation(Aggregation):
    """An aggregation operator that takes the feature-wise variance across a
    set of elements

    .. math::
        \\mathrm{var}(\\mathcal{X}) = \\mathrm{mean}(\\{ \\mathbf{x}_i^2 : x \\in
        \\mathcal{X} \\}) - \\mathrm{mean}(\\mathcal{X})^2.

    Args:
        semi_grad (bool, optional): If set to :obj:`True`, will turn off
            gradient calculation during :math:`E[X^2]` computation. Therefore,
            only semi-gradients are used during backpropagation. Useful for
            saving memory and accelerating backward computation.
            (default: :obj:`False`)
    """

    def __init__(self, semi_grad: bool=False):
        super().__init__()
        self.semi_grad = semi_grad

    def forward(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2) ->Tensor:
        mean = self.reduce(x, index, ptr, dim_size, dim, reduce='mean')
        if self.semi_grad:
            with torch.no_grad():
                mean2 = self.reduce(x * x, index, ptr, dim_size, dim, 'mean')
        else:
            mean2 = self.reduce(x * x, index, ptr, dim_size, dim, 'mean')
        return mean2 - mean * mean


class StdAggregation(Aggregation):
    """An aggregation operator that takes the feature-wise standard deviation
    across a set of elements

    .. math::
        \\mathrm{std}(\\mathcal{X}) = \\sqrt{\\mathrm{var}(\\mathcal{X})}.

    Args:
        semi_grad (bool, optional): If set to :obj:`True`, will turn off
            gradient calculation during :math:`E[X^2]` computation. Therefore,
            only semi-gradients are used during backpropagation. Useful for
            saving memory and accelerating backward computation.
            (default: :obj:`False`)
    """

    def __init__(self, semi_grad: bool=False):
        super().__init__()
        self.var_aggr = VarAggregation(semi_grad)

    def forward(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2) ->Tensor:
        var = self.var_aggr(x, index, ptr, dim_size, dim)
        return var.clamp(min=1e-05).sqrt()


class SumAggregation(Aggregation):
    """An aggregation operator that sums up features across a set of elements

    .. math::
        \\mathrm{sum}(\\mathcal{X}) = \\sum_{\\mathbf{x}_i \\in \\mathcal{X}}
        \\mathbf{x}_i.
    """

    def forward(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2) ->Tensor:
        return self.reduce(x, index, ptr, dim_size, dim, reduce='sum')


def normalize_string(s: str) ->str:
    return s.lower().replace('-', '').replace('_', '').replace(' ', '')


def resolver(classes: List[Any], class_dict: Dict[str, Any], query: Union[Any, str], base_cls: Optional[Any], base_cls_repr: Optional[str], *args, **kwargs):
    if not isinstance(query, str):
        return query
    query_repr = normalize_string(query)
    if base_cls_repr is None:
        base_cls_repr = base_cls.__name__ if base_cls else ''
    base_cls_repr = normalize_string(base_cls_repr)
    for key_repr, cls in class_dict.items():
        if query_repr == key_repr:
            if inspect.isclass(cls):
                obj = cls(*args, **kwargs)
                assert callable(obj)
                return obj
            assert callable(cls)
            return cls
    for cls in classes:
        cls_repr = normalize_string(cls.__name__)
        if query_repr in [cls_repr, cls_repr.replace(base_cls_repr, '')]:
            if inspect.isclass(cls):
                obj = cls(*args, **kwargs)
                assert callable(obj)
                return obj
            assert callable(cls)
            return cls
    choices = set(cls.__name__ for cls in classes) | set(class_dict.keys())
    raise ValueError(f"Could not resolve '{query}' among choices {choices}")


def aggregation_resolver(query: Union[Any, str], *args, **kwargs):
    base_cls = aggr.Aggregation
    aggrs = [aggr for aggr in vars(aggr).values() if isinstance(aggr, type) and issubclass(aggr, base_cls)]
    aggr_dict = {'add': aggr.SumAggregation}
    return resolver(aggrs, aggr_dict, query, base_cls, None, *args, **kwargs)


class FusedAggregation(Aggregation):
    """Helper class to fuse computation of multiple aggregations together.
    Used internally in :class:`~torch_geometric.nn.aggr.MultiAggregation` to
    speed-up computation.
    Currently, the following optimizations are performed:

    * :class:`MeanAggregation` will share the output with
      :class:`SumAggregation` in case it is present as well.

    * :class:`VarAggregation` will share the output with either
      :class:`MeanAggregation` or :class:`SumAggregation` in case one of them
      is present as well.

    * :class:`StdAggregation` will share the output with either
      :class:`VarAggregation`, :class:`MeanAggregation` or
      :class:`SumAggregation` in case one of them is present as well.

    In addition, temporary values such as the count per group index are shared
    as well.

    Benchmarking results on PyTorch 1.12 (summed over 1000 runs):

    +------------------------------+---------+---------+
    | Aggregators                  | Vanilla | Fusion  |
    +==============================+=========+=========+
    | :obj:`[sum, mean]`           | 0.3325s | 0.1996s |
    +------------------------------+---------+---------+
    | :obj:`[sum, mean, min, max]` | 0.7139s | 0.5037s |
    +------------------------------+---------+---------+
    | :obj:`[sum, mean, var]`      | 0.6849s | 0.3871s |
    +------------------------------+---------+---------+
    | :obj:`[sum, mean, var, std]` | 1.0955s | 0.3973s |
    +------------------------------+---------+---------+

    Args:
        aggrs (list): The list of aggregation schemes to use.
    """
    FUSABLE_AGGRS = {SumAggregation, MeanAggregation, MinAggregation, MaxAggregation, MulAggregation, VarAggregation, StdAggregation}
    DEGREE_BASED_AGGRS = {MeanAggregation, VarAggregation, StdAggregation}
    REDUCE = {'SumAggregation': 'sum', 'MeanAggregation': 'sum', 'MinAggregation': 'min', 'MaxAggregation': 'max', 'MulAggregation': 'mul', 'VarAggregation': 'pow_sum', 'StdAggregation': 'pow_sum'}

    def __init__(self, aggrs: List[Union[Aggregation, str]]):
        super().__init__()
        if not isinstance(aggrs, (list, tuple)):
            raise ValueError(f"'aggrs' of '{self.__class__.__name__}' should be a list or tuple (got '{type(aggrs)}').")
        if len(aggrs) == 0:
            raise ValueError(f"'aggrs' of '{self.__class__.__name__}' should not be empty.")
        aggrs = [aggregation_resolver(aggr) for aggr in aggrs]
        aggr_classes = [aggr.__class__ for aggr in aggrs]
        self.aggr_names = [cls.__name__ for cls in aggr_classes]
        self.aggr_index: Dict[str, int] = {name: i for i, name in enumerate(self.aggr_names)}
        for cls in aggr_classes:
            if cls not in self.FUSABLE_AGGRS:
                raise ValueError(f"Received aggregation '{cls.__name__}' in '{self.__class__.__name__}' which is not fusable")
        self.semi_grad = False
        for aggr in aggrs:
            if hasattr(aggr, 'semi_grad'):
                self.semi_grad = self.semi_grad or aggr.semi_grad
        self.need_degree = False
        for cls in aggr_classes:
            if cls in self.DEGREE_BASED_AGGRS:
                self.need_degree = True
        self.reduce_ops: List[Optional[str]] = []
        self.lookup_ops: List[Optional[Tuple[str, int]]] = []
        for name in self.aggr_names:
            if name == 'MeanAggregation':
                if 'SumAggregation' in self.aggr_index:
                    self.reduce_ops.append(None)
                    self.lookup_ops.append(('SumAggregation', self.aggr_index['SumAggregation']))
                else:
                    self.reduce_ops.append(self.REDUCE[name])
                    self.lookup_ops.append(None)
            elif name == 'VarAggregation':
                if 'MeanAggregation' in self.aggr_index:
                    self.reduce_ops.append(self.REDUCE[name])
                    self.lookup_ops.append(('MeanAggregation', self.aggr_index['MeanAggregation']))
                elif 'SumAggregation' in self.aggr_index:
                    self.reduce_ops.append(self.REDUCE[name])
                    self.lookup_ops.append(('SumAggregation', self.aggr_index['SumAggregation']))
                else:
                    self.reduce_ops.append(self.REDUCE[name])
                    self.lookup_ops.append(None)
            elif name == 'StdAggregation':
                if 'VarAggregation' in self.aggr_index:
                    self.reduce_ops.append(None)
                    self.lookup_ops.append(('VarAggregation', self.aggr_index['VarAggregation']))
                elif 'MeanAggregation' in self.aggr_index:
                    self.reduce_ops.append(self.REDUCE[name])
                    self.lookup_ops.append(('MeanAggregation', self.aggr_index['MeanAggregation']))
                elif 'SumAggregation' in self.aggr_index:
                    self.reduce_ops.append(self.REDUCE[name])
                    self.lookup_ops.append(('SumAggregation', self.aggr_index['SumAggregation']))
                else:
                    self.reduce_ops.append(self.REDUCE[name])
                    self.lookup_ops.append(None)
            else:
                self.reduce_ops.append(self.REDUCE[name])
                self.lookup_ops.append(None)

    def forward(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2) ->List[Tensor]:
        self.assert_index_present(index)
        self.assert_two_dimensional_input(x, dim)
        assert index is not None
        if dim_size is None:
            if ptr is not None:
                dim_size = ptr.numel() - 1
            else:
                dim_size = int(index.max()) + 1 if index.numel() > 0 else 0
        count: Optional[Tensor] = None
        if self.need_degree:
            count = x.new_zeros(dim_size)
            count.scatter_add_(0, index, x.new_ones(x.size(0)))
            count = count.clamp_(min=1).view(-1, 1)
        outs: List[Optional[Tensor]] = []
        for i, reduce in enumerate(self.reduce_ops):
            if reduce is None:
                outs.append(None)
                continue
            assert isinstance(reduce, str)
            if reduce == 'pow_sum':
                if self.semi_grad:
                    out = scatter(x.detach() * x.detach(), index, 0, dim_size, reduce='sum')
                else:
                    out = scatter(x * x, index, 0, dim_size, reduce='sum')
            else:
                out = scatter(x, index, 0, dim_size, reduce=reduce)
            outs.append(out)
        i = self.aggr_index.get('MeanAggregation')
        if i is not None:
            assert count is not None
            if self.lookup_ops[i] is None:
                sum_ = outs[i]
            else:
                lookup_op = self.lookup_ops[i]
                assert lookup_op is not None
                tmp_aggr, j = lookup_op
                assert tmp_aggr == 'SumAggregation'
                sum_ = outs[j]
            assert sum_ is not None
            outs[i] = sum_ / count
        i = self.aggr_index.get('VarAggregation')
        if i is not None:
            assert count is not None
            if self.lookup_ops[i] is None:
                sum_ = scatter(x, index, 0, dim_size, reduce='sum')
                mean = sum_ / count
            else:
                lookup_op = self.lookup_ops[i]
                assert lookup_op is not None
                tmp_aggr, j = lookup_op
                if tmp_aggr == 'SumAggregation':
                    sum_ = outs[j]
                    assert sum_ is not None
                    mean = sum_ / count
                elif tmp_aggr == 'MeanAggregation':
                    mean = outs[j]
                else:
                    raise NotImplementedError
            pow_sum = outs[i]
            assert pow_sum is not None
            assert mean is not None
            outs[i] = pow_sum / count - mean * mean
        i = self.aggr_index.get('StdAggregation')
        if i is not None:
            var: Optional[Tensor] = None
            pow_sum: Optional[Tensor] = None
            mean: Optional[Tensor] = None
            if self.lookup_ops[i] is None:
                pow_sum = outs[i]
                sum_ = scatter(x, index, 0, dim_size, reduce='sum')
                assert count is not None
                mean = sum_ / count
            else:
                lookup_op = self.lookup_ops[i]
                assert lookup_op is not None
                tmp_aggr, j = lookup_op
                if tmp_aggr == 'VarAggregation':
                    var = outs[j]
                elif tmp_aggr == 'SumAggregation':
                    pow_sum = outs[i]
                    sum_ = outs[j]
                    assert sum_ is not None
                    assert count is not None
                    mean = sum_ / count
                elif tmp_aggr == 'MeanAggregation':
                    pow_sum = outs[i]
                    mean = outs[j]
                else:
                    raise NotImplementedError
            if var is None:
                assert pow_sum is not None
                assert count is not None
                assert mean is not None
                var = pow_sum / count - mean * mean
            outs[i] = var.clamp(min=1e-05).sqrt()
        vals: List[Tensor] = []
        for out in outs:
            assert out is not None
            vals.append(out)
        return vals


class MultiAggregation(Aggregation):
    """Performs aggregations with one or more aggregators and combines
    aggregated results, as described in the `"Principal Neighbourhood
    Aggregation for Graph Nets" <https://arxiv.org/abs/2004.05718>`_ and
    `"Adaptive Filters and Aggregator Fusion for Efficient Graph Convolutions"
    <https://arxiv.org/abs/2104.01481>`_ papers.

    Args:
        aggrs (list): The list of aggregation schemes to use.
        aggrs_kwargs (dict, optional): Arguments passed to the
            respective aggregation function in case it gets automatically
            resolved. (default: :obj:`None`)
        mode (string, optional): The combine mode to use for combining
            aggregated results from multiple aggregations (:obj:`"cat"`,
            :obj:`"proj"`, :obj:`"sum"`, :obj:`"mean"`, :obj:`"max"`,
            :obj:`"min"`, :obj:`"logsumexp"`, :obj:`"std"`, :obj:`"var"`,
            :obj:`"attn"`). (default: :obj:`"cat"`)
        mode_kwargs (dict, optional): Arguments passed for the combine
            :obj:`mode`. When :obj:`"proj"` or :obj:`"attn"` is used as the
            combine :obj:`mode`, :obj:`in_channels` (int or tuple) and
            :obj:`out_channels` (int) are needed to be specified respectively
            for the size of each input sample to combine from the respective
            aggregation outputs and the size of each output sample after
            combination. When :obj:`"attn"` mode is used, :obj:`num_heads`
            (int) is needed to be specified for the number of parallel
            attention heads. (default: :obj:`None`)
    """

    def __init__(self, aggrs: List[Union[Aggregation, str]], aggrs_kwargs: Optional[List[Dict[str, Any]]]=None, mode: Optional[str]='cat', mode_kwargs: Optional[Dict[str, Any]]=None):
        super().__init__()
        if not isinstance(aggrs, (list, tuple)):
            raise ValueError(f"'aggrs' of '{self.__class__.__name__}' should be a list or tuple (got '{type(aggrs)}').")
        if len(aggrs) == 0:
            raise ValueError(f"'aggrs' of '{self.__class__.__name__}' should not be empty.")
        if aggrs_kwargs is None:
            aggrs_kwargs = [{}] * len(aggrs)
        elif len(aggrs) != len(aggrs_kwargs):
            raise ValueError(f"'aggrs_kwargs' with invalid length passed to '{self.__class__.__name__}' (got '{len(aggrs_kwargs)}', expected '{len(aggrs)}'). Ensure that both 'aggrs' and 'aggrs_kwargs' are consistent.")
        self.aggrs = torch.nn.ModuleList([aggregation_resolver(aggr, **aggr_kwargs) for aggr, aggr_kwargs in zip(aggrs, aggrs_kwargs)])
        fused_aggrs: List[Aggregation] = []
        self.fused_out_index: List[int] = []
        self.is_fused_aggr: List[bool] = []
        for i, aggr in enumerate(self.aggrs):
            if aggr.__class__ in FusedAggregation.FUSABLE_AGGRS:
                fused_aggrs.append(aggr)
                self.fused_out_index.append(i)
                self.is_fused_aggr.append(True)
            else:
                self.is_fused_aggr.append(False)
        if len(fused_aggrs) > 0:
            self.fused_aggr = FusedAggregation(fused_aggrs)
        else:
            self.fused_aggr = None
        self.mode = mode
        mode_kwargs = copy.copy(mode_kwargs) or {}
        self.in_channels = mode_kwargs.pop('in_channels', None)
        self.out_channels = mode_kwargs.pop('out_channels', None)
        if mode == 'proj' or mode == 'attn':
            if len(aggrs) == 1:
                raise ValueError("Multiple aggregations are required for 'proj' or 'attn' combine mode.")
            if (self.in_channels and self.out_channels) is None:
                raise ValueError(f"Combine mode '{mode}' must have `in_channels` and `out_channels` specified.")
            if isinstance(self.in_channels, int):
                self.in_channels = [self.in_channels] * len(aggrs)
            if mode == 'proj':
                self.lin = Linear(sum(self.in_channels), self.out_channels, **mode_kwargs)
            elif mode == 'attn':
                self.lin_heads = torch.nn.ModuleList([Linear(channels, self.out_channels) for channels in self.in_channels])
                num_heads = mode_kwargs.pop('num_heads', 1)
                self.multihead_attn = MultiheadAttention(self.out_channels, num_heads, **mode_kwargs)
        dense_combine_modes = ['sum', 'mean', 'max', 'min', 'logsumexp', 'std', 'var']
        if mode in dense_combine_modes:
            self.dense_combine = getattr(torch, mode)

    def reset_parameters(self):
        for aggr in self.aggrs:
            aggr.reset_parameters()
        if self.mode == 'proj':
            self.lin.reset_parameters()
        if self.mode == 'attn':
            for lin in self.lin_heads:
                lin.reset_parameters()
            self.multihead_attn._reset_parameters()

    def get_out_channels(self, in_channels: int) ->int:
        if self.out_channels is not None:
            return self.out_channels
        if self.mode == 'cat':
            return in_channels * len(self.aggrs)
        return in_channels

    def forward(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2) ->Tensor:
        if index is None or x.dim() != 2 or self.fused_aggr is None:
            outs = [aggr(x, index, ptr, dim_size, dim) for aggr in self.aggrs]
            return self.combine(outs)
        outs: List[Tensor] = [x] * len(self.aggrs)
        fused_outs = self.fused_aggr(x, index, ptr, dim_size, dim)
        for i, out in zip(self.fused_out_index, fused_outs):
            outs[i] = out
        for i, aggr in enumerate(self.aggrs):
            if not self.is_fused_aggr[i]:
                outs[i] = aggr(x, index, ptr, dim_size, dim)
        return self.combine(outs)

    def combine(self, inputs: List[Tensor]) ->Tensor:
        if len(inputs) == 1:
            return inputs[0]
        if self.mode == 'cat':
            return torch.cat(inputs, dim=-1)
        if hasattr(self, 'lin'):
            return self.lin(torch.cat(inputs, dim=-1))
        if hasattr(self, 'multihead_attn'):
            x = torch.stack([head(x) for x, head in zip(inputs, self.lin_heads)], dim=0)
            attn_out, _ = self.multihead_attn(x, x, x)
            return torch.mean(attn_out, dim=0)
        if hasattr(self, 'dense_combine'):
            out = self.dense_combine(torch.stack(inputs, dim=0), dim=0)
            return out if isinstance(out, Tensor) else out[0]
        raise ValueError(f"Combine mode '{self.mode}' is not supported.")

    def __repr__(self) ->str:
        aggrs = ',\n'.join([f'  {aggr}' for aggr in self.aggrs]) + ',\n'
        return f'{self.__class__.__name__}([\n{aggrs}], mode={self.mode})'


Size = Optional[Tuple[int, int]]


def makedirs(path: str):
    """Recursive directory creation function."""
    try:
        os.makedirs(osp.expanduser(osp.normpath(path)))
    except OSError as e:
        if e.errno != errno.EEXIST and osp.isdir(path):
            raise e


def class_from_module_repr(cls_name, module_repr):
    path = osp.join(gettempdir(), f'{getuser()}_pyg')
    makedirs(path)
    with TempFile(mode='w+', suffix='.py', delete=False, dir=path) as f:
        f.write(module_repr)
    spec = spec_from_file_location(cls_name, f.name)
    mod = module_from_spec(spec)
    sys.modules[cls_name] = mod
    spec.loader.exec_module(mod)
    return getattr(mod, cls_name)


def func_body_repr(func: Callable, keep_annotation: bool=True) ->str:
    source = inspect.getsource(func)
    body_repr = re.split('\\).*?:.*?\\n', source, maxsplit=1)[1]
    if not keep_annotation:
        body_repr = re.sub('\\s*# type:.*\\n', '', body_repr)
    return body_repr


def func_header_repr(func: Callable, keep_annotation: bool=True) ->str:
    source = inspect.getsource(func)
    signature = inspect.signature(func)
    if keep_annotation:
        return ''.join(re.split('(\\).*?:.*?\\n)', source, maxsplit=1)[:2]).strip()
    params_repr = ['self']
    for param in signature.parameters.values():
        params_repr.append(param.name)
        if param.default is not inspect.Parameter.empty:
            params_repr[-1] += f'={param.default}'
    return f"def {func.__name__}({', '.join(params_repr)}):"


def is_torch_sparse_tensor(src: Any) ->bool:
    """Returns :obj:`True` if the input :obj:`src` is a
    :class:`torch.sparse.Tensor` (in any sparse layout).

    Args:
        src (Any): The input object to be checked.
    """
    return isinstance(src, Tensor) and src.is_sparse


def is_sparse(src: Any) ->bool:
    """Returns :obj:`True` if the input :obj:`src` is of type
    :class:`torch.sparse.Tensor` (in any sparse layout) or of type
    :class:`torch_sparse.SparseTensor`.

    Args:
        src (Any): The input object to be checked.
    """
    return is_torch_sparse_tensor(src) or isinstance(src, SparseTensor)


def resolve_types(arg_types: Dict[str, str], return_type_repr: str) ->List[Tuple[List[str], str]]:
    out = []
    for type_repr in arg_types.values():
        if type_repr[:5] == 'Union':
            out.append(split_types_repr(type_repr[6:-1]))
        else:
            out.append([type_repr])
    return [(x, return_type_repr) for x in product(*out)]


OptPairTensor = Tuple[Tensor, Optional[Tensor]]


OptTensor = Optional[Tensor]


def maybe_num_nodes(edge_index, num_nodes=None):
    if num_nodes is not None:
        return num_nodes
    elif isinstance(edge_index, Tensor):
        return int(edge_index.max()) + 1 if edge_index.numel() > 0 else 0
    else:
        return max(edge_index.size(0), edge_index.size(1))


def add_remaining_self_loops(edge_index: Tensor, edge_attr: OptTensor=None, fill_value: Union[float, Tensor, str]=None, num_nodes: Optional[int]=None) ->Tuple[Tensor, OptTensor]:
    """Adds remaining self-loop :math:`(i,i) \\in \\mathcal{E}` to every node
    :math:`i \\in \\mathcal{V}` in the graph given by :attr:`edge_index`.
    In case the graph is weighted or has multi-dimensional edge features
    (:obj:`edge_attr != None`), edge features of non-existing self-loops will
    be added according to :obj:`fill_value`.

    Args:
        edge_index (LongTensor): The edge indices.
        edge_attr (Tensor, optional): Edge weights or multi-dimensional edge
            features. (default: :obj:`None`)
        fill_value (float or Tensor or str, optional): The way to generate
            edge features of self-loops (in case :obj:`edge_attr != None`).
            If given as :obj:`float` or :class:`torch.Tensor`, edge features of
            self-loops will be directly given by :obj:`fill_value`.
            If given as :obj:`str`, edge features of self-loops are computed by
            aggregating all features of edges that point to the specific node,
            according to a reduce operation. (:obj:`"add"`, :obj:`"mean"`,
            :obj:`"min"`, :obj:`"max"`, :obj:`"mul"`). (default: :obj:`1.`)
        num_nodes (int, optional): The number of nodes, *i.e.*
            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)

    :rtype: (:class:`LongTensor`, :class:`Tensor`)

    Example:

        >>> edge_index = torch.tensor([[0, 1],
        ...                            [1, 0]])
        >>> edge_weight = torch.tensor([0.5, 0.5])
        >>> add_remaining_self_loops(edge_index, edge_weight)
        (tensor([[0, 1, 0, 1],
                [1, 0, 0, 1]]),
        tensor([0.5000, 0.5000, 1.0000, 1.0000]))
    """
    N = maybe_num_nodes(edge_index, num_nodes)
    mask = edge_index[0] != edge_index[1]
    loop_index = torch.arange(0, N, dtype=torch.long, device=edge_index.device)
    loop_index = loop_index.unsqueeze(0).repeat(2, 1)
    if edge_attr is not None:
        if fill_value is None:
            loop_attr = edge_attr.new_full((N,) + edge_attr.size()[1:], 1.0)
        elif isinstance(fill_value, (int, float)):
            loop_attr = edge_attr.new_full((N,) + edge_attr.size()[1:], fill_value)
        elif isinstance(fill_value, Tensor):
            loop_attr = fill_value
            if edge_attr.dim() != loop_attr.dim():
                loop_attr = loop_attr.unsqueeze(0)
            sizes = [N] + [1] * (loop_attr.dim() - 1)
            loop_attr = loop_attr.repeat(*sizes)
        elif isinstance(fill_value, str):
            loop_attr = scatter(edge_attr, edge_index[1], dim=0, dim_size=N, reduce=fill_value)
        else:
            raise AttributeError("No valid 'fill_value' provided")
        inv_mask = ~mask
        loop_attr[edge_index[0][inv_mask]] = edge_attr[inv_mask]
        edge_attr = torch.cat([edge_attr[mask], loop_attr], dim=0)
    edge_index = torch.cat([edge_index[:, mask], loop_index], dim=1)
    return edge_index, edge_attr


def to_torch_coo_tensor(edge_index: Tensor, edge_attr: Optional[Tensor]=None, size: Optional[Union[int, Tuple[int, int]]]=None) ->Tensor:
    """Converts a sparse adjacency matrix defined by edge indices and edge
    attributes to a :class:`torch.sparse.Tensor`.

    Args:
        edge_index (LongTensor): The edge indices.
        edge_attr (Tensor, optional): The edge attributes.
            (default: :obj:`None`)
        size (int or (int, int), optional): The size of the sparse matrix.
            If given as an integer, will create a quadratic sparse matrix.
            If set to :obj:`None`, will infer a quadratic sparse matrix based
            on :obj:`edge_index.max() + 1`. (default: :obj:`None`)

    :rtype: :class:`torch.sparse.FloatTensor`

    Example:

        >>> edge_index = torch.tensor([[0, 1, 1, 2, 2, 3],
        ...                            [1, 0, 2, 1, 3, 2]])
        >>> to_torch_coo_tensor(edge_index)
        tensor(indices=tensor([[0, 1, 1, 2, 2, 3],
                            [1, 0, 2, 1, 3, 2]]),
            values=tensor([1., 1., 1., 1., 1., 1.]),
            size=(4, 4), nnz=6, layout=torch.sparse_coo)

    """
    if size is None:
        size = int(edge_index.max()) + 1
    if not isinstance(size, (tuple, list)):
        size = size, size
    if edge_attr is None:
        edge_attr = torch.ones(edge_index.size(1), device=edge_index.device)
    size = tuple(size) + edge_attr.size()[1:]
    out = torch.sparse_coo_tensor(edge_index, edge_attr, size, device=edge_index.device)
    out = out.coalesce()
    return out


def gcn_norm(edge_index, edge_weight=None, num_nodes=None, improved=False, add_self_loops=True, flow='source_to_target', dtype=None):
    fill_value = 2.0 if improved else 1.0
    if isinstance(edge_index, SparseTensor):
        assert flow == 'source_to_target'
        adj_t = edge_index
        if not adj_t.has_value():
            adj_t = adj_t.fill_value(1.0, dtype=dtype)
        if add_self_loops:
            adj_t = fill_diag(adj_t, fill_value)
        deg = sparsesum(adj_t, dim=1)
        deg_inv_sqrt = deg.pow_(-0.5)
        deg_inv_sqrt.masked_fill_(deg_inv_sqrt == float('inf'), 0.0)
        adj_t = mul(adj_t, deg_inv_sqrt.view(-1, 1))
        adj_t = mul(adj_t, deg_inv_sqrt.view(1, -1))
        return adj_t
    is_sparse_tensor = is_torch_sparse_tensor(edge_index)
    if is_sparse_tensor:
        assert flow == 'source_to_target'
        flow = 'target_to_source'
        adj_t = edge_index
        num_nodes = adj_t.size(0)
        edge_index = adj_t._indices()
        edge_weight = adj_t._values()
    else:
        assert flow in ['source_to_target', 'target_to_source']
        num_nodes = maybe_num_nodes(edge_index, num_nodes)
        if edge_weight is None:
            edge_weight = torch.ones((edge_index.size(1),), dtype=dtype, device=edge_index.device)
    if add_self_loops:
        edge_index, tmp_edge_weight = add_remaining_self_loops(edge_index, edge_weight, fill_value, num_nodes)
        assert tmp_edge_weight is not None
        edge_weight = tmp_edge_weight
    row, col = edge_index[0], edge_index[1]
    idx = col if flow == 'source_to_target' else row
    deg = scatter(edge_weight, idx, dim=0, dim_size=num_nodes, reduce='sum')
    deg_inv_sqrt = deg.pow_(-0.5)
    deg_inv_sqrt.masked_fill_(deg_inv_sqrt == float('inf'), 0)
    edge_weight = deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]
    if is_sparse_tensor:
        adj_t = to_torch_coo_tensor(edge_index, edge_weight, size=num_nodes)
        return adj_t, None
    else:
        return edge_index, edge_weight


def constant(value: Any, fill_value: float):
    if isinstance(value, Tensor):
        value.data.fill_(fill_value)
    else:
        for v in (value.parameters() if hasattr(value, 'parameters') else []):
            constant(v, fill_value)
        for v in (value.buffers() if hasattr(value, 'buffers') else []):
            constant(v, fill_value)


def zeros(value: Any):
    constant(value, 0.0)


class Net(torch.nn.Module):

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv1 = GCNConv(in_channels, out_channels)
        self.conv2 = GCNConv(out_channels, out_channels)

    def forward(self, x, edge_index):
        x = torch.nn.functional.relu(self.conv1(x, edge_index))
        x = self.conv2(x, edge_index)
        return x


PairTensor = Tuple[Tensor, Tensor]


FeatureTensorType = Union[Tensor, np.ndarray]


def index_select(value: FeatureTensorType, index: Tensor, dim: int=0) ->Tensor:
    index = index
    if isinstance(value, Tensor):
        out: Optional[Tensor] = None
        if torch.utils.data.get_worker_info() is not None:
            size = list(value.shape)
            size[dim] = index.numel()
            numel = math.prod(size)
            storage = value.storage()._new_shared(numel)
            out = value.new(storage).view(size)
        return torch.index_select(value, dim, index, out=out)
    elif isinstance(value, np.ndarray):
        return torch.from_numpy(np.take(value, index, axis=dim))
    raise ValueError(f"Encountered invalid feature tensor type (got '{type(value)}')")


def softmax(src: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, num_nodes: Optional[int]=None, dim: int=0) ->Tensor:
    """Computes a sparsely evaluated softmax.
    Given a value tensor :attr:`src`, this function first groups the values
    along the first dimension based on the indices specified in :attr:`index`,
    and then proceeds to compute the softmax individually for each group.

    Args:
        src (Tensor): The source tensor.
        index (LongTensor, optional): The indices of elements for applying the
            softmax. (default: :obj:`None`)
        ptr (LongTensor, optional): If given, computes the softmax based on
            sorted inputs in CSR representation. (default: :obj:`None`)
        num_nodes (int, optional): The number of nodes, *i.e.*
            :obj:`max_val + 1` of :attr:`index`. (default: :obj:`None`)
        dim (int, optional): The dimension in which to normalize.
            (default: :obj:`0`)

    :rtype: :class:`Tensor`

    Examples:

        >>> src = torch.tensor([1., 1., 1., 1.])
        >>> index = torch.tensor([0, 0, 1, 2])
        >>> ptr = torch.tensor([0, 2, 3, 4])
        >>> softmax(src, index)
        tensor([0.5000, 0.5000, 1.0000, 1.0000])

        >>> softmax(src, None, ptr)
        tensor([0.5000, 0.5000, 1.0000, 1.0000])

        >>> src = torch.randn(4, 4)
        >>> ptr = torch.tensor([0, 4])
        >>> softmax(src, index, dim=-1)
        tensor([[0.7404, 0.2596, 1.0000, 1.0000],
                [0.1702, 0.8298, 1.0000, 1.0000],
                [0.7607, 0.2393, 1.0000, 1.0000],
                [0.8062, 0.1938, 1.0000, 1.0000]])
    """
    if ptr is not None:
        dim = dim + src.dim() if dim < 0 else dim
        size = [1] * dim + [-1]
        ptr = ptr.view(size)
        with torch.no_grad():
            src_max = segment_csr(src, ptr, reduce='max')
            src_max = gather_csr(src_max, ptr)
        out = (src - src_max).exp()
        out_sum = segment_csr(out, ptr, reduce='sum') + 1e-16
        out_sum = gather_csr(out_sum, ptr)
    elif index is not None:
        N = maybe_num_nodes(index, num_nodes)
        with torch.no_grad():
            src_max = scatter(src, index, dim, dim_size=N, reduce='max')
        if torch_geometric.typing.WITH_PYG_LIB and src.dim() == 2 and (dim == 0 or dim == -2):
            out = pyg_lib.ops.sampled_sub(src, src_max, right_index=index)
        else:
            out = src - src_max.index_select(dim, index)
        out = out.exp()
        out_sum = scatter(out, index, dim, dim_size=N, reduce='sum') + 1e-16
        out_sum = out_sum.index_select(dim, index)
    else:
        raise NotImplementedError
    return out / out_sum


def topk(x: Tensor, ratio: Optional[Union[float, int]], batch: Tensor, min_score: Optional[float]=None, tol: float=1e-07) ->Tensor:
    if min_score is not None:
        scores_max = scatter_max(x, batch)[0].index_select(0, batch) - tol
        scores_min = scores_max.clamp(max=min_score)
        perm = (x > scores_min).nonzero().view(-1)
    elif ratio is not None:
        num_nodes = scatter_add(batch.new_ones(x.size(0)), batch, dim=0)
        batch_size, max_num_nodes = num_nodes.size(0), int(num_nodes.max())
        cum_num_nodes = torch.cat([num_nodes.new_zeros(1), num_nodes.cumsum(dim=0)[:-1]], dim=0)
        index = torch.arange(batch.size(0), dtype=torch.long, device=x.device)
        index = index - cum_num_nodes[batch] + batch * max_num_nodes
        dense_x = x.new_full((batch_size * max_num_nodes,), -60000.0)
        dense_x[index] = x
        dense_x = dense_x.view(batch_size, max_num_nodes)
        _, perm = dense_x.sort(dim=-1, descending=True)
        perm = perm + cum_num_nodes.view(-1, 1)
        perm = perm.view(-1)
        if ratio >= 1:
            k = num_nodes.new_full((num_nodes.size(0),), int(ratio))
            k = torch.min(k, num_nodes)
        else:
            k = (float(ratio) * num_nodes.to(x.dtype)).ceil()
        if isinstance(ratio, int) and (k == ratio).all():
            index = torch.arange(batch_size, device=x.device) * max_num_nodes
            index = index.view(-1, 1).repeat(1, ratio).view(-1)
            index += torch.arange(ratio, device=x.device).repeat(batch_size)
        else:
            index = torch.cat([(torch.arange(k[i], device=x.device) + i * max_num_nodes) for i in range(batch_size)], dim=0)
        perm = perm[index]
    else:
        raise ValueError("At least one of 'min_score' and 'ratio' parameters must be specified")
    return perm


class ASAPooling(torch.nn.Module):
    """The Adaptive Structure Aware Pooling operator from the
    `"ASAP: Adaptive Structure Aware Pooling for Learning Hierarchical
    Graph Representations" <https://arxiv.org/abs/1911.07979>`_ paper.

    Args:
        in_channels (int): Size of each input sample.
        ratio (float or int): Graph pooling ratio, which is used to compute
            :math:`k = \\lceil \\mathrm{ratio} \\cdot N \\rceil`, or the value
            of :math:`k` itself, depending on whether the type of :obj:`ratio`
            is :obj:`float` or :obj:`int`. (default: :obj:`0.5`)
        GNN (torch.nn.Module, optional): A graph neural network layer for
            using intra-cluster properties.
            Especially helpful for graphs with higher degree of neighborhood
            (one of :class:`torch_geometric.nn.conv.GraphConv`,
            :class:`torch_geometric.nn.conv.GCNConv` or
            any GNN which supports the :obj:`edge_weight` parameter).
            (default: :obj:`None`)
        dropout (float, optional): Dropout probability of the normalized
            attention coefficients which exposes each node to a stochastically
            sampled neighborhood during training. (default: :obj:`0`)
        negative_slope (float, optional): LeakyReLU angle of the negative
            slope. (default: :obj:`0.2`)
        add_self_loops (bool, optional): If set to :obj:`True`, will add self
            loops to the new graph connectivity. (default: :obj:`False`)
        **kwargs (optional): Additional parameters for initializing the
            graph neural network layer.

    Returns:
        A tuple of tensors containing

            - **x** (*Tensor*): The pooled node embeddings.
            - **edge_index** (*Tensor*): The coarsened graph connectivity.
            - **edge_weight** (*Tensor*): The edge weights corresponding to the
              coarsened graph connectivity.
            - **batch** (*Tensor*): The pooled :obj:`batch` vector.
            - **perm** (*Tensor*): The top-:math:`k` node indices of nodes
              which are kept after pooling.
    """

    def __init__(self, in_channels: int, ratio: Union[float, int]=0.5, GNN: Optional[Callable]=None, dropout: float=0.0, negative_slope: float=0.2, add_self_loops: bool=False, **kwargs):
        super().__init__()
        self.in_channels = in_channels
        self.ratio = ratio
        self.negative_slope = negative_slope
        self.dropout = dropout
        self.GNN = GNN
        self.add_self_loops = add_self_loops
        self.lin = Linear(in_channels, in_channels)
        self.att = Linear(2 * in_channels, 1)
        self.gnn_score = LEConv(self.in_channels, 1)
        if self.GNN is not None:
            self.gnn_intra_cluster = GNN(self.in_channels, self.in_channels, **kwargs)
        else:
            self.gnn_intra_cluster = None
        self.reset_parameters()

    def reset_parameters(self):
        self.lin.reset_parameters()
        self.att.reset_parameters()
        self.gnn_score.reset_parameters()
        if self.gnn_intra_cluster is not None:
            self.gnn_intra_cluster.reset_parameters()

    def forward(self, x: Tensor, edge_index: Tensor, edge_weight: Optional[Tensor]=None, batch: Optional[Tensor]=None) ->Tuple[Tensor, Tensor, Optional[Tensor], Tensor, Tensor]:
        """"""
        N = x.size(0)
        edge_index, edge_weight = add_remaining_self_loops(edge_index, edge_weight, fill_value=1.0, num_nodes=N)
        if batch is None:
            batch = edge_index.new_zeros(x.size(0))
        x = x.unsqueeze(-1) if x.dim() == 1 else x
        x_pool = x
        if self.gnn_intra_cluster is not None:
            x_pool = self.gnn_intra_cluster(x=x, edge_index=edge_index, edge_weight=edge_weight)
        x_pool_j = x_pool[edge_index[0]]
        x_q = scatter(x_pool_j, edge_index[1], dim=0, reduce='max')
        x_q = self.lin(x_q)[edge_index[1]]
        score = self.att(torch.cat([x_q, x_pool_j], dim=-1)).view(-1)
        score = F.leaky_relu(score, self.negative_slope)
        score = softmax(score, edge_index[1], num_nodes=N)
        score = F.dropout(score, p=self.dropout, training=self.training)
        v_j = x[edge_index[0]] * score.view(-1, 1)
        x = scatter(v_j, edge_index[1], dim=0, reduce='add')
        fitness = self.gnn_score(x, edge_index).sigmoid().view(-1)
        perm = topk(fitness, self.ratio, batch)
        x = x[perm] * fitness[perm].view(-1, 1)
        batch = batch[perm]
        row, col = edge_index[0], edge_index[1]
        A = SparseTensor(row=row, col=col, value=edge_weight, sparse_sizes=(N, N))
        S = SparseTensor(row=row, col=col, value=score, sparse_sizes=(N, N))
        S = index_select(S, 1, perm)
        A = matmul(matmul(transpose(S), A), S)
        if self.add_self_loops:
            A = fill_diag(A, 1.0)
        else:
            A = remove_diag(A)
        row, col, edge_weight = A.coo()
        edge_index = torch.stack([row, col], dim=0)
        return x, edge_index, edge_weight, batch, perm

    @torch.jit.unused
    def jittable(self) ->'ASAPooling':
        out = copy.deepcopy(self)
        out.gnn_score = out.gnn_score.jittable()
        if out.gnn_intra_cluster is not None:
            out.gnn_intra_cluster = out.gnn_intra_cluster.jittable()
        return out

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}({self.in_channels}, ratio={self.ratio})'


class JumpingKnowledge(torch.nn.Module):
    """The Jumping Knowledge layer aggregation module from the
    `"Representation Learning on Graphs with Jumping Knowledge Networks"
    <https://arxiv.org/abs/1806.03536>`_ paper based on either
    **concatenation** (:obj:`"cat"`)

    .. math::

        \\mathbf{x}_v^{(1)} \\, \\Vert \\, \\ldots \\, \\Vert \\, \\mathbf{x}_v^{(T)}

    **max pooling** (:obj:`"max"`)

    .. math::

        \\max \\left( \\mathbf{x}_v^{(1)}, \\ldots, \\mathbf{x}_v^{(T)} \\right)

    or **weighted summation**

    .. math::

        \\sum_{t=1}^T \\alpha_v^{(t)} \\mathbf{x}_v^{(t)}

    with attention scores :math:`\\alpha_v^{(t)}` obtained from a bi-directional
    LSTM (:obj:`"lstm"`).

    Args:
        mode (string): The aggregation scheme to use
            (:obj:`"cat"`, :obj:`"max"` or :obj:`"lstm"`).
        channels (int, optional): The number of channels per representation.
            Needs to be only set for LSTM-style aggregation.
            (default: :obj:`None`)
        num_layers (int, optional): The number of layers to aggregate. Needs to
            be only set for LSTM-style aggregation. (default: :obj:`None`)
    """

    def __init__(self, mode: str, channels: Optional[int]=None, num_layers: Optional[int]=None):
        super().__init__()
        self.mode = mode.lower()
        assert self.mode in ['cat', 'max', 'lstm']
        if mode == 'lstm':
            assert channels is not None, 'channels cannot be None for lstm'
            assert num_layers is not None, 'num_layers cannot be None for lstm'
            self.lstm = LSTM(channels, num_layers * channels // 2, bidirectional=True, batch_first=True)
            self.att = Linear(2 * (num_layers * channels // 2), 1)
            self.channels = channels
            self.num_layers = num_layers
        else:
            self.lstm = None
            self.att = None
            self.channels = None
            self.num_layers = None
        self.reset_parameters()

    def reset_parameters(self):
        if self.lstm is not None:
            self.lstm.reset_parameters()
        if self.att is not None:
            self.att.reset_parameters()

    def forward(self, xs: List[Tensor]) ->Tensor:
        """Aggregates representations across different layers.

        Args:
            xs (List[Tensor]): List containing layer-wise representations.
        """
        if self.mode == 'cat':
            return torch.cat(xs, dim=-1)
        elif self.mode == 'max':
            return torch.stack(xs, dim=-1).max(dim=-1)[0]
        else:
            assert self.lstm is not None and self.att is not None
            x = torch.stack(xs, dim=1)
            alpha, _ = self.lstm(x)
            alpha = self.att(alpha).squeeze(-1)
            alpha = torch.softmax(alpha, dim=-1)
            return (x * alpha.unsqueeze(-1)).sum(dim=1)

    def __repr__(self) ->str:
        if self.mode == 'lstm':
            return f'{self.__class__.__name__}({self.mode}, channels={self.channels}, layers={self.num_layers})'
        return f'{self.__class__.__name__}({self.mode})'


def global_mean_pool(x: Tensor, batch: Optional[Tensor], size: Optional[int]=None) ->Tensor:
    """Returns batch-wise graph-level-outputs by averaging node features
    across the node dimension, so that for a single graph
    :math:`\\mathcal{G}_i` its output is computed by

    .. math::
        \\mathbf{r}_i = \\frac{1}{N_i} \\sum_{n=1}^{N_i} \\mathbf{x}_n.

    Functional method of the
    :class:`~torch_geometric.nn.aggr.MeanAggregation` module.

    Args:
        x (Tensor): Node feature matrix
            :math:`\\mathbf{X} \\in \\mathbb{R}^{(N_1 + \\ldots + N_B) \\times F}`.
        batch (LongTensor, optional): Batch vector
            :math:`\\mathbf{b} \\in {\\{ 0, \\ldots, B-1\\}}^N`, which assigns each
            node to a specific example.
        size (int, optional): Batch-size :math:`B`.
            Automatically calculated if not given. (default: :obj:`None`)
    """
    if batch is None:
        return x.mean(dim=-2, keepdim=x.dim() == 2)
    size = int(batch.max().item() + 1) if size is None else size
    return scatter(x, batch, dim=-2, dim_size=size, reduce='mean')


class ASAP(torch.nn.Module):

    def __init__(self, dataset, num_layers, hidden, ratio=0.8, dropout=0):
        super().__init__()
        self.conv1 = GraphConv(dataset.num_features, hidden, aggr='mean')
        self.convs = torch.nn.ModuleList()
        self.pools = torch.nn.ModuleList()
        self.convs.extend([GraphConv(hidden, hidden, aggr='mean') for i in range(num_layers - 1)])
        self.pools.extend([ASAPooling(hidden, ratio, dropout=dropout) for i in range(num_layers // 2)])
        self.jump = JumpingKnowledge(mode='cat')
        self.lin1 = Linear(num_layers * hidden, hidden)
        self.lin2 = Linear(hidden, dataset.num_classes)

    def reset_parameters(self):
        self.conv1.reset_parameters()
        for conv in self.convs:
            conv.reset_parameters()
        for pool in self.pools:
            pool.reset_parameters()
        self.lin1.reset_parameters()
        self.lin2.reset_parameters()

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
        edge_weight = None
        x = F.relu(self.conv1(x, edge_index))
        xs = [global_mean_pool(x, batch)]
        for i, conv in enumerate(self.convs):
            x = conv(x=x, edge_index=edge_index, edge_weight=edge_weight)
            x = F.relu(x)
            xs += [global_mean_pool(x, batch)]
            if i % 2 == 0 and i < len(self.convs) - 1:
                pool = self.pools[i // 2]
                x, edge_index, edge_weight, batch, _ = pool(x=x, edge_index=edge_index, edge_weight=edge_weight, batch=batch)
        x = self.jump(xs)
        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin2(x)
        return F.log_softmax(x, dim=-1)

    def __repr__(self):
        return self.__class__.__name__


class DenseSAGEConv(torch.nn.Module):
    """See :class:`torch_geometric.nn.conv.SAGEConv`.

    .. note::

        :class:`~torch_geometric.nn.dense.DenseSAGEConv` expects to work on
        binary adjacency matrices.
        If you want to make use of weighted dense adjacency matrices, please
        use :class:`torch_geometric.nn.dense.DenseGraphConv` instead.

    """

    def __init__(self, in_channels: int, out_channels: int, normalize: bool=False, bias: bool=True):
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.normalize = normalize
        self.lin_rel = Linear(in_channels, out_channels, bias=False)
        self.lin_root = Linear(in_channels, out_channels, bias=bias)
        self.reset_parameters()

    def reset_parameters(self):
        self.lin_rel.reset_parameters()
        self.lin_root.reset_parameters()

    def forward(self, x: Tensor, adj: Tensor, mask: OptTensor=None) ->Tensor:
        """
        Args:
            x (Tensor): Node feature tensor :math:`\\mathbf{X} \\in \\mathbb{R}^{B
                \\times N \\times F}`, with batch-size :math:`B`, (maximum)
                number of nodes :math:`N` for each graph, and feature
                dimension :math:`F`.
            adj (Tensor): Adjacency tensor :math:`\\mathbf{A} \\in \\mathbb{R}^{B
                \\times N \\times N}`. The adjacency tensor is broadcastable in
                the batch dimension, resulting in a shared adjacency matrix for
                the complete batch.
            mask (BoolTensor, optional): Mask matrix
                :math:`\\mathbf{M} \\in {\\{ 0, 1 \\}}^{B \\times N}` indicating
                the valid nodes for each graph. (default: :obj:`None`)
        """
        x = x.unsqueeze(0) if x.dim() == 2 else x
        adj = adj.unsqueeze(0) if adj.dim() == 2 else adj
        B, N, _ = adj.size()
        out = torch.matmul(adj, x)
        out = out / adj.sum(dim=-1, keepdim=True).clamp(min=1)
        out = self.lin_rel(out) + self.lin_root(x)
        if self.normalize:
            out = F.normalize(out, p=2.0, dim=-1)
        if mask is not None:
            out = out * mask.view(B, N, 1)
        return out

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}({self.in_channels}, {self.out_channels})'


class Block(torch.nn.Module):

    def __init__(self, in_channels, hidden_channels, out_channels, mode='cat'):
        super().__init__()
        self.conv1 = DenseSAGEConv(in_channels, hidden_channels)
        self.conv2 = DenseSAGEConv(hidden_channels, out_channels)
        self.jump = JumpingKnowledge(mode)
        if mode == 'cat':
            self.lin = Linear(hidden_channels + out_channels, out_channels)
        else:
            self.lin = Linear(out_channels, out_channels)

    def reset_parameters(self):
        self.conv1.reset_parameters()
        self.conv2.reset_parameters()
        self.lin.reset_parameters()

    def forward(self, x, adj, mask=None):
        x1 = F.relu(self.conv1(x, adj, mask))
        x2 = F.relu(self.conv2(x1, adj, mask))
        return self.lin(self.jump([x1, x2]))


def dense_diff_pool(x: Tensor, adj: Tensor, s: Tensor, mask: Optional[Tensor]=None, normalize: bool=True) ->Tuple[Tensor, Tensor, Tensor, Tensor]:
    """The differentiable pooling operator from the `"Hierarchical Graph
    Representation Learning with Differentiable Pooling"
    <https://arxiv.org/abs/1806.08804>`_ paper

    .. math::
        \\mathbf{X}^{\\prime} &= {\\mathrm{softmax}(\\mathbf{S})}^{\\top} \\cdot
        \\mathbf{X}

        \\mathbf{A}^{\\prime} &= {\\mathrm{softmax}(\\mathbf{S})}^{\\top} \\cdot
        \\mathbf{A} \\cdot \\mathrm{softmax}(\\mathbf{S})

    based on dense learned assignments :math:`\\mathbf{S} \\in \\mathbb{R}^{B
    \\times N \\times C}`.
    Returns the pooled node feature matrix, the coarsened adjacency matrix and
    two auxiliary objectives: (1) The link prediction loss

    .. math::
        \\mathcal{L}_{LP} = {\\| \\mathbf{A} -
        \\mathrm{softmax}(\\mathbf{S}) {\\mathrm{softmax}(\\mathbf{S})}^{\\top}
        \\|}_F,

    and (2) the entropy regularization

    .. math::
        \\mathcal{L}_E = \\frac{1}{N} \\sum_{n=1}^N H(\\mathbf{S}_n).

    Args:
        x (Tensor): Node feature tensor :math:`\\mathbf{X} \\in \\mathbb{R}^{B
            \\times N \\times F}` with batch-size :math:`B`, (maximum)
            number of nodes :math:`N` for each graph, and feature dimension
            :math:`F`.
        adj (Tensor): Adjacency tensor :math:`\\mathbf{A} \\in \\mathbb{R}^{B
            \\times N \\times N}`.
        s (Tensor): Assignment tensor :math:`\\mathbf{S} \\in \\mathbb{R}^{B
            \\times N \\times C}` with number of clusters :math:`C`. The softmax
            does not have to be applied beforehand, since it is executed
            within this method.
        mask (BoolTensor, optional): Mask matrix
            :math:`\\mathbf{M} \\in {\\{ 0, 1 \\}}^{B \\times N}` indicating
            the valid nodes for each graph. (default: :obj:`None`)
        normalize (bool, optional): If set to :obj:`False`, the link
            prediction loss is not divided by :obj:`adj.numel()`.
            (default: :obj:`True`)

    :rtype: (:class:`Tensor`, :class:`Tensor`, :class:`Tensor`,
        :class:`Tensor`)
    """
    x = x.unsqueeze(0) if x.dim() == 2 else x
    adj = adj.unsqueeze(0) if adj.dim() == 2 else adj
    s = s.unsqueeze(0) if s.dim() == 2 else s
    batch_size, num_nodes, _ = x.size()
    s = torch.softmax(s, dim=-1)
    if mask is not None:
        mask = mask.view(batch_size, num_nodes, 1)
        x, s = x * mask, s * mask
    out = torch.matmul(s.transpose(1, 2), x)
    out_adj = torch.matmul(torch.matmul(s.transpose(1, 2), adj), s)
    link_loss = adj - torch.matmul(s, s.transpose(1, 2))
    link_loss = torch.norm(link_loss, p=2)
    if normalize is True:
        link_loss = link_loss / adj.numel()
    ent_loss = (-s * torch.log(s + 1e-15)).sum(dim=-1).mean()
    return out, out_adj, link_loss, ent_loss


class DiffPool(torch.nn.Module):

    def __init__(self, dataset, num_layers, hidden, ratio=0.25):
        super().__init__()
        num_nodes = ceil(ratio * dataset[0].num_nodes)
        self.embed_block1 = Block(dataset.num_features, hidden, hidden)
        self.pool_block1 = Block(dataset.num_features, hidden, num_nodes)
        self.embed_blocks = torch.nn.ModuleList()
        self.pool_blocks = torch.nn.ModuleList()
        for i in range(num_layers // 2 - 1):
            num_nodes = ceil(ratio * num_nodes)
            self.embed_blocks.append(Block(hidden, hidden, hidden))
            self.pool_blocks.append(Block(hidden, hidden, num_nodes))
        self.jump = JumpingKnowledge(mode='cat')
        self.lin1 = Linear((len(self.embed_blocks) + 1) * hidden, hidden)
        self.lin2 = Linear(hidden, dataset.num_classes)

    def reset_parameters(self):
        self.embed_block1.reset_parameters()
        self.pool_block1.reset_parameters()
        for embed_block, pool_block in zip(self.embed_blocks, self.pool_blocks):
            embed_block.reset_parameters()
            pool_block.reset_parameters()
        self.jump.reset_parameters()
        self.lin1.reset_parameters()
        self.lin2.reset_parameters()

    def forward(self, data):
        x, adj, mask = data.x, data.adj, data.mask
        s = self.pool_block1(x, adj, mask)
        x = F.relu(self.embed_block1(x, adj, mask))
        xs = [x.mean(dim=1)]
        x, adj, _, _ = dense_diff_pool(x, adj, s, mask)
        for i, (embed_block, pool_block) in enumerate(zip(self.embed_blocks, self.pool_blocks)):
            s = pool_block(x, adj)
            x = F.relu(embed_block(x, adj))
            xs.append(x.mean(dim=1))
            if i < len(self.embed_blocks) - 1:
                x, adj, _, _ = dense_diff_pool(x, adj, s)
        x = self.jump(xs)
        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin2(x)
        return F.log_softmax(x, dim=-1)

    def __repr__(self):
        return self.__class__.__name__


class UnpoolInfo(NamedTuple):
    edge_index: Tensor
    cluster: Tensor
    batch: Tensor
    new_edge_score: Tensor


def coalesce(edge_index: Tensor, edge_attr: Union[Optional[Tensor], List[Tensor]]=None, num_nodes: Optional[int]=None, reduce: str='add', is_sorted: bool=False, sort_by_row: bool=True) ->Union[Tensor, Tuple[Tensor, Tensor], Tuple[Tensor, List[Tensor]]]:
    """Row-wise sorts :obj:`edge_index` and removes its duplicated entries.
    Duplicate entries in :obj:`edge_attr` are merged by scattering them
    together according to the given :obj:`reduce` option.

    Args:
        edge_index (LongTensor): The edge indices.
        edge_attr (Tensor or List[Tensor], optional): Edge weights or multi-
            dimensional edge features.
            If given as a list, will re-shuffle and remove duplicates for all
            its entries. (default: :obj:`None`)
        num_nodes (int, optional): The number of nodes, *i.e.*
            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)
        reduce (string, optional): The reduce operation to use for merging edge
            features (:obj:`"add"`, :obj:`"mean"`, :obj:`"min"`, :obj:`"max"`,
            :obj:`"mul"`). (default: :obj:`"add"`)
        is_sorted (bool, optional): If set to :obj:`True`, will expect
            :obj:`edge_index` to be already sorted row-wise.
        sort_by_row (bool, optional): If set to :obj:`False`, will sort
            :obj:`edge_index` column-wise.

    :rtype: :class:`LongTensor` if :attr:`edge_attr` is :obj:`None`, else
        (:class:`LongTensor`, :obj:`Tensor` or :obj:`List[Tensor]]`)

    Example:

        >>> edge_index = torch.tensor([[1, 1, 2, 3],
        ...                            [3, 3, 1, 2]])
        >>> edge_attr = torch.tensor([1., 1., 1., 1.])
        >>> coalesce(edge_index)
        tensor([[1, 2, 3],
                [3, 1, 2]])

        >>> # Sort `edge_index` column-wise
        >>> coalesce(edge_index, sort_by_row=False)
        tensor([[2, 3, 1],
                [1, 2, 3]])

        >>> coalesce(edge_index, edge_attr)
        (tensor([[1, 2, 3],
                [3, 1, 2]]),
        tensor([2., 1., 1.]))

        >>> # Use 'mean' operation to merge edge features
        >>> coalesce(edge_index, edge_attr, reduce='mean')
        (tensor([[1, 2, 3],
                [3, 1, 2]]),
        tensor([1., 1., 1.]))
    """
    nnz = edge_index.size(1)
    num_nodes = maybe_num_nodes(edge_index, num_nodes)
    idx = edge_index.new_empty(nnz + 1)
    idx[0] = -1
    idx[1:] = edge_index[1 - int(sort_by_row)]
    idx[1:].mul_(num_nodes).add_(edge_index[int(sort_by_row)])
    if not is_sorted:
        idx[1:], perm = idx[1:].sort()
        edge_index = edge_index[:, perm]
        if isinstance(edge_attr, Tensor):
            edge_attr = edge_attr[perm]
        elif isinstance(edge_attr, (list, tuple)):
            edge_attr = [e[perm] for e in edge_attr]
    mask = idx[1:] > idx[:-1]
    if mask.all():
        if isinstance(edge_attr, (Tensor, list, tuple)):
            return edge_index, edge_attr
        return edge_index
    edge_index = edge_index[:, mask]
    if edge_attr is None:
        return edge_index
    dim_size = edge_index.size(1)
    idx = torch.arange(0, nnz, device=edge_index.device)
    idx.sub_(mask.logical_not_().cumsum(dim=0))
    if isinstance(edge_attr, Tensor):
        edge_attr = scatter(edge_attr, idx, 0, None, dim_size, reduce)
        return edge_index, edge_attr
    elif isinstance(edge_attr, (list, tuple)):
        edge_attr = [scatter(e, idx, 0, None, dim_size, reduce) for e in edge_attr]
        return edge_index, edge_attr
    return edge_index


class EdgePooling(torch.nn.Module):
    """The edge pooling operator from the `"Towards Graph Pooling by Edge
    Contraction" <https://graphreason.github.io/papers/17.pdf>`_ and
    `"Edge Contraction Pooling for Graph Neural Networks"
    <https://arxiv.org/abs/1905.10990>`_ papers.

    In short, a score is computed for each edge.
    Edges are contracted iteratively according to that score unless one of
    their nodes has already been part of a contracted edge.

    To duplicate the configuration from the "Towards Graph Pooling by Edge
    Contraction" paper, use either
    :func:`EdgePooling.compute_edge_score_softmax`
    or :func:`EdgePooling.compute_edge_score_tanh`, and set
    :obj:`add_to_edge_score` to :obj:`0.0`.

    To duplicate the configuration from the "Edge Contraction Pooling for
    Graph Neural Networks" paper, set :obj:`dropout` to :obj:`0.2`.

    Args:
        in_channels (int): Size of each input sample.
        edge_score_method (function, optional): The function to apply
            to compute the edge score from raw edge scores. By default,
            this is the softmax over all incoming edges for each node.
            This function takes in a :obj:`raw_edge_score` tensor of shape
            :obj:`[num_nodes]`, an :obj:`edge_index` tensor and the number of
            nodes :obj:`num_nodes`, and produces a new tensor of the same size
            as :obj:`raw_edge_score` describing normalized edge scores.
            Included functions are
            :func:`EdgePooling.compute_edge_score_softmax`,
            :func:`EdgePooling.compute_edge_score_tanh`, and
            :func:`EdgePooling.compute_edge_score_sigmoid`.
            (default: :func:`EdgePooling.compute_edge_score_softmax`)
        dropout (float, optional): The probability with
            which to drop edge scores during training. (default: :obj:`0.0`)
        add_to_edge_score (float, optional): This is added to each
            computed edge score. Adding this greatly helps with unpool
            stability. (default: :obj:`0.5`)
    """

    def __init__(self, in_channels: int, edge_score_method: Optional[Callable]=None, dropout: Optional[float]=0.0, add_to_edge_score: float=0.5):
        super().__init__()
        self.in_channels = in_channels
        if edge_score_method is None:
            edge_score_method = self.compute_edge_score_softmax
        self.compute_edge_score = edge_score_method
        self.add_to_edge_score = add_to_edge_score
        self.dropout = dropout
        self.lin = torch.nn.Linear(2 * in_channels, 1)
        self.reset_parameters()

    def reset_parameters(self):
        self.lin.reset_parameters()

    @staticmethod
    def compute_edge_score_softmax(raw_edge_score: Tensor, edge_index: Tensor, num_nodes: int) ->Tensor:
        return softmax(raw_edge_score, edge_index[1], num_nodes=num_nodes)

    @staticmethod
    def compute_edge_score_tanh(raw_edge_score: Tensor, edge_index: Optional[Tensor]=None, num_nodes: Optional[int]=None) ->Tensor:
        return torch.tanh(raw_edge_score)

    @staticmethod
    def compute_edge_score_sigmoid(raw_edge_score: Tensor, edge_index: Optional[Tensor]=None, num_nodes: Optional[int]=None) ->Tensor:
        return torch.sigmoid(raw_edge_score)

    def forward(self, x: Tensor, edge_index: Tensor, batch: Tensor) ->Tuple[Tensor, Tensor, Tensor, UnpoolInfo]:
        """Forward computation which computes the raw edge score, normalizes
        it, and merges the edges.

        Args:
            x (Tensor): The node features.
            edge_index (LongTensor): The edge indices.
            batch (LongTensor): Batch vector
                :math:`\\mathbf{b} \\in {\\{ 0, \\ldots, B-1\\}}^N`, which assigns
                each node to a specific example.

        Return types:
            * **x** *(Tensor)* - The pooled node features.
            * **edge_index** *(LongTensor)* - The coarsened edge indices.
            * **batch** *(LongTensor)* - The coarsened batch vector.
            * **unpool_info** *(UnpoolInfo)* - Information that is
              consumed by :func:`EdgePooling.unpool` for unpooling.
        """
        e = torch.cat([x[edge_index[0]], x[edge_index[1]]], dim=-1)
        e = self.lin(e).view(-1)
        e = F.dropout(e, p=self.dropout, training=self.training)
        e = self.compute_edge_score(e, edge_index, x.size(0))
        e = e + self.add_to_edge_score
        x, edge_index, batch, unpool_info = self.__merge_edges__(x, edge_index, batch, e)
        return x, edge_index, batch, unpool_info

    def __merge_edges__(self, x: Tensor, edge_index: Tensor, batch: Tensor, edge_score: Tensor) ->Tuple[Tensor, Tensor, Tensor, UnpoolInfo]:
        cluster = torch.empty_like(batch)
        perm: List[int] = torch.argsort(edge_score, descending=True).tolist()
        mask = torch.ones(x.size(0), dtype=torch.bool)
        i = 0
        new_edge_indices: List[int] = []
        edge_index_cpu = edge_index.cpu()
        for edge_idx in perm:
            source = int(edge_index_cpu[0, edge_idx])
            if not bool(mask[source]):
                continue
            target = int(edge_index_cpu[1, edge_idx])
            if not bool(mask[target]):
                continue
            new_edge_indices.append(edge_idx)
            cluster[source] = i
            mask[source] = False
            if source != target:
                cluster[target] = i
                mask[target] = False
            i += 1
        j = int(mask.sum())
        cluster[mask] = torch.arange(i, i + j, device=x.device)
        i += j
        new_x = scatter_add(x, cluster, dim=0, dim_size=i)
        new_edge_score = edge_score[new_edge_indices]
        if int(mask.sum()) > 0:
            remaining_score = x.new_ones((new_x.size(0) - len(new_edge_indices),))
            new_edge_score = torch.cat([new_edge_score, remaining_score])
        new_x = new_x * new_edge_score.view(-1, 1)
        new_edge_index = coalesce(cluster[edge_index], num_nodes=new_x.size(0))
        new_batch = x.new_empty(new_x.size(0), dtype=torch.long)
        new_batch = new_batch.scatter_(0, cluster, batch)
        unpool_info = UnpoolInfo(edge_index=edge_index, cluster=cluster, batch=batch, new_edge_score=new_edge_score)
        return new_x, new_edge_index, new_batch, unpool_info

    def unpool(self, x: Tensor, unpool_info: UnpoolInfo) ->Tuple[Tensor, Tensor, Tensor]:
        """Unpools a previous edge pooling step.

        For unpooling, :obj:`x` should be of same shape as those produced by
        this layer's :func:`forward` function. Then, it will produce an
        unpooled :obj:`x` in addition to :obj:`edge_index` and :obj:`batch`.

        Args:
            x (Tensor): The node features.
            unpool_info (UnpoolInfo): Information that has
                been produced by :func:`EdgePooling.forward`.

        Return types:
            * **x** *(Tensor)* - The unpooled node features.
            * **edge_index** *(LongTensor)* - The new edge indices.
            * **batch** *(LongTensor)* - The new batch vector.
        """
        new_x = x / unpool_info.new_edge_score.view(-1, 1)
        new_x = new_x[unpool_info.cluster]
        return new_x, unpool_info.edge_index, unpool_info.batch

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}({self.in_channels})'


class EdgePool(torch.nn.Module):

    def __init__(self, dataset, num_layers, hidden):
        super().__init__()
        self.conv1 = GraphConv(dataset.num_features, hidden, aggr='mean')
        self.convs = torch.nn.ModuleList()
        self.pools = torch.nn.ModuleList()
        self.convs.extend([GraphConv(hidden, hidden, aggr='mean') for i in range(num_layers - 1)])
        self.pools.extend([EdgePooling(hidden) for i in range(num_layers // 2)])
        self.jump = JumpingKnowledge(mode='cat')
        self.lin1 = Linear(num_layers * hidden, hidden)
        self.lin2 = Linear(hidden, dataset.num_classes)

    def reset_parameters(self):
        self.conv1.reset_parameters()
        for conv in self.convs:
            conv.reset_parameters()
        for pool in self.pools:
            pool.reset_parameters()
        self.lin1.reset_parameters()
        self.lin2.reset_parameters()

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
        x = F.relu(self.conv1(x, edge_index))
        xs = [global_mean_pool(x, batch)]
        for i, conv in enumerate(self.convs):
            x = F.relu(conv(x, edge_index))
            xs += [global_mean_pool(x, batch)]
            if i % 2 == 0 and i < len(self.convs) - 1:
                pool = self.pools[i // 2]
                x, edge_index, batch, _ = pool(x, edge_index, batch=batch)
        x = self.jump(xs)
        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin2(x)
        return F.log_softmax(x, dim=-1)

    def __repr__(self):
        return self.__class__.__name__


class MappingView(object):

    def __init__(self, mapping: Mapping, *args: List[str]):
        self._mapping = mapping
        self._args = args

    def _keys(self) ->Iterable:
        if len(self._args) == 0:
            return self._mapping.keys()
        else:
            return [arg for arg in self._args if arg in self._mapping]

    def __len__(self) ->int:
        return len(self._keys())

    def __repr__(self) ->str:
        mapping = {key: self._mapping[key] for key in self._keys()}
        return f'{self.__class__.__name__}({mapping})'
    __class_getitem__ = classmethod(type([]))


class ItemsView(MappingView):

    def __iter__(self):
        for key in self._keys():
            yield key, self._mapping[key]


class KeysView(MappingView):

    def __iter__(self) ->Iterable:
        yield from self._keys()


class ValuesView(MappingView):

    def __iter__(self) ->Iterable:
        for key in self._keys():
            yield self._mapping[key]


def recursive_apply(data: Any, func: Callable) ->Any:
    if isinstance(data, Tensor):
        return func(data)
    elif isinstance(data, torch.nn.utils.rnn.PackedSequence):
        return func(data)
    elif isinstance(data, tuple) and hasattr(data, '_fields'):
        return type(data)(*(recursive_apply(d, func) for d in data))
    elif isinstance(data, Sequence) and not isinstance(data, str):
        return [recursive_apply(d, func) for d in data]
    elif isinstance(data, Mapping):
        return {key: recursive_apply(data[key], func) for key in data}
    else:
        try:
            return func(data)
        except:
            return data


def recursive_apply_(data: Any, func: Callable):
    if isinstance(data, Tensor):
        func(data)
    elif isinstance(data, tuple) and hasattr(data, '_fields'):
        for value in data:
            recursive_apply_(value, func)
    elif isinstance(data, Sequence) and not isinstance(data, str):
        for value in data:
            recursive_apply_(value, func)
    elif isinstance(data, Mapping):
        for value in data.values():
            recursive_apply_(value, func)
    else:
        try:
            func(data)
        except:
            pass


class BaseStorage(MutableMapping):

    def __init__(self, _mapping: Optional[Dict[str, Any]]=None, **kwargs):
        super().__init__()
        self._mapping = {}
        for key, value in (_mapping or {}).items():
            setattr(self, key, value)
        for key, value in kwargs.items():
            setattr(self, key, value)

    @property
    def _key(self) ->Any:
        return None

    def __len__(self) ->int:
        return len(self._mapping)

    def __getattr__(self, key: str) ->Any:
        if key == '_mapping':
            self._mapping = {}
            return self._mapping
        try:
            return self[key]
        except KeyError:
            raise AttributeError(f"'{self.__class__.__name__}' object has no attribute '{key}'")

    def __setattr__(self, key: str, value: Any):
        propobj = getattr(self.__class__, key, None)
        if propobj is not None and getattr(propobj, 'fset', None) is not None:
            propobj.fset(self, value)
        elif key == '_parent':
            self.__dict__[key] = weakref.ref(value)
        elif key[:1] == '_':
            self.__dict__[key] = value
        else:
            self[key] = value

    def __delattr__(self, key: str):
        if key[:1] == '_':
            del self.__dict__[key]
        else:
            del self[key]

    def __getitem__(self, key: str) ->Any:
        return self._mapping[key]

    def __setitem__(self, key: str, value: Any):
        if value is None and key in self._mapping:
            del self._mapping[key]
        elif value is not None:
            self._mapping[key] = value

    def __delitem__(self, key: str):
        if key in self._mapping:
            del self._mapping[key]

    def __iter__(self) ->Iterable:
        return iter(self._mapping)

    def __copy__(self):
        out = self.__class__.__new__(self.__class__)
        for key, value in self.__dict__.items():
            out.__dict__[key] = value
        out._mapping = copy.copy(out._mapping)
        return out

    def __deepcopy__(self, memo):
        out = self.__class__.__new__(self.__class__)
        for key, value in self.__dict__.items():
            out.__dict__[key] = value
        out._mapping = copy.deepcopy(out._mapping, memo)
        return out

    def __getstate__(self) ->Dict[str, Any]:
        out = self.__dict__.copy()
        _parent = out.get('_parent', None)
        if _parent is not None:
            out['_parent'] = _parent()
        return out

    def __setstate__(self, mapping: Dict[str, Any]):
        for key, value in mapping.items():
            self.__dict__[key] = value
        _parent = self.__dict__.get('_parent', None)
        if _parent is not None:
            self.__dict__['_parent'] = weakref.ref(_parent)

    def __repr__(self) ->str:
        return repr(self._mapping)

    def keys(self, *args: List[str]) ->KeysView:
        return KeysView(self._mapping, *args)

    def values(self, *args: List[str]) ->ValuesView:
        return ValuesView(self._mapping, *args)

    def items(self, *args: List[str]) ->ItemsView:
        return ItemsView(self._mapping, *args)

    def apply_(self, func: Callable, *args: List[str]):
        """Applies the in-place function :obj:`func`, either to all attributes
        or only the ones given in :obj:`*args`."""
        for value in self.values(*args):
            recursive_apply_(value, func)
        return self

    def apply(self, func: Callable, *args: List[str]):
        """Applies the function :obj:`func`, either to all attributes or only
        the ones given in :obj:`*args`."""
        for key, value in self.items(*args):
            self[key] = recursive_apply(value, func)
        return self

    def get(self, key: str, value: Optional[Any]=None) ->Any:
        return self._mapping.get(key, value)

    def to_dict(self) ->Dict[str, Any]:
        """Returns a dictionary of stored key/value pairs."""
        return copy.copy(self._mapping)

    def to_namedtuple(self) ->NamedTuple:
        """Returns a :obj:`NamedTuple` of stored key/value pairs."""
        field_names = list(self.keys())
        typename = f'{self.__class__.__name__}Tuple'
        StorageTuple = namedtuple(typename, field_names)
        return StorageTuple(*[self[key] for key in field_names])

    def clone(self, *args: List[str]):
        """Performs a deep-copy of the object."""
        return copy.deepcopy(self)

    def contiguous(self, *args: List[str]):
        """Ensures a contiguous memory layout, either for all attributes or
        only the ones given in :obj:`*args`."""
        return self.apply(lambda x: x.contiguous(), *args)

    def to(self, device: Union[int, str], *args: List[str], non_blocking: bool=False):
        """Performs tensor dtype and/or device conversion, either for all
        attributes or only the ones given in :obj:`*args`."""
        return self.apply(lambda x: x, *args)

    def cpu(self, *args: List[str]):
        """Copies attributes to CPU memory, either for all attributes or only
        the ones given in :obj:`*args`."""
        return self.apply(lambda x: x.cpu(), *args)

    def cuda(self, device: Optional[Union[int, str]]=None, *args: List[str], non_blocking: bool=False):
        """Copies attributes to CUDA memory, either for all attributes or only
        the ones given in :obj:`*args`."""
        return self.apply(lambda x: x, *args)

    def pin_memory(self, *args: List[str]):
        """Copies attributes to pinned memory, either for all attributes or
        only the ones given in :obj:`*args`."""
        return self.apply(lambda x: x.pin_memory(), *args)

    def share_memory_(self, *args: List[str]):
        """Moves attributes to shared memory, either for all attributes or
        only the ones given in :obj:`*args`."""
        return self.apply(lambda x: x.share_memory_(), *args)

    def detach_(self, *args: List[str]):
        """Detaches attributes from the computation graph, either for all
        attributes or only the ones given in :obj:`*args`."""
        return self.apply(lambda x: x.detach_(), *args)

    def detach(self, *args: List[str]):
        """Detaches attributes from the computation graph by creating a new
        tensor, either for all attributes or only the ones given in
        :obj:`*args`."""
        return self.apply(lambda x: x.detach(), *args)

    def requires_grad_(self, *args: List[str], requires_grad: bool=True):
        """Tracks gradient computation, either for all attributes or only the
        ones given in :obj:`*args`."""
        return self.apply(lambda x: x.requires_grad_(requires_grad=requires_grad), *args)

    def record_stream(self, stream: torch.Stream, *args: List[str]):
        """Ensures that the tensor memory is not reused for another tensor
        until all current work queued on :obj:`stream` has been completed,
        either for all attributes or only the ones given in :obj:`*args`."""
        return self.apply_(lambda x: x.record_stream(stream), *args)


EdgeType = Tuple[str, str, str]


def remove_self_loops(edge_index: Tensor, edge_attr: OptTensor=None) ->Tuple[Tensor, OptTensor]:
    """Removes every self-loop in the graph given by :attr:`edge_index`, so
    that :math:`(i,i) \\not\\in \\mathcal{E}` for every :math:`i \\in \\mathcal{V}`.

    Args:
        edge_index (LongTensor): The edge indices.
        edge_attr (Tensor, optional): Edge weights or multi-dimensional
            edge features. (default: :obj:`None`)

    :rtype: (:class:`LongTensor`, :class:`Tensor`)

    Example:

        >>> edge_index = torch.tensor([[0, 1, 0],
        ...                            [1, 0, 0]])
        >>> edge_attr = [[1, 2], [3, 4], [5, 6]]
        >>> edge_attr = torch.tensor(edge_attr)
        >>> remove_self_loops(edge_index, edge_attr)
        (tensor([[0, 1],
                [1, 0]]),
        tensor([[1, 2],
                [3, 4]]))
    """
    mask = edge_index[0] != edge_index[1]
    edge_index = edge_index[:, mask]
    if edge_attr is None:
        return edge_index, None
    else:
        return edge_index, edge_attr[mask]


def contains_isolated_nodes(edge_index: Tensor, num_nodes: Optional[int]=None) ->bool:
    """Returns :obj:`True` if the graph given by :attr:`edge_index` contains
    isolated nodes.

    Args:
        edge_index (LongTensor): The edge indices.
        num_nodes (int, optional): The number of nodes, *i.e.*
            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)

    :rtype: bool

    Examples:

        >>> edge_index = torch.tensor([[0, 1, 0],
        ...                            [1, 0, 0]])
        >>> contains_isolated_nodes(edge_index)
        False

        >>> contains_isolated_nodes(edge_index, num_nodes=3)
        True
    """
    num_nodes = maybe_num_nodes(edge_index, num_nodes)
    edge_index, _ = remove_self_loops(edge_index)
    return torch.unique(edge_index.view(-1)).numel() < num_nodes


class EdgeStorage(BaseStorage):
    """We support multiple ways to store edge connectivity in a
    :class:`EdgeStorage` object:

    * :obj:`edge_index`: A :class:`torch.LongTensor` holding edge indices in
      COO format with shape :obj:`[2, num_edges]` (the default format)

    * :obj:`adj`: A :class:`torch_sparse.SparseTensor` holding edge indices in
      a sparse format, supporting both COO and CSR format.

    * :obj:`adj_t`: A **transposed** :class:`torch_sparse.SparseTensor` holding
      edge indices in a sparse format, supporting both COO and CSR format.
      This is the most efficient one for graph-based deep learning models as
      indices are sorted based on target nodes.
    """

    @property
    def _key(self) ->EdgeType:
        key = self.__dict__.get('_key', None)
        if key is None or not isinstance(key, tuple) or not len(key) == 3:
            raise ValueError("'_key' does not denote a valid edge type")
        return key

    @property
    def edge_index(self) ->Tensor:
        if 'edge_index' in self:
            return self['edge_index']
        if 'adj' in self and isinstance(self.adj, SparseTensor):
            return torch.stack(self.adj.coo()[:2], dim=0)
        if 'adj_t' in self and isinstance(self.adj_t, SparseTensor):
            return torch.stack(self.adj_t.coo()[:2][::-1], dim=0)
        raise AttributeError(f"'{self.__class__.__name__}' object has no attribute 'edge_index', 'adj' or 'adj_t'")

    @property
    def num_edges(self) ->int:
        for key, value in self.items():
            if isinstance(value, (Tensor, np.ndarray)) and 'edge' in key:
                cat_dim = self._parent().__cat_dim__(key, value, self)
                return value.shape[cat_dim]
        for value in self.values('adj', 'adj_t'):
            if isinstance(value, SparseTensor):
                return value.nnz()
        return 0

    @property
    def num_edge_features(self) ->int:
        if 'edge_attr' in self and isinstance(self.edge_attr, (Tensor, np.ndarray)):
            return 1 if self.edge_attr.ndim == 1 else self.edge_attr.shape[-1]
        return 0

    @property
    def num_features(self) ->int:
        return self.num_edge_features

    def size(self, dim: Optional[int]=None) ->Union[Tuple[Optional[int], Optional[int]], Optional[int]]:
        if self._key is None:
            raise NameError("Unable to infer 'size' without explicit '_key' assignment")
        size = self._parent()[self._key[0]].num_nodes, self._parent()[self._key[-1]].num_nodes
        return size if dim is None else size[dim]

    def is_node_attr(self, key: str) ->bool:
        return False

    def is_edge_attr(self, key: str) ->bool:
        value = self[key]
        cat_dim = self._parent().__cat_dim__(key, value, self)
        if not isinstance(value, (Tensor, np.ndarray)):
            return False
        if value.ndim == 0 or value.shape[cat_dim] != self.num_edges:
            return False
        return True

    def edge_attrs(self) ->List[str]:
        return [key for key in self.keys() if self.is_edge_attr(key)]

    def is_coalesced(self) ->bool:
        for value in self.values('adj', 'adj_t'):
            return value.is_coalesced()
        if 'edge_index' in self:
            new_edge_index = coalesce(self.edge_index, num_nodes=max(self.size(0), self.size(1)))
            return self.edge_index.numel() == new_edge_index.numel() and torch.equal(self.edge_index, new_edge_index)
        return True

    def coalesce(self, reduce: str='sum'):
        for key, value in self.items('adj', 'adj_t'):
            self[key] = value.coalesce(reduce)
        if 'edge_index' in self:
            if 'edge_attr' in self:
                self.edge_index, self.edge_attr = coalesce(self.edge_index, self.edge_attr, num_nodes=max(self.size(0), self.size(1)))
            else:
                self.edge_index = coalesce(self.edge_index, num_nodes=max(self.size(0), self.size(1)))
        return self

    def has_isolated_nodes(self) ->bool:
        edge_index, num_nodes = self.edge_index, self.size(1)
        if num_nodes is None:
            raise NameError("Unable to infer 'num_nodes'")
        if self.is_bipartite():
            return torch.unique(edge_index[1]).numel() < num_nodes
        else:
            return contains_isolated_nodes(edge_index, num_nodes)

    def has_self_loops(self) ->bool:
        if self.is_bipartite():
            return False
        edge_index = self.edge_index
        return int((edge_index[0] == edge_index[1]).sum()) > 0

    def is_undirected(self) ->bool:
        if self.is_bipartite():
            return False
        for value in self.values('adj', 'adj_t'):
            return value.is_symmetric()
        edge_index = self.edge_index
        edge_attr = self.edge_attr if 'edge_attr' in self else None
        return is_undirected(edge_index, edge_attr, num_nodes=self.size(0))

    def is_directed(self) ->bool:
        return not self.is_undirected()

    def is_bipartite(self) ->bool:
        return self._key is not None and self._key[0] != self._key[-1]


N_KEYS = {'x', 'feat', 'pos', 'batch'}


NodeType = str


class NodeStorage(BaseStorage):

    @property
    def _key(self) ->NodeType:
        key = self.__dict__.get('_key', None)
        if key is None or not isinstance(key, str):
            raise ValueError("'_key' does not denote a valid node type")
        return key

    @property
    def can_infer_num_nodes(self):
        keys = set(self.keys())
        num_node_keys = {'num_nodes', 'x', 'pos', 'batch', 'adj', 'adj_t', 'edge_index', 'face'}
        if len(keys & num_node_keys) > 0:
            return True
        elif len([key for key in keys if 'node' in key]) > 0:
            return True
        else:
            return False

    @property
    def num_nodes(self) ->Optional[int]:
        if 'num_nodes' in self:
            return self['num_nodes']
        for key, value in self.items():
            if isinstance(value, (Tensor, np.ndarray)) and (key in N_KEYS or 'node' in key):
                cat_dim = self._parent().__cat_dim__(key, value, self)
                return value.shape[cat_dim]
        if 'adj' in self and isinstance(self.adj, SparseTensor):
            return self.adj.size(0)
        if 'adj_t' in self and isinstance(self.adj_t, SparseTensor):
            return self.adj_t.size(1)
        warnings.warn(f"Unable to accurately infer 'num_nodes' from the attribute set '{set(self.keys())}'. Please explicitly set 'num_nodes' as an attribute of " + ("'data'" if self._key is None else f"'data[{self._key}]'") + ' to suppress this warning')
        if 'edge_index' in self and isinstance(self.edge_index, Tensor):
            if self.edge_index.numel() > 0:
                return int(self.edge_index.max()) + 1
            else:
                return 0
        if 'face' in self and isinstance(self.face, Tensor):
            if self.face.numel() > 0:
                return int(self.face.max()) + 1
            else:
                return 0
        return None

    @property
    def num_node_features(self) ->int:
        if 'x' in self and isinstance(self.x, (Tensor, np.ndarray)):
            return 1 if self.x.ndim == 1 else self.x.shape[-1]
        if 'x' in self and isinstance(self.x, SparseTensor):
            return 1 if self.x.dim() == 1 else self.x.size(-1)
        return 0

    @property
    def num_features(self) ->int:
        return self.num_node_features

    def is_node_attr(self, key: str) ->bool:
        value = self[key]
        cat_dim = self._parent().__cat_dim__(key, value, self)
        if not isinstance(value, (Tensor, np.ndarray)):
            return False
        if value.ndim == 0 or value.shape[cat_dim] != self.num_nodes:
            return False
        return True

    def is_edge_attr(self, key: str) ->bool:
        return False

    def node_attrs(self) ->List[str]:
        return [key for key in self.keys() if self.is_node_attr(key)]


def deprecated(details: Optional[str]=None, func_name: Optional[str]=None):

    def decorator(func):

        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            out = f"'{func_name or func.__name__}' is deprecated" + (f', {details}' if details is not None else '')
            warnings.warn(out)
            return func(*args, **kwargs)
        return wrapper
    return decorator


class BaseData(object):

    def __getattr__(self, key: str) ->Any:
        raise NotImplementedError

    def __setattr__(self, key: str, value: Any):
        raise NotImplementedError

    def __delattr__(self, key: str):
        raise NotImplementedError

    def __getitem__(self, key: str) ->Any:
        raise NotImplementedError

    def __setitem__(self, key: str, value: Any):
        raise NotImplementedError

    def __delitem__(self, key: str):
        raise NotImplementedError

    def __copy__(self):
        raise NotImplementedError

    def __deepcopy__(self, memo):
        raise NotImplementedError

    def __repr__(self) ->str:
        raise NotImplementedError

    def stores_as(self, data: 'BaseData'):
        raise NotImplementedError

    @property
    def stores(self) ->List[BaseStorage]:
        raise NotImplementedError

    @property
    def node_stores(self) ->List[NodeStorage]:
        raise NotImplementedError

    @property
    def edge_stores(self) ->List[EdgeStorage]:
        raise NotImplementedError

    def to_dict(self) ->Dict[str, Any]:
        """Returns a dictionary of stored key/value pairs."""
        raise NotImplementedError

    def to_namedtuple(self) ->NamedTuple:
        """Returns a :obj:`NamedTuple` of stored key/value pairs."""
        raise NotImplementedError

    def __cat_dim__(self, key: str, value: Any, *args, **kwargs) ->Any:
        """Returns the dimension for which the value :obj:`value` of the
        attribute :obj:`key` will get concatenated when creating mini-batches
        using :class:`torch_geometric.loader.DataLoader`.

        .. note::

            This method is for internal use only, and should only be overridden
            in case the mini-batch creation process is corrupted for a specific
            attribute.
        """
        raise NotImplementedError

    def __inc__(self, key: str, value: Any, *args, **kwargs) ->Any:
        """Returns the incremental count to cumulatively increase the value
        :obj:`value` of the attribute :obj:`key` when creating mini-batches
        using :class:`torch_geometric.loader.DataLoader`.

        .. note::

            This method is for internal use only, and should only be overridden
            in case the mini-batch creation process is corrupted for a specific
            attribute.
        """
        raise NotImplementedError

    def debug(self):
        raise NotImplementedError

    @property
    def keys(self) ->List[str]:
        """Returns a list of all graph attribute names."""
        out = []
        for store in self.stores:
            out += list(store.keys())
        return list(set(out))

    def __len__(self) ->int:
        """Returns the number of graph attributes."""
        return len(self.keys)

    def __contains__(self, key: str) ->bool:
        """Returns :obj:`True` if the attribute :obj:`key` is present in the
        data."""
        return key in self.keys

    def __getstate__(self) ->Dict[str, Any]:
        return self.__dict__

    def __setstate__(self, mapping: Dict[str, Any]):
        for key, value in mapping.items():
            self.__dict__[key] = value

    @property
    def num_nodes(self) ->Optional[int]:
        """Returns the number of nodes in the graph.

        .. note::
            The number of nodes in the data object is automatically inferred
            in case node-level attributes are present, *e.g.*, :obj:`data.x`.
            In some cases, however, a graph may only be given without any
            node-level attributes.
            PyG then *guesses* the number of nodes according to
            :obj:`edge_index.max().item() + 1`.
            However, in case there exists isolated nodes, this number does not
            have to be correct which can result in unexpected behaviour.
            Thus, we recommend to set the number of nodes in your data object
            explicitly via :obj:`data.num_nodes = ...`.
            You will be given a warning that requests you to do so.
        """
        try:
            return sum([v.num_nodes for v in self.node_stores])
        except TypeError:
            return None

    def size(self, dim: Optional[int]=None) ->Union[Tuple[Optional[int], Optional[int]], Optional[int]]:
        """Returns the size of the adjacency matrix induced by the graph."""
        size = self.num_nodes, self.num_nodes
        return size if dim is None else size[dim]

    @property
    def num_edges(self) ->int:
        """Returns the number of edges in the graph.
        For undirected graphs, this will return the number of bi-directional
        edges, which is double the amount of unique edges."""
        return sum([v.num_edges for v in self.edge_stores])

    def node_attrs(self) ->List[str]:
        """Returns all node-level tensor attribute names."""
        return list(set(chain(*[s.node_attrs() for s in self.node_stores])))

    def edge_attrs(self) ->List[str]:
        """Returns all edge-level tensor attribute names."""
        return list(set(chain(*[s.edge_attrs() for s in self.edge_stores])))

    def is_coalesced(self) ->bool:
        """Returns :obj:`True` if edge indices :obj:`edge_index` are sorted
        and do not contain duplicate entries."""
        return all([store.is_coalesced() for store in self.edge_stores])

    def generate_ids(self):
        """Generates and sets :obj:`n_id` and :obj:`e_id` attributes to assign
        each node and edge to a continuously ascending and unique ID."""
        for store in self.node_stores:
            store.n_id = torch.arange(store.num_nodes)
        for store in self.edge_stores:
            store.e_id = torch.arange(store.num_edges)

    def coalesce(self):
        """Sorts and removes duplicated entries from edge indices
        :obj:`edge_index`."""
        for store in self.edge_stores:
            store.coalesce()
        return self

    def has_isolated_nodes(self) ->bool:
        """Returns :obj:`True` if the graph contains isolated nodes."""
        return any([store.has_isolated_nodes() for store in self.edge_stores])

    def has_self_loops(self) ->bool:
        """Returns :obj:`True` if the graph contains self-loops."""
        return any([store.has_self_loops() for store in self.edge_stores])

    def is_undirected(self) ->bool:
        """Returns :obj:`True` if graph edges are undirected."""
        return all([store.is_undirected() for store in self.edge_stores])

    def is_directed(self) ->bool:
        """Returns :obj:`True` if graph edges are directed."""
        return not self.is_undirected()

    def apply_(self, func: Callable, *args: List[str]):
        """Applies the in-place function :obj:`func`, either to all attributes
        or only the ones given in :obj:`*args`."""
        for store in self.stores:
            store.apply_(func, *args)
        return self

    def apply(self, func: Callable, *args: List[str]):
        """Applies the function :obj:`func`, either to all attributes or only
        the ones given in :obj:`*args`."""
        for store in self.stores:
            store.apply(func, *args)
        return self

    def clone(self, *args: List[str]):
        """Performs cloning of tensors, either for all attributes or only the
        ones given in :obj:`*args`."""
        return copy.copy(self).apply(lambda x: x.clone(), *args)

    def contiguous(self, *args: List[str]):
        """Ensures a contiguous memory layout, either for all attributes or
        only the ones given in :obj:`*args`."""
        return self.apply(lambda x: x.contiguous(), *args)

    def to(self, device: Union[int, str], *args: List[str], non_blocking: bool=False):
        """Performs tensor device conversion, either for all attributes or
        only the ones given in :obj:`*args`."""
        return self.apply(lambda x: x, *args)

    def cpu(self, *args: List[str]):
        """Copies attributes to CPU memory, either for all attributes or only
        the ones given in :obj:`*args`."""
        return self.apply(lambda x: x.cpu(), *args)

    def cuda(self, device: Optional[Union[int, str]]=None, *args: List[str], non_blocking: bool=False):
        """Copies attributes to CUDA memory, either for all attributes or only
        the ones given in :obj:`*args`."""
        device = 'cuda' if device is None else device
        return self.apply(lambda x: x, *args)

    def pin_memory(self, *args: List[str]):
        """Copies attributes to pinned memory, either for all attributes or
        only the ones given in :obj:`*args`."""
        return self.apply(lambda x: x.pin_memory(), *args)

    def share_memory_(self, *args: List[str]):
        """Moves attributes to shared memory, either for all attributes or
        only the ones given in :obj:`*args`."""
        return self.apply_(lambda x: x.share_memory_(), *args)

    def detach_(self, *args: List[str]):
        """Detaches attributes from the computation graph, either for all
        attributes or only the ones given in :obj:`*args`."""
        return self.apply_(lambda x: x.detach_(), *args)

    def detach(self, *args: List[str]):
        """Detaches attributes from the computation graph by creating a new
        tensor, either for all attributes or only the ones given in
        :obj:`*args`."""
        return self.apply(lambda x: x.detach(), *args)

    def requires_grad_(self, *args: List[str], requires_grad: bool=True):
        """Tracks gradient computation, either for all attributes or only the
        ones given in :obj:`*args`."""
        return self.apply_(lambda x: x.requires_grad_(requires_grad=requires_grad), *args)

    def record_stream(self, stream: torch.Stream, *args: List[str]):
        """Ensures that the tensor memory is not reused for another tensor
        until all current work queued on :obj:`stream` has been completed,
        either for all attributes or only the ones given in :obj:`*args`."""
        return self.apply_(lambda x: x.record_stream(stream), *args)

    @property
    def is_cuda(self) ->bool:
        """Returns :obj:`True` if any :class:`torch.Tensor` attribute is
        stored on the GPU, :obj:`False` otherwise."""
        for store in self.stores:
            for value in store.values():
                if isinstance(value, Tensor) and value.is_cuda:
                    return True
        return False

    @deprecated(details="use 'has_isolated_nodes' instead")
    def contains_isolated_nodes(self) ->bool:
        return self.has_isolated_nodes()

    @deprecated(details="use 'has_self_loops' instead")
    def contains_self_loops(self) ->bool:
        return self.has_self_loops()


class CastMixin:

    @classmethod
    def cast(cls, *args, **kwargs):
        if len(args) == 1 and len(kwargs) == 0:
            elem = args[0]
            if elem is None:
                return None
            if isinstance(elem, CastMixin):
                return elem
            if isinstance(elem, (tuple, list)):
                return cls(*elem)
            if isinstance(elem, dict):
                return cls(**elem)
        return cls(*args, **kwargs)


class EdgeLayout(Enum):
    COO = 'coo'
    CSC = 'csc'
    CSR = 'csr'


IndexType = Union[torch.Tensor, np.ndarray, slice, int]


_field_status = Enum('FieldStatus', 'UNSET')


EDGE_LAYOUT_TO_ATTR_NAME = {EdgeLayout.COO: 'edge_index', EdgeLayout.CSR: 'adj', EdgeLayout.CSC: 'adj_t'}


EdgeTensorType = Tuple[Tensor, Tensor]


class GlobalStorage(NodeStorage, EdgeStorage):

    @property
    def _key(self) ->Any:
        return None

    @property
    def num_features(self) ->int:
        return self.num_node_features

    def size(self, dim: Optional[int]=None) ->Union[Tuple[Optional[int], Optional[int]], Optional[int]]:
        size = self.num_nodes, self.num_nodes
        return size if dim is None else size[dim]

    def is_node_attr(self, key: str) ->bool:
        value = self[key]
        cat_dim = self._parent().__cat_dim__(key, value, self)
        num_nodes, num_edges = self.num_nodes, self.num_edges
        if not isinstance(value, (Tensor, np.ndarray)):
            return False
        if value.ndim == 0 or value.shape[cat_dim] != num_nodes:
            return False
        if num_nodes != num_edges:
            return True
        return 'edge' not in key

    def is_edge_attr(self, key: str) ->bool:
        value = self[key]
        cat_dim = self._parent().__cat_dim__(key, value, self)
        num_nodes, num_edges = self.num_nodes, self.num_edges
        if not isinstance(value, (Tensor, np.ndarray)):
            return False
        if value.ndim == 0 or value.shape[cat_dim] != num_edges:
            return False
        if num_nodes != num_edges:
            return True
        return 'edge' in key


ConversionOutputType = Tuple[Dict[str, Tensor], Dict[str, Tensor], Dict[str, OptTensor]]


def sort_csc(row: Tensor, col: Tensor, src_node_time: OptTensor=None) ->Tuple[Tensor, Tensor, Tensor]:
    if src_node_time is None:
        col, perm = col.sort()
        return row[perm], col, perm
    else:
        perm = np.lexsort([src_node_time[row].detach().cpu().numpy(), col.detach().cpu().numpy()])
        perm = torch.from_numpy(perm)
        return row[perm], col[perm], perm


def mask_select(src: Tensor, dim: int, mask: Tensor) ->Tensor:
    """Returns a new tensor which masks the :obj:`src` tensor along the
    dimension :obj:`dim` according to the boolean mask :obj:`mask`.

    Args:
        src (torch.Tensor): The input tensor.
        dim (int): The dimension in which to mask.
        mask (torch.BoolTensor): The 1-D tensor containing the binary mask to
            index with.
    """
    assert mask.dim() == 1
    assert src.size(dim) == mask.numel()
    dim = dim + src.dim() if dim < 0 else dim
    assert dim >= 0 and dim < src.dim()
    size = [1] * src.dim()
    size[dim] = mask.numel()
    out = src.masked_select(mask.view(size))
    size = list(src.size())
    size[dim] = -1
    return out.view(size)


def size_repr(key: Any, value: Any, indent: int=0) ->str:
    pad = ' ' * indent
    if isinstance(value, Tensor) and value.dim() == 0:
        out = value.item()
    elif isinstance(value, Tensor):
        out = str(list(value.size()))
    elif isinstance(value, np.ndarray):
        out = str(list(value.shape))
    elif isinstance(value, SparseTensor):
        out = str(value.sizes())[:-1] + f', nnz={value.nnz()}]'
    elif isinstance(value, str):
        out = f"'{value}'"
    elif isinstance(value, Sequence):
        out = str([len(value)])
    elif isinstance(value, Mapping) and len(value) == 0:
        out = '{}'
    elif isinstance(value, Mapping) and len(value) == 1 and not isinstance(list(value.values())[0], Mapping):
        lines = [size_repr(k, v, 0) for k, v in value.items()]
        out = '{ ' + ', '.join(lines) + ' }'
    elif isinstance(value, Mapping):
        lines = [size_repr(k, v, indent + 2) for k, v in value.items()]
        out = '{\n' + ',\n'.join(lines) + '\n' + pad + '}'
    else:
        out = str(value)
    key = str(key).replace("'", '')
    if isinstance(value, BaseStorage):
        return f'{pad}\x1b[1m{key}\x1b[0m={out}'
    else:
        return f'{pad}{key}={out}'


def warn_or_raise(msg: str, raise_on_error: bool=True):
    if raise_on_error:
        raise ValueError(msg)
    else:
        warnings.warn(msg)


NodeOrEdgeStorage = Union[NodeStorage, EdgeStorage]


NodeOrEdgeType = Union[NodeType, EdgeType]


QueryType = Union[NodeType, EdgeType, str, Tuple[str, str]]


def index_to_mask(index: Tensor, size: Optional[int]=None) ->Tensor:
    """Converts indices to a mask representation.

    Args:
        idx (Tensor): The indices.
        size (int, optional). The size of the mask. If set to :obj:`None`, a
            minimal sized output mask is returned.

    Example:

        >>> index = torch.tensor([1, 3, 5])
        >>> index_to_mask(index)
        tensor([False,  True, False,  True, False,  True])

        >>> index_to_mask(index, size=7)
        tensor([False,  True, False,  True, False,  True, False])
    """
    index = index.view(-1)
    size = int(index.max()) + 1 if size is None else size
    mask = index.new_zeros(size, dtype=torch.bool)
    mask[index] = True
    return mask


def bipartite_subgraph(subset: Union[PairTensor, Tuple[List[int], List[int]]], edge_index: Tensor, edge_attr: Optional[Tensor]=None, relabel_nodes: bool=False, size: Tuple[int, int]=None, return_edge_mask: bool=False) ->Tuple[Tensor, Tensor]:
    """Returns the induced subgraph of the bipartite graph
    :obj:`(edge_index, edge_attr)` containing the nodes in :obj:`subset`.

    Args:
        subset (Tuple[Tensor, Tensor] or tuple([int],[int])): The nodes
            to keep.
        edge_index (LongTensor): The edge indices.
        edge_attr (Tensor, optional): Edge weights or multi-dimensional
            edge features. (default: :obj:`None`)
        relabel_nodes (bool, optional): If set to :obj:`True`, the resulting
            :obj:`edge_index` will be relabeled to hold consecutive indices
            starting from zero. (default: :obj:`False`)
        size (tuple, optional): The number of nodes.
            (default: :obj:`None`)
        return_edge_mask (bool, optional): If set to :obj:`True`, will return
            the edge mask to filter out additional edge features.
            (default: :obj:`False`)

    :rtype: (:class:`LongTensor`, :class:`Tensor`)

    Examples:

        >>> edge_index = torch.tensor([[0, 5, 2, 3, 3, 4, 4, 3, 5, 5, 6],
        ...                            [0, 0, 3, 2, 0, 0, 2, 1, 2, 3, 1]])
        >>> edge_attr = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])
        >>> subset = (torch.tensor([2, 3, 5]), torch.tensor([2, 3]))
        >>> bipartite_subgraph(subset, edge_index, edge_attr)
        (tensor([[2, 3, 5, 5],
                [3, 2, 2, 3]]),
        tensor([ 3,  4,  9, 10]))

        >>> bipartite_subgraph(subset, edge_index, edge_attr,
        ...                    return_edge_mask=True)
        (tensor([[2, 3, 5, 5],
                [3, 2, 2, 3]]),
        tensor([ 3,  4,  9, 10]),
        tensor([False, False,  True,  True, False, False, False, False,
                True,  True,  False]))
    """
    device = edge_index.device
    if isinstance(subset[0], (list, tuple)):
        subset = torch.tensor(subset[0], dtype=torch.long, device=device), torch.tensor(subset[1], dtype=torch.long, device=device)
    if subset[0].dtype == torch.bool or subset[0].dtype == torch.uint8:
        size = subset[0].size(0), subset[1].size(0)
    else:
        if size is None:
            size = maybe_num_nodes(edge_index[0]), maybe_num_nodes(edge_index[1])
        subset = index_to_mask(subset[0], size=size[0]), index_to_mask(subset[1], size=size[1])
    node_mask = subset
    edge_mask = node_mask[0][edge_index[0]] & node_mask[1][edge_index[1]]
    edge_index = edge_index[:, edge_mask]
    edge_attr = edge_attr[edge_mask] if edge_attr is not None else None
    if relabel_nodes:
        node_idx_i = torch.zeros(node_mask[0].size(0), dtype=torch.long, device=device)
        node_idx_j = torch.zeros(node_mask[1].size(0), dtype=torch.long, device=device)
        node_idx_i[node_mask[0]] = torch.arange(node_mask[0].sum().item(), device=device)
        node_idx_j[node_mask[1]] = torch.arange(node_mask[1].sum().item(), device=device)
        edge_index = torch.stack([node_idx_i[edge_index[0]], node_idx_j[edge_index[1]]])
    if return_edge_mask:
        return edge_index, edge_attr, edge_mask
    else:
        return edge_index, edge_attr


InputNodes = Union[OptTensor, NodeType, Tuple[NodeType, OptTensor]]


class NegativeSamplingMode(Enum):
    binary = 'binary'
    triplet = 'triplet'


NumNeighbors = Union[List[int], Dict[EdgeType, List[int]]]


X, Y = TypeVar('X'), TypeVar('Y')


def remap_keys(inputs: Dict[X, Any], mapping: Dict[X, Y], exclude: Optional[List[X]]=None) ->Dict[Union[X, Y], Any]:
    exclude = exclude or []
    return {(k if k in exclude else mapping.get(k, k)): v for k, v in inputs.items()}


class DataLoaderIterator:
    """A data loader iterator extended by a simple post transformation
    function :meth:`transform_fn`. While the iterator may request items from
    different sub-processes, :meth:`transform_fn` will always be executed in
    the main process.

    This iterator is used in PyG's sampler classes, and is responsible for
    feature fetching and filtering data objects after sampling has taken place
    in a sub-process. This has the following advantages:

    * We do not need to share feature matrices across processes which may
      prevent any errors due to too many open file handles.
    * We can execute any expensive post-processing commands on the main thread
      with full parallelization power (which usually executes faster).
    * It lets us naturally support data already being present on the GPU.
    """

    def __init__(self, iterator: _BaseDataLoaderIter, transform_fn: Callable):
        self.iterator = iterator
        self.transform_fn = transform_fn

    def __iter__(self) ->'DataLoaderIterator':
        return self

    def _reset(self, loader: Any, first_iter: bool=False):
        self.iterator._reset(loader, first_iter)

    def __len__(self) ->int:
        return len(self.iterator)

    def __next__(self) ->Any:
        return self.transform_fn(next(self.iterator))


class WorkerInitWrapper:
    """Wraps the :attr:`worker_init_fn` argument for PyTorch data loader
    workers."""

    def __init__(self, func):
        self.func = func

    def __call__(self, worker_id):
        if self.func is not None:
            self.func(worker_id)


def filter_edge_store_(store: EdgeStorage, out_store: EdgeStorage, row: Tensor, col: Tensor, index: Tensor, perm: OptTensor=None) ->None:
    for key, value in store.items():
        if key == 'edge_index':
            edge_index = torch.stack([row, col], dim=0)
            out_store.edge_index = edge_index
        elif key == 'adj_t':
            row = row
            col = col
            edge_attr = value.storage.value()
            if edge_attr is not None:
                index = index
                edge_attr = index_select(edge_attr, index, dim=0)
            sparse_sizes = out_store.size()[::-1]
            out_store.adj_t = SparseTensor(row=col, col=row, value=edge_attr, sparse_sizes=sparse_sizes, is_sorted=False, trust_data=True)
        elif store.is_edge_attr(key):
            dim = store._parent().__cat_dim__(key, value, store)
            if isinstance(value, Tensor):
                index = index
            elif isinstance(value, np.ndarray):
                index = index.cpu()
            if perm is None:
                out_store[key] = index_select(value, index, dim=dim)
            else:
                if isinstance(value, Tensor):
                    perm = perm
                elif isinstance(value, np.ndarray):
                    perm = perm.cpu()
                out_store[key] = index_select(value, perm[index], dim=dim)


def filter_node_store_(store: NodeStorage, out_store: NodeStorage, index: Tensor) ->None:
    for key, value in store.items():
        if key == 'num_nodes':
            out_store.num_nodes = index.numel()
        elif store.is_node_attr(key):
            if isinstance(value, Tensor):
                index = index
            elif isinstance(value, np.ndarray):
                index = index.cpu()
            dim = store._parent().__cat_dim__(key, value, store)
            out_store[key] = index_select(value, index, dim=dim)


def get_numa_nodes_cores():
    """ Returns numa nodes info, format:
        {<node_id>: [(<core_id>, [<sibling_thread_id_0>, <sibling_thread_id_1>
        ...]), ...], ...}
        E.g.: {0: [(0, [0, 4]), (1, [1, 5])], 1: [(2, [2, 6]), (3, [3, 7])]}

        If not available, returns {}
    """
    numa_node_paths = glob.glob('/sys/devices/system/node/node[0-9]*')
    if not numa_node_paths:
        return {}
    nodes = {}
    try:
        for node_path in numa_node_paths:
            numa_node_id = int(os.path.basename(node_path)[4:])
            thread_siblings = {}
            for cpu_dir in glob.glob(os.path.join(node_path, 'cpu[0-9]*')):
                cpu_id = int(os.path.basename(cpu_dir)[3:])
                if cpu_id > 0:
                    with open(os.path.join(cpu_dir, 'online')) as core_online_file:
                        core_online = int(core_online_file.read().splitlines()[0])
                else:
                    core_online = 1
                if core_online == 1:
                    with open(os.path.join(cpu_dir, 'topology', 'core_id')) as core_id_file:
                        core_id = int(core_id_file.read().strip())
                        if core_id in thread_siblings:
                            thread_siblings[core_id].append(cpu_id)
                        else:
                            thread_siblings[core_id] = [cpu_id]
            nodes[numa_node_id] = sorted([(k, sorted(v)) for k, v in thread_siblings.items()])
    except (OSError, ValueError, IndexError, IOError):
        Warning('Failed to read NUMA info')
        return {}
    return nodes


def swish(x: Tensor) ->Tensor:
    return x * x.sigmoid()


def activation_resolver(query: Union[Any, str]='relu', *args, **kwargs):
    import torch
    base_cls = torch.nn.Module
    base_cls_repr = 'Act'
    acts = [act for act in vars(torch.nn.modules.activation).values() if isinstance(act, type) and issubclass(act, base_cls)]
    acts += [swish]
    act_dict = {}
    return resolver(acts, act_dict, query, base_cls, base_cls_repr, *args, **kwargs)


def normalization_resolver(query: Union[Any, str], *args, **kwargs):
    import torch
    base_cls = torch.nn.Module
    base_cls_repr = 'Norm'
    norms = [norm for norm in vars(norm).values() if isinstance(norm, type) and issubclass(norm, base_cls)]
    norm_dict = {}
    return resolver(norms, norm_dict, query, base_cls, base_cls_repr, *args, **kwargs)


class GCNWithJK(torch.nn.Module):

    def __init__(self, dataset, num_layers, hidden, mode='cat'):
        super().__init__()
        self.conv1 = GCNConv(dataset.num_features, hidden)
        self.convs = torch.nn.ModuleList()
        for i in range(num_layers - 1):
            self.convs.append(GCNConv(hidden, hidden))
        self.jump = JumpingKnowledge(mode)
        if mode == 'cat':
            self.lin1 = Linear(num_layers * hidden, hidden)
        else:
            self.lin1 = Linear(hidden, hidden)
        self.lin2 = Linear(hidden, dataset.num_classes)

    def reset_parameters(self):
        self.conv1.reset_parameters()
        for conv in self.convs:
            conv.reset_parameters()
        self.jump.reset_parameters()
        self.lin1.reset_parameters()
        self.lin2.reset_parameters()

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
        x = F.relu(self.conv1(x, edge_index))
        xs = [x]
        for conv in self.convs:
            x = F.relu(conv(x, edge_index))
            xs += [x]
        x = self.jump(xs)
        x = global_mean_pool(x, batch)
        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin2(x)
        return F.log_softmax(x, dim=-1)

    def __repr__(self):
        return self.__class__.__name__


def reset(value: Any):
    if hasattr(value, 'reset_parameters'):
        value.reset_parameters()
    else:
        for child in (value.children() if hasattr(value, 'children') else []):
            reset(child)


class GIN0(torch.nn.Module):

    def __init__(self, dataset, num_layers, hidden):
        super().__init__()
        self.conv1 = GINConv(Sequential(Linear(dataset.num_features, hidden), ReLU(), Linear(hidden, hidden), ReLU(), BN(hidden)), train_eps=False)
        self.convs = torch.nn.ModuleList()
        for i in range(num_layers - 1):
            self.convs.append(GINConv(Sequential(Linear(hidden, hidden), ReLU(), Linear(hidden, hidden), ReLU(), BN(hidden)), train_eps=False))
        self.lin1 = Linear(hidden, hidden)
        self.lin2 = Linear(hidden, dataset.num_classes)

    def reset_parameters(self):
        self.conv1.reset_parameters()
        for conv in self.convs:
            conv.reset_parameters()
        self.lin1.reset_parameters()
        self.lin2.reset_parameters()

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
        x = self.conv1(x, edge_index)
        for conv in self.convs:
            x = conv(x, edge_index)
        x = global_mean_pool(x, batch)
        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin2(x)
        return F.log_softmax(x, dim=-1)

    def __repr__(self):
        return self.__class__.__name__


class GIN0WithJK(torch.nn.Module):

    def __init__(self, dataset, num_layers, hidden, mode='cat'):
        super().__init__()
        self.conv1 = GINConv(Sequential(Linear(dataset.num_features, hidden), ReLU(), Linear(hidden, hidden), ReLU(), BN(hidden)), train_eps=False)
        self.convs = torch.nn.ModuleList()
        for i in range(num_layers - 1):
            self.convs.append(GINConv(Sequential(Linear(hidden, hidden), ReLU(), Linear(hidden, hidden), ReLU(), BN(hidden)), train_eps=False))
        self.jump = JumpingKnowledge(mode)
        if mode == 'cat':
            self.lin1 = Linear(num_layers * hidden, hidden)
        else:
            self.lin1 = Linear(hidden, hidden)
        self.lin2 = Linear(hidden, dataset.num_classes)

    def reset_parameters(self):
        self.conv1.reset_parameters()
        for conv in self.convs:
            conv.reset_parameters()
        self.jump.reset_parameters()
        self.lin1.reset_parameters()
        self.lin2.reset_parameters()

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
        x = self.conv1(x, edge_index)
        xs = [x]
        for conv in self.convs:
            x = conv(x, edge_index)
            xs += [x]
        x = self.jump(xs)
        x = global_mean_pool(x, batch)
        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin2(x)
        return F.log_softmax(x, dim=-1)

    def __repr__(self):
        return self.__class__.__name__


NoneType = Optional[Tensor]


class MLP(torch.nn.Module):
    """A Multi-Layer Perception (MLP) model.
    There exists two ways to instantiate an :class:`MLP`:

    1. By specifying explicit channel sizes, *e.g.*,

       .. code-block:: python

          mlp = MLP([16, 32, 64, 128])

       creates a three-layer MLP with **differently** sized hidden layers.

    1. By specifying fixed hidden channel sizes over a number of layers,
       *e.g.*,

       .. code-block:: python

          mlp = MLP(in_channels=16, hidden_channels=32,
                    out_channels=128, num_layers=3)

       creates a three-layer MLP with **equally** sized hidden layers.

    Args:
        channel_list (List[int] or int, optional): List of input, intermediate
            and output channels such that :obj:`len(channel_list) - 1` denotes
            the number of layers of the MLP (default: :obj:`None`)
        in_channels (int, optional): Size of each input sample.
            Will override :attr:`channel_list`. (default: :obj:`None`)
        hidden_channels (int, optional): Size of each hidden sample.
            Will override :attr:`channel_list`. (default: :obj:`None`)
        out_channels (int, optional): Size of each output sample.
            Will override :attr:`channel_list`. (default: :obj:`None`)
        num_layers (int, optional): The number of layers.
            Will override :attr:`channel_list`. (default: :obj:`None`)
        dropout (float or List[float], optional): Dropout probability of each
            hidden embedding. If a list is provided, sets the dropout value per
            layer. (default: :obj:`0.`)
        act (str or Callable, optional): The non-linear activation function to
            use. (default: :obj:`"relu"`)
        act_first (bool, optional): If set to :obj:`True`, activation is
            applied before normalization. (default: :obj:`False`)
        act_kwargs (Dict[str, Any], optional): Arguments passed to the
            respective activation function defined by :obj:`act`.
            (default: :obj:`None`)
        norm (str or Callable, optional): The normalization function to
            use. (default: :obj:`"batch_norm"`)
        norm_kwargs (Dict[str, Any], optional): Arguments passed to the
            respective normalization function defined by :obj:`norm`.
            (default: :obj:`None`)
        plain_last (bool, optional): If set to :obj:`False`, will apply
            non-linearity, batch normalization and dropout to the last layer as
            well. (default: :obj:`True`)
        bias (bool or List[bool], optional): If set to :obj:`False`, the module
            will not learn additive biases. If a list is provided, sets the
            bias per layer. (default: :obj:`True`)
        **kwargs (optional): Additional deprecated arguments of the MLP layer.
    """

    def __init__(self, channel_list: Optional[Union[List[int], int]]=None, *, in_channels: Optional[int]=None, hidden_channels: Optional[int]=None, out_channels: Optional[int]=None, num_layers: Optional[int]=None, dropout: Union[float, List[float]]=0.0, act: Union[str, Callable, None]='relu', act_first: bool=False, act_kwargs: Optional[Dict[str, Any]]=None, norm: Union[str, Callable, None]='batch_norm', norm_kwargs: Optional[Dict[str, Any]]=None, plain_last: bool=True, bias: Union[bool, List[bool]]=True, **kwargs):
        super().__init__()
        act_first = act_first or kwargs.get('relu_first', False)
        batch_norm = kwargs.get('batch_norm', None)
        if batch_norm is not None and isinstance(batch_norm, bool):
            warnings.warn('Argument `batch_norm` is deprecated, please use `norm` to specify normalization layer.')
            norm = 'batch_norm' if batch_norm else None
            batch_norm_kwargs = kwargs.get('batch_norm_kwargs', None)
            norm_kwargs = batch_norm_kwargs or {}
        if isinstance(channel_list, int):
            in_channels = channel_list
        if in_channels is not None:
            assert num_layers >= 1
            channel_list = [hidden_channels] * (num_layers - 1)
            channel_list = [in_channels] + channel_list + [out_channels]
        assert isinstance(channel_list, (tuple, list))
        assert len(channel_list) >= 2
        self.channel_list = channel_list
        self.act = activation_resolver(act, **act_kwargs or {})
        self.act_first = act_first
        self.plain_last = plain_last
        if isinstance(dropout, float):
            dropout = [dropout] * (len(channel_list) - 1)
            if plain_last:
                dropout[-1] = 0.0
        if len(dropout) != len(channel_list) - 1:
            raise ValueError(f'Number of dropout values provided ({len(dropout)} does not match the number of layers specified ({len(channel_list) - 1})')
        self.dropout = dropout
        if isinstance(bias, bool):
            bias = [bias] * (len(channel_list) - 1)
        if len(bias) != len(channel_list) - 1:
            raise ValueError(f'Number of bias values provided ({len(bias)}) does not match the number of layers specified ({len(channel_list) - 1})')
        self.lins = torch.nn.ModuleList()
        iterator = zip(channel_list[:-1], channel_list[1:], bias)
        for in_channels, out_channels, _bias in iterator:
            self.lins.append(Linear(in_channels, out_channels, bias=_bias))
        self.norms = torch.nn.ModuleList()
        iterator = channel_list[1:-1] if plain_last else channel_list[1:]
        for hidden_channels in iterator:
            if norm is not None:
                norm_layer = normalization_resolver(norm, hidden_channels, **norm_kwargs or {})
            else:
                norm_layer = Identity()
            self.norms.append(norm_layer)
        self.reset_parameters()

    @property
    def in_channels(self) ->int:
        """Size of each input sample."""
        return self.channel_list[0]

    @property
    def out_channels(self) ->int:
        """Size of each output sample."""
        return self.channel_list[-1]

    @property
    def num_layers(self) ->int:
        """The number of layers."""
        return len(self.channel_list) - 1

    def reset_parameters(self):
        for lin in self.lins:
            lin.reset_parameters()
        for norm in self.norms:
            if hasattr(norm, 'reset_parameters'):
                norm.reset_parameters()

    def forward(self, x: Tensor, return_emb: NoneType=None) ->Tensor:
        """"""
        for i, (lin, norm) in enumerate(zip(self.lins, self.norms)):
            x = lin(x)
            if self.act is not None and self.act_first:
                x = self.act(x)
            x = norm(x)
            if self.act is not None and not self.act_first:
                x = self.act(x)
            x = F.dropout(x, p=self.dropout[i], training=self.training)
            emb = x
        if self.plain_last:
            x = self.lins[-1](x)
            x = F.dropout(x, p=self.dropout[-1], training=self.training)
        return (x, emb) if isinstance(return_emb, bool) else x

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}({str(self.channel_list)[1:-1]})'


class GINWithJK(torch.nn.Module):

    def __init__(self, dataset, num_layers, hidden, mode='cat'):
        super().__init__()
        self.conv1 = GINConv(Sequential(Linear(dataset.num_features, hidden), ReLU(), Linear(hidden, hidden), ReLU(), BN(hidden)), train_eps=True)
        self.convs = torch.nn.ModuleList()
        for i in range(num_layers - 1):
            self.convs.append(GINConv(Sequential(Linear(hidden, hidden), ReLU(), Linear(hidden, hidden), ReLU(), BN(hidden)), train_eps=True))
        self.jump = JumpingKnowledge(mode)
        if mode == 'cat':
            self.lin1 = Linear(num_layers * hidden, hidden)
        else:
            self.lin1 = Linear(hidden, hidden)
        self.lin2 = Linear(hidden, dataset.num_classes)

    def reset_parameters(self):
        self.conv1.reset_parameters()
        for conv in self.convs:
            conv.reset_parameters()
        self.jump.reset_parameters()
        self.lin1.reset_parameters()
        self.lin2.reset_parameters()

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
        x = self.conv1(x, edge_index)
        xs = [x]
        for conv in self.convs:
            x = conv(x, edge_index)
            xs += [x]
        x = self.jump(xs)
        x = global_mean_pool(x, batch)
        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin2(x)
        return F.log_softmax(x, dim=-1)

    def __repr__(self):
        return self.__class__.__name__


class AttentionalAggregation(Aggregation):
    """The soft attention aggregation layer from the `"Graph Matching Networks
    for Learning the Similarity of Graph Structured Objects"
    <https://arxiv.org/abs/1904.12787>`_ paper

    .. math::
        \\mathbf{r}_i = \\sum_{n=1}^{N_i} \\mathrm{softmax} \\left(
        h_{\\mathrm{gate}} ( \\mathbf{x}_n ) \\right) \\cdot
        h_{\\mathbf{\\Theta}} ( \\mathbf{x}_n ),

    where :math:`h_{\\mathrm{gate}} \\colon \\mathbb{R}^F \\to
    \\mathbb{R}` and :math:`h_{\\mathbf{\\Theta}}` denote neural networks, *i.e.*
    MLPs.

    Args:
        gate_nn (torch.nn.Module): A neural network :math:`h_{\\mathrm{gate}}`
            that computes attention scores by mapping node features :obj:`x` of
            shape :obj:`[-1, in_channels]` to shape :obj:`[-1, 1]` (for
            node-level gating) or :obj:`[1, out_channels]` (for feature-level
            gating), *e.g.*, defined by :class:`torch.nn.Sequential`.
        nn (torch.nn.Module, optional): A neural network
            :math:`h_{\\mathbf{\\Theta}}` that maps node features :obj:`x` of
            shape :obj:`[-1, in_channels]` to shape :obj:`[-1, out_channels]`
            before combining them with the attention scores, *e.g.*, defined by
            :class:`torch.nn.Sequential`. (default: :obj:`None`)
    """

    def __init__(self, gate_nn: torch.nn.Module, nn: Optional[torch.nn.Module]=None):
        super().__init__()
        self.gate_nn = gate_nn
        self.nn = nn
        self.reset_parameters()

    def reset_parameters(self):
        reset(self.gate_nn)
        reset(self.nn)

    def forward(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2) ->Tensor:
        self.assert_two_dimensional_input(x, dim)
        gate = self.gate_nn(x)
        x = self.nn(x) if self.nn is not None else x
        gate = softmax(gate, index, ptr, dim_size, dim)
        return self.reduce(gate * x, index, ptr, dim_size, dim)

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}(gate_nn={self.gate_nn}, nn={self.nn})'


class GlobalAttentionNet(torch.nn.Module):

    def __init__(self, dataset, num_layers, hidden):
        super().__init__()
        self.conv1 = SAGEConv(dataset.num_features, hidden)
        self.convs = torch.nn.ModuleList()
        for i in range(num_layers - 1):
            self.convs.append(SAGEConv(hidden, hidden))
        self.att = AttentionalAggregation(Linear(hidden, 1))
        self.lin1 = Linear(hidden, hidden)
        self.lin2 = Linear(hidden, dataset.num_classes)

    def reset_parameters(self):
        self.conv1.reset_parameters()
        for conv in self.convs:
            conv.reset_parameters()
        self.att.reset_parameters()
        self.lin1.reset_parameters()
        self.lin2.reset_parameters()

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
        x = F.relu(self.conv1(x, edge_index))
        for conv in self.convs:
            x = F.relu(conv(x, edge_index))
        x = self.att(x, batch)
        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin2(x)
        return F.log_softmax(x, dim=-1)

    def __repr__(self):
        return self.__class__.__name__


class DynamicInheritance(type):

    def __call__(cls, *args, **kwargs):
        base_cls = kwargs.pop('_base_cls', Data)
        if issubclass(base_cls, Batch):
            new_cls = base_cls
        else:
            name = f'{base_cls.__name__}{cls.__name__}'


            class MetaResolver(type(cls), type(base_cls)):
                pass
            if name not in globals():
                globals()[name] = MetaResolver(name, (cls, base_cls), {})
            new_cls = globals()[name]
        params = list(inspect.signature(base_cls.__init__).parameters.items())
        for i, (k, v) in enumerate(params[1:]):
            if k == 'args' or k == 'kwargs':
                continue
            if i < len(args) or k in kwargs:
                continue
            if v.default is not inspect.Parameter.empty:
                continue
            kwargs[k] = None
        return super(DynamicInheritance, new_cls).__call__(*args, **kwargs)


class DynamicInheritanceGetter(object):

    def __call__(self, cls, base_cls):
        return cls(_base_cls=base_cls)


def cumsum(value: Union[Tensor, List[int]]) ->Tensor:
    if not isinstance(value, Tensor):
        value = torch.tensor(value)
    out = value.new_empty((value.size(0) + 1,) + value.size()[1:])
    out[0] = 0
    torch.cumsum(value, 0, out=out[1:])
    return out


def repeat_interleave(repeats: List[int], device: Optional[torch.device]=None) ->Tensor:
    outs = [torch.full((n,), i, device=device) for i, n in enumerate(repeats)]
    return torch.cat(outs, dim=0)


def _batch_and_ptr(slices: Any, device: Optional[torch.device]=None) ->Tuple[Any, Any]:
    if isinstance(slices, Tensor) and slices.dim() == 1:
        repeats = slices[1:] - slices[:-1]
        batch = repeat_interleave(repeats.tolist(), device=device)
        ptr = cumsum(repeats)
        return batch, ptr
    elif isinstance(slices, Mapping):
        batch, ptr = {}, {}
        for k, v in slices.items():
            batch[k], ptr[k] = _batch_and_ptr(v, device)
        return batch, ptr
    elif isinstance(slices, Sequence) and not isinstance(slices, str) and isinstance(slices[0], Tensor):
        batch, ptr = [], []
        for s in slices:
            sub_batch, sub_ptr = _batch_and_ptr(s, device)
            batch.append(sub_batch)
            ptr.append(sub_ptr)
        return batch, ptr
    else:
        return None, None


def get_incs(key, values: List[Any], data_list: List[BaseData], stores: List[BaseStorage]) ->Tensor:
    repeats = [data.__inc__(key, value, store) for value, data, store in zip(values, data_list, stores)]
    if isinstance(repeats[0], Tensor):
        repeats = torch.stack(repeats, dim=0)
    else:
        repeats = torch.tensor(repeats)
    return cumsum(repeats[:-1])


def _collate(key: str, values: List[Any], data_list: List[BaseData], stores: List[BaseStorage], increment: bool) ->Tuple[Any, Any, Any]:
    elem = values[0]
    if isinstance(elem, Tensor):
        key = str(key)
        cat_dim = data_list[0].__cat_dim__(key, elem, stores[0])
        if cat_dim is None or elem.dim() == 0:
            values = [value.unsqueeze(0) for value in values]
        slices = cumsum([value.size(cat_dim or 0) for value in values])
        if increment:
            incs = get_incs(key, values, data_list, stores)
            if incs.dim() > 1 or int(incs[-1]) != 0:
                values = [(value + inc) for value, inc in zip(values, incs)]
        else:
            incs = None
        if torch.utils.data.get_worker_info() is not None:
            numel = sum(value.numel() for value in values)
            storage = elem.storage()._new_shared(numel)
            shape = list(elem.size())
            if cat_dim is None or elem.dim() == 0:
                shape = [len(values)] + shape
            else:
                shape[cat_dim] = int(slices[-1])
            out = elem.new(storage).resize_(*shape)
        else:
            out = None
        value = torch.cat(values, dim=cat_dim or 0, out=out)
        return value, slices, incs
    elif isinstance(elem, SparseTensor) and increment:
        key = str(key)
        cat_dim = data_list[0].__cat_dim__(key, elem, stores[0])
        cat_dims = (cat_dim,) if isinstance(cat_dim, int) else cat_dim
        repeats = [[value.size(dim) for dim in cat_dims] for value in values]
        slices = cumsum(repeats)
        value = cat(values, dim=cat_dim)
        return value, slices, None
    elif isinstance(elem, (int, float)):
        value = torch.tensor(values)
        if increment:
            incs = get_incs(key, values, data_list, stores)
            if int(incs[-1]) != 0:
                value.add_(incs)
        else:
            incs = None
        slices = torch.arange(len(values) + 1)
        return value, slices, incs
    elif isinstance(elem, Mapping):
        value_dict, slice_dict, inc_dict = {}, {}, {}
        for key in elem.keys():
            value_dict[key], slice_dict[key], inc_dict[key] = _collate(key, [v[key] for v in values], data_list, stores, increment)
        return value_dict, slice_dict, inc_dict
    elif isinstance(elem, Sequence) and not isinstance(elem, str) and len(elem) > 0 and isinstance(elem[0], (Tensor, SparseTensor)):
        value_list, slice_list, inc_list = [], [], []
        for i in range(len(elem)):
            value, slices, incs = _collate(key, [v[i] for v in values], data_list, stores, increment)
            value_list.append(value)
            slice_list.append(slices)
            inc_list.append(incs)
        return value_list, slice_list, inc_list
    else:
        slices = torch.arange(len(values) + 1)
        return values, slices, None


def collate(cls, data_list: List[BaseData], increment: bool=True, add_batch: bool=True, follow_batch: Optional[List[str]]=None, exclude_keys: Optional[List[str]]=None) ->Tuple[BaseData, Mapping, Mapping]:
    if not isinstance(data_list, (list, tuple)):
        data_list = list(data_list)
    if cls != data_list[0].__class__:
        out = cls(_base_cls=data_list[0].__class__)
    else:
        out = cls()
    out.stores_as(data_list[0])
    follow_batch = set(follow_batch or [])
    exclude_keys = set(exclude_keys or [])
    key_to_stores = defaultdict(list)
    for data in data_list:
        for store in data.stores:
            key_to_stores[store._key].append(store)
    device = None
    slice_dict, inc_dict = defaultdict(dict), defaultdict(dict)
    for out_store in out.stores:
        key = out_store._key
        stores = key_to_stores[key]
        for attr in stores[0].keys():
            if attr in exclude_keys:
                continue
            values = [store[attr] for store in stores]
            if attr == 'num_nodes':
                out_store._num_nodes = values
                out_store.num_nodes = sum(values)
                continue
            if attr == 'ptr':
                continue
            value, slices, incs = _collate(attr, values, data_list, stores, increment)
            if isinstance(value, Tensor) and value.is_cuda:
                device = value.device
            out_store[attr] = value
            if key is not None:
                slice_dict[key][attr] = slices
                inc_dict[key][attr] = incs
            else:
                slice_dict[attr] = slices
                inc_dict[attr] = incs
            if attr in follow_batch:
                batch, ptr = _batch_and_ptr(slices, device)
                out_store[f'{attr}_batch'] = batch
                out_store[f'{attr}_ptr'] = ptr
        if add_batch and isinstance(stores[0], NodeStorage) and stores[0].can_infer_num_nodes:
            repeats = [store.num_nodes for store in stores]
            out_store.batch = repeat_interleave(repeats, device=device)
            out_store.ptr = cumsum(torch.tensor(repeats, device=device))
    return out, slice_dict, inc_dict


def _separate(key: str, value: Any, idx: int, slices: Any, incs: Any, batch: BaseData, store: BaseStorage, decrement: bool) ->Any:
    if isinstance(value, Tensor):
        key = str(key)
        cat_dim = batch.__cat_dim__(key, value, store)
        start, end = int(slices[idx]), int(slices[idx + 1])
        value = value.narrow(cat_dim or 0, start, end - start)
        value = value.squeeze(0) if cat_dim is None else value
        if decrement and (incs.dim() > 1 or int(incs[idx]) != 0):
            value = value - incs[idx]
        return value
    elif isinstance(value, SparseTensor) and decrement:
        key = str(key)
        cat_dim = batch.__cat_dim__(key, value, store)
        cat_dims = (cat_dim,) if isinstance(cat_dim, int) else cat_dim
        for i, dim in enumerate(cat_dims):
            start, end = int(slices[idx][i]), int(slices[idx + 1][i])
            value = value.narrow(dim, start, end - start)
        return value
    elif isinstance(value, Mapping):
        return {key: _separate(key, elem, idx, slices[key], incs[key] if decrement else None, batch, store, decrement) for key, elem in value.items()}
    elif isinstance(value, Sequence) and isinstance(value[0], Sequence) and not isinstance(value[0], str) and len(value[0]) > 0 and isinstance(value[0][0], (Tensor, SparseTensor)) and isinstance(slices, Sequence):
        return [elem[idx] for elem in value]
    elif isinstance(value, Sequence) and not isinstance(value, str) and isinstance(value[0], (Tensor, SparseTensor)) and isinstance(slices, Sequence):
        return [_separate(key, elem, idx, slices[i], incs[i] if decrement else None, batch, store, decrement) for i, elem in enumerate(value)]
    else:
        return value[idx]


def separate(cls, batch: BaseData, idx: int, slice_dict: Any, inc_dict: Any=None, decrement: bool=True) ->BaseData:
    data = cls().stores_as(batch)
    for batch_store, data_store in zip(batch.stores, data.stores):
        key = batch_store._key
        if key is not None:
            attrs = slice_dict[key].keys()
        else:
            attrs = set(batch_store.keys())
            attrs = [attr for attr in slice_dict.keys() if attr in attrs]
        for attr in attrs:
            if key is not None:
                slices = slice_dict[key][attr]
                incs = inc_dict[key][attr] if decrement else None
            else:
                slices = slice_dict[attr]
                incs = inc_dict[attr] if decrement else None
            data_store[attr] = _separate(attr, batch_store[attr], idx, slices, incs, batch, batch_store, decrement)
        if hasattr(batch_store, '_num_nodes'):
            data_store.num_nodes = batch_store._num_nodes[idx]
    return data


class Batch(metaclass=DynamicInheritance):
    """A data object describing a batch of graphs as one big (disconnected)
    graph.
    Inherits from :class:`torch_geometric.data.Data` or
    :class:`torch_geometric.data.HeteroData`.
    In addition, single graphs can be identified via the assignment vector
    :obj:`batch`, which maps each node to its respective graph identifier.
    """

    @classmethod
    def from_data_list(cls, data_list: List[BaseData], follow_batch: Optional[List[str]]=None, exclude_keys: Optional[List[str]]=None):
        """Constructs a :class:`~torch_geometric.data.Batch` object from a
        Python list of :class:`~torch_geometric.data.Data` or
        :class:`~torch_geometric.data.HeteroData` objects.
        The assignment vector :obj:`batch` is created on the fly.
        In addition, creates assignment vectors for each key in
        :obj:`follow_batch`.
        Will exclude any keys given in :obj:`exclude_keys`."""
        batch, slice_dict, inc_dict = collate(cls, data_list=data_list, increment=True, add_batch=not isinstance(data_list[0], Batch), follow_batch=follow_batch, exclude_keys=exclude_keys)
        batch._num_graphs = len(data_list)
        batch._slice_dict = slice_dict
        batch._inc_dict = inc_dict
        return batch

    def get_example(self, idx: int) ->BaseData:
        """Gets the :class:`~torch_geometric.data.Data` or
        :class:`~torch_geometric.data.HeteroData` object at index :obj:`idx`.
        The :class:`~torch_geometric.data.Batch` object must have been created
        via :meth:`from_data_list` in order to be able to reconstruct the
        initial object."""
        if not hasattr(self, '_slice_dict'):
            raise RuntimeError("Cannot reconstruct 'Data' object from 'Batch' because 'Batch' was not created via 'Batch.from_data_list()'")
        data = separate(cls=self.__class__.__bases__[-1], batch=self, idx=idx, slice_dict=self._slice_dict, inc_dict=self._inc_dict, decrement=True)
        return data

    def index_select(self, idx: IndexType) ->List[BaseData]:
        """Creates a subset of :class:`~torch_geometric.data.Data` or
        :class:`~torch_geometric.data.HeteroData` objects from specified
        indices :obj:`idx`.
        Indices :obj:`idx` can be a slicing object, *e.g.*, :obj:`[2:5]`, a
        list, a tuple, or a :obj:`torch.Tensor` or :obj:`np.ndarray` of type
        long or bool.
        The :class:`~torch_geometric.data.Batch` object must have been created
        via :meth:`from_data_list` in order to be able to reconstruct the
        initial objects."""
        if isinstance(idx, slice):
            idx = list(range(self.num_graphs)[idx])
        elif isinstance(idx, Tensor) and idx.dtype == torch.long:
            idx = idx.flatten().tolist()
        elif isinstance(idx, Tensor) and idx.dtype == torch.bool:
            idx = idx.flatten().nonzero(as_tuple=False).flatten().tolist()
        elif isinstance(idx, np.ndarray) and idx.dtype == np.int64:
            idx = idx.flatten().tolist()
        elif isinstance(idx, np.ndarray) and idx.dtype == bool:
            idx = idx.flatten().nonzero()[0].flatten().tolist()
        elif isinstance(idx, Sequence) and not isinstance(idx, str):
            pass
        else:
            raise IndexError(f"Only slices (':'), list, tuples, torch.tensor and np.ndarray of dtype long or bool are valid indices (got '{type(idx).__name__}')")
        return [self.get_example(i) for i in idx]

    def __getitem__(self, idx: Union[int, np.integer, str, IndexType]) ->Any:
        if isinstance(idx, (int, np.integer)) or isinstance(idx, Tensor) and idx.dim() == 0 or isinstance(idx, np.ndarray) and np.isscalar(idx):
            return self.get_example(idx)
        elif isinstance(idx, str) or isinstance(idx, tuple) and isinstance(idx[0], str):
            return super().__getitem__(idx)
        else:
            return self.index_select(idx)

    def to_data_list(self) ->List[BaseData]:
        """Reconstructs the list of :class:`~torch_geometric.data.Data` or
        :class:`~torch_geometric.data.HeteroData` objects from the
        :class:`~torch_geometric.data.Batch` object.
        The :class:`~torch_geometric.data.Batch` object must have been created
        via :meth:`from_data_list` in order to be able to reconstruct the
        initial objects."""
        return [self.get_example(i) for i in range(self.num_graphs)]

    @property
    def num_graphs(self) ->int:
        """Returns the number of graphs in the batch."""
        if hasattr(self, '_num_graphs'):
            return self._num_graphs
        elif hasattr(self, 'ptr'):
            return self.ptr.numel() - 1
        elif hasattr(self, 'batch'):
            return int(self.batch.max()) + 1
        else:
            raise ValueError('Can not infer the number of graphs')

    def __len__(self) ->int:
        return self.num_graphs

    def __reduce__(self):
        state = self.__dict__.copy()
        return DynamicInheritanceGetter(), self.__class__.__bases__, state


def graclus(edge_index, weight: Optional[torch.Tensor]=None, num_nodes: Optional[int]=None):
    """A greedy clustering algorithm from the `"Weighted Graph Cuts without
    Eigenvectors: A Multilevel Approach" <http://www.cs.utexas.edu/users/
    inderjit/public_papers/multilevel_pami.pdf>`_ paper of picking an unmarked
    vertex and matching it with one of its unmarked neighbors (that maximizes
    its edge weight).
    The GPU algorithm is adapted from the `"A GPU Algorithm for Greedy Graph
    Matching" <http://www.staff.science.uu.nl/~bisse101/Articles/match12.pdf>`_
    paper.

    Args:
        edge_index (LongTensor): The edge indices.
        weight (Tensor, optional): One-dimensional edge weights.
            (default: :obj:`None`)
        num_nodes (int, optional): The number of nodes, *i.e.*
            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)

    :rtype: :class:`LongTensor`
    """
    if graclus_cluster is None:
        raise ImportError('`graclus` requires `torch-cluster`.')
    return graclus_cluster(edge_index[0], edge_index[1], weight, num_nodes)


def _max_pool_x(cluster: Tensor, x: Tensor, size: Optional[int]=None) ->Tensor:
    return scatter(x, cluster, dim=0, dim_size=size, reduce='max')


def consecutive_cluster(src):
    unique, inv = torch.unique(src, sorted=True, return_inverse=True)
    perm = torch.arange(inv.size(0), dtype=inv.dtype, device=inv.device)
    perm = inv.new_empty(unique.size(0)).scatter_(0, inv, perm)
    return inv, perm


def pool_batch(perm, batch):
    return batch[perm]


def pool_edge(cluster, edge_index, edge_attr: Optional[torch.Tensor]=None):
    num_nodes = cluster.size(0)
    edge_index = cluster[edge_index.view(-1)].view(2, -1)
    edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)
    if edge_index.numel() > 0:
        edge_index, edge_attr = coalesce(edge_index, edge_attr, num_nodes, num_nodes)
    return edge_index, edge_attr


def pool_pos(cluster, pos):
    return scatter_mean(pos, cluster, dim=0)


class Graclus(torch.nn.Module):

    def __init__(self, dataset, num_layers, hidden):
        super().__init__()
        self.conv1 = GraphConv(dataset.num_features, hidden, aggr='mean')
        self.convs = torch.nn.ModuleList()
        for i in range(num_layers - 1):
            self.convs.append(GraphConv(hidden, hidden, aggr='mean'))
        self.jump = JumpingKnowledge(mode='cat')
        self.lin1 = Linear(num_layers * hidden, hidden)
        self.lin2 = Linear(hidden, dataset.num_classes)

    def reset_parameters(self):
        self.conv1.reset_parameters()
        for conv in self.convs:
            conv.reset_parameters()
        self.jump.reset_parameters()
        self.lin1.reset_parameters()
        self.lin2.reset_parameters()

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
        x = F.relu(self.conv1(x, edge_index))
        xs = [global_mean_pool(x, batch)]
        for i, conv in enumerate(self.convs):
            x = F.relu(conv(x, edge_index))
            xs += [global_mean_pool(x, batch)]
            if i % 2 == 0 and i < len(self.convs) - 1:
                cluster = graclus(edge_index, num_nodes=x.size(0))
                data = Batch(x=x, edge_index=edge_index, batch=batch)
                data = max_pool(cluster, data)
                x, edge_index, batch = data.x, data.edge_index, data.batch
        x = self.jump(xs)
        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin2(x)
        return F.log_softmax(x, dim=-1)

    def __repr__(self):
        return self.__class__.__name__


class GraphSAGEWithJK(torch.nn.Module):

    def __init__(self, dataset, num_layers, hidden, mode='cat'):
        super().__init__()
        self.conv1 = SAGEConv(dataset.num_features, hidden)
        self.convs = torch.nn.ModuleList()
        for i in range(num_layers - 1):
            self.convs.append(SAGEConv(hidden, hidden))
        self.jump = JumpingKnowledge(mode)
        if mode == 'cat':
            self.lin1 = Linear(num_layers * hidden, hidden)
        else:
            self.lin1 = Linear(hidden, hidden)
        self.lin2 = Linear(hidden, dataset.num_classes)

    def reset_parameters(self):
        self.conv1.reset_parameters()
        for conv in self.convs:
            conv.reset_parameters()
        self.jump.reset_parameters()
        self.lin1.reset_parameters()
        self.lin2.reset_parameters()

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
        x = F.relu(self.conv1(x, edge_index))
        xs = [x]
        for conv in self.convs:
            x = F.relu(conv(x, edge_index))
            xs += [x]
        x = self.jump(xs)
        x = global_mean_pool(x, batch)
        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin2(x)
        return F.log_softmax(x, dim=-1)

    def __repr__(self):
        return self.__class__.__name__


def filter_adj(row: Tensor, col: Tensor, edge_attr: OptTensor, mask: Tensor) ->Tuple[Tensor, Tensor, OptTensor]:
    return row[mask], col[mask], None if edge_attr is None else edge_attr[mask]


class SAGPool(torch.nn.Module):

    def __init__(self, dataset, num_layers, hidden, ratio=0.8):
        super().__init__()
        self.conv1 = GraphConv(dataset.num_features, hidden, aggr='mean')
        self.convs = torch.nn.ModuleList()
        self.pools = torch.nn.ModuleList()
        self.convs.extend([GraphConv(hidden, hidden, aggr='mean') for i in range(num_layers - 1)])
        self.pools.extend([SAGPooling(hidden, ratio) for i in range(num_layers // 2)])
        self.jump = JumpingKnowledge(mode='cat')
        self.lin1 = Linear(num_layers * hidden, hidden)
        self.lin2 = Linear(hidden, dataset.num_classes)

    def reset_parameters(self):
        self.conv1.reset_parameters()
        for conv in self.convs:
            conv.reset_parameters()
        for pool in self.pools:
            pool.reset_parameters()
        self.lin1.reset_parameters()
        self.lin2.reset_parameters()

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
        x = F.relu(self.conv1(x, edge_index))
        xs = [global_mean_pool(x, batch)]
        for i, conv in enumerate(self.convs):
            x = F.relu(conv(x, edge_index))
            xs += [global_mean_pool(x, batch)]
            if i % 2 == 0 and i < len(self.convs) - 1:
                pool = self.pools[i // 2]
                x, edge_index, _, batch, _, _ = pool(x, edge_index, batch=batch)
        x = self.jump(xs)
        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin2(x)
        return F.log_softmax(x, dim=-1)

    def __repr__(self):
        return self.__class__.__name__


class Set2Set(Aggregation):
    """The Set2Set aggregation operator based on iterative content-based
    attention, as described in the `"Order Matters: Sequence to sequence for
    Sets" <https://arxiv.org/abs/1511.06391>`_ paper

    .. math::
        \\mathbf{q}_t &= \\mathrm{LSTM}(\\mathbf{q}^{*}_{t-1})

        \\alpha_{i,t} &= \\mathrm{softmax}(\\mathbf{x}_i \\cdot \\mathbf{q}_t)

        \\mathbf{r}_t &= \\sum_{i=1}^N \\alpha_{i,t} \\mathbf{x}_i

        \\mathbf{q}^{*}_t &= \\mathbf{q}_t \\, \\Vert \\, \\mathbf{r}_t,

    where :math:`\\mathbf{q}^{*}_T` defines the output of the layer with twice
    the dimensionality as the input.

    Args:
        in_channels (int): Size of each input sample.
        processing_steps (int): Number of iterations :math:`T`.
        **kwargs (optional): Additional arguments of :class:`torch.nn.LSTM`.
    """

    def __init__(self, in_channels: int, processing_steps: int, **kwargs):
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = 2 * in_channels
        self.processing_steps = processing_steps
        self.lstm = torch.nn.LSTM(self.out_channels, in_channels, **kwargs)
        self.reset_parameters()

    def reset_parameters(self):
        self.lstm.reset_parameters()

    def forward(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2) ->Tensor:
        self.assert_index_present(index)
        self.assert_two_dimensional_input(x, dim)
        h = x.new_zeros((self.lstm.num_layers, dim_size, x.size(-1))), x.new_zeros((self.lstm.num_layers, dim_size, x.size(-1)))
        q_star = x.new_zeros(dim_size, self.out_channels)
        for _ in range(self.processing_steps):
            q, h = self.lstm(q_star.unsqueeze(0), h)
            q = q.view(dim_size, self.in_channels)
            e = (x * q[index]).sum(dim=-1, keepdim=True)
            a = softmax(e, index, ptr, dim_size, dim)
            r = self.reduce(a * x, index, ptr, dim_size, dim, reduce='add')
            q_star = torch.cat([q, r], dim=-1)
        return q_star

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}({self.in_channels}, {self.out_channels})'


class Set2SetNet(torch.nn.Module):

    def __init__(self, dataset, num_layers, hidden):
        super().__init__()
        self.conv1 = SAGEConv(dataset.num_features, hidden)
        self.convs = torch.nn.ModuleList()
        for i in range(num_layers - 1):
            self.convs.append(SAGEConv(hidden, hidden))
        self.set2set = Set2Set(hidden, processing_steps=4)
        self.lin1 = Linear(2 * hidden, hidden)
        self.lin2 = Linear(hidden, dataset.num_classes)

    def reset_parameters(self):
        self.conv1.reset_parameters()
        for conv in self.convs:
            conv.reset_parameters()
        self.set2set.reset_parameters()
        self.lin1.reset_parameters()
        self.lin2.reset_parameters()

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
        x = F.relu(self.conv1(x, edge_index))
        for conv in self.convs:
            x = F.relu(conv(x, edge_index))
        x = self.set2set(x, batch)
        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin2(x)
        return F.log_softmax(x, dim=-1)

    def __repr__(self):
        return self.__class__.__name__


class SortAggregation(Aggregation):
    """The pooling operator from the `"An End-to-End Deep Learning
    Architecture for Graph Classification"
    <https://www.cse.wustl.edu/~muhan/papers/AAAI_2018_DGCNN.pdf>`_ paper,
    where node features are sorted in descending order based on their last
    feature channel. The first :math:`k` nodes form the output of the layer.

    Args:
        k (int): The number of nodes to hold for each graph.
    """

    def __init__(self, k: int):
        super().__init__()
        self.k = k

    def forward(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2) ->Tensor:
        fill_value = x.min().item() - 1
        batch_x, _ = self.to_dense_batch(x, index, ptr, dim_size, dim, fill_value=fill_value)
        B, N, D = batch_x.size()
        _, perm = batch_x[:, :, -1].sort(dim=-1, descending=True)
        arange = torch.arange(B, dtype=torch.long, device=perm.device) * N
        perm = perm + arange.view(-1, 1)
        batch_x = batch_x.view(B * N, D)
        batch_x = batch_x[perm]
        batch_x = batch_x.view(B, N, D)
        if N >= self.k:
            batch_x = batch_x[:, :self.k].contiguous()
        else:
            expand_batch_x = batch_x.new_full((B, self.k - N, D), fill_value)
            batch_x = torch.cat([batch_x, expand_batch_x], dim=1)
        batch_x[batch_x == fill_value] = 0
        x = batch_x.view(B, self.k * D)
        return x

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}(k={self.k})'


@deprecated(details="use 'nn.aggr.SortAggr' instead", func_name='nn.glob.global_sort_pool')
def global_sort_pool(x, index, k):
    module = SortAggregation(k=k)
    return module(x, index=index)


class SortPool(torch.nn.Module):

    def __init__(self, dataset, num_layers, hidden):
        super().__init__()
        self.k = 30
        self.conv1 = SAGEConv(dataset.num_features, hidden)
        self.convs = torch.nn.ModuleList()
        for i in range(num_layers - 1):
            self.convs.append(SAGEConv(hidden, hidden))
        self.conv1d = Conv1d(hidden, 32, 5)
        self.lin1 = Linear(32 * (self.k - 5 + 1), hidden)
        self.lin2 = Linear(hidden, dataset.num_classes)

    def reset_parameters(self):
        self.conv1.reset_parameters()
        for conv in self.convs:
            conv.reset_parameters()
        self.conv1d.reset_parameters()
        self.lin1.reset_parameters()
        self.lin2.reset_parameters()

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
        x = F.relu(self.conv1(x, edge_index))
        for conv in self.convs:
            x = F.relu(conv(x, edge_index))
        x = global_sort_pool(x, batch, self.k)
        x = x.view(len(x), self.k, -1).permute(0, 2, 1)
        x = F.relu(self.conv1d(x))
        x = x.view(len(x), -1)
        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin2(x)
        return F.log_softmax(x, dim=-1)

    def __repr__(self):
        return self.__class__.__name__


def uniform(size: int, value: Any):
    if isinstance(value, Tensor):
        bound = 1.0 / math.sqrt(size)
        value.data.uniform_(-bound, bound)
    else:
        for v in (value.parameters() if hasattr(value, 'parameters') else []):
            uniform(size, v)
        for v in (value.buffers() if hasattr(value, 'buffers') else []):
            uniform(size, v)


class TopKPooling(torch.nn.Module):
    """:math:`\\mathrm{top}_k` pooling operator from the `"Graph U-Nets"
    <https://arxiv.org/abs/1905.05178>`_, `"Towards Sparse
    Hierarchical Graph Classifiers" <https://arxiv.org/abs/1811.01287>`_
    and `"Understanding Attention and Generalization in Graph Neural
    Networks" <https://arxiv.org/abs/1905.02850>`_ papers

    if min_score :math:`\\tilde{\\alpha}` is None:

        .. math::
            \\mathbf{y} &= \\frac{\\mathbf{X}\\mathbf{p}}{\\| \\mathbf{p} \\|}

            \\mathbf{i} &= \\mathrm{top}_k(\\mathbf{y})

            \\mathbf{X}^{\\prime} &= (\\mathbf{X} \\odot
            \\mathrm{tanh}(\\mathbf{y}))_{\\mathbf{i}}

            \\mathbf{A}^{\\prime} &= \\mathbf{A}_{\\mathbf{i},\\mathbf{i}}

    if min_score :math:`\\tilde{\\alpha}` is a value in [0, 1]:

        .. math::
            \\mathbf{y} &= \\mathrm{softmax}(\\mathbf{X}\\mathbf{p})

            \\mathbf{i} &= \\mathbf{y}_i > \\tilde{\\alpha}

            \\mathbf{X}^{\\prime} &= (\\mathbf{X} \\odot \\mathbf{y})_{\\mathbf{i}}

            \\mathbf{A}^{\\prime} &= \\mathbf{A}_{\\mathbf{i},\\mathbf{i}},

    where nodes are dropped based on a learnable projection score
    :math:`\\mathbf{p}`.

    Args:
        in_channels (int): Size of each input sample.
        ratio (float or int): Graph pooling ratio, which is used to compute
            :math:`k = \\lceil \\mathrm{ratio} \\cdot N \\rceil`, or the value
            of :math:`k` itself, depending on whether the type of :obj:`ratio`
            is :obj:`float` or :obj:`int`.
            This value is ignored if :obj:`min_score` is not :obj:`None`.
            (default: :obj:`0.5`)
        min_score (float, optional): Minimal node score :math:`\\tilde{\\alpha}`
            which is used to compute indices of pooled nodes
            :math:`\\mathbf{i} = \\mathbf{y}_i > \\tilde{\\alpha}`.
            When this value is not :obj:`None`, the :obj:`ratio` argument is
            ignored. (default: :obj:`None`)
        multiplier (float, optional): Coefficient by which features gets
            multiplied after pooling. This can be useful for large graphs and
            when :obj:`min_score` is used. (default: :obj:`1`)
        nonlinearity (torch.nn.functional, optional): The nonlinearity to use.
            (default: :obj:`torch.tanh`)
    """

    def __init__(self, in_channels: int, ratio: Union[int, float]=0.5, min_score: Optional[float]=None, multiplier: float=1.0, nonlinearity: Callable=torch.tanh):
        super().__init__()
        self.in_channels = in_channels
        self.ratio = ratio
        self.min_score = min_score
        self.multiplier = multiplier
        self.nonlinearity = nonlinearity
        self.weight = Parameter(torch.Tensor(1, in_channels))
        self.reset_parameters()

    def reset_parameters(self):
        size = self.in_channels
        uniform(size, self.weight)

    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Optional[Tensor]=None, batch: Optional[Tensor]=None, attn: Optional[Tensor]=None) ->Tuple[Tensor, Tensor, Optional[Tensor], Tensor, Tensor, Tensor]:
        """"""
        if batch is None:
            batch = edge_index.new_zeros(x.size(0))
        attn = x if attn is None else attn
        attn = attn.unsqueeze(-1) if attn.dim() == 1 else attn
        score = (attn * self.weight).sum(dim=-1)
        if self.min_score is None:
            score = self.nonlinearity(score / self.weight.norm(p=2, dim=-1))
        else:
            score = softmax(score, batch)
        perm = topk(score, self.ratio, batch, self.min_score)
        x = x[perm] * score[perm].view(-1, 1)
        x = self.multiplier * x if self.multiplier != 1 else x
        batch = batch[perm]
        edge_index, edge_attr = filter_adj(edge_index, edge_attr, perm, num_nodes=score.size(0))
        return x, edge_index, edge_attr, batch, perm, score[perm]

    def __repr__(self) ->str:
        if self.min_score is None:
            ratio = f'ratio={self.ratio}'
        else:
            ratio = f'min_score={self.min_score}'
        return f'{self.__class__.__name__}({self.in_channels}, {ratio}, multiplier={self.multiplier})'


class TopK(torch.nn.Module):

    def __init__(self, dataset, num_layers, hidden, ratio=0.8):
        super().__init__()
        self.conv1 = GraphConv(dataset.num_features, hidden, aggr='mean')
        self.convs = torch.nn.ModuleList()
        self.pools = torch.nn.ModuleList()
        self.convs.extend([GraphConv(hidden, hidden, aggr='mean') for i in range(num_layers - 1)])
        self.pools.extend([TopKPooling(hidden, ratio) for i in range(num_layers // 2)])
        self.jump = JumpingKnowledge(mode='cat')
        self.lin1 = Linear(num_layers * hidden, hidden)
        self.lin2 = Linear(hidden, dataset.num_classes)

    def reset_parameters(self):
        self.conv1.reset_parameters()
        for conv in self.convs:
            conv.reset_parameters()
        for pool in self.pools:
            pool.reset_parameters()
        self.lin1.reset_parameters()
        self.lin2.reset_parameters()

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
        x = F.relu(self.conv1(x, edge_index))
        xs = [global_mean_pool(x, batch)]
        for i, conv in enumerate(self.convs):
            x = F.relu(conv(x, edge_index))
            xs += [global_mean_pool(x, batch)]
            if i % 2 == 0 and i < len(self.convs) - 1:
                pool = self.pools[i // 2]
                x, edge_index, _, batch, _, _ = pool(x, edge_index, batch=batch)
        x = self.jump(xs)
        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin2(x)
        return F.log_softmax(x, dim=-1)

    def __repr__(self):
        return self.__class__.__name__


def add_self_loops(edge_index: Tensor, edge_attr: OptTensor=None, fill_value: Union[float, Tensor, str]=None, num_nodes: Optional[int]=None) ->Tuple[Tensor, OptTensor]:
    """Adds a self-loop :math:`(i,i) \\in \\mathcal{E}` to every node
    :math:`i \\in \\mathcal{V}` in the graph given by :attr:`edge_index`.
    In case the graph is weighted or has multi-dimensional edge features
    (:obj:`edge_attr != None`), edge features of self-loops will be added
    according to :obj:`fill_value`.

    Args:
        edge_index (LongTensor): The edge indices.
        edge_attr (Tensor, optional): Edge weights or multi-dimensional edge
            features. (default: :obj:`None`)
        fill_value (float or Tensor or str, optional): The way to generate
            edge features of self-loops (in case :obj:`edge_attr != None`).
            If given as :obj:`float` or :class:`torch.Tensor`, edge features of
            self-loops will be directly given by :obj:`fill_value`.
            If given as :obj:`str`, edge features of self-loops are computed by
            aggregating all features of edges that point to the specific node,
            according to a reduce operation. (:obj:`"add"`, :obj:`"mean"`,
            :obj:`"min"`, :obj:`"max"`, :obj:`"mul"`). (default: :obj:`1.`)
        num_nodes (int, optional): The number of nodes, *i.e.*
            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)

    :rtype: (:class:`LongTensor`, :class:`Tensor`)

    Examples:

        >>> edge_index = torch.tensor([[0, 1, 0],
        ...                            [1, 0, 0]])
        >>> edge_weight = torch.tensor([0.5, 0.5, 0.5])
        >>> add_self_loops(edge_index)
        (tensor([[0, 1, 0, 0, 1],
                [1, 0, 0, 0, 1]]),
        None)

        >>> add_self_loops(edge_index, edge_weight)
        (tensor([[0, 1, 0, 0, 1],
                [1, 0, 0, 0, 1]]),
        tensor([0.5000, 0.5000, 0.5000, 1.0000, 1.0000]))

        >>> # edge features of self-loops are filled by constant `2.0`
        >>> add_self_loops(edge_index, edge_weight,
        ...                fill_value=2.)
        (tensor([[0, 1, 0, 0, 1],
                [1, 0, 0, 0, 1]]),
        tensor([0.5000, 0.5000, 0.5000, 2.0000, 2.0000]))

        >>> # Use 'add' operation to merge edge features for self-loops
        >>> add_self_loops(edge_index, edge_weight,
        ...                fill_value='add')
        (tensor([[0, 1, 0, 0, 1],
                [1, 0, 0, 0, 1]]),
        tensor([0.5000, 0.5000, 0.5000, 1.0000, 0.5000]))
    """
    N = maybe_num_nodes(edge_index, num_nodes)
    loop_index = torch.arange(0, N, dtype=torch.long, device=edge_index.device)
    loop_index = loop_index.unsqueeze(0).repeat(2, 1)
    if edge_attr is not None:
        if fill_value is None:
            loop_attr = edge_attr.new_full((N,) + edge_attr.size()[1:], 1.0)
        elif isinstance(fill_value, (int, float)):
            loop_attr = edge_attr.new_full((N,) + edge_attr.size()[1:], fill_value)
        elif isinstance(fill_value, Tensor):
            loop_attr = fill_value
            if edge_attr.dim() != loop_attr.dim():
                loop_attr = loop_attr.unsqueeze(0)
            sizes = [N] + [1] * (loop_attr.dim() - 1)
            loop_attr = loop_attr.repeat(*sizes)
        elif isinstance(fill_value, str):
            loop_attr = scatter(edge_attr, edge_index[1], dim=0, dim_size=N, reduce=fill_value)
        else:
            raise AttributeError("No valid 'fill_value' provided")
        edge_attr = torch.cat([edge_attr, loop_attr], dim=0)
    edge_index = torch.cat([edge_index, loop_index], dim=1)
    return edge_index, edge_attr


def glorot(value: Any):
    if isinstance(value, Tensor):
        stdv = math.sqrt(6.0 / (value.size(-2) + value.size(-1)))
        value.data.uniform_(-stdv, stdv)
    else:
        for v in (value.parameters() if hasattr(value, 'parameters') else []):
            glorot(v)
        for v in (value.buffers() if hasattr(value, 'buffers') else []):
            glorot(v)


class GATSPMVConv(torch.nn.Module):

    def __init__(self, g, in_channels, out_channels, heads=1, negative_slope=0.2, dropout=0):
        super().__init__()
        self.g = g
        self.out_channels = out_channels
        self.heads = heads
        self.negative_slope = negative_slope
        self.dropout = dropout
        self.weight = Parameter(torch.Tensor(in_channels, heads * out_channels))
        self.att_l = Parameter(torch.Tensor(heads, out_channels, 1))
        self.att_r = Parameter(torch.Tensor(heads, out_channels, 1))
        self.bias = Parameter(torch.Tensor(heads * out_channels))
        self.softmax = EdgeSoftmax()
        self.reset_parameters()

    def reset_parameters(self):
        glorot(self.weight)
        glorot(self.att_l)
        glorot(self.att_r)
        zeros(self.bias)

    def forward(self, x):
        x = torch.matmul(x, self.weight)
        x = x.reshape((x.size(0), self.heads, -1))
        head_x = x.transpose(0, 1)
        a1 = torch.bmm(head_x, self.att_l).transpose(0, 1)
        a2 = torch.bmm(head_x, self.att_r).transpose(0, 1)
        self.g.ndata.update({'x': x, 'a1': a1, 'a2': a2})
        self.g.apply_edges(self.edge_attention)
        self.edge_softmax()
        self.g.update_all(fn.src_mul_edge('x', 'a', 'x'), fn.sum('x', 'x'))
        x = self.g.ndata['x'] / self.g.ndata['z']
        return x.view(-1, self.heads * self.out_channels)

    def edge_attention(self, edge):
        a = F.leaky_relu(edge.src['a1'] + edge.dst['a2'], self.negative_slope)
        return {'a': a}

    def edge_softmax(self):
        alpha, normalizer = self.softmax(self.g.edata['a'], self.g)
        self.g.ndata['z'] = normalizer
        if self.training and self.dropout > 0:
            alpha = F.dropout(alpha, p=self.dropout, training=True)
        self.g.edata['a'] = alpha


class GATSPMV(torch.nn.Module):

    def __init__(self, g, in_channels, out_channels):
        super().__init__()
        self.g = g
        self.conv1 = GATSPMVConv(g, in_channels, 8, 8, 0.6, 0.2)
        self.conv2 = GATSPMVConv(g, 64, out_channels, 1, 0.6, 0.2)

    def forward(self, x):
        x = F.dropout(x, p=0.6, training=self.training)
        x = F.elu(self.conv1(x))
        x = F.dropout(x, p=0.6, training=self.training)
        x = self.conv2(x)
        return F.log_softmax(x, dim=1)


class GCNSPMVConv(torch.nn.Module):

    def __init__(self, g, in_channels, out_channels):
        super().__init__()
        self.g = g
        self.weight = Parameter(torch.Tensor(in_channels, out_channels))
        self.bias = Parameter(torch.Tensor(out_channels))
        self.reset_parameters()

    def reset_parameters(self):
        glorot(self.weight)
        zeros(self.bias)

    def forward(self, x):
        x = torch.matmul(x, self.weight)
        self.g.ndata['x'] = x * self.g.ndata['norm']
        self.g.update_all(fn.copy_src(src='x', out='m'), fn.sum(msg='m', out='x'))
        x = self.g.ndata.pop('x') * self.g.ndata['norm']
        x = x + self.bias
        return x


class GCNSPMV(torch.nn.Module):

    def __init__(self, g, in_channels, out_channels):
        super().__init__()
        self.conv1 = GCNSPMVConv(g, in_channels, 16)
        self.conv2 = GCNSPMVConv(g, 16, out_channels)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.dropout(x, training=self.training)
        x = self.conv2(x)
        return F.log_softmax(x, dim=1)


def masked_edge_index(edge_index, edge_mask):
    if isinstance(edge_index, Tensor):
        return edge_index[:, edge_mask]
    else:
        return masked_select_nnz(edge_index, edge_mask, layout='coo')


class RGCN(torch.nn.Module):

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv = GraphConv(in_channels, out_channels)
        self.lin = Linear(in_channels, out_channels, bias=True)

    def forward(self, x, edge_index):
        return self.lin(x) + self.conv(x, edge_index)


class RGCNSPMVConv(torch.nn.Module):

    def __init__(self, g, in_channels, out_channels, num_relations, num_bases):
        super().__init__()
        self.g = g
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.num_relations = num_relations
        self.num_bases = num_bases
        self.basis = Param(torch.Tensor(num_bases, in_channels, out_channels))
        self.att = Param(torch.Tensor(num_relations, num_bases))
        self.root = Param(torch.Tensor(in_channels, out_channels))
        self.bias = Param(torch.Tensor(out_channels))
        self.reset_parameters()

    def reset_parameters(self):
        size = self.num_bases * self.in_channels
        uniform(size, self.basis)
        uniform(size, self.att)
        uniform(size, self.root)
        uniform(size, self.bias)

    def forward(self, x):
        self.w = torch.matmul(self.att, self.basis.view(self.num_bases, -1))
        self.w = self.w.view(self.num_relations, self.in_channels, self.out_channels)
        if x is None:

            def msg_func(edge):
                w = self.w.view(-1, self.out_channels)
                index = edge.data['type'] * self.in_channels + edge.src['id']
                m = w.index_select(0, index) * edge.data['norm'].unsqueeze(1)
                return {'m': m}
        else:
            self.g.ndata['x'] = x

            def msg_func(edge):
                w = self.w.index_select(0, edge.data['type'])
                m = torch.bmm(edge.src['x'].unsqueeze(1), w).squeeze()
                m = m * edge.data['norm'].unsqueeze(1)
                return {'m': m}
        self.g.update_all(msg_func, fn.sum(msg='m', out='x'))
        out = self.g.ndata.pop('x')
        if x is None:
            out = out + self.root
        else:
            out = out + torch.matmul(x, self.root)
        out = out + self.bias
        return out


class RGCNSPMV(torch.nn.Module):

    def __init__(self, g, in_channels, out_channels, num_relations):
        super().__init__()
        self.conv1 = RGCNSPMVConv(g, in_channels, 16, num_relations, num_bases=30)
        self.conv2 = RGCNSPMVConv(g, 16, out_channels, num_relations, num_bases=30)

    def forward(self, x):
        x = F.relu(self.conv1(None))
        x = self.conv2(x)
        return F.log_softmax(x, dim=1)


Metadata = Tuple[List[NodeType], List[EdgeType]]


def get_submodule(module: Module, target: str) ->Module:
    out = module
    for attr in target.split('.'):
        out = getattr(out, attr)
    return out


def is_global_pooling_op(module: Module, op: str, target: str) ->bool:
    if op == 'call_module':
        return isinstance(get_submodule(module, target), Aggregation)
    return False


def is_message_passing_op(module: Module, op: str, target: str) ->bool:
    if op == 'call_module':
        return isinstance(get_submodule(module, target), MessagePassing)
    return False


def check_add_self_loops(module: torch.nn.Module, edge_types: List[EdgeType]):
    is_bipartite = any([(key[0] != key[-1]) for key in edge_types])
    if is_bipartite and getattr(module, 'add_self_loops', False):
        raise ValueError(f"'add_self_loops' attribute set to 'True' on module '{module}' for use with edge type(s) '{edge_types}'. This will lead to incorrect message passing results.")


def get_dict(mapping: Optional[Dict[str, Any]]) ->Dict[str, Any]:
    return mapping if mapping is not None else {}


def get_unused_node_types(node_types: List[NodeType], edge_types: List[EdgeType]) ->Set[NodeType]:
    dst_node_types = set(edge_type[-1] for edge_type in edge_types)
    return set(node_types) - set(dst_node_types)


def key2str(key: Union[NodeType, EdgeType]) ->str:
    key = '__'.join(key) if isinstance(key, tuple) else key
    return key.replace(' ', '_').replace('-', '_').replace(':', '_')


class HeteroGAT(torch.nn.Module):

    def __init__(self, metadata, hidden_channels, num_layers, output_channels, num_heads):
        super().__init__()
        self.model = to_hetero(GAT((-1, -1), hidden_channels, num_layers, output_channels, add_self_loops=False, heads=num_heads), metadata)

    def forward(self, x_dict, edge_index_dict):
        return self.model(x_dict, edge_index_dict)

    @torch.no_grad()
    def inference(self, loader, device, progress_bar=False):
        self.model.eval()
        if progress_bar:
            loader = tqdm(loader, desc='Inference')
        for batch in loader:
            batch = batch
            if len(batch.adj_t_dict) > 0:
                self.model(batch.x_dict, batch.adj_t_dict)
            else:
                self.model(batch.x_dict, batch.edge_index_dict)


class HeteroGraphSAGE(torch.nn.Module):

    def __init__(self, metadata, hidden_channels, num_layers, output_channels):
        super().__init__()
        self.model = to_hetero(GraphSAGE((-1, -1), hidden_channels, num_layers, output_channels), metadata)

    def forward(self, x_dict, edge_index_dict):
        return self.model(x_dict, edge_index_dict)

    @torch.no_grad()
    def inference(self, loader, device, progress_bar=False):
        self.model.eval()
        if progress_bar:
            loader = tqdm(loader, desc='Inference')
        for batch in loader:
            batch = batch
            if len(batch.adj_t_dict) > 0:
                self.model(batch.x_dict, batch.adj_t_dict)
            else:
                self.model(batch.x_dict, batch.edge_index_dict)


class Encoder(nn.Module):

    def __init__(self, in_channels, hidden_channels):
        super().__init__()
        self.conv = GCNConv(in_channels, hidden_channels, cached=True)
        self.prelu = nn.PReLU(hidden_channels)

    def forward(self, x, edge_index):
        x = self.conv(x, edge_index)
        x = self.prelu(x)
        return x


class Discriminator(torch.nn.Module):

    def __init__(self, in_channels, hidden_channels, out_channels):
        super().__init__()
        self.lin1 = Linear(in_channels, hidden_channels)
        self.lin2 = Linear(hidden_channels, hidden_channels)
        self.lin3 = Linear(hidden_channels, out_channels)

    def forward(self, x):
        x = self.lin1(x).relu()
        x = self.lin2(x).relu()
        return self.lin3(x)


class GCNEncoder(torch.nn.Module):

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv1 = GCNConv(in_channels, 2 * out_channels)
        self.conv2 = GCNConv(2 * out_channels, out_channels)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index).relu()
        return self.conv2(x, edge_index)


class VariationalGCNEncoder(torch.nn.Module):

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv1 = GCNConv(in_channels, 2 * out_channels)
        self.conv_mu = GCNConv(2 * out_channels, out_channels)
        self.conv_logstd = GCNConv(2 * out_channels, out_channels)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index).relu()
        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)


class LinearEncoder(torch.nn.Module):

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv = GCNConv(in_channels, out_channels)

    def forward(self, x, edge_index):
        return self.conv(x, edge_index)


class VariationalLinearEncoder(torch.nn.Module):

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv_mu = GCNConv(in_channels, out_channels)
        self.conv_logstd = GCNConv(in_channels, out_channels)

    def forward(self, x, edge_index):
        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)


class Breadth(torch.nn.Module):

    def __init__(self, in_dim, out_dim):
        super().__init__()
        self.gatconv = GATConv(in_dim, out_dim, heads=1)

    def forward(self, x, edge_index):
        x = torch.tanh(self.gatconv(x, edge_index))
        return x


class Depth(torch.nn.Module):

    def __init__(self, in_dim, hidden):
        super().__init__()
        self.lstm = torch.nn.LSTM(in_dim, hidden, 1, bias=False)

    def forward(self, x, h, c):
        x, (h, c) = self.lstm(x, (h, c))
        return x, (h, c)


dim = 64


lstm_hidden = 256


class GeniePathLayer(torch.nn.Module):

    def __init__(self, in_dim):
        super().__init__()
        self.breadth_func = Breadth(in_dim, dim)
        self.depth_func = Depth(dim, lstm_hidden)

    def forward(self, x, edge_index, h, c):
        x = self.breadth_func(x, edge_index)
        x = x[None, :]
        x, (h, c) = self.depth_func(x, h, c)
        x = x[0]
        return x, (h, c)


layer_num = 4


class GeniePath(torch.nn.Module):

    def __init__(self, in_dim, out_dim):
        super().__init__()
        self.lin1 = torch.nn.Linear(in_dim, dim)
        self.gplayers = torch.nn.ModuleList([GeniePathLayer(dim) for i in range(layer_num)])
        self.lin2 = torch.nn.Linear(dim, out_dim)

    def forward(self, x, edge_index):
        x = self.lin1(x)
        h = torch.zeros(1, x.shape[0], lstm_hidden, device=x.device)
        c = torch.zeros(1, x.shape[0], lstm_hidden, device=x.device)
        for i, l in enumerate(self.gplayers):
            x, (h, c) = self.gplayers[i](x, edge_index, h, c)
        x = self.lin2(x)
        return x


class GeniePathLazy(torch.nn.Module):

    def __init__(self, in_dim, out_dim):
        super().__init__()
        self.lin1 = torch.nn.Linear(in_dim, dim)
        self.breadths = torch.nn.ModuleList([Breadth(dim, dim) for i in range(layer_num)])
        self.depths = torch.nn.ModuleList([Depth(dim * 2, lstm_hidden) for i in range(layer_num)])
        self.lin2 = torch.nn.Linear(dim, out_dim)

    def forward(self, x, edge_index):
        x = self.lin1(x)
        h = torch.zeros(1, x.shape[0], lstm_hidden, device=x.device)
        c = torch.zeros(1, x.shape[0], lstm_hidden, device=x.device)
        h_tmps = []
        for i, l in enumerate(self.breadths):
            h_tmps.append(self.breadths[i](x, edge_index))
        x = x[None, :]
        for i, l in enumerate(self.depths):
            in_cat = torch.cat((h_tmps[i][None, :], x), -1)
            x, (h, c) = self.depths[i](in_cat, h, c)
        x = self.lin2(x[0])
        return x


class MovieGNNEncoder(torch.nn.Module):

    def __init__(self, hidden_channels, out_channels):
        super().__init__()
        self.conv1 = SAGEConv(-1, hidden_channels)
        self.conv2 = SAGEConv(hidden_channels, hidden_channels)
        self.lin = Linear(hidden_channels, out_channels)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index).relu()
        x = self.conv2(x, edge_index).relu()
        return self.lin(x)


class UserGNNEncoder(torch.nn.Module):

    def __init__(self, hidden_channels, out_channels):
        super().__init__()
        self.conv1 = SAGEConv((-1, -1), hidden_channels)
        self.conv2 = SAGEConv((-1, -1), hidden_channels)
        self.conv3 = SAGEConv((-1, -1), hidden_channels)
        self.lin = Linear(hidden_channels, out_channels)

    def forward(self, x_dict, edge_index_dict):
        movie_x = self.conv1(x_dict['movie'], edge_index_dict['movie', 'metapath_0', 'movie']).relu()
        user_x = self.conv2((x_dict['movie'], x_dict['user']), edge_index_dict['movie', 'rev_rates', 'user']).relu()
        user_x = self.conv3((movie_x, user_x), edge_index_dict['movie', 'rev_rates', 'user']).relu()
        return self.lin(user_x)


class EdgeDecoder(torch.nn.Module):

    def __init__(self, hidden_channels):
        super().__init__()
        self.lin1 = Linear(2 * hidden_channels, hidden_channels)
        self.lin2 = Linear(hidden_channels, 1)

    def forward(self, z_dict, edge_label_index):
        row, col = edge_label_index
        z = torch.cat([z_dict['user'][row], z_dict['movie'][col]], dim=-1)
        z = self.lin1(z).relu()
        z = self.lin2(z)
        return z.view(-1)


class DMGI(torch.nn.Module):

    def __init__(self, num_nodes, in_channels, out_channels, num_relations):
        super().__init__()
        self.convs = torch.nn.ModuleList([GCNConv(in_channels, out_channels) for _ in range(num_relations)])
        self.M = torch.nn.Bilinear(out_channels, out_channels, 1)
        self.Z = torch.nn.Parameter(torch.Tensor(num_nodes, out_channels))
        self.reset_parameters()

    def reset_parameters(self):
        for conv in self.convs:
            conv.reset_parameters()
        torch.nn.init.xavier_uniform_(self.M.weight)
        self.M.bias.data.zero_()
        torch.nn.init.xavier_uniform_(self.Z)

    def forward(self, x, edge_indices):
        pos_hs, neg_hs, summaries = [], [], []
        for conv, edge_index in zip(self.convs, edge_indices):
            pos_h = F.dropout(x, p=0.5, training=self.training)
            pos_h = conv(pos_h, edge_index).relu()
            pos_hs.append(pos_h)
            neg_h = F.dropout(x, p=0.5, training=self.training)
            neg_h = neg_h[torch.randperm(neg_h.size(0), device=neg_h.device)]
            neg_h = conv(neg_h, edge_index).relu()
            neg_hs.append(neg_h)
            summaries.append(pos_h.mean(dim=0, keepdim=True))
        return pos_hs, neg_hs, summaries

    def loss(self, pos_hs, neg_hs, summaries):
        loss = 0.0
        for pos_h, neg_h, s in zip(pos_hs, neg_hs, summaries):
            s = s.expand_as(pos_h)
            loss += -torch.log(self.M(pos_h, s).sigmoid() + 1e-15).mean()
            loss += -torch.log(1 - self.M(neg_h, s).sigmoid() + 1e-15).mean()
        pos_mean = torch.stack(pos_hs, dim=0).mean(dim=0)
        neg_mean = torch.stack(neg_hs, dim=0).mean(dim=0)
        pos_reg_loss = (self.Z - pos_mean).pow(2).sum()
        neg_reg_loss = (self.Z - neg_mean).pow(2).sum()
        loss += 0.001 * (pos_reg_loss - neg_reg_loss)
        return loss


def group(xs: List[Tensor], aggr: Optional[str]) ->Optional[Tensor]:
    if len(xs) == 0:
        return None
    elif aggr is None:
        return torch.stack(xs, dim=1)
    elif len(xs) == 1:
        return xs[0]
    else:
        out = torch.stack(xs, dim=0)
        out = getattr(torch, aggr)(out, dim=0)
        out = out[0] if isinstance(out, tuple) else out
        return out


class HAN(nn.Module):

    def __init__(self, in_channels: Union[int, Dict[str, int]], out_channels: int, hidden_channels=128, heads=8):
        super().__init__()
        self.han_conv = HANConv(in_channels, hidden_channels, heads=heads, dropout=0.6, metadata=data.metadata())
        self.lin = nn.Linear(hidden_channels, out_channels)

    def forward(self, x_dict, edge_index_dict):
        out = self.han_conv(x_dict, edge_index_dict)
        out = self.lin(out['movie'])
        return out


class HeteroGNN(torch.nn.Module):

    def __init__(self, metadata, hidden_channels, out_channels, num_layers):
        super().__init__()
        self.convs = torch.nn.ModuleList()
        for _ in range(num_layers):
            conv = HeteroConv({edge_type: SAGEConv((-1, -1), hidden_channels) for edge_type in metadata[1]})
            self.convs.append(conv)
        self.lin = Linear(hidden_channels, out_channels)

    def forward(self, x_dict, edge_index_dict):
        for conv in self.convs:
            x_dict = conv(x_dict, edge_index_dict)
            x_dict = {key: F.leaky_relu(x) for key, x in x_dict.items()}
        return self.lin(x_dict['author'])


class GNNEncoder(torch.nn.Module):

    def __init__(self, hidden_channels, out_channels):
        super().__init__()
        self.conv1 = SAGEConv((-1, -1), hidden_channels)
        self.conv2 = SAGEConv((-1, -1), out_channels)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index).relu()
        x = self.conv2(x, edge_index)
        return x


class ParameterDict(torch.nn.ParameterDict):

    def __init__(self, parameters: Optional[Mapping[str, Parameter]]=None):
        if parameters:
            parameters = {self.to_internal_key(key): module for key, module in parameters.items()}
        super().__init__(parameters)

    @staticmethod
    def to_internal_key(key: str) ->str:
        return key.replace('.', '#')

    @staticmethod
    def to_external_key(key: str) ->str:
        return key.replace('#', '.')

    def __getitem__(self, key: str) ->Parameter:
        return super().__getitem__(self.to_internal_key(key))

    def __setitem__(self, key: str, parameter: Parameter) ->None:
        return super().__setitem__(self.to_internal_key(key), parameter)

    def __delitem__(self, key: str) ->None:
        return super().__delitem__(self.to_internal_key(key))

    def __contains__(self, key: str) ->bool:
        return super().__contains__(self.to_internal_key(key))

    def keys(self) ->Iterable[str]:
        return [self.to_external_key(key) for key in super().keys()]


def ones(tensor: Any):
    constant(tensor, 1.0)


class HGT(torch.nn.Module):

    def __init__(self, hidden_channels, out_channels, num_heads, num_layers):
        super().__init__()
        self.lin_dict = torch.nn.ModuleDict()
        for node_type in data.node_types:
            self.lin_dict[node_type] = Linear(-1, hidden_channels)
        self.convs = torch.nn.ModuleList()
        for _ in range(num_layers):
            conv = HGTConv(hidden_channels, hidden_channels, data.metadata(), num_heads, group='sum')
            self.convs.append(conv)
        self.lin = Linear(hidden_channels, out_channels)

    def forward(self, x_dict, edge_index_dict):
        x_dict = {node_type: self.lin_dict[node_type](x).relu_() for node_type, x in x_dict.items()}
        for conv in self.convs:
            x_dict = conv(x_dict, edge_index_dict)
        return self.lin(x_dict['author'])


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


class SAGE(torch.nn.Module):

    def __init__(self, in_channels, hidden_channels, out_channels):
        super().__init__()
        self.convs = torch.nn.ModuleList()
        self.convs.append(SAGEConv(in_channels, hidden_channels))
        self.convs.append(SAGEConv(hidden_channels, out_channels))

    def forward(self, x, edge_index):
        for i, conv in enumerate(self.convs):
            x = conv(x, edge_index)
            if i < len(self.convs) - 1:
                x = x.relu_()
                x = F.dropout(x, p=0.5, training=self.training)
        return x

    @torch.no_grad()
    def inference(self, x_all, subgraph_loader):
        pbar = tqdm(total=len(subgraph_loader.dataset) * len(self.convs))
        pbar.set_description('Evaluating')
        for i, conv in enumerate(self.convs):
            xs = []
            for batch in subgraph_loader:
                x = x_all[batch.n_id.to(x_all.device)]
                x = conv(x, batch.edge_index)
                if i < len(self.convs) - 1:
                    x = x.relu_()
                xs.append(x[:batch.batch_size].cpu())
                pbar.update(batch.batch_size)
            x_all = torch.cat(xs, dim=0)
        pbar.close()
        return x_all


class DeepGCNLayer(torch.nn.Module):
    """The skip connection operations from the
    `"DeepGCNs: Can GCNs Go as Deep as CNNs?"
    <https://arxiv.org/abs/1904.03751>`_ and `"All You Need to Train Deeper
    GCNs" <https://arxiv.org/abs/2006.07739>`_ papers.
    The implemented skip connections includes the pre-activation residual
    connection (:obj:`"res+"`), the residual connection (:obj:`"res"`),
    the dense connection (:obj:`"dense"`) and no connections (:obj:`"plain"`).

    * **Res+** (:obj:`"res+"`):

    .. math::
        \\text{Normalization}\\to\\text{Activation}\\to\\text{Dropout}\\to
        \\text{GraphConv}\\to\\text{Res}

    * **Res** (:obj:`"res"`) / **Dense** (:obj:`"dense"`) / **Plain**
      (:obj:`"plain"`):

    .. math::
        \\text{GraphConv}\\to\\text{Normalization}\\to\\text{Activation}\\to
        \\text{Res/Dense/Plain}\\to\\text{Dropout}

    .. note::

        For an example of using :obj:`GENConv`, see
        `examples/ogbn_proteins_deepgcn.py
        <https://github.com/pyg-team/pytorch_geometric/blob/master/examples/
        ogbn_proteins_deepgcn.py>`_.

    Args:
        conv (torch.nn.Module, optional): the GCN operator.
            (default: :obj:`None`)
        norm (torch.nn.Module): the normalization layer. (default: :obj:`None`)
        act (torch.nn.Module): the activation layer. (default: :obj:`None`)
        block (string, optional): The skip connection operation to use
            (:obj:`"res+"`, :obj:`"res"`, :obj:`"dense"` or :obj:`"plain"`).
            (default: :obj:`"res+"`)
        dropout (float, optional): Whether to apply or dropout.
            (default: :obj:`0.`)
        ckpt_grad (bool, optional): If set to :obj:`True`, will checkpoint this
            part of the model. Checkpointing works by trading compute for
            memory, since intermediate activations do not need to be kept in
            memory. Set this to :obj:`True` in case you encounter out-of-memory
            errors while going deep. (default: :obj:`False`)
    """

    def __init__(self, conv: Optional[Module]=None, norm: Optional[Module]=None, act: Optional[Module]=None, block: str='res+', dropout: float=0.0, ckpt_grad: bool=False):
        super().__init__()
        self.conv = conv
        self.norm = norm
        self.act = act
        self.block = block.lower()
        assert self.block in ['res+', 'res', 'dense', 'plain']
        self.dropout = dropout
        self.ckpt_grad = ckpt_grad

    def reset_parameters(self):
        self.conv.reset_parameters()
        self.norm.reset_parameters()

    def forward(self, *args, **kwargs) ->Tensor:
        """"""
        args = list(args)
        x = args.pop(0)
        if self.block == 'res+':
            h = x
            if self.norm is not None:
                h = self.norm(h)
            if self.act is not None:
                h = self.act(h)
            h = F.dropout(h, p=self.dropout, training=self.training)
            if self.conv is not None and self.ckpt_grad and h.requires_grad:
                h = checkpoint(self.conv, h, *args, **kwargs)
            else:
                h = self.conv(h, *args, **kwargs)
            return x + h
        else:
            if self.conv is not None and self.ckpt_grad and x.requires_grad:
                h = checkpoint(self.conv, x, *args, **kwargs)
            else:
                h = self.conv(x, *args, **kwargs)
            if self.norm is not None:
                h = self.norm(h)
            if self.act is not None:
                h = self.act(h)
            if self.block == 'res':
                h = x + h
            elif self.block == 'dense':
                h = torch.cat([x, h], dim=-1)
            elif self.block == 'plain':
                pass
            return F.dropout(h, p=self.dropout, training=self.training)

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}(block={self.block})'


class MessageNorm(torch.nn.Module):
    """Applies message normalization over the aggregated messages as described
    in the `"DeeperGCNs: All You Need to Train Deeper GCNs"
    <https://arxiv.org/abs/2006.07739>`_ paper

    .. math::

        \\mathbf{x}_i^{\\prime} = \\mathrm{MLP} \\left( \\mathbf{x}_{i} + s \\cdot
        {\\| \\mathbf{x}_i \\|}_2 \\cdot
        \\frac{\\mathbf{m}_{i}}{{\\|\\mathbf{m}_i\\|}_2} \\right)

    Args:
        learn_scale (bool, optional): If set to :obj:`True`, will learn the
            scaling factor :math:`s` of message normalization.
            (default: :obj:`False`)
    """

    def __init__(self, learn_scale: bool=False):
        super().__init__()
        self.scale = Parameter(torch.Tensor([1.0]), requires_grad=learn_scale)
        self.reset_parameters()

    def reset_parameters(self):
        self.scale.data.fill_(1.0)

    def forward(self, x: Tensor, msg: Tensor, p: float=2.0) ->Tensor:
        """"""
        msg = F.normalize(msg, p=p, dim=-1)
        x_norm = x.norm(p=p, dim=-1, keepdim=True)
        return msg * x_norm * self.scale

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}(learn_scale={self.scale.requires_grad})'


class DeeperGCN(torch.nn.Module):

    def __init__(self, hidden_channels, num_layers):
        super().__init__()
        self.node_encoder = Linear(data.x.size(-1), hidden_channels)
        self.edge_encoder = Linear(data.edge_attr.size(-1), hidden_channels)
        self.layers = torch.nn.ModuleList()
        for i in range(1, num_layers + 1):
            conv = GENConv(hidden_channels, hidden_channels, aggr='softmax', t=1.0, learn_t=True, num_layers=2, norm='layer')
            norm = LayerNorm(hidden_channels, elementwise_affine=True)
            act = ReLU(inplace=True)
            layer = DeepGCNLayer(conv, norm, act, block='res+', dropout=0.1, ckpt_grad=i % 3)
            self.layers.append(layer)
        self.lin = Linear(hidden_channels, data.y.size(-1))

    def forward(self, x, edge_index, edge_attr):
        x = self.node_encoder(x)
        edge_attr = self.edge_encoder(edge_attr)
        x = self.layers[0].conv(x, edge_index, edge_attr)
        for layer in self.layers[1:]:
            x = layer(x, edge_index, edge_attr)
        x = self.layers[0].act(self.layers[0].norm(x))
        x = F.dropout(x, p=0.1, training=self.training)
        return self.lin(x)


class TransformerBlock(torch.nn.Module):

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.lin_in = Lin(in_channels, in_channels)
        self.lin_out = Lin(out_channels, out_channels)
        self.pos_nn = MLP([3, 64, out_channels], norm=None, plain_last=False)
        self.attn_nn = MLP([out_channels, 64, out_channels], norm=None, plain_last=False)
        self.transformer = PointTransformerConv(in_channels, out_channels, pos_nn=self.pos_nn, attn_nn=self.attn_nn)

    def forward(self, x, pos, edge_index):
        x = self.lin_in(x).relu()
        x = self.transformer(x, pos, edge_index)
        x = self.lin_out(x).relu()
        return x


def fps(x: Tensor, batch: OptTensor=None, ratio: float=0.5, random_start: bool=True) ->Tensor:
    """A sampling algorithm from the `"PointNet++: Deep Hierarchical Feature
    Learning on Point Sets in a Metric Space"
    <https://arxiv.org/abs/1706.02413>`_ paper, which iteratively samples the
    most distant point with regard to the rest points.

    Args:
        x (Tensor): Node feature matrix
            :math:`\\mathbf{X} \\in \\mathbb{R}^{N \\times F}`.
        batch (LongTensor, optional): Batch vector
            :math:`\\mathbf{b} \\in {\\{ 0, \\ldots, B-1\\}}^N`, which assigns each
            node to a specific example. (default: :obj:`None`)
        ratio (float, optional): Sampling ratio. (default: :obj:`0.5`)
        random_start (bool, optional): If set to :obj:`False`, use the first
            node in :math:`\\mathbf{X}` as starting node. (default: obj:`True`)

    :rtype: :class:`LongTensor`

    .. code-block:: python

        import torch
        from torch_geometric.nn import fps

        x = torch.Tensor([[-1, -1], [-1, 1], [1, -1], [1, 1]])
        batch = torch.tensor([0, 0, 0, 0])
        index = fps(x, batch, ratio=0.5)
    """
    return torch_cluster.fps(x, batch, ratio, random_start)


def knn(x: Tensor, y: Tensor, k: int, batch_x: OptTensor=None, batch_y: OptTensor=None, cosine: bool=False, num_workers: int=1) ->Tensor:
    """Finds for each element in :obj:`y` the :obj:`k` nearest points in
    :obj:`x`.

    Args:
        x (Tensor): Node feature matrix
            :math:`\\mathbf{X} \\in \\mathbb{R}^{N \\times F}`.
        y (Tensor): Node feature matrix
            :math:`\\mathbf{X} \\in \\mathbb{R}^{M \\times F}`.
        k (int): The number of neighbors.
        batch_x (LongTensor, optional): Batch vector
            :math:`\\mathbf{b} \\in {\\{ 0, \\ldots, B-1\\}}^N`, which assigns each
            node to a specific example. (default: :obj:`None`)
        batch_y (LongTensor, optional): Batch vector
            :math:`\\mathbf{b} \\in {\\{ 0, \\ldots, B-1\\}}^M`, which assigns each
            node to a specific example. (default: :obj:`None`)
        cosine (boolean, optional): If :obj:`True`, will use the cosine
            distance instead of euclidean distance to find nearest neighbors.
            (default: :obj:`False`)
        num_workers (int): Number of workers to use for computation. Has no
            effect in case :obj:`batch_x` or :obj:`batch_y` is not
            :obj:`None`, or the input lies on the GPU. (default: :obj:`1`)

    :rtype: :class:`LongTensor`

    .. code-block:: python

        import torch
        from torch_geometric.nn import knn

        x = torch.Tensor([[-1, -1], [-1, 1], [1, -1], [1, 1]])
        batch_x = torch.tensor([0, 0, 0, 0])
        y = torch.Tensor([[-1, 0], [1, 0]])
        batch_y = torch.tensor([0, 0])
        assign_index = knn(x, y, 2, batch_x, batch_y)
    """
    return torch_cluster.knn(x, y, k, batch_x, batch_y, cosine, num_workers)


class TransitionDown(torch.nn.Module):
    """
        Samples the input point cloud by a ratio percentage to reduce
        cardinality and uses an mlp to augment features dimensionnality
    """

    def __init__(self, in_channels, out_channels, ratio=0.25, k=16):
        super().__init__()
        self.k = k
        self.ratio = ratio
        self.mlp = MLP([in_channels, out_channels], plain_last=False)

    def forward(self, x, pos, batch):
        id_clusters = fps(pos, ratio=self.ratio, batch=batch)
        sub_batch = batch[id_clusters] if batch is not None else None
        id_k_neighbor = knn(pos, pos[id_clusters], k=self.k, batch_x=batch, batch_y=sub_batch)
        x = self.mlp(x)
        x_out, _ = scatter_max(x[id_k_neighbor[1]], id_k_neighbor[0], dim_size=id_clusters.size(0), dim=0)
        sub_pos, out = pos[id_clusters], x_out
        return out, sub_pos, sub_batch


def knn_interpolate(x: torch.Tensor, pos_x: torch.Tensor, pos_y: torch.Tensor, batch_x: OptTensor=None, batch_y: OptTensor=None, k: int=3, num_workers: int=1):
    """The k-NN interpolation from the `"PointNet++: Deep Hierarchical
    Feature Learning on Point Sets in a Metric Space"
    <https://arxiv.org/abs/1706.02413>`_ paper.
    For each point :math:`y` with position :math:`\\mathbf{p}(y)`, its
    interpolated features :math:`\\mathbf{f}(y)` are given by

    .. math::
        \\mathbf{f}(y) = \\frac{\\sum_{i=1}^k w(x_i) \\mathbf{f}(x_i)}{\\sum_{i=1}^k
        w(x_i)} \\textrm{, where } w(x_i) = \\frac{1}{d(\\mathbf{p}(y),
        \\mathbf{p}(x_i))^2}

    and :math:`\\{ x_1, \\ldots, x_k \\}` denoting the :math:`k` nearest points
    to :math:`y`.

    Args:
        x (Tensor): Node feature matrix
            :math:`\\mathbf{X} \\in \\mathbb{R}^{N \\times F}`.
        pos_x (Tensor): Node position matrix
            :math:`\\in \\mathbb{R}^{N \\times d}`.
        pos_y (Tensor): Upsampled node position matrix
            :math:`\\in \\mathbb{R}^{M \\times d}`.
        batch_x (LongTensor, optional): Batch vector
            :math:`\\mathbf{b_x} \\in {\\{ 0, \\ldots, B-1\\}}^N`, which assigns
            each node from :math:`\\mathbf{X}` to a specific example.
            (default: :obj:`None`)
        batch_y (LongTensor, optional): Batch vector
            :math:`\\mathbf{b_y} \\in {\\{ 0, \\ldots, B-1\\}}^N`, which assigns
            each node from :math:`\\mathbf{Y}` to a specific example.
            (default: :obj:`None`)
        k (int, optional): Number of neighbors. (default: :obj:`3`)
        num_workers (int): Number of workers to use for computation. Has no
            effect in case :obj:`batch_x` or :obj:`batch_y` is not
            :obj:`None`, or the input lies on the GPU. (default: :obj:`1`)
    """
    with torch.no_grad():
        assign_index = knn(pos_x, pos_y, k, batch_x=batch_x, batch_y=batch_y, num_workers=num_workers)
        y_idx, x_idx = assign_index[0], assign_index[1]
        diff = pos_x[x_idx] - pos_y[y_idx]
        squared_distance = (diff * diff).sum(dim=-1, keepdim=True)
        weights = 1.0 / torch.clamp(squared_distance, min=1e-16)
    y = scatter_add(x[x_idx] * weights, y_idx, dim=0, dim_size=pos_y.size(0))
    y = y / scatter_add(weights, y_idx, dim=0, dim_size=pos_y.size(0))
    return y


class TransitionUp(torch.nn.Module):
    """
        Reduce features dimensionnality and interpolate back to higher
        resolution and cardinality
    """

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.mlp_sub = MLP([in_channels, out_channels], plain_last=False)
        self.mlp = MLP([out_channels, out_channels], plain_last=False)

    def forward(self, x, x_sub, pos, pos_sub, batch=None, batch_sub=None):
        x_sub = self.mlp_sub(x_sub)
        x_interpolated = knn_interpolate(x_sub, pos_sub, pos, k=3, batch_x=batch_sub, batch_y=batch)
        x = self.mlp(x) + x_interpolated
        return x


PairOptTensor = Tuple[Optional[Tensor], Optional[Tensor]]


def radius(x: Tensor, y: Tensor, r: float, batch_x: OptTensor=None, batch_y: OptTensor=None, max_num_neighbors: int=32, num_workers: int=1) ->Tensor:
    """Finds for each element in :obj:`y` all points in :obj:`x` within
    distance :obj:`r`.

    Args:
        x (Tensor): Node feature matrix
            :math:`\\mathbf{X} \\in \\mathbb{R}^{N \\times F}`.
        y (Tensor): Node feature matrix
            :math:`\\mathbf{Y} \\in \\mathbb{R}^{M \\times F}`.
        r (float): The radius.
        batch_x (LongTensor, optional): Batch vector
            :math:`\\mathbf{b} \\in {\\{ 0, \\ldots, B-1\\}}^N`, which assigns each
            node to a specific example. (default: :obj:`None`)
        batch_y (LongTensor, optional): Batch vector
            :math:`\\mathbf{b} \\in {\\{ 0, \\ldots, B-1\\}}^M`, which assigns each
            node to a specific example. (default: :obj:`None`)
        max_num_neighbors (int, optional): The maximum number of neighbors to
            return for each element in :obj:`y`. (default: :obj:`32`)
        num_workers (int): Number of workers to use for computation. Has no
            effect in case :obj:`batch_x` or :obj:`batch_y` is not
            :obj:`None`, or the input lies on the GPU. (default: :obj:`1`)

    :rtype: :class:`LongTensor`

    .. code-block:: python

        import torch
        from torch_geometric.nn import radius

        x = torch.Tensor([[-1, -1], [-1, 1], [1, -1], [1, 1]])
        batch_x = torch.tensor([0, 0, 0, 0])
        y = torch.Tensor([[-1, 0], [1, 0]])
        batch_y = torch.tensor([0, 0])
        assign_index = radius(x, y, 1.5, batch_x, batch_y)
    """
    return torch_cluster.radius(x, y, r, batch_x, batch_y, max_num_neighbors, num_workers)


class SAModule(torch.nn.Module):

    def __init__(self, ratio, r, nn):
        super().__init__()
        self.ratio = ratio
        self.r = r
        self.conv = PointConv(nn, add_self_loops=False)

    def forward(self, x, pos, batch):
        idx = fps(pos, batch, ratio=self.ratio)
        row, col = radius(pos, pos[idx], self.r, batch, batch[idx], max_num_neighbors=64)
        edge_index = torch.stack([col, row], dim=0)
        x_dst = None if x is None else x[idx]
        x = self.conv((x, x_dst), (pos, pos[idx]), edge_index)
        pos, batch = pos[idx], batch[idx]
        return x, pos, batch


def global_max_pool(x: Tensor, batch: Optional[Tensor], size: Optional[int]=None) ->Tensor:
    """Returns batch-wise graph-level-outputs by taking the channel-wise
    maximum across the node dimension, so that for a single graph
    :math:`\\mathcal{G}_i` its output is computed by

    .. math::
        \\mathbf{r}_i = \\mathrm{max}_{n=1}^{N_i} \\, \\mathbf{x}_n.

    Functional method of the
    :class:`~torch_geometric.nn.aggr.MaxAggregation` module.

    Args:
        x (Tensor): Node feature matrix
            :math:`\\mathbf{X} \\in \\mathbb{R}^{(N_1 + \\ldots + N_B) \\times F}`.
        batch (LongTensor, optional): Batch vector
            :math:`\\mathbf{b} \\in {\\{ 0, \\ldots, B-1\\}}^N`, which assigns each
            node to a specific example.
        size (int, optional): Batch-size :math:`B`.
            Automatically calculated if not given. (default: :obj:`None`)
    """
    if batch is None:
        return x.max(dim=-2, keepdim=x.dim() == 2)[0]
    size = int(batch.max().item() + 1) if size is None else size
    return scatter(x, batch, dim=-2, dim_size=size, reduce='max')


class GlobalSAModule(torch.nn.Module):

    def __init__(self, nn):
        super().__init__()
        self.nn = nn

    def forward(self, x, pos, batch):
        x = self.nn(torch.cat([x, pos], dim=1))
        x = global_max_pool(x, batch)
        pos = pos.new_zeros((x.size(0), 3))
        batch = torch.arange(x.size(0), device=batch.device)
        return x, pos, batch


class FPModule(torch.nn.Module):
    """Upsampling with a skip connection."""

    def __init__(self, k, nn):
        super().__init__()
        self.k = k
        self.nn = nn

    def forward(self, x, pos, batch, x_skip, pos_skip, batch_skip):
        x = knn_interpolate(x, pos, pos_skip, batch, batch_skip, k=self.k)
        x = torch.cat([x, x_skip], dim=1)
        x = self.nn(x)
        return x, pos_skip, batch_skip


def new_layer_config(dim_in, dim_out, num_layers, has_act, has_bias, cfg):
    return LayerConfig(has_batchnorm=cfg.gnn.batchnorm, bn_eps=cfg.bn.eps, bn_mom=cfg.bn.mom, mem_inplace=cfg.mem.inplace, dim_in=dim_in, dim_out=dim_out, edge_dim=cfg.dataset.edge_dim, has_l2norm=cfg.gnn.l2norm, dropout=cfg.gnn.dropout, has_act=has_act, final_act=True, act=cfg.gnn.act, has_bias=has_bias, keep_edge=cfg.gnn.keep_edge, dim_inner=cfg.gnn.dim_inner, num_layers=num_layers)


def get_config_store() ->Any:
    """Returns the global configuration store."""
    return ConfigStore.instance()


EXCLUDE = {'self', 'args', 'kwargs'}


MAPPING = {torch.nn.Module: Any, torch.Tensor: Any}


def dataclass_from_class(cls: Union[str, Any]) ->Optional[Any]:
    """Returns the :obj:`dataclass` of a class registered in the global
    configuration store."""
    node = get_node(cls)
    return node._metadata.object_type if node is not None else None


def map_annotation(annotation: Any, mapping: Optional[Dict[Any, Any]]=None) ->Any:
    origin = getattr(annotation, '__origin__', None)
    args = getattr(annotation, '__args__', [])
    if origin == Union or origin == list or origin == dict:
        annotation = copy.copy(annotation)
        annotation.__args__ = tuple(map_annotation(a, mapping) for a in args)
        return annotation
    if annotation in mapping or {}:
        return mapping[annotation]
    out = dataclass_from_class(annotation)
    if out is not None:
        return out
    return annotation


def to_dataclass(cls: Any, base_cls: Optional[Any]=None, with_target: Optional[bool]=None, map_args: Optional[Dict[str, Tuple]]=None, exclude_args: Optional[List[str]]=None, strict: bool=False) ->Any:
    """Converts the input arguments of a given class :obj:`cls` to a
    :obj:`dataclass` schema, *e.g.*,

    .. code-block:: python

        from torch_geometric.transforms import NormalizeFeatures

        dataclass = to_dataclass(NormalizeFeatures)

    will generate

    .. code-block:: python

        @dataclass
        class NormalizeFeatures:
            _target_: str = "torch_geometric.transforms.NormalizeFeatures"
            attrs: List[str] = field(default_factory = lambda: ["x"])

    Args:
        cls (Any): The class to generate a schema for.
        base_cls (Any, optional): The base class of the schema.
            (default: :obj:`None`)
        with_target (bool, optional): If set to :obj:`False`, will not add the
            :obj:`_target_` attribute to the schema. If set to :obj:`None`,
            will only add the :obj:`_target_` in case :obj:`base_cls` is given.
            (default: :obj:`None`)
        map_args (Dict[str, Tuple], optional): Arguments for which annotation
            and default values should be overridden. (default: :obj:`None`)
        exclude_args (List[str or int], optional): Arguments to exclude.
            (default: :obj:`None`)
        strict (bool, optional): If set to :obj:`True`, ensures that all
            arguments in both :obj:`map_args` and :obj:`exclude_args` are
            present in the input parameters. (default: :obj:`False`)
    """
    fields = []
    params = inspect.signature(cls.__init__).parameters
    if strict:
        args = set() if map_args is None else set(map_args.keys())
        if exclude_args is not None:
            args |= set([arg for arg in exclude_args if isinstance(arg, str)])
        diff = args - set(params.keys())
        if len(diff) > 0:
            raise ValueError(f"Expected input argument(s) {diff} in '{cls.__name__}'")
    for i, (name, arg) in enumerate(params.items()):
        if name in EXCLUDE:
            continue
        if exclude_args is not None:
            if name in exclude_args or i in exclude_args:
                continue
        if base_cls is not None:
            if name in base_cls.__dataclass_fields__:
                continue
        if map_args is not None and name in map_args:
            fields.append((name,) + map_args[name])
            continue
        annotation, default = arg.annotation, arg.default
        annotation = map_annotation(annotation, mapping=MAPPING)
        if annotation != inspect.Parameter.empty:
            origin = getattr(annotation, '__origin__', None)
            args = getattr(annotation, '__args__', [])
            if origin == Union and type(None) in args and len(args) > 2:
                annotation = Optional[Any]
            elif origin == Union and type(None) not in args:
                annotation = Any
            elif origin == list:
                if getattr(args[0], '__origin__', None) == Union:
                    annotation = List[Any]
            elif origin == dict:
                if getattr(args[1], '__origin__', None) == Union:
                    annotation = Dict[args[0], Any]
        else:
            annotation = Any
        if str(default) == '<required parameter>':
            default = field(default=MISSING)
        elif default != inspect.Parameter.empty:
            if isinstance(default, (list, dict)):

                def wrapper(default):
                    return lambda : default
                default = field(default_factory=wrapper(default))
        else:
            default = field(default=MISSING)
        fields.append((name, annotation, default))
    with_target = base_cls is not None if with_target is None else with_target
    if with_target:
        full_cls_name = f'{cls.__module__}.{cls.__qualname__}'
        fields.append(('_target_', str, field(default=full_cls_name)))
    return make_dataclass(cls.__qualname__, fields=fields, bases=() if base_cls is None else (base_cls,))


def register(cls: Optional[Any]=None, data_cls: Optional[Any]=None, group: Optional[str]=None, **kwargs) ->Union[Any, Callable]:
    """Registers a class in the global configuration store.

    Args:
        cls (Any, optional): The class to register. If set to :obj:`None`, will
            return a decorator. (default: :obj:`None`)
        data_cls (Any, optional): The data class to register. If set to
            :obj:`None`, will dynamically create the data class according to
            :class:`~torch_geometric.graphgym.config_store.to_dataclass`.
            (default: :obj:`None`)
        group (str, optional): The group in the global configuration store.
            (default: :obj:`None`)
        **kwargs (optional): Additional arguments of
            :class:`~torch_geometric.graphgym.config_store.to_dataclass`.
    """
    if cls is not None:
        name = cls.__name__
        if data_cls is None:
            data_cls = to_dataclass(cls, **kwargs)
        get_config_store().store(name, data_cls, group)
        get_node(name)._metadata.orig_type = cls
        return data_cls

    def bounded_register(cls: Any) ->Any:
        register(cls=cls, data_cls=data_cls, group=group, **kwargs)
        return cls
    return bounded_register


class FeatureEncoder(nn.Module):
    """
    Encoding node and edge features

    Args:
        dim_in (int): Input feature dimension
    """

    def __init__(self, dim_in):
        super().__init__()
        self.dim_in = dim_in
        if cfg.dataset.node_encoder:
            NodeEncoder = register.node_encoder_dict[cfg.dataset.node_encoder_name]
            self.node_encoder = NodeEncoder(cfg.gnn.dim_inner)
            if cfg.dataset.node_encoder_bn:
                self.node_encoder_bn = BatchNorm1dNode(new_layer_config(cfg.gnn.dim_inner, -1, -1, has_act=False, has_bias=False, cfg=cfg))
            self.dim_in = cfg.gnn.dim_inner
        if cfg.dataset.edge_encoder:
            EdgeEncoder = register.edge_encoder_dict[cfg.dataset.edge_encoder_name]
            self.edge_encoder = EdgeEncoder(cfg.gnn.dim_inner)
            if cfg.dataset.edge_encoder_bn:
                self.edge_encoder_bn = BatchNorm1dNode(new_layer_config(cfg.gnn.dim_inner, -1, -1, has_act=False, has_bias=False, cfg=cfg))

    def forward(self, batch):
        """"""
        for module in self.children():
            batch = module(batch)
        return batch


def GNNPreMP(dim_in, dim_out, num_layers):
    """
    Wrapper for NN layer before GNN message passing

    Args:
        dim_in (int): Input dimension
        dim_out (int): Output dimension
        num_layers (int): Number of layers

    """
    return GeneralMultiLayer('linear', layer_config=new_layer_config(dim_in, dim_out, num_layers, has_act=False, has_bias=False, cfg=cfg))


def init_weights(m):
    """
    Performs weight initialization

    Args:
        m (nn.Module): PyTorch module

    """
    if isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):
        m.weight.data.fill_(1.0)
        m.bias.data.zero_()
    elif isinstance(m, nn.Linear):
        m.weight.data = nn.init.xavier_uniform_(m.weight.data, gain=nn.init.calculate_gain('relu'))
        if m.bias is not None:
            m.bias.data.zero_()


class GNN(nn.Module):
    """
    General GNN model: encoder + stage + head

    Args:
        dim_in (int): Input dimension
        dim_out (int): Output dimension
        **kwargs (optional): Optional additional args
    """

    def __init__(self, dim_in, dim_out, **kwargs):
        super().__init__()
        GNNStage = register.stage_dict[cfg.gnn.stage_type]
        GNNHead = register.head_dict[cfg.gnn.head]
        self.encoder = FeatureEncoder(dim_in)
        dim_in = self.encoder.dim_in
        if cfg.gnn.layers_pre_mp > 0:
            self.pre_mp = GNNPreMP(dim_in, cfg.gnn.dim_inner, cfg.gnn.layers_pre_mp)
            dim_in = cfg.gnn.dim_inner
        if cfg.gnn.layers_mp > 0:
            self.mp = GNNStage(dim_in=dim_in, dim_out=cfg.gnn.dim_inner, num_layers=cfg.gnn.layers_mp)
        self.post_mp = GNNHead(dim_in=cfg.gnn.dim_inner, dim_out=dim_out)
        self.apply(init_weights)

    def forward(self, batch):
        """"""
        for module in self.children():
            batch = module(batch)
        return batch


bn099_kwargs = {'momentum': 0.01, 'eps': 1e-06}


lrelu02_kwargs = {'negative_slope': 0.2}


class SharedMLP(MLP):
    """SharedMLP following RandLA-Net paper."""

    def __init__(self, *args, **kwargs):
        kwargs['plain_last'] = False
        kwargs['act'] = kwargs.get('act', 'LeakyReLU')
        kwargs['act_kwargs'] = kwargs.get('act_kwargs', lrelu02_kwargs)
        kwargs['norm_kwargs'] = kwargs.get('norm_kwargs', bn099_kwargs)
        super().__init__(*args, **kwargs)


def knn_graph(x: Tensor, k: int, batch: OptTensor=None, loop: bool=False, flow: str='source_to_target', cosine: bool=False, num_workers: int=1) ->Tensor:
    """Computes graph edges to the nearest :obj:`k` points.

    Args:
        x (Tensor): Node feature matrix
            :math:`\\mathbf{X} \\in \\mathbb{R}^{N \\times F}`.
        k (int): The number of neighbors.
        batch (LongTensor, optional): Batch vector
            :math:`\\mathbf{b} \\in {\\{ 0, \\ldots, B-1\\}}^N`, which assigns each
            node to a specific example. (default: :obj:`None`)
        loop (bool, optional): If :obj:`True`, the graph will contain
            self-loops. (default: :obj:`False`)
        flow (string, optional): The flow direction when using in combination
            with message passing (:obj:`"source_to_target"` or
            :obj:`"target_to_source"`). (default: :obj:`"source_to_target"`)
        cosine (boolean, optional): If :obj:`True`, will use the cosine
            distance instead of euclidean distance to find nearest neighbors.
            (default: :obj:`False`)
        num_workers (int): Number of workers to use for computation. Has no
            effect in case :obj:`batch` is not :obj:`None`, or the input lies
            on the GPU. (default: :obj:`1`)

    :rtype: :class:`LongTensor`

    .. code-block:: python

        import torch
        from torch_geometric.nn import knn_graph

        x = torch.Tensor([[-1, -1], [-1, 1], [1, -1], [1, 1]])
        batch = torch.tensor([0, 0, 0, 0])
        edge_index = knn_graph(x, k=2, batch=batch, loop=False)
    """
    return torch_cluster.knn_graph(x, k, batch, loop, flow, cosine, num_workers)


class DilatedResidualBlock(torch.nn.Module):

    def __init__(self, num_neighbors, d_in: int, d_out: int):
        super().__init__()
        self.num_neighbors = num_neighbors
        self.d_in = d_in
        self.d_out = d_out
        self.mlp1 = SharedMLP([d_in, d_out // 8])
        self.shortcut = SharedMLP([d_in, d_out], act=None)
        self.mlp2 = SharedMLP([d_out // 2, d_out], act=None)
        self.lfa1 = LocalFeatureAggregation(d_out // 4)
        self.lfa2 = LocalFeatureAggregation(d_out // 2)
        self.lrelu = torch.nn.LeakyReLU(**lrelu02_kwargs)

    def forward(self, x, pos, batch):
        edge_index = knn_graph(pos, self.num_neighbors, batch=batch, loop=True)
        shortcut_of_x = self.shortcut(x)
        x = self.mlp1(x)
        x = self.lfa1(edge_index, x, pos)
        x = self.lfa2(edge_index, x, pos)
        x = self.mlp2(x)
        x = self.lrelu(x + shortcut_of_x)
        return x, pos, batch


class GNNBlock(torch.nn.Module):

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.norm = LayerNorm(in_channels, elementwise_affine=True)
        self.conv = SAGEConv(in_channels, out_channels)

    def reset_parameters(self):
        self.norm.reset_parameters()
        self.conv.reset_parameters()

    def forward(self, x, edge_index, dropout_mask=None):
        x = self.norm(x).relu()
        if self.training and dropout_mask is not None:
            x = x * dropout_mask
        return self.conv(x, edge_index)


class InvertibleFunction(torch.autograd.Function):
    """An invertible autograd function. This allows for automatic
    backpropagation in a reversible fashion so that the memory of intermediate
    results can be freed during the forward pass and be constructed on-the-fly
    during the bachward pass.

    Args:
        ctx (torch.autograd.function.InvertibleFunctionBackward):
            A context object that can be used to stash information for backward
            computation.
        fn (torch.nn.Module): The forward function.
        fn_inverse (torch.nn.Module): The inverse function to recompute the
            freed input.
        num_bwd_passes (int): Number of backward passes to retain a link
            with the output. After the last backward pass the output is
            discarded and memory is freed.
        num_inputs (int): The number of inputs to the forward function.
        *args (tuple): Inputs and weights.
    """

    @staticmethod
    def forward(ctx, fn: torch.nn.Module, fn_inverse: torch.nn.Module, num_bwd_passes: int, num_inputs: int, *args):
        ctx.fn = fn
        ctx.fn_inverse = fn_inverse
        ctx.weights = args[num_inputs:]
        ctx.num_bwd_passes = num_bwd_passes
        ctx.num_inputs = num_inputs
        inputs = args[:num_inputs]
        ctx.input_requires_grad = []
        with torch.no_grad():
            x = []
            for element in inputs:
                if isinstance(element, torch.Tensor):
                    x.append(element.detach())
                    ctx.input_requires_grad.append(element.requires_grad)
                else:
                    x.append(element)
                    ctx.input_requires_grad.append(None)
            outputs = ctx.fn(*x)
        if not isinstance(outputs, tuple):
            outputs = outputs,
        detached_outputs = tuple(element.detach_() for element in outputs)
        inputs[0].storage().resize_(0)
        ctx.inputs = [inputs] * num_bwd_passes
        ctx.outputs = [detached_outputs] * num_bwd_passes
        return detached_outputs

    @staticmethod
    def backward(ctx, *grad_outputs):
        if len(ctx.outputs) == 0:
            raise RuntimeError(f"Trying to perform a backward pass on the 'InvertibleFunction' for more than '{ctx.num_bwd_passes}' times. Try raising 'num_bwd_passes'.")
        inputs = ctx.inputs.pop()
        outputs = ctx.outputs.pop()
        with torch.no_grad():
            inputs_inverted = ctx.fn_inverse(*(outputs + inputs[1:]))
            if len(ctx.outputs) == 0:
                for element in outputs:
                    element.storage().resize_(0)
            if not isinstance(inputs_inverted, tuple):
                inputs_inverted = inputs_inverted,
            for elem_orig, elem_inv in zip(inputs, inputs_inverted):
                elem_orig.storage().resize_(int(np.prod(elem_orig.size())))
                elem_orig.set_(elem_inv)
        with torch.set_grad_enabled(True):
            detached_inputs = []
            for element in inputs:
                if isinstance(element, torch.Tensor):
                    detached_inputs.append(element.detach())
                else:
                    detached_inputs.append(element)
            detached_inputs = tuple(detached_inputs)
            for x, req_grad in zip(detached_inputs, ctx.input_requires_grad):
                if isinstance(x, torch.Tensor):
                    x.requires_grad = req_grad
            tmp_output = ctx.fn(*detached_inputs)
        if not isinstance(tmp_output, tuple):
            tmp_output = tmp_output,
        filtered_detached_inputs = tuple(filter(lambda x: x.requires_grad if isinstance(x, torch.Tensor) else False, detached_inputs))
        gradients = torch.autograd.grad(outputs=tmp_output, inputs=filtered_detached_inputs + ctx.weights, grad_outputs=grad_outputs)
        input_gradients = []
        i = 0
        for rg in ctx.input_requires_grad:
            if rg:
                input_gradients.append(gradients[i])
                i += 1
            else:
                input_gradients.append(None)
        gradients = tuple(input_gradients) + gradients[-len(ctx.weights):]
        return (None, None, None, None) + gradients


class InvertibleModule(torch.nn.Module, ABC):
    """An abstract class for implementing invertible modules.

    Args:
        disable (bool, optional): If set to :obj:`True`, will disable the usage
            of :class:`InvertibleFunction` and will execute the module without
            memory savings. (default: :obj:`False`)
        num_bwd_passes (int, optional): Number of backward passes to retain a
            link with the output. After the last backward pass the output is
            discarded and memory is freed. (default: :obj:`1`)
    """

    def __init__(self, disable: bool=False, num_bwd_passes: int=1):
        super().__init__()
        self.disable = disable
        self.num_bwd_passes = num_bwd_passes

    def forward(self, *args):
        return self._fn_apply(args, self._forward, self._inverse)

    def inverse(self, *args):
        return self._fn_apply(args, self._inverse, self._forward)

    @abstractmethod
    def _forward(self):
        pass

    @abstractmethod
    def _inverse(self):
        pass

    def _fn_apply(self, args, fn, fn_inverse):
        if not self.disable:
            out = InvertibleFunction.apply(fn, fn_inverse, self.num_bwd_passes, len(args), *args, *tuple(p for p in self.parameters() if p.requires_grad))
        else:
            out = fn(*args)
        if isinstance(out, tuple) and len(out) == 1:
            return out[0]
        return out


class RevGNN(torch.nn.Module):

    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout, num_groups=2):
        super().__init__()
        self.dropout = dropout
        self.lin1 = Linear(in_channels, hidden_channels)
        self.lin2 = Linear(hidden_channels, out_channels)
        self.norm = LayerNorm(hidden_channels, elementwise_affine=True)
        assert hidden_channels % num_groups == 0
        self.convs = torch.nn.ModuleList()
        for _ in range(num_layers):
            conv = GNNBlock(hidden_channels // num_groups, hidden_channels // num_groups)
            self.convs.append(GroupAddRev(conv, num_groups=num_groups))

    def reset_parameters(self):
        self.lin1.reset_parameters()
        self.lin2.reset_parameters()
        self.norm.reset_parameters()
        for conv in self.convs:
            conv.reset_parameters()

    def forward(self, x, edge_index):
        x = self.lin1(x)
        mask = None
        if self.training and self.dropout > 0:
            mask = torch.zeros_like(x).bernoulli_(1 - self.dropout)
            mask = mask.requires_grad_(False)
            mask = mask / (1 - self.dropout)
        for conv in self.convs:
            x = conv(x, edge_index, mask)
        x = self.norm(x).relu()
        x = F.dropout(x, p=self.dropout, training=self.training)
        return self.lin2(x)


class RGAT(torch.nn.Module):

    def __init__(self, in_channels, hidden_channels, out_channels, num_relations):
        super().__init__()
        self.conv1 = RGATConv(in_channels, hidden_channels, num_relations)
        self.conv2 = RGATConv(hidden_channels, hidden_channels, num_relations)
        self.lin = torch.nn.Linear(hidden_channels, out_channels)

    def forward(self, x, edge_index, edge_type):
        x = self.conv1(x, edge_index, edge_type).relu()
        x = self.conv2(x, edge_index, edge_type).relu()
        x = self.lin(x)
        return F.log_softmax(x, dim=-1)


class RGCNEncoder(torch.nn.Module):

    def __init__(self, num_nodes, hidden_channels, num_relations):
        super().__init__()
        self.node_emb = Parameter(torch.Tensor(num_nodes, hidden_channels))
        self.conv1 = RGCNConv(hidden_channels, hidden_channels, num_relations, num_blocks=5)
        self.conv2 = RGCNConv(hidden_channels, hidden_channels, num_relations, num_blocks=5)
        self.reset_parameters()

    def reset_parameters(self):
        torch.nn.init.xavier_uniform_(self.node_emb)
        self.conv1.reset_parameters()
        self.conv2.reset_parameters()

    def forward(self, edge_index, edge_type):
        x = self.node_emb
        x = self.conv1(x, edge_index, edge_type).relu_()
        x = F.dropout(x, p=0.2, training=self.training)
        x = self.conv2(x, edge_index, edge_type)
        return x


class DistMultDecoder(torch.nn.Module):

    def __init__(self, num_relations, hidden_channels):
        super().__init__()
        self.rel_emb = Parameter(torch.Tensor(num_relations, hidden_channels))
        self.reset_parameters()

    def reset_parameters(self):
        torch.nn.init.xavier_uniform_(self.rel_emb)

    def forward(self, z, edge_index, edge_type):
        z_src, z_dst = z[edge_index[0]], z[edge_index[1]]
        rel = self.rel_emb[edge_type]
        return torch.sum(z_src * rel * z_dst, dim=1)


class BaseTransform(ABC):
    """An abstract base class for writing transforms.

    Transforms are a general way to modify and customize
    :class:`~torch_geometric.data.Data` objects, either by implicitly passing
    them as an argument to a :class:`~torch_geometric.data.Dataset`, or by
    applying them explicitly to individual :class:`~torch_geometric.data.Data`
    objects.

    .. code-block:: python

        import torch_geometric.transforms as T
        from torch_geometric.datasets import TUDataset

        transform = T.Compose([T.ToUndirected(), T.AddSelfLoops()])

        dataset = TUDataset(path, name='MUTAG', transform=transform)
        data = dataset[0]  # Implicitly transform data on every access.

        data = TUDataset(path, name='MUTAG')[0]
        data = transform(data)  # Explicitly transform data.
    """

    def __call__(self, data: Any) ->Any:
        raise NotImplementedError

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}()'


def functional_transform(name: str) ->Callable:

    def wrapper(cls: Any) ->Any:


        @functional_datapipe(name)
        class DynamicMapper(IterDataPipe):

            def __init__(self, dp: IterDataPipe, *args, **kwargs):
                super().__init__()
                self.dp = dp
                self.fn = cls(*args, **kwargs)

            def __iter__(self):
                for data in self.dp:
                    yield self.fn(copy.copy(data))
        return cls
    return wrapper


def to_undirected(edge_index: Tensor, edge_attr: Union[Optional[Tensor], List[Tensor]]=None, num_nodes: Optional[int]=None, reduce: str='add') ->Union[Tensor, Tuple[Tensor, Tensor], Tuple[Tensor, List[Tensor]]]:
    """Converts the graph given by :attr:`edge_index` to an undirected graph
    such that :math:`(j,i) \\in \\mathcal{E}` for every edge :math:`(i,j) \\in
    \\mathcal{E}`.

    Args:
        edge_index (LongTensor): The edge indices.
        edge_attr (Tensor or List[Tensor], optional): Edge weights or multi-
            dimensional edge features.
            If given as a list, will remove duplicates for all its entries.
            (default: :obj:`None`)
        num_nodes (int, optional): The number of nodes, *i.e.*
            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)
        reduce (string, optional): The reduce operation to use for merging edge
            features (:obj:`"add"`, :obj:`"mean"`, :obj:`"min"`, :obj:`"max"`,
            :obj:`"mul"`). (default: :obj:`"add"`)

    :rtype: :class:`LongTensor` if :attr:`edge_attr` is :obj:`None`, else
        (:class:`LongTensor`, :obj:`Tensor` or :obj:`List[Tensor]]`)

    Examples:

        >>> edge_index = torch.tensor([[0, 1, 1],
        ...                            [1, 0, 2]])
        >>> to_undirected(edge_index)
        tensor([[0, 1, 1, 2],
                [1, 0, 2, 1]])

        >>> edge_index = torch.tensor([[0, 1, 1],
        ...                            [1, 0, 2]])
        >>> edge_weight = torch.tensor([1., 1., 1.])
        >>> to_undirected(edge_index, edge_weight)
        (tensor([[0, 1, 1, 2],
                [1, 0, 2, 1]]),
        tensor([2., 2., 1., 1.]))

        >>> # Use 'mean' operation to merge edge features
        >>>  to_undirected(edge_index, edge_weight, reduce='mean')
        (tensor([[0, 1, 1, 2],
                [1, 0, 2, 1]]),
        tensor([1., 1., 1., 1.]))
    """
    if isinstance(edge_attr, int):
        edge_attr = None
        num_nodes = edge_attr
    row, col = edge_index[0], edge_index[1]
    row, col = torch.cat([row, col], dim=0), torch.cat([col, row], dim=0)
    edge_index = torch.stack([row, col], dim=0)
    if isinstance(edge_attr, Tensor):
        edge_attr = torch.cat([edge_attr, edge_attr], dim=0)
    elif isinstance(edge_attr, (list, tuple)):
        edge_attr = [torch.cat([e, e], dim=0) for e in edge_attr]
    return coalesce(edge_index, edge_attr, num_nodes, reduce)


def nested_iter(node: Union[Mapping, Sequence]) ->Iterable:
    if isinstance(node, Mapping):
        for key, value in node.items():
            for inner_key, inner_value in nested_iter(value):
                yield inner_key, inner_value
    elif isinstance(node, Sequence):
        for i, inner_value in enumerate(node):
            yield i, inner_value
    else:
        yield None, node


def download_url(url: str, folder: str, log: bool=True, filename: Optional[str]=None):
    """Downloads the content of an URL to a specific folder.

    Args:
        url (string): The url.
        folder (string): The folder.
        log (bool, optional): If :obj:`False`, will not print anything to the
            console. (default: :obj:`True`)
    """
    if filename is None:
        filename = url.rpartition('/')[2]
        filename = filename if filename[0] == '?' else filename.split('?')[0]
    path = osp.join(folder, filename)
    if osp.exists(path):
        if log:
            None
        return path
    if log:
        None
    makedirs(folder)
    context = ssl._create_unverified_context()
    data = urllib.request.urlopen(url, context=context)
    with open(path, 'wb') as f:
        while True:
            chunk = data.read(10 * 1024 * 1024)
            if not chunk:
                break
            f.write(chunk)
    return path


def maybe_log(path, log=True):
    if log:
        None


def extract_zip(path: str, folder: str, log: bool=True):
    """Extracts a zip archive to a specific folder.

    Args:
        path (string): The path to the tar archive.
        folder (string): The folder.
        log (bool, optional): If :obj:`False`, will not print anything to the
            console. (default: :obj:`True`)
    """
    maybe_log(path, log)
    with zipfile.ZipFile(path, 'r') as f:
        f.extractall(folder)


def parse_txt_array(src, sep=None, start=0, end=None, dtype=None, device=None):
    to_number = int
    if torch.is_floating_point(torch.empty(0, dtype=dtype)):
        to_number = float
    src = [[to_number(x) for x in line.split(sep)[start:end]] for line in src]
    src = torch.tensor(src).squeeze()
    return src


def read_txt_array(path, sep=None, start=0, end=None, dtype=None, device=None):
    with open(path, 'r') as f:
        src = f.read().split('\n')[:-1]
    return parse_txt_array(src, sep, start, end, dtype, device)


class GraphAttentionEmbedding(torch.nn.Module):

    def __init__(self, in_channels, out_channels, msg_dim, time_enc):
        super().__init__()
        self.time_enc = time_enc
        edge_dim = msg_dim + time_enc.out_channels
        self.conv = TransformerConv(in_channels, out_channels // 2, heads=2, dropout=0.1, edge_dim=edge_dim)

    def forward(self, x, last_update, edge_index, t, msg):
        rel_t = last_update[edge_index[0]] - t
        rel_t_enc = self.time_enc(rel_t)
        edge_attr = torch.cat([rel_t_enc, msg], dim=-1)
        return self.conv(x, edge_index, edge_attr)


class LinkPredictor(torch.nn.Module):

    def __init__(self, in_channels):
        super().__init__()
        self.lin_src = Linear(in_channels, in_channels)
        self.lin_dst = Linear(in_channels, in_channels)
        self.lin_final = Linear(in_channels, 1)

    def forward(self, z_src, z_dst):
        h = self.lin_src(z_src) + self.lin_dst(z_dst)
        h = h.relu()
        return self.lin_final(h)


class MaskLabel(torch.nn.Module):
    """The label embedding and masking layer from the `"Masked Label
    Prediction: Unified Message Passing Model for Semi-Supervised
    Classification" <https://arxiv.org/abs/2009.03509>`_ paper.

    Here, node labels :obj:`y` are merged to the initial node features :obj:`x`
    for a subset of their nodes according to :obj:`mask`.

    .. note::

        For an example of using :class:`MaskLabel`, see
        `examples/unimp_arxiv.py <https://github.com/pyg-team/
        pytorch_geometric/blob/master/examples/unimp_arxiv.py>`_.


    Args:
        num_classes (int): The number of classes.
        out_channels (int): Size of each output sample.
        method (str, optional): If set to :obj:`"add"`, label embeddings are
            added to the input. If set to :obj:`"concat"`, label embeddings are
            concatenated. In case :obj:`method="add"`, then :obj:`out_channels`
            needs to be identical to the input dimensionality of node features.
            (default: :obj:`"add"`)
    """

    def __init__(self, num_classes: int, out_channels: int, method: str='add'):
        super().__init__()
        self.method = method
        if method not in ['add', 'concat']:
            raise ValueError(f"'method' must be either 'add' or 'concat' (got '{method}')")
        self.emb = torch.nn.Embedding(num_classes, out_channels)
        self.reset_parameters()

    def reset_parameters(self):
        self.emb.reset_parameters()

    def forward(self, x: Tensor, y: Tensor, mask: Tensor) ->Tensor:
        """"""
        if self.method == 'concat':
            out = x.new_zeros(y.size(0), self.emb.weight.size(-1))
            out[mask] = self.emb(y[mask])
            return torch.cat([x, out], dim=-1)
        else:
            x = torch.clone(x)
            x[mask] += self.emb(y[mask])
            return x

    @staticmethod
    def ratio_mask(mask: Tensor, ratio: float):
        """Modifies :obj:`mask` by setting :obj:`ratio` of :obj:`True`
        entries to :obj:`False`. Does not operate in-place.

        Args:
            mask (torch.Tensor): The mask to re-mask.
            ratio (float): The ratio of entries to keep.
        """
        n = int(mask.sum())
        out = mask.clone()
        out[mask] = torch.rand(n, device=mask.device) < ratio
        return out

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}()'


class UniMP(torch.nn.Module):

    def __init__(self, in_channels, num_classes, hidden_channels, num_layers, heads, dropout=0.3):
        super().__init__()
        self.label_emb = MaskLabel(num_classes, in_channels)
        self.convs = torch.nn.ModuleList()
        self.norms = torch.nn.ModuleList()
        for i in range(1, num_layers + 1):
            if i < num_layers:
                out_channels = hidden_channels // heads
                concat = True
            else:
                out_channels = num_classes
                concat = False
            conv = TransformerConv(in_channels, out_channels, heads, concat=concat, beta=True, dropout=dropout)
            self.convs.append(conv)
            in_channels = hidden_channels
            if i < num_layers:
                self.norms.append(torch.nn.LayerNorm(hidden_channels))

    def forward(self, x, y, edge_index, label_mask):
        x = self.label_emb(x, y, label_mask)
        for conv, norm in zip(self.convs, self.norms):
            x = norm(conv(x, edge_index)).relu()
        return self.convs[-1](x, edge_index)


class WL(torch.nn.Module):

    def __init__(self, num_layers):
        super().__init__()
        self.convs = torch.nn.ModuleList([WLConv() for _ in range(num_layers)])

    def forward(self, x, edge_index, batch=None):
        hists = []
        for conv in self.convs:
            x = conv(x, edge_index)
            hists.append(conv.histogram(x, batch, norm=True))
        return hists


class SWISH(nn.Module):

    def __init__(self, inplace=False):
        super().__init__()
        self.inplace = inplace

    def forward(self, x):
        if self.inplace:
            x.mul_(torch.sigmoid(x))
            return x
        else:
            return x * torch.sigmoid(x)


def register_base(mapping: Dict[str, Any], key: str, module: Any=None) ->Union[None, Callable]:
    """Base function for registering a module in GraphGym.

    Args:
        mapping (dict): Python dictionary to register the module.
            hosting all the registered modules
        key (string): The name of the module.
        module (any, optional): The module. If set to :obj:`None`, will return
            a decorator to register a module.
    """
    if module is not None:
        if key in mapping:
            raise KeyError(f"Module with '{key}' already defined")
        mapping[key] = module
        return

    def bounded_register(module):
        register_base(mapping, key, module)
        return module
    return bounded_register


def register_node_encoder(key: str, module: Any=None):
    """Registers a node feature encoder in GraphGym."""
    return register_base(node_encoder_dict, key, module)


class ExampleNodeEncoder(torch.nn.Module):
    """
        Provides an encoder for integer node features

        Parameters:
        num_classes - the number of classes for the embedding mapping to learn
    """

    def __init__(self, emb_dim, num_classes=None):
        super().__init__()
        self.encoder = torch.nn.Embedding(num_classes, emb_dim)
        torch.nn.init.xavier_uniform_(self.encoder.weight.data)

    def forward(self, batch):
        batch.x = self.encoder(batch.x[:, 0])
        return batch


def register_edge_encoder(key: str, module: Any=None):
    """Registers an edge feature encoder in GraphGym."""
    return register_base(edge_encoder_dict, key, module)


class ExampleEdgeEncoder(torch.nn.Module):

    def __init__(self, emb_dim):
        super().__init__()
        self.bond_embedding_list = torch.nn.ModuleList()
        full_bond_feature_dims = get_bond_feature_dims()
        for i, dim in enumerate(full_bond_feature_dims):
            emb = torch.nn.Embedding(dim, emb_dim)
            torch.nn.init.xavier_uniform_(emb.weight.data)
            self.bond_embedding_list.append(emb)

    def forward(self, batch):
        bond_embedding = 0
        for i in range(batch.edge_feature.shape[1]):
            bond_embedding += self.bond_embedding_list[i](batch.edge_attr[:, i])
        batch.edge_attr = bond_embedding
        return batch


def register_head(key: str, module: Any=None):
    """Registers a GNN prediction head in GraphGym."""
    return register_base(head_dict, key, module)


class ExampleNodeHead(nn.Module):
    """Head of GNN, node prediction"""

    def __init__(self, dim_in, dim_out):
        super().__init__()
        self.layer_post_mp = nn.Linear(dim_in, dim_out, bias=True)

    def _apply_index(self, batch):
        if batch.node_label_index.shape[0] == batch.node_label.shape[0]:
            return batch.x[batch.node_label_index], batch.node_label
        else:
            return batch.x[batch.node_label_index], batch.node_label[batch.node_label_index]

    def forward(self, batch):
        batch = self.layer_post_mp(batch)
        pred, label = self._apply_index(batch)
        return pred, label


def register_layer(key: str, module: Any=None):
    """Registers a GNN layer in GraphGym."""
    return register_base(layer_dict, key, module)


class ExampleConv2(nn.Module):

    def __init__(self, dim_in, dim_out, bias=False, **kwargs):
        super().__init__()
        self.model = ExampleConv2Layer(dim_in, dim_out, bias=bias)

    def forward(self, batch):
        batch.x = self.model(batch.x, batch.edge_index)
        return batch


def register_network(key: str, module: Any=None):
    """Registers a GNN model in GraphGym."""
    return register_base(network_dict, key, module)


class ExampleGNN(torch.nn.Module):

    def __init__(self, dim_in, dim_out, num_layers=2, model_type='GCN'):
        super().__init__()
        conv_model = self.build_conv_model(model_type)
        self.convs = nn.ModuleList()
        self.convs.append(conv_model(dim_in, dim_in))
        for _ in range(num_layers - 1):
            self.convs.append(conv_model(dim_in, dim_in))
        GNNHead = register.head_dict[cfg.dataset.task]
        self.post_mp = GNNHead(dim_in=dim_in, dim_out=dim_out)

    def build_conv_model(self, model_type):
        if model_type == 'GCN':
            return pyg_nn.GCNConv
        elif model_type == 'GAT':
            return pyg_nn.GATConv
        elif model_type == 'GraphSage':
            return pyg_nn.SAGEConv
        else:
            raise ValueError(f'Model {model_type} unavailable')

    def forward(self, batch):
        x, edge_index = batch.x, batch.edge_index
        for i in range(len(self.convs)):
            x = self.convs[i](x, edge_index)
            x = F.relu(x)
            x = F.dropout(x, p=0.1, training=self.training)
        batch.x = x
        batch = self.post_mp(batch)
        return batch


def GNNLayer(dim_in, dim_out, has_act=True):
    """
    Wrapper for a GNN layer

    Args:
        dim_in (int): Input dimension
        dim_out (int): Output dimension
        has_act (bool): Whether has activation function after the layer

    """
    return GeneralLayer(cfg.gnn.layer_type, layer_config=new_layer_config(dim_in, dim_out, 1, has_act=has_act, has_bias=False, cfg=cfg))


def register_stage(key: str, module: Any=None):
    """Registers a customized GNN stage in GraphGym."""
    return register_base(stage_dict, key, module)


class GNNStackStage(nn.Module):
    """
    Simple Stage that stack GNN layers

    Args:
        dim_in (int): Input dimension
        dim_out (int): Output dimension
        num_layers (int): Number of GNN layers
    """

    def __init__(self, dim_in, dim_out, num_layers):
        super().__init__()
        self.num_layers = num_layers
        for i in range(num_layers):
            if cfg.gnn.stage_type == 'skipconcat':
                d_in = dim_in if i == 0 else dim_in + i * dim_out
            else:
                d_in = dim_in if i == 0 else dim_out
            layer = GNNLayer(d_in, dim_out)
            self.add_module('layer{}'.format(i), layer)

    def forward(self, batch):
        """"""
        for i, layer in enumerate(self.children()):
            x = batch.x
            batch = layer(batch)
            if cfg.gnn.stage_type == 'skipsum':
                batch.x = x + batch.x
            elif cfg.gnn.stage_type == 'skipconcat' and i < self.num_layers - 1:
                batch.x = torch.cat([x, batch.x], dim=1)
        if cfg.gnn.l2norm:
            batch.x = F.normalize(batch.x, p=2, dim=-1)
        return batch


class HeteroModel(torch.nn.Module):

    def __init__(self):
        super().__init__()
        self.conv1 = HeteroConv({('paper', 'to', 'paper'): GCNConv(-1, 32), ('author', 'to', 'paper'): SAGEConv((-1, -1), 32), ('paper', 'to', 'author'): SAGEConv((-1, -1), 32)})
        self.conv2 = HeteroConv({('paper', 'to', 'paper'): GCNConv(-1, 32), ('author', 'to', 'paper'): SAGEConv((-1, -1), 32), ('paper', 'to', 'author'): SAGEConv((-1, -1), 32)})


class DummyModel(torch.nn.Module):

    def forward(self, x_dict, edge_index_dict, *args) ->torch.Tensor:
        return x_dict['paper'].mean().view(-1)


class HeteroSAGE(torch.nn.Module):

    def __init__(self, metadata):
        super().__init__()
        self.graph_sage = to_hetero(GraphSAGE(), metadata, debug=False)

    def forward(self, x_dict, edge_index_dict, additonal_arg=None) ->torch.Tensor:
        assert additonal_arg is not None
        return self.graph_sage(x_dict, edge_index_dict)['paper']


class ModuleDictModel(nn.Module):

    def __init__(self):
        super().__init__()
        self.acts = nn.ModuleDict({'lrelu': nn.LeakyReLU(), 'prelu': nn.PReLU()})

    def forward(self, x: torch.Tensor, act_type: str) ->torch.Tensor:
        return self.acts[act_type](x)


class Net1(torch.nn.Module):

    def __init__(self):
        super().__init__()
        self.lin1 = Linear(16, 32)
        self.lin2 = Linear(8, 16)

    def forward(self, x: Tensor, edge_attr: Tensor) ->Tuple[Tensor, Tensor]:
        x = self.lin1(x)
        edge_attr = self.lin2(edge_attr)
        return x, edge_attr


class Net2(torch.nn.Module):

    def __init__(self):
        super().__init__()
        self.lin1 = Linear(16, 16)
        self.conv1 = SAGEConv(16, 32)
        self.lin2 = Linear(32, 32)

    def forward(self, x: Tensor, edge_index: Tensor) ->Tensor:
        x = self.lin1(x).relu_()
        x = self.conv1(x, edge_index).relu_()
        x = self.lin2(x)
        return x


class Net3(torch.nn.Module):

    def __init__(self):
        super().__init__()
        self.lin1 = Linear(8, 16)
        self.conv1 = GINEConv(nn=Linear(16, 32))

    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor) ->Tensor:
        x = self.conv1(x, edge_index, self.lin1(edge_attr))
        return x


class Net4(torch.nn.Module):

    def __init__(self):
        super().__init__()
        self.conv1 = SAGEConv(16, 16)
        self.conv2 = SAGEConv(16, 16)
        self.lin1 = Linear(3 * 16, 32)

    def forward(self, x0: Tensor, edge_index: Tensor) ->Tensor:
        x1 = self.conv1(x0, edge_index).relu_()
        x2 = self.conv2(x1, edge_index).relu_()
        return self.lin1(torch.cat([x0, x1, x2], dim=-1))


class Net5(torch.nn.Module):

    def __init__(self, num_layers):
        super().__init__()
        self.lins = torch.nn.ModuleList()
        self.convs = torch.nn.ModuleList()
        for _ in range(num_layers):
            self.lins.append(Linear(16, 16))
            self.convs.append(SAGEConv(16, 16))

    def forward(self, x: Tensor, edge_index: Tensor) ->Tensor:
        for lin, conv in zip(self.lins, self.convs):
            x = conv(x, edge_index) + lin(x)
        return x


class Net6(torch.nn.Module):

    def __init__(self, num_layers):
        super().__init__()
        self.lins = torch.nn.ModuleDict()
        self.convs = torch.nn.ModuleDict()
        for i in range(num_layers):
            self.lins[str(i)] = Linear(16, 16)
            self.convs[str(i)] = SAGEConv(16, 16)

    def forward(self, x: Tensor, edge_index: Tensor) ->Tensor:
        for i in range(len(self.lins)):
            x = self.convs[str(i)](x, edge_index) + self.lins[str(i)](x)
        return x


class Net7(torch.nn.Module):

    def __init__(self):
        super().__init__()
        self.mlp1 = Sequential(Linear(16, 16), ReLU(), Linear(16, 16))
        self.conv1 = SAGEConv(16, 32)

    def forward(self, x: Tensor, edge_index: Tensor) ->Tensor:
        x = self.mlp1(x)
        x = self.conv1(x, edge_index)
        return x


class Net8(torch.nn.Module):

    def __init__(self):
        super().__init__()
        self.lin1 = LazyLinear(-1, 32)

    def forward(self, x: Tensor) ->Tensor:
        x = self.lin1(x)
        return x


class Net9(torch.nn.Module):

    def __init__(self):
        super().__init__()
        self.batch_norm = BatchNorm(16)

    def forward(self, x: Tensor) ->Tensor:
        return self.batch_norm(x)


def dropout_edge(edge_index: Tensor, p: float=0.5, force_undirected: bool=False, training: bool=True) ->Tuple[Tensor, Tensor]:
    """Randomly drops edges from the adjacency matrix
    :obj:`edge_index` with probability :obj:`p` using samples from
    a Bernoulli distribution.

    The method returns (1) the retained :obj:`edge_index`, (2) the edge mask
    or index indicating which edges were retained, depending on the argument
    :obj:`force_undirected`.

    Args:
        edge_index (LongTensor): The edge indices.
        p (float, optional): Dropout probability. (default: :obj:`0.5`)
        force_undirected (bool, optional): If set to :obj:`True`, will either
            drop or keep both edges of an undirected edge.
            (default: :obj:`False`)
        training (bool, optional): If set to :obj:`False`, this operation is a
            no-op. (default: :obj:`True`)

    :rtype: (:class:`LongTensor`, :class:`BoolTensor` or :class:`LongTensor`)

    Examples:

        >>> edge_index = torch.tensor([[0, 1, 1, 2, 2, 3],
        ...                            [1, 0, 2, 1, 3, 2]])
        >>> edge_index, edge_mask = dropout_edge(edge_index)
        >>> edge_index
        tensor([[0, 1, 2, 2],
                [1, 2, 1, 3]])
        >>> edge_mask # masks indicating which edges are retained
        tensor([ True, False,  True,  True,  True, False])

        >>> edge_index, edge_id = dropout_edge(edge_index,
        ...                                    force_undirected=True)
        >>> edge_index
        tensor([[0, 1, 2, 1, 2, 3],
                [1, 2, 3, 0, 1, 2]])
        >>> edge_id # indices indicating which edges are retained
        tensor([0, 2, 4, 0, 2, 4])
    """
    if p < 0.0 or p > 1.0:
        raise ValueError(f'Dropout probability has to be between 0 and 1 (got {p}')
    if not training or p == 0.0:
        edge_mask = edge_index.new_ones(edge_index.size(1), dtype=torch.bool)
        return edge_index, edge_mask
    row, col = edge_index
    edge_mask = torch.rand(row.size(0), device=edge_index.device) >= p
    if force_undirected:
        edge_mask[row > col] = False
    edge_index = edge_index[:, edge_mask]
    if force_undirected:
        edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)
        edge_mask = edge_mask.nonzero().repeat((2, 1)).squeeze()
    return edge_index, edge_mask


class Net10(torch.nn.Module):

    def __init__(self):
        super().__init__()
        self.conv = SAGEConv(16, 32)

    def forward(self, x: Tensor, edge_index: Tensor) ->Tensor:
        x = F.dropout(x, p=0.5, training=self.training)
        edge_index, _ = dropout_edge(edge_index, p=0.5, training=self.training)
        return self.conv(x, edge_index)


class GraphLevelGNN(torch.nn.Module):

    def __init__(self):
        super().__init__()
        self.conv = SAGEConv(16, 32)
        self.pool = MeanAggregation()
        self.lin = Linear(32, 64)

    def forward(self, x: Tensor, edge_index: Tensor, batch: Tensor) ->Tensor:
        x = self.conv(x, edge_index)
        x = self.pool(x, batch)
        x = self.lin(x)
        return x


class ModelLoops(torch.nn.Module):

    def __init__(self):
        super().__init__()
        self.conv = MessagePassingLoops()

    def forward(self, x):
        return self.conv(x)


class ExplanationType(Enum):
    """Enum class for the explanation type."""
    model = 'model'
    phenomenon = 'phenomenon'


class MaskType(Enum):
    """Enum class for the mask type."""
    object = 'object'
    common_attributes = 'common_attributes'
    attributes = 'attributes'


class ThresholdType(Enum):
    """Enum class for the threshold type."""
    hard = 'hard'
    topk = 'topk'
    topk_hard = 'topk_hard'


class ModelMode(Enum):
    """Enum class for the model return type."""
    binary_classification = 'binary_classification'
    multiclass_classification = 'multiclass_classification'
    regression = 'regression'


class ModelReturnType(Enum):
    """Enum class for the model return type."""
    raw = 'raw'
    probs = 'probs'
    log_probs = 'log_probs'


class ModelTaskLevel(Enum):
    """Enum class for the model task level."""
    node = 'node'
    edge = 'edge'
    graph = 'graph'


def k_hop_subgraph(node_idx: Union[int, List[int], Tensor], num_hops: int, edge_index: Tensor, relabel_nodes: bool=False, num_nodes: Optional[int]=None, flow: str='source_to_target', directed: bool=False) ->Tuple[Tensor, Tensor, Tensor, Tensor]:
    """Computes the induced subgraph of :obj:`edge_index` around all nodes in
    :attr:`node_idx` reachable within :math:`k` hops.

    The :attr:`flow` argument denotes the direction of edges for finding
    :math:`k`-hop neighbors. If set to :obj:`"source_to_target"`, then the
    method will find all neighbors that point to the initial set of seed nodes
    in :attr:`node_idx.`
    This mimics the natural flow of message passing in Graph Neural Networks.

    The method returns (1) the nodes involved in the subgraph, (2) the filtered
    :obj:`edge_index` connectivity, (3) the mapping from node indices in
    :obj:`node_idx` to their new location, and (4) the edge mask indicating
    which edges were preserved.

    Args:
        node_idx (int, list, tuple or :obj:`torch.Tensor`): The central seed
            node(s).
        num_hops (int): The number of hops :math:`k`.
        edge_index (LongTensor): The edge indices.
        relabel_nodes (bool, optional): If set to :obj:`True`, the resulting
            :obj:`edge_index` will be relabeled to hold consecutive indices
            starting from zero. (default: :obj:`False`)
        num_nodes (int, optional): The number of nodes, *i.e.*
            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)
        flow (string, optional): The flow direction of :math:`k`-hop
            aggregation (:obj:`"source_to_target"` or
            :obj:`"target_to_source"`). (default: :obj:`"source_to_target"`)
        directed (bool, optional): If set to :obj:`False`, will include all
            edges between all sampled nodes. (default: :obj:`True`)

    :rtype: (:class:`LongTensor`, :class:`LongTensor`, :class:`LongTensor`,
             :class:`BoolTensor`)

    Examples:

        >>> edge_index = torch.tensor([[0, 1, 2, 3, 4, 5],
        ...                            [2, 2, 4, 4, 6, 6]])

        >>> # Center node 6, 2-hops
        >>> subset, edge_index, mapping, edge_mask = k_hop_subgraph(
        ...     6, 2, edge_index, relabel_nodes=True)
        >>> subset
        tensor([2, 3, 4, 5, 6])
        >>> edge_index
        tensor([[0, 1, 2, 3],
                [2, 2, 4, 4]])
        >>> mapping
        tensor([4])
        >>> edge_mask
        tensor([False, False,  True,  True,  True,  True])
        >>> subset[mapping]
        tensor([6])

        >>> edge_index = torch.tensor([[1, 2, 4, 5],
        ...                            [0, 1, 5, 6]])
        >>> (subset, edge_index,
        ...  mapping, edge_mask) = k_hop_subgraph([0, 6], 2,
        ...                                       edge_index,
        ...                                       relabel_nodes=True)
        >>> subset
        tensor([0, 1, 2, 4, 5, 6])
        >>> edge_index
        tensor([[1, 2, 3, 4],
                [0, 1, 4, 5]])
        >>> mapping
        tensor([0, 5])
        >>> edge_mask
        tensor([True, True, True, True])
        >>> subset[mapping]
        tensor([0, 6])
    """
    num_nodes = maybe_num_nodes(edge_index, num_nodes)
    assert flow in ['source_to_target', 'target_to_source']
    if flow == 'target_to_source':
        row, col = edge_index
    else:
        col, row = edge_index
    node_mask = row.new_empty(num_nodes, dtype=torch.bool)
    edge_mask = row.new_empty(row.size(0), dtype=torch.bool)
    if isinstance(node_idx, (int, list, tuple)):
        node_idx = torch.tensor([node_idx], device=row.device).flatten()
    else:
        node_idx = node_idx
    subsets = [node_idx]
    for _ in range(num_hops):
        node_mask.fill_(False)
        node_mask[subsets[-1]] = True
        torch.index_select(node_mask, 0, row, out=edge_mask)
        subsets.append(col[edge_mask])
    subset, inv = torch.cat(subsets).unique(return_inverse=True)
    inv = inv[:node_idx.numel()]
    node_mask.fill_(False)
    node_mask[subset] = True
    if not directed:
        edge_mask = node_mask[row] & node_mask[col]
    edge_index = edge_index[:, edge_mask]
    if relabel_nodes:
        node_idx = row.new_full((num_nodes,), -1)
        node_idx[subset] = torch.arange(subset.size(0), device=row.device)
        edge_index = node_idx[edge_index]
    return subset, edge_index, inv, edge_mask


def clear_masks(model: torch.nn.Module):
    """Clear all masks from the model."""
    for module in model.modules():
        if isinstance(module, MessagePassing):
            module.explain = False
            module._edge_mask = None
            module._loop_mask = None
            module._apply_sigmoid = True
    return module


def set_masks(model: torch.nn.Module, mask: Tensor, edge_index: Tensor, apply_sigmoid: bool=True):
    """Apply mask to every graph layer in the :obj:`model`."""
    loop_mask = edge_index[0] != edge_index[1]
    for module in model.modules():
        if isinstance(module, MessagePassing):
            module.explain = True
            module._edge_mask = mask
            module._loop_mask = loop_mask
            module._apply_sigmoid = apply_sigmoid


class IntegerFeatureEncoder(torch.nn.Module):
    """
    Provides an encoder for integer node features.

    Args:
        emb_dim (int): Output embedding dimension
        num_classes (int): the number of classes for the
        embedding mapping to learn from
    """

    def __init__(self, emb_dim, num_classes=None):
        super().__init__()
        self.encoder = torch.nn.Embedding(num_classes, emb_dim)
        torch.nn.init.xavier_uniform_(self.encoder.weight.data)

    def forward(self, batch):
        """"""
        batch.x = self.encoder(batch.x[:, 0])
        return batch


class AtomEncoder(torch.nn.Module):
    """
    The atom Encoder used in OGB molecule dataset.

    Args:
        emb_dim (int): Output embedding dimension
        num_classes: None
    """

    def __init__(self, emb_dim, num_classes=None):
        super().__init__()
        self.atom_embedding_list = torch.nn.ModuleList()
        for i, dim in enumerate(get_atom_feature_dims()):
            emb = torch.nn.Embedding(dim, emb_dim)
            torch.nn.init.xavier_uniform_(emb.weight.data)
            self.atom_embedding_list.append(emb)

    def forward(self, batch):
        """"""
        encoded_features = 0
        for i in range(batch.x.shape[1]):
            encoded_features += self.atom_embedding_list[i](batch.x[:, i])
        batch.x = encoded_features
        return batch


class BondEncoder(torch.nn.Module):
    """
    The bond Encoder used in OGB molecule dataset.

    Args:
        emb_dim (int): Output edge embedding dimension
    """

    def __init__(self, emb_dim):
        super().__init__()
        self.bond_embedding_list = torch.nn.ModuleList()
        for i, dim in enumerate(get_bond_feature_dims()):
            emb = torch.nn.Embedding(dim, emb_dim)
            torch.nn.init.xavier_uniform_(emb.weight.data)
            self.bond_embedding_list.append(emb)

    def forward(self, batch):
        """"""
        bond_embedding = 0
        for i in range(batch.edge_attr.shape[1]):
            edge_attr = batch.edge_attr
            bond_embedding += self.bond_embedding_list[i](edge_attr[:, i])
        batch.edge_attr = bond_embedding
        return batch


class GNNNodeHead(nn.Module):
    """
    GNN prediction head for node prediction tasks.

    Args:
        dim_in (int): Input dimension
        dim_out (int): Output dimension. For binary prediction, dim_out=1.
    """

    def __init__(self, dim_in, dim_out):
        super().__init__()
        self.layer_post_mp = MLP(new_layer_config(dim_in, dim_out, cfg.gnn.layers_post_mp, has_act=False, has_bias=True, cfg=cfg))

    def _apply_index(self, batch):
        mask = '{}_mask'.format(batch.split)
        return batch.x[batch[mask]], batch.y[batch[mask]]

    def forward(self, batch):
        batch = self.layer_post_mp(batch)
        pred, label = self._apply_index(batch)
        return pred, label


class GNNEdgeHead(nn.Module):
    """
    GNN prediction head for edge/link prediction tasks.

    Args:
        dim_in (int): Input dimension
        dim_out (int): Output dimension. For binary prediction, dim_out=1.
    """

    def __init__(self, dim_in, dim_out):
        super().__init__()
        if cfg.model.edge_decoding == 'concat':
            self.layer_post_mp = MLP(new_layer_config(dim_in * 2, dim_out, cfg.gnn.layers_post_mp, has_act=False, has_bias=True, cfg=cfg))
            self.decode_module = lambda v1, v2: self.layer_post_mp(torch.cat((v1, v2), dim=-1))
        else:
            if dim_out > 1:
                raise ValueError('Binary edge decoding ({})is used for multi-class edge/link prediction.'.format(cfg.model.edge_decoding))
            self.layer_post_mp = MLP(new_layer_config(dim_in, dim_in, cfg.gnn.layers_post_mp, has_act=False, has_bias=True, cfg=cfg))
            if cfg.model.edge_decoding == 'dot':
                self.decode_module = lambda v1, v2: torch.sum(v1 * v2, dim=-1)
            elif cfg.model.edge_decoding == 'cosine_similarity':
                self.decode_module = nn.CosineSimilarity(dim=-1)
            else:
                raise ValueError('Unknown edge decoding {}.'.format(cfg.model.edge_decoding))

    def _apply_index(self, batch):
        index = '{}_edge_index'.format(batch.split)
        label = '{}_edge_label'.format(batch.split)
        return batch.x[batch[index]], batch[label]

    def forward(self, batch):
        if cfg.model.edge_decoding != 'concat':
            batch = self.layer_post_mp(batch)
        pred, label = self._apply_index(batch)
        nodes_first = pred[0]
        nodes_second = pred[1]
        pred = self.decode_module(nodes_first, nodes_second)
        return pred, label


class GNNGraphHead(nn.Module):
    """
    GNN prediction head for graph prediction tasks.
    The optional post_mp layer (specified by cfg.gnn.post_mp) is used
    to transform the pooled embedding using an MLP.

    Args:
        dim_in (int): Input dimension
        dim_out (int): Output dimension. For binary prediction, dim_out=1.
    """

    def __init__(self, dim_in, dim_out):
        super().__init__()
        self.layer_post_mp = MLP(new_layer_config(dim_in, dim_out, cfg.gnn.layers_post_mp, has_act=False, has_bias=True, cfg=cfg))
        self.pooling_fun = register.pooling_dict[cfg.model.graph_pooling]

    def _apply_index(self, batch):
        return batch.graph_feature, batch.y

    def forward(self, batch):
        graph_emb = self.pooling_fun(batch.x, batch.batch)
        graph_emb = self.layer_post_mp(graph_emb)
        batch.graph_feature = graph_emb
        pred, label = self._apply_index(batch)
        return pred, label


def is_uninitialized_parameter(x: Any) ->bool:
    if not hasattr(nn.parameter, 'UninitializedParameter'):
        return False
    return isinstance(x, nn.parameter.UninitializedParameter)


def reset_bias_(bias: Optional[Tensor], in_channels: int, initializer: Optional[str]=None) ->Optional[Tensor]:
    if bias is None or in_channels <= 0:
        pass
    elif initializer == 'zeros':
        inits.zeros(bias)
    elif initializer is None:
        inits.uniform(in_channels, bias)
    else:
        raise RuntimeError(f"Bias initializer '{initializer}' not supported")
    return bias


def reset_weight_(weight: Tensor, in_channels: int, initializer: Optional[str]=None) ->Tensor:
    if in_channels <= 0:
        pass
    elif initializer == 'glorot':
        inits.glorot(weight)
    elif initializer == 'uniform':
        bound = 1.0 / math.sqrt(in_channels)
        torch.nn.init.uniform_(weight.data, -bound, bound)
    elif initializer == 'kaiming_uniform':
        inits.kaiming_uniform(weight, fan=in_channels, a=math.sqrt(5))
    elif initializer is None:
        inits.kaiming_uniform(weight, fan=in_channels, a=math.sqrt(5))
    else:
        raise RuntimeError(f"Weight initializer '{initializer}' not supported")
    return weight


class Linear(torch.nn.Module):
    """Applies a linear tranformation to the incoming data

    .. math::
        \\mathbf{x}^{\\prime} = \\mathbf{x} \\mathbf{W}^{\\top} + \\mathbf{b}

    similar to :class:`torch.nn.Linear`.
    It supports lazy initialization and customizable weight and bias
    initialization.

    Args:
        in_channels (int): Size of each input sample. Will be initialized
            lazily in case it is given as :obj:`-1`.
        out_channels (int): Size of each output sample.
        bias (bool, optional): If set to :obj:`False`, the layer will not learn
            an additive bias. (default: :obj:`True`)
        weight_initializer (str, optional): The initializer for the weight
            matrix (:obj:`"glorot"`, :obj:`"uniform"`, :obj:`"kaiming_uniform"`
            or :obj:`None`).
            If set to :obj:`None`, will match default weight initialization of
            :class:`torch.nn.Linear`. (default: :obj:`None`)
        bias_initializer (str, optional): The initializer for the bias vector
            (:obj:`"zeros"` or :obj:`None`).
            If set to :obj:`None`, will match default bias initialization of
            :class:`torch.nn.Linear`. (default: :obj:`None`)

    Shapes:
        - **input:** features :math:`(*, F_{in})`
        - **output:** features :math:`(*, F_{out})`
    """

    def __init__(self, in_channels: int, out_channels: int, bias: bool=True, weight_initializer: Optional[str]=None, bias_initializer: Optional[str]=None):
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.weight_initializer = weight_initializer
        self.bias_initializer = bias_initializer
        if in_channels > 0:
            self.weight = Parameter(torch.Tensor(out_channels, in_channels))
        else:
            self.weight = nn.parameter.UninitializedParameter()
            self._hook = self.register_forward_pre_hook(self.initialize_parameters)
        if bias:
            self.bias = Parameter(torch.Tensor(out_channels))
        else:
            self.register_parameter('bias', None)
        self._load_hook = self._register_load_state_dict_pre_hook(self._lazy_load_hook)
        self.reset_parameters()

    def __deepcopy__(self, memo):
        out = Linear(self.in_channels, self.out_channels, self.bias is not None, self.weight_initializer, self.bias_initializer)
        if self.in_channels > 0:
            out.weight = copy.deepcopy(self.weight, memo)
        if self.bias is not None:
            out.bias = copy.deepcopy(self.bias, memo)
        return out

    def reset_parameters(self):
        reset_weight_(self.weight, self.in_channels, self.weight_initializer)
        reset_bias_(self.bias, self.in_channels, self.bias_initializer)

    def forward(self, x: Tensor) ->Tensor:
        """
        Args:
            x (Tensor): The features.
        """
        return F.linear(x, self.weight, self.bias)

    @torch.no_grad()
    def initialize_parameters(self, module, input):
        if is_uninitialized_parameter(self.weight):
            self.in_channels = input[0].size(-1)
            self.weight.materialize((self.out_channels, self.in_channels))
            self.reset_parameters()
        self._hook.remove()
        delattr(self, '_hook')

    def _save_to_state_dict(self, destination, prefix, keep_vars):
        if is_uninitialized_parameter(self.weight) or torch.onnx.is_in_onnx_export():
            destination[prefix + 'weight'] = self.weight
        else:
            destination[prefix + 'weight'] = self.weight.detach()
        if self.bias is not None:
            if torch.onnx.is_in_onnx_export():
                destination[prefix + 'bias'] = self.bias
            else:
                destination[prefix + 'bias'] = self.bias.detach()

    def _lazy_load_hook(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs):
        weight = state_dict.get(prefix + 'weight', None)
        if weight is not None and is_uninitialized_parameter(weight):
            self.in_channels = -1
            self.weight = nn.parameter.UninitializedParameter()
            if not hasattr(self, '_hook'):
                self._hook = self.register_forward_pre_hook(self.initialize_parameters)
        elif weight is not None and is_uninitialized_parameter(self.weight):
            self.in_channels = weight.size(-1)
            self.weight.materialize((self.out_channels, self.in_channels))
            if hasattr(self, '_hook'):
                self._hook.remove()
                delattr(self, '_hook')

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}({self.in_channels}, {self.out_channels}, bias={self.bias is not None})'


class SoftmaxAggregation(Aggregation):
    """The softmax aggregation operator based on a temperature term, as
    described in the `"DeeperGCN: All You Need to Train Deeper GCNs"
    <https://arxiv.org/abs/2006.07739>`_ paper

    .. math::
        \\mathrm{softmax}(\\mathcal{X}|t) = \\sum_{\\mathbf{x}_i\\in\\mathcal{X}}
        \\frac{\\exp(t\\cdot\\mathbf{x}_i)}{\\sum_{\\mathbf{x}_j\\in\\mathcal{X}}
        \\exp(t\\cdot\\mathbf{x}_j)}\\cdot\\mathbf{x}_{i},

    where :math:`t` controls the softness of the softmax when aggregating over
    a set of features :math:`\\mathcal{X}`.

    Args:
        t (float, optional): Initial inverse temperature for softmax
            aggregation. (default: :obj:`1.0`)
        learn (bool, optional): If set to :obj:`True`, will learn the value
            :obj:`t` for softmax aggregation dynamically.
            (default: :obj:`False`)
        semi_grad (bool, optional): If set to :obj:`True`, will turn off
            gradient calculation during softmax computation. Therefore, only
            semi-gradients are used during backpropagation. Useful for saving
            memory and accelerating backward computation when :obj:`t` is not
            learnable. (default: :obj:`False`)
        channels (int, optional): Number of channels to learn from :math:`t`.
            If set to a value greater than :obj:`1`, :math:`t` will be learned
            per input feature channel. This requires compatible shapes for the
            input to the forward calculation. (default: :obj:`1`)
    """

    def __init__(self, t: float=1.0, learn: bool=False, semi_grad: bool=False, channels: int=1):
        super().__init__()
        if learn and semi_grad:
            raise ValueError(f"Cannot enable 'semi_grad' in '{self.__class__.__name__}' in case the temperature term 't' is learnable")
        if not learn and channels != 1:
            raise ValueError(f"Cannot set 'channels' greater than '1' in case '{self.__class__.__name__}' is not trainable")
        self._init_t = t
        self.learn = learn
        self.semi_grad = semi_grad
        self.channels = channels
        self.t = Parameter(torch.Tensor(channels)) if learn else t
        self.reset_parameters()

    def reset_parameters(self):
        if isinstance(self.t, Tensor):
            self.t.data.fill_(self._init_t)

    def forward(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2) ->Tensor:
        t = self.t
        if self.channels != 1:
            self.assert_two_dimensional_input(x, dim)
            assert isinstance(t, Tensor)
            t = t.view(-1, self.channels)
        alpha = x
        if not isinstance(t, (int, float)) or t != 1:
            alpha = x * t
        if not self.learn and self.semi_grad:
            with torch.no_grad():
                alpha = softmax(alpha, index, ptr, dim_size, dim)
        else:
            alpha = softmax(alpha, index, ptr, dim_size, dim)
        return self.reduce(x * alpha, index, ptr, dim_size, dim, reduce='sum')

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}(learn={self.learn})'


class PowerMeanAggregation(Aggregation):
    """The powermean aggregation operator based on a power term, as
    described in the `"DeeperGCN: All You Need to Train Deeper GCNs"
    <https://arxiv.org/abs/2006.07739>`_ paper

    .. math::
        \\mathrm{powermean}(\\mathcal{X}|p) = \\left(\\frac{1}{|\\mathcal{X}|}
        \\sum_{\\mathbf{x}_i\\in\\mathcal{X}}\\mathbf{x}_i^{p}\\right)^{1/p},

    where :math:`p` controls the power of the powermean when aggregating over
    a set of features :math:`\\mathcal{X}`.

    Args:
        p (float, optional): Initial power for powermean aggregation.
            (default: :obj:`1.0`)
        learn (bool, optional): If set to :obj:`True`, will learn the value
            :obj:`p` for powermean aggregation dynamically.
            (default: :obj:`False`)
        channels (int, optional): Number of channels to learn from :math:`p`.
            If set to a value greater than :obj:`1`, :math:`p` will be learned
            per input feature channel. This requires compatible shapes for the
            input to the forward calculation. (default: :obj:`1`)
    """

    def __init__(self, p: float=1.0, learn: bool=False, channels: int=1):
        super().__init__()
        if not learn and channels != 1:
            raise ValueError(f"Cannot set 'channels' greater than '1' in case '{self.__class__.__name__}' is not trainable")
        self._init_p = p
        self.learn = learn
        self.channels = channels
        self.p = Parameter(torch.Tensor(channels)) if learn else p
        self.reset_parameters()

    def reset_parameters(self):
        if isinstance(self.p, Tensor):
            self.p.data.fill_(self._init_p)

    def forward(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2) ->Tensor:
        p = self.p
        if self.channels != 1:
            assert isinstance(p, Tensor)
            self.assert_two_dimensional_input(x, dim)
            p = p.view(-1, self.channels)
        if not isinstance(p, (int, float)) or p != 1:
            x = x.clamp(min=0, max=100).pow(p)
        out = self.reduce(x, index, ptr, dim_size, dim, reduce='mean')
        if not isinstance(p, (int, float)) or p != 1:
            out = out.clamp(min=0, max=100).pow(1.0 / p)
        return out

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}(learn={self.learn})'


class ResNetPotential(torch.nn.Module):

    def __init__(self, in_channels: int, out_channels: int, num_layers: List[int]):
        super().__init__()
        sizes = [in_channels] + num_layers + [out_channels]
        self.layers = torch.nn.ModuleList([torch.nn.Sequential(torch.nn.Linear(in_size, out_size), torch.nn.LayerNorm(out_size), torch.nn.Tanh()) for in_size, out_size in zip(sizes[:-2], sizes[1:-1])])
        self.layers.append(torch.nn.Linear(sizes[-2], sizes[-1]))
        self.res_trans = torch.nn.ModuleList([torch.nn.Linear(in_channels, layer_size) for layer_size in num_layers + [out_channels]])

    def forward(self, x: Tensor, y: Tensor, index: Optional[Tensor]) ->Tensor:
        if index is None:
            inp = torch.cat([x, y.expand(x.size(0), -1)], dim=1)
        else:
            inp = torch.cat([x, y[index]], dim=1)
        h = inp
        for layer, res in zip(self.layers, self.res_trans):
            h = layer(h)
            h = res(inp) + h
        if index is None:
            return h.mean()
        size = int(index.max().item() + 1)
        return scatter(h, index, dim=0, dim_size=size, reduce='mean').sum()


class MomentumOptimizer(torch.nn.Module):
    """
    Provides an inner loop optimizer for the implicitly defined output
    layer. It is based on an unrolled Nesterov momentum algorithm.

    Args:
        learning_rate (flaot): learning rate for optimizer.
        momentum (float): momentum for optimizer.
        learnable (bool): If :obj:`True` then the :obj:`learning_rate` and
            :obj:`momentum` will be learnable parameters. If False they
            are fixed. (default: :obj:`True`)
    """

    def __init__(self, learning_rate: float=0.1, momentum: float=0.9, learnable: bool=True):
        super().__init__()
        self._initial_lr = learning_rate
        self._initial_mom = momentum
        self._lr = torch.nn.Parameter(Tensor([learning_rate]), requires_grad=learnable)
        self._mom = torch.nn.Parameter(Tensor([momentum]), requires_grad=learnable)
        self.softplus = torch.nn.Softplus()
        self.sigmoid = torch.nn.Sigmoid()

    def reset_parameters(self):
        self._lr.data.fill_(self._initial_lr)
        self._mom.data.fill_(self._initial_mom)

    @property
    def learning_rate(self):
        return self.softplus(self._lr)

    @property
    def momentum(self):
        return self.sigmoid(self._mom)

    def forward(self, x: Tensor, y: Tensor, index: Optional[Tensor], func: Callable[[Tensor, Tensor, Optional[Tensor]], Tensor], iterations: int=5) ->Tuple[Tensor, float]:
        momentum_buffer = torch.zeros_like(y)
        for _ in range(iterations):
            val = func(x, y, index)
            grad = torch.autograd.grad(val, y, create_graph=True, retain_graph=True)[0]
            delta = self.learning_rate * grad
            momentum_buffer = self.momentum * momentum_buffer - delta
            y = y + momentum_buffer
        return y


class EquilibriumAggregation(Aggregation):
    """The equilibrium aggregation layer from the `"Equilibrium Aggregation:
    Encoding Sets via Optimization" <https://arxiv.org/abs/2202.12795>`_ paper.
    The output of this layer :math:`\\mathbf{y}` is defined implicitly via a
    potential function :math:`F(\\mathbf{x}, \\mathbf{y})`, a regularization term
    :math:`R(\\mathbf{y})`, and the condition

    .. math::
        \\mathbf{y} = \\min_\\mathbf{y} R(\\mathbf{y}) + \\sum_{i}
        F(\\mathbf{x}_i, \\mathbf{y}).

    The given implementation uses a ResNet-like model for the potential
    function and a simple :math:`L_2` norm :math:`R(\\mathbf{y}) =
    \\textrm{softplus}(\\lambda) \\cdot {\\| \\mathbf{y} \\|}^2_2` for the
    regularizer with learnable weight :math:`\\lambda`.

    Args:
        in_channels (int): Size of each input sample.
        out_channels (int): Size of each output sample.
        num_layers (List[int): List of hidden channels in the potential
            function.
        grad_iter (int): The number of steps to take in the internal gradient
            descent. (default: :obj:`5`)
        lamb (float): The initial regularization constant.
            (default: :obj:`0.1`)
    """

    def __init__(self, in_channels: int, out_channels: int, num_layers: List[int], grad_iter: int=5, lamb: float=0.1):
        super().__init__()
        self.potential = ResNetPotential(in_channels + out_channels, 1, num_layers)
        self.optimizer = MomentumOptimizer()
        self.initial_lamb = lamb
        self.lamb = torch.nn.Parameter(Tensor(1), requires_grad=True)
        self.softplus = torch.nn.Softplus()
        self.grad_iter = grad_iter
        self.output_dim = out_channels
        self.reset_parameters()

    def reset_parameters(self):
        self.lamb.data.fill_(self.initial_lamb)
        reset(self.optimizer)
        reset(self.potential)

    def init_output(self, index: Optional[Tensor]=None) ->Tensor:
        index_size = 1 if index is None else int(index.max().item() + 1)
        return torch.zeros(index_size, self.output_dim, requires_grad=True, device=self.lamb.device).float()

    def reg(self, y: Tensor) ->Tensor:
        return self.softplus(self.lamb) * y.square().sum(dim=-1).mean()

    def energy(self, x: Tensor, y: Tensor, index: Optional[Tensor]):
        return self.potential(x, y, index) + self.reg(y)

    def forward(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2) ->Tensor:
        self.assert_index_present(index)
        index_size = 1 if index is None else index.max() + 1
        dim_size = index_size if dim_size is None else dim_size
        if dim_size < index_size:
            raise ValueError('`dim_size` is less than `index` implied size')
        with torch.enable_grad():
            y = self.optimizer(x, self.init_output(index), index, self.energy, iterations=self.grad_iter)
        if dim_size > index_size:
            zero = torch.zeros(dim_size - index_size, *y.size()[1:])
            y = torch.cat([y, zero])
        return y

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}()'


def to_dense_batch(x: Tensor, batch: Optional[Tensor]=None, fill_value: float=0.0, max_num_nodes: Optional[int]=None, batch_size: Optional[int]=None) ->Tuple[Tensor, Tensor]:
    """Given a sparse batch of node features
    :math:`\\mathbf{X} \\in \\mathbb{R}^{(N_1 + \\ldots + N_B) \\times F}` (with
    :math:`N_i` indicating the number of nodes in graph :math:`i`), creates a
    dense node feature tensor
    :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times N_{\\max} \\times F}` (with
    :math:`N_{\\max} = \\max_i^B N_i`).
    In addition, a mask of shape :math:`\\mathbf{M} \\in \\{ 0, 1 \\}^{B \\times
    N_{\\max}}` is returned, holding information about the existence of
    fake-nodes in the dense representation.

    Args:
        x (Tensor): Node feature matrix
            :math:`\\mathbf{X} \\in \\mathbb{R}^{(N_1 + \\ldots + N_B) \\times F}`.
        batch (LongTensor, optional): Batch vector
            :math:`\\mathbf{b} \\in {\\{ 0, \\ldots, B-1\\}}^N`, which assigns each
            node to a specific example. Must be ordered. (default: :obj:`None`)
        fill_value (float, optional): The value for invalid entries in the
            resulting dense output tensor. (default: :obj:`0`)
        max_num_nodes (int, optional): The size of the output node dimension.
            (default: :obj:`None`)
        batch_size (int, optional) The batch size. (default: :obj:`None`)

    :rtype: (:class:`Tensor`, :class:`BoolTensor`)

    Examples:

        >>> x = torch.arange(12).view(6, 2)
        >>> x
        tensor([[ 0,  1],
                [ 2,  3],
                [ 4,  5],
                [ 6,  7],
                [ 8,  9],
                [10, 11]])

        >>> out, mask = to_dense_batch(x)
        >>> mask
        tensor([[True, True, True, True, True, True]])

        >>> batch = torch.tensor([0, 0, 1, 2, 2, 2])
        >>> out, mask = to_dense_batch(x, batch)
        >>> out
        tensor([[[ 0,  1],
                [ 2,  3],
                [ 0,  0]],
                [[ 4,  5],
                [ 0,  0],
                [ 0,  0]],
                [[ 6,  7],
                [ 8,  9],
                [10, 11]]])
        >>> mask
        tensor([[ True,  True, False],
                [ True, False, False],
                [ True,  True,  True]])

        >>> out, mask = to_dense_batch(x, batch, max_num_nodes=4)
        >>> out
        tensor([[[ 0,  1],
                [ 2,  3],
                [ 0,  0],
                [ 0,  0]],
                [[ 4,  5],
                [ 0,  0],
                [ 0,  0],
                [ 0,  0]],
                [[ 6,  7],
                [ 8,  9],
                [10, 11],
                [ 0,  0]]])

        >>> mask
        tensor([[ True,  True, False, False],
                [ True, False, False, False],
                [ True,  True,  True, False]])
    """
    if batch is None and max_num_nodes is None:
        mask = torch.ones(1, x.size(0), dtype=torch.bool, device=x.device)
        return x.unsqueeze(0), mask
    if batch is None:
        batch = x.new_zeros(x.size(0), dtype=torch.long)
    if batch_size is None:
        batch_size = int(batch.max()) + 1
    num_nodes = scatter_add(batch.new_ones(x.size(0)), batch, dim=0, dim_size=batch_size)
    cum_nodes = torch.cat([batch.new_zeros(1), num_nodes.cumsum(dim=0)])
    filter_nodes = False
    if max_num_nodes is None:
        max_num_nodes = int(num_nodes.max())
    elif num_nodes.max() > max_num_nodes:
        filter_nodes = True
    tmp = torch.arange(batch.size(0), device=x.device) - cum_nodes[batch]
    idx = tmp + batch * max_num_nodes
    if filter_nodes:
        mask = tmp < max_num_nodes
        x, idx = x[mask], idx[mask]
    size = [batch_size * max_num_nodes] + list(x.size())[1:]
    out = x.new_full(size, fill_value)
    out[idx] = x
    out = out.view([batch_size, max_num_nodes] + list(x.size())[1:])
    mask = torch.zeros(batch_size * max_num_nodes, dtype=torch.bool, device=x.device)
    mask[idx] = 1
    mask = mask.view(batch_size, max_num_nodes)
    return out, mask


class MAB(torch.nn.Module):
    """Multihead-Attention Block."""

    def __init__(self, dim_Q: int, dim_K: int, dim_V: int, num_heads: int, Conv: Optional[Type]=None, layer_norm: bool=False):
        super().__init__()
        self.dim_V = dim_V
        self.num_heads = num_heads
        self.layer_norm = layer_norm
        self.fc_q = Linear(dim_Q, dim_V)
        if Conv is None:
            self.layer_k = Linear(dim_K, dim_V)
            self.layer_v = Linear(dim_K, dim_V)
        else:
            self.layer_k = Conv(dim_K, dim_V)
            self.layer_v = Conv(dim_K, dim_V)
        if layer_norm:
            self.ln0 = LayerNorm(dim_V)
            self.ln1 = LayerNorm(dim_V)
        self.fc_o = Linear(dim_V, dim_V)

    def reset_parameters(self):
        self.fc_q.reset_parameters()
        self.layer_k.reset_parameters()
        self.layer_v.reset_parameters()
        if self.layer_norm:
            self.ln0.reset_parameters()
            self.ln1.reset_parameters()
        self.fc_o.reset_parameters()
        pass

    def forward(self, Q: Tensor, K: Tensor, graph: Optional[Tuple[Tensor, Tensor, Tensor]]=None, mask: Optional[Tensor]=None) ->Tensor:
        Q = self.fc_q(Q)
        if graph is not None:
            x, edge_index, batch = graph
            K, V = self.layer_k(x, edge_index), self.layer_v(x, edge_index)
            K, _ = to_dense_batch(K, batch)
            V, _ = to_dense_batch(V, batch)
        else:
            K, V = self.layer_k(K), self.layer_v(K)
        dim_split = self.dim_V // self.num_heads
        Q_ = torch.cat(Q.split(dim_split, 2), dim=0)
        K_ = torch.cat(K.split(dim_split, 2), dim=0)
        V_ = torch.cat(V.split(dim_split, 2), dim=0)
        if mask is not None:
            mask = torch.cat([mask for _ in range(self.num_heads)], 0)
            attention_score = Q_.bmm(K_.transpose(1, 2))
            attention_score = attention_score / math.sqrt(self.dim_V)
            A = torch.softmax(mask + attention_score, 1)
        else:
            A = torch.softmax(Q_.bmm(K_.transpose(1, 2)) / math.sqrt(self.dim_V), 1)
        out = torch.cat((Q_ + A.bmm(V_)).split(Q.size(0), 0), 2)
        if self.layer_norm:
            out = self.ln0(out)
        out = out + self.fc_o(out).relu()
        if self.layer_norm:
            out = self.ln1(out)
        return out


class SAB(torch.nn.Module):
    """Self-Attention Block."""

    def __init__(self, in_channels: int, out_channels: int, num_heads: int, Conv: Optional[Type]=None, layer_norm: bool=False):
        super().__init__()
        self.mab = MAB(in_channels, in_channels, out_channels, num_heads, Conv=Conv, layer_norm=layer_norm)

    def reset_parameters(self):
        self.mab.reset_parameters()

    def forward(self, x: Tensor, graph: Optional[Tuple[Tensor, Tensor, Tensor]]=None, mask: Optional[Tensor]=None) ->Tensor:
        return self.mab(x, x, graph, mask)


class PMA(torch.nn.Module):
    """Graph pooling with Multihead-Attention."""

    def __init__(self, channels: int, num_heads: int, num_seeds: int, Conv: Optional[Type]=None, layer_norm: bool=False):
        super().__init__()
        self.S = torch.nn.Parameter(torch.Tensor(1, num_seeds, channels))
        self.mab = MAB(channels, channels, channels, num_heads, Conv=Conv, layer_norm=layer_norm)
        self.reset_parameters()

    def reset_parameters(self):
        torch.nn.init.xavier_uniform_(self.S)
        self.mab.reset_parameters()

    def forward(self, x: Tensor, graph: Optional[Tuple[Tensor, Tensor, Tensor]]=None, mask: Optional[Tensor]=None) ->Tensor:
        return self.mab(self.S.repeat(x.size(0), 1, 1), x, graph, mask)


class GraphMultisetTransformer(Aggregation):
    """The Graph Multiset Transformer pooling operator from the
    `"Accurate Learning of Graph Representations
    with Graph Multiset Pooling" <https://arxiv.org/abs/2102.11533>`_ paper.

    The Graph Multiset Transformer clusters nodes of the entire graph via
    attention-based pooling operations (:obj:`"GMPool_G"` or
    :obj:`"GMPool_I"`).
    In addition, self-attention (:obj:`"SelfAtt"`) can be used to calculate
    the inter-relationships among nodes.

    Args:
        in_channels (int): Size of each input sample.
        hidden_channels (int): Size of each hidden sample.
        out_channels (int): Size of each output sample.
        conv (Type, optional): A graph neural network layer
            for calculating hidden representations of nodes for
            :obj:`"GMPool_G"` (one of
            :class:`~torch_geometric.nn.conv.GCNConv`,
            :class:`~torch_geometric.nn.conv.GraphConv` or
            :class:`~torch_geometric.nn.conv.GATConv`).
            (default: :class:`~torch_geometric.nn.conv.GCNConv`)
        num_nodes (int, optional): The number of average
            or maximum nodes. (default: :obj:`300`)
        pooling_ratio (float, optional): Graph pooling ratio
            for each pooling. (default: :obj:`0.25`)
        pool_sequences ([str], optional): A sequence of pooling layers
            consisting of Graph Multiset Transformer submodules (one of
            :obj:`["GMPool_I"]`,
            :obj:`["GMPool_G"]`,
            :obj:`["GMPool_G", "GMPool_I"]`,
            :obj:`["GMPool_G", "SelfAtt", "GMPool_I"]` or
            :obj:`["GMPool_G", "SelfAtt", "SelfAtt", "GMPool_I"]`).
            (default: :obj:`["GMPool_G", "SelfAtt", "GMPool_I"]`)
        num_heads (int, optional): Number of attention heads.
            (default: :obj:`4`)
        layer_norm (bool, optional): If set to :obj:`True`, will make use of
            layer normalization. (default: :obj:`False`)
    """

    def __init__(self, in_channels: int, hidden_channels: int, out_channels: int, Conv: Optional[Type]=None, num_nodes: int=300, pooling_ratio: float=0.25, pool_sequences: List[str]=['GMPool_G', 'SelfAtt', 'GMPool_I'], num_heads: int=4, layer_norm: bool=False):
        super().__init__()
        self.in_channels = in_channels
        self.hidden_channels = hidden_channels
        self.out_channels = out_channels
        self.Conv = Conv or GCNConv
        self.num_nodes = num_nodes
        self.pooling_ratio = pooling_ratio
        self.pool_sequences = pool_sequences
        self.num_heads = num_heads
        self.layer_norm = layer_norm
        self.lin1 = Linear(in_channels, hidden_channels)
        self.lin2 = Linear(hidden_channels, out_channels)
        self.pools = torch.nn.ModuleList()
        num_out_nodes = math.ceil(num_nodes * pooling_ratio)
        for i, pool_type in enumerate(pool_sequences):
            if pool_type not in ['GMPool_G', 'GMPool_I', 'SelfAtt']:
                raise ValueError("Elements in 'pool_sequences' should be one of 'GMPool_G', 'GMPool_I', or 'SelfAtt'")
            if i == len(pool_sequences) - 1:
                num_out_nodes = 1
            if pool_type == 'GMPool_G':
                self.pools.append(PMA(hidden_channels, num_heads, num_out_nodes, Conv=self.Conv, layer_norm=layer_norm))
                num_out_nodes = math.ceil(num_out_nodes * self.pooling_ratio)
            elif pool_type == 'GMPool_I':
                self.pools.append(PMA(hidden_channels, num_heads, num_out_nodes, Conv=None, layer_norm=layer_norm))
                num_out_nodes = math.ceil(num_out_nodes * self.pooling_ratio)
            elif pool_type == 'SelfAtt':
                self.pools.append(SAB(hidden_channels, hidden_channels, num_heads, Conv=None, layer_norm=layer_norm))

    def reset_parameters(self):
        self.lin1.reset_parameters()
        self.lin2.reset_parameters()
        for pool in self.pools:
            pool.reset_parameters()

    def forward(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2, edge_index: Optional[Tensor]=None) ->Tensor:
        x = self.lin1(x)
        batch_x, mask = self.to_dense_batch(x, index)
        mask = (~mask).unsqueeze(1) * -1000000000.0
        for i, (name, pool) in enumerate(zip(self.pool_sequences, self.pools)):
            graph = (x, edge_index, index) if name == 'GMPool_G' else None
            batch_x = pool(batch_x, graph, mask)
            mask = None
        return self.lin2(batch_x.squeeze(1))

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}({self.in_channels}, {self.out_channels}, pool_sequences={self.pool_sequences})'


class LSTMAggregation(Aggregation):
    """Performs LSTM-style aggregation in which the elements to aggregate are
    interpreted as a sequence, as described in the `"Inductive Representation
    Learning on Large Graphs" <https://arxiv.org/abs/1706.02216>`_ paper.

    .. warning::
        :class:`LSTMAggregation` is not a permutation-invariant operator.

    Args:
        in_channels (int): Size of each input sample.
        out_channels (int): Size of each output sample.
        **kwargs (optional): Additional arguments of :class:`torch.nn.LSTM`.
    """

    def __init__(self, in_channels: int, out_channels: int, **kwargs):
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.lstm = LSTM(in_channels, out_channels, batch_first=True, **kwargs)
        self.reset_parameters()

    def reset_parameters(self):
        self.lstm.reset_parameters()

    def forward(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2) ->Tensor:
        x, _ = self.to_dense_batch(x, index, ptr, dim_size, dim)
        return self.lstm(x)[0][:, -1]

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}({self.in_channels}, {self.out_channels})'


class QuantileAggregation(Aggregation):
    """An aggregation operator that returns the feature-wise :math:`q`-th
    quantile of a set :math:`\\mathcal{X}`. That is, for every feature
    :math:`d`, it computes

    .. math::
        {\\mathrm{Q}_q(\\mathcal{X})}_d = \\begin{cases}
            x_{\\pi_i,d} & i = q \\cdot n, \\\\
            f(x_{\\pi_i,d}, x_{\\pi_{i+1},d}) & i < q \\cdot n < i + 1,\\\\
        \\end{cases}

    where :math:`x_{\\pi_1,d} \\le \\dots \\le x_{\\pi_i,d} \\le \\dots \\le
    x_{\\pi_n,d}` and :math:`f(a, b)` is an interpolation
    function defined by :obj:`interpolation`.

    Args:
        q (float or list): The quantile value(s) :math:`q`. Can be a scalar or
            a list of scalars in the range :math:`[0, 1]`. If more than a
            quantile is passed, the results are concatenated.
        interpolation (str): Interpolation method applied if the quantile point
            :math:`q\\cdot n` lies between two values
            :math:`a \\le b`. Can be one of the following:

            * :obj:`"lower"`: Returns the one with lowest value.

            * :obj:`"higher"`: Returns the one with highest value.

            * :obj:`"midpoint"`: Returns the average of the two values.

            * :obj:`"nearest"`: Returns the one whose index is nearest to the
              quantile point.

            * :obj:`"linear"`: Returns a linear combination of the two
              elements, defined as
              :math:`f(a, b) = a + (b - a)\\cdot(q\\cdot n - i)`.

            (default: :obj:`"linear"`)
        fill_value (float, optional): The default value in the case no entry is
            found for a given index (default: :obj:`0.0`).
    """
    interpolations = {'linear', 'lower', 'higher', 'nearest', 'midpoint'}

    def __init__(self, q: Union[float, List[float]], interpolation: str='linear', fill_value: float=0.0):
        super().__init__()
        qs = [q] if not isinstance(q, (list, tuple)) else q
        if len(qs) == 0:
            raise ValueError('Provide at least one quantile value for `q`.')
        if not all(0.0 <= quantile <= 1.0 for quantile in qs):
            raise ValueError('`q` must be in the range [0, 1].')
        if interpolation not in self.interpolations:
            raise ValueError(f"Invalid interpolation method got ('{interpolation}')")
        self._q = q
        self.register_buffer('q', torch.Tensor(qs).view(-1, 1))
        self.interpolation = interpolation
        self.fill_value = fill_value

    def forward(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2) ->Tensor:
        dim = x.dim() + dim if dim < 0 else dim
        self.assert_index_present(index)
        assert index is not None
        count = torch.bincount(index, minlength=dim_size or 0)
        cumsum = torch.cumsum(count, dim=0) - count
        q_point = self.q * (count - 1) + cumsum
        q_point = q_point.t().reshape(-1)
        shape = [1] * x.dim()
        shape[dim] = -1
        index = index.view(shape).expand_as(x)
        x, x_perm = torch.sort(x, dim=dim)
        index = index.take_along_dim(x_perm, dim=dim)
        index, index_perm = torch.sort(index, dim=dim, stable=True)
        x = x.take_along_dim(index_perm, dim=dim)
        if self.interpolation == 'lower':
            quantile = x.index_select(dim, q_point.floor().long())
        elif self.interpolation == 'higher':
            quantile = x.index_select(dim, q_point.ceil().long())
        elif self.interpolation == 'nearest':
            quantile = x.index_select(dim, q_point.round().long())
        else:
            l_quant = x.index_select(dim, q_point.floor().long())
            r_quant = x.index_select(dim, q_point.ceil().long())
            if self.interpolation == 'linear':
                q_frac = q_point.frac().view(shape)
                quantile = l_quant + (r_quant - l_quant) * q_frac
            else:
                quantile = 0.5 * l_quant + 0.5 * r_quant
        mask = (count == 0).repeat_interleave(self.q.numel()).view(shape)
        out = quantile.masked_fill(mask, self.fill_value)
        if self.q.numel() > 1:
            shape = list(out.shape)
            shape = shape[:dim] + [shape[dim] // self.q.numel(), -1] + shape[dim + 2:]
            out = out.view(shape)
        return out

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}(q={self._q})'


class MedianAggregation(QuantileAggregation):
    """An aggregation operator that returns the feature-wise median of a set.
    That is, for every feature :math:`d`, it computes

    .. math::
        {\\mathrm{median}(\\mathcal{X})}_d = x_{\\pi_i,d}

    where :math:`x_{\\pi_1,d} \\le x_{\\pi_2,d} \\le \\dots \\le
    x_{\\pi_n,d}` and :math:`i = \\lfloor \\frac{n}{2} \\rfloor`.

    .. note::
        If the median lies between two values, the lowest one is returned.
        To compute the midpoint (or other kind of interpolation) of the two
        values, use :class:`QuantileAggregation` instead.

    Args:
        fill_value (float, optional): The default value in the case no entry is
            found for a given index (default: :obj:`0.0`).
    """

    def __init__(self, fill_value: float=0.0):
        super().__init__(0.5, 'lower', fill_value)

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}()'


def degree(index: Tensor, num_nodes: Optional[int]=None, dtype: Optional[torch.dtype]=None) ->Tensor:
    """Computes the (unweighted) degree of a given one-dimensional index
    tensor.

    Args:
        index (LongTensor): Index tensor.
        num_nodes (int, optional): The number of nodes, *i.e.*
            :obj:`max_val + 1` of :attr:`index`. (default: :obj:`None`)
        dtype (:obj:`torch.dtype`, optional): The desired data type of the
            returned tensor.

    :rtype: :class:`Tensor`

    Example:

        >>> row = torch.tensor([0, 1, 0, 2, 0])
        >>> degree(row, dtype=torch.long)
        tensor([3, 1, 1])
    """
    N = maybe_num_nodes(index, num_nodes)
    out = torch.zeros((N,), dtype=dtype, device=index.device)
    one = torch.ones((index.size(0),), dtype=out.dtype, device=out.device)
    return out.scatter_add_(0, index, one)


class DegreeScalerAggregation(Aggregation):
    """Combines one or more aggregators and transforms its output with one or
    more scalers as introduced in the `"Principal Neighbourhood Aggregation for
    Graph Nets" <https://arxiv.org/abs/2004.05718>`_ paper.
    The scalers are normalised by the in-degree of the training set and so must
    be provided at time of construction.
    See :class:`torch_geometric.nn.conv.PNAConv` for more information.

    Args:
        aggr (string or list or Aggregation): The aggregation scheme to use.
            See :class:`~torch_geometric.nn.conv.MessagePassing` for more
            information.
        scaler (str or list): Set of scaling function identifiers, namely one
            or more of :obj:`"identity"`, :obj:`"amplification"`,
            :obj:`"attenuation"`, :obj:`"linear"` and :obj:`"inverse_linear"`.
        deg (Tensor): Histogram of in-degrees of nodes in the training set,
            used by scalers to normalize.
        train_norm (bool, optional) Whether normalization parameters
            are trainable. (default: :obj:`False`)
        aggr_kwargs (Dict[str, Any], optional): Arguments passed to the
            respective aggregation function in case it gets automatically
            resolved. (default: :obj:`None`)
    """

    def __init__(self, aggr: Union[str, List[str], Aggregation], scaler: Union[str, List[str]], deg: Tensor, train_norm: bool=False, aggr_kwargs: Optional[List[Dict[str, Any]]]=None):
        super().__init__()
        if isinstance(aggr, (str, Aggregation)):
            self.aggr = aggr_resolver(aggr, **aggr_kwargs or {})
        elif isinstance(aggr, (tuple, list)):
            self.aggr = MultiAggregation(aggr, aggr_kwargs)
        else:
            raise ValueError(f"Only strings, list, tuples and instances of`torch_geometric.nn.aggr.Aggregation` are valid aggregation schemes (got '{type(aggr)}')")
        self.scaler = [scaler] if isinstance(aggr, str) else scaler
        deg = deg
        N = int(deg.sum())
        bin_degree = torch.arange(deg.numel(), device=deg.device)
        self.init_avg_deg_lin = float((bin_degree * deg).sum()) / N
        self.init_avg_deg_log = float(((bin_degree + 1).log() * deg).sum()) / N
        if train_norm:
            self.avg_deg_lin = torch.nn.Parameter(torch.Tensor(1))
            self.avg_deg_log = torch.nn.Parameter(torch.Tensor(1))
        else:
            self.register_buffer('avg_deg_lin', torch.Tensor(1))
            self.register_buffer('avg_deg_log', torch.Tensor(1))
        self.reset_parameters()

    def reset_parameters(self):
        self.avg_deg_lin.data.fill_(self.init_avg_deg_lin)
        self.avg_deg_log.data.fill_(self.init_avg_deg_log)

    def forward(self, x: Tensor, index: Optional[Tensor]=None, ptr: Optional[Tensor]=None, dim_size: Optional[int]=None, dim: int=-2) ->Tensor:
        self.assert_index_present(index)
        out = self.aggr(x, index, ptr, dim_size, dim)
        assert index is not None
        deg = degree(index, num_nodes=dim_size, dtype=out.dtype).clamp_(1)
        size = [1] * len(out.size())
        size[dim] = -1
        deg = deg.view(size)
        outs = []
        for scaler in self.scaler:
            if scaler == 'identity':
                out_scaler = out
            elif scaler == 'amplification':
                out_scaler = out * (torch.log(deg + 1) / self.avg_deg_log)
            elif scaler == 'attenuation':
                out_scaler = out * (self.avg_deg_log / torch.log(deg + 1))
            elif scaler == 'linear':
                out_scaler = out * (deg / self.avg_deg_lin)
            elif scaler == 'inverse_linear':
                out_scaler = out * (self.avg_deg_lin / deg)
            else:
                raise ValueError(f"Unknown scaler '{scaler}'")
            outs.append(out_scaler)
        return torch.cat(outs, dim=-1) if len(outs) > 1 else outs[0]


def restricted_softmax(src, dim: int=-1, margin: float=0.0):
    src_max = torch.clamp(src.max(dim=dim, keepdim=True)[0], min=0.0)
    out = (src - src_max).exp()
    out = out / (out.sum(dim=dim, keepdim=True) + (margin - src_max).exp())
    return out


class Attention(torch.nn.Module):

    def __init__(self, dropout=0):
        super().__init__()
        self.dropout = dropout

    def forward(self, query, key, value):
        return self.compute_attention(query, key, value)

    def compute_attention(self, query, key, value):
        assert query.dim() == key.dim() == value.dim() >= 2
        assert query.size(-1) == key.size(-1)
        assert key.size(-2) == value.size(-2)
        score = torch.matmul(query, key.transpose(-2, -1))
        score = score / math.sqrt(key.size(-1))
        score = restricted_softmax(score, dim=-1)
        score = F.dropout(score, p=self.dropout, training=self.training)
        return torch.matmul(score, value)

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}(dropout={self.dropout})'


class MultiHead(Attention):

    def __init__(self, in_channels, out_channels, heads=1, groups=1, dropout=0, bias=True):
        super().__init__(dropout)
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.heads = heads
        self.groups = groups
        self.bias = bias
        assert in_channels % heads == 0 and out_channels % heads == 0
        assert in_channels % groups == 0 and out_channels % groups == 0
        assert max(groups, self.heads) % min(groups, self.heads) == 0
        self.lin_q = Linear(in_channels, out_channels, groups, bias)
        self.lin_k = Linear(in_channels, out_channels, groups, bias)
        self.lin_v = Linear(in_channels, out_channels, groups, bias)
        self.reset_parameters()

    def reset_parameters(self):
        self.lin_q.reset_parameters()
        self.lin_k.reset_parameters()
        self.lin_v.reset_parameters()

    def forward(self, query, key, value):
        assert query.dim() == key.dim() == value.dim() >= 2
        assert query.size(-1) == key.size(-1) == value.size(-1)
        assert key.size(-2) == value.size(-2)
        query = self.lin_q(query)
        key = self.lin_k(key)
        value = self.lin_v(value)
        size = query.size()[:-2]
        out_channels_per_head = self.out_channels // self.heads
        query_size = size + (query.size(-2), self.heads, out_channels_per_head)
        query = query.view(query_size).transpose(-2, -3)
        key_size = size + (key.size(-2), self.heads, out_channels_per_head)
        key = key.view(key_size).transpose(-2, -3)
        value_size = size + (value.size(-2), self.heads, out_channels_per_head)
        value = value.view(value_size).transpose(-2, -3)
        out = self.compute_attention(query, key, value)
        out = out.transpose(-3, -2).contiguous()
        out = out.view(size + (query.size(-2), self.out_channels))
        return out

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}({self.in_channels}, {self.out_channels}, heads={self.heads}, groups={self.groups}, dropout={self.droput}, bias={self.bias})'


def get_angle(v1: Tensor, v2: Tensor) ->Tensor:
    return torch.atan2(torch.cross(v1, v2, dim=1).norm(p=2, dim=1), (v1 * v2).sum(dim=1))


def point_pair_features(pos_i: Tensor, pos_j: Tensor, normal_i: Tensor, normal_j: Tensor) ->Tensor:
    pseudo = pos_j - pos_i
    return torch.stack([pseudo.norm(p=2, dim=1), get_angle(normal_i, pseudo), get_angle(normal_j, pseudo), get_angle(normal_i, normal_j)], dim=1)


def edge_index_to_vector(edge_index: Tensor, size: Tuple[int, int], bipartite: bool, force_undirected: bool=False) ->Tuple[Tensor, int]:
    row, col = edge_index
    if bipartite:
        idx = (row * size[1]).add_(col)
        population = size[0] * size[1]
        return idx, population
    elif force_undirected:
        assert size[0] == size[1]
        num_nodes = size[0]
        mask = row < col
        row, col = row[mask], col[mask]
        offset = torch.arange(1, num_nodes, device=row.device).cumsum(0)[row]
        idx = row.mul_(num_nodes).add_(col).sub_(offset)
        population = num_nodes * (num_nodes + 1) // 2 - num_nodes
        return idx, population
    else:
        assert size[0] == size[1]
        num_nodes = size[0]
        mask = row != col
        row, col = row[mask], col[mask]
        col[row < col] -= 1
        idx = row.mul_(num_nodes - 1).add_(col)
        population = num_nodes * num_nodes - num_nodes
        return idx, population


def sample(population: int, k: int, device=None) ->Tensor:
    if population <= k:
        return torch.arange(population, device=device)
    else:
        return torch.tensor(random.sample(range(population), k), device=device)


def vector_to_edge_index(idx: Tensor, size: Tuple[int, int], bipartite: bool, force_undirected: bool=False) ->Tensor:
    if bipartite:
        row = idx.div(size[1], rounding_mode='floor')
        col = idx % size[1]
        return torch.stack([row, col], dim=0)
    elif force_undirected:
        assert size[0] == size[1]
        num_nodes = size[0]
        offset = torch.arange(1, num_nodes, device=idx.device).cumsum(0)
        end = torch.arange(num_nodes, num_nodes * num_nodes, num_nodes, device=idx.device)
        row = torch.bucketize(idx, end.sub_(offset), right=True)
        col = offset[row].add_(idx) % num_nodes
        return torch.stack([torch.cat([row, col]), torch.cat([col, row])], 0)
    else:
        assert size[0] == size[1]
        num_nodes = size[0]
        row = idx.div(num_nodes - 1, rounding_mode='floor')
        col = idx % (num_nodes - 1)
        col[row <= col] += 1
        return torch.stack([row, col], dim=0)


def negative_sampling(edge_index: Tensor, num_nodes: Optional[Union[int, Tuple[int, int]]]=None, num_neg_samples: Optional[int]=None, method: str='sparse', force_undirected: bool=False) ->Tensor:
    """Samples random negative edges of a graph given by :attr:`edge_index`.

    Args:
        edge_index (LongTensor): The edge indices.
        num_nodes (int or Tuple[int, int], optional): The number of nodes,
            *i.e.* :obj:`max_val + 1` of :attr:`edge_index`.
            If given as a tuple, then :obj:`edge_index` is interpreted as a
            bipartite graph with shape :obj:`(num_src_nodes, num_dst_nodes)`.
            (default: :obj:`None`)
        num_neg_samples (int, optional): The (approximate) number of negative
            samples to return.
            If set to :obj:`None`, will try to return a negative edge for every
            positive edge. (default: :obj:`None`)
        method (string, optional): The method to use for negative sampling,
            *i.e.*, :obj:`"sparse"` or :obj:`"dense"`.
            This is a memory/runtime trade-off.
            :obj:`"sparse"` will work on any graph of any size, while
            :obj:`"dense"` can perform faster true-negative checks.
            (default: :obj:`"sparse"`)
        force_undirected (bool, optional): If set to :obj:`True`, sampled
            negative edges will be undirected. (default: :obj:`False`)

    :rtype: LongTensor

    Examples:

        >>> # Standard usage
        >>> edge_index = torch.as_tensor([[0, 0, 1, 2],
        ...                               [0, 1, 2, 3]])
        >>> negative_sampling(edge_index)
        tensor([[3, 0, 0, 3],
                [2, 3, 2, 1]])

        >>> # For bipartite graph
        >>> negative_sampling(edge_index, num_nodes=(3, 4))
        tensor([[0, 2, 2, 1],
                [2, 2, 1, 3]])
    """
    assert method in ['sparse', 'dense']
    size = num_nodes
    bipartite = isinstance(size, (tuple, list))
    size = maybe_num_nodes(edge_index) if size is None else size
    size = (size, size) if not bipartite else size
    force_undirected = False if bipartite else force_undirected
    idx, population = edge_index_to_vector(edge_index, size, bipartite, force_undirected)
    if idx.numel() >= population:
        return edge_index.new_empty((2, 0))
    if num_neg_samples is None:
        num_neg_samples = edge_index.size(1)
    if force_undirected:
        num_neg_samples = num_neg_samples // 2
    prob = 1.0 - idx.numel() / population
    sample_size = int(1.1 * num_neg_samples / prob)
    neg_idx = None
    if method == 'dense':
        mask = idx.new_ones(population, dtype=torch.bool)
        mask[idx] = False
        for _ in range(3):
            rnd = sample(population, sample_size, idx.device)
            rnd = rnd[mask[rnd]]
            neg_idx = rnd if neg_idx is None else torch.cat([neg_idx, rnd])
            if neg_idx.numel() >= num_neg_samples:
                neg_idx = neg_idx[:num_neg_samples]
                break
            mask[neg_idx] = False
    else:
        idx = idx
        for _ in range(3):
            rnd = sample(population, sample_size, device='cpu')
            mask = np.isin(rnd, idx)
            if neg_idx is not None:
                mask |= np.isin(rnd, neg_idx)
            mask = torch.from_numpy(mask)
            rnd = rnd[~mask]
            neg_idx = rnd if neg_idx is None else torch.cat([neg_idx, rnd])
            if neg_idx.numel() >= num_neg_samples:
                neg_idx = neg_idx[:num_neg_samples]
                break
    return vector_to_edge_index(neg_idx, size, bipartite, force_undirected)


def batched_negative_sampling(edge_index: Tensor, batch: Union[Tensor, Tuple[Tensor, Tensor]], num_neg_samples: Optional[int]=None, method: str='sparse', force_undirected: bool=False) ->Tensor:
    """Samples random negative edges of multiple graphs given by
    :attr:`edge_index` and :attr:`batch`.

    Args:
        edge_index (LongTensor): The edge indices.
        batch (LongTensor or Tuple[LongTensor, LongTensor]): Batch vector
            :math:`\\mathbf{b} \\in {\\{ 0, \\ldots, B-1\\}}^N`, which assigns each
            node to a specific example.
            If given as a tuple, then :obj:`edge_index` is interpreted as a
            bipartite graph connecting two different node types.
        num_neg_samples (int, optional): The number of negative samples to
            return. If set to :obj:`None`, will try to return a negative edge
            for every positive edge. (default: :obj:`None`)
        method (string, optional): The method to use for negative sampling,
            *i.e.*, :obj:`"sparse"` or :obj:`"dense"`.
            This is a memory/runtime trade-off.
            :obj:`"sparse"` will work on any graph of any size, while
            :obj:`"dense"` can perform faster true-negative checks.
            (default: :obj:`"sparse"`)
        force_undirected (bool, optional): If set to :obj:`True`, sampled
            negative edges will be undirected. (default: :obj:`False`)

    :rtype: LongTensor

    Examples:

        >>> # Standard usage
        >>> edge_index = torch.as_tensor([[0, 0, 1, 2], [0, 1, 2, 3]])
        >>> edge_index = torch.cat([edge_index, edge_index + 4], dim=1)
        >>> edge_index
        tensor([[0, 0, 1, 2, 4, 4, 5, 6],
                [0, 1, 2, 3, 4, 5, 6, 7]])
        >>> batch = torch.tensor([0, 0, 0, 0, 1, 1, 1, 1])
        >>> batched_negative_sampling(edge_index, batch)
        tensor([[3, 1, 3, 2, 7, 7, 6, 5],
                [2, 0, 1, 1, 5, 6, 4, 4]])

        >>> # For bipartite graph
        >>> edge_index1 = torch.as_tensor([[0, 0, 1, 1], [0, 1, 2, 3]])
        >>> edge_index2 = edge_index1 + torch.tensor([[2], [4]])
        >>> edge_index3 = edge_index2 + torch.tensor([[2], [4]])
        >>> edge_index = torch.cat([edge_index1, edge_index2,
        ...                         edge_index3], dim=1)
        >>> edge_index
        tensor([[ 0,  0,  1,  1,  2,  2,  3,  3,  4,  4,  5,  5],
                [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]])
        >>> src_batch = torch.tensor([0, 0, 1, 1, 2, 2])
        >>> dst_batch = torch.tensor([0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2])
        >>> batched_negative_sampling(edge_index,
        ...                           (src_batch, dst_batch))
        tensor([[ 0,  0,  1,  1,  2,  2,  3,  3,  4,  4,  5,  5],
                [ 2,  3,  0,  1,  6,  7,  4,  5, 10, 11,  8,  9]])
    """
    if isinstance(batch, Tensor):
        src_batch, dst_batch = batch, batch
    else:
        src_batch, dst_batch = batch[0], batch[1]
    split = degree(src_batch[edge_index[0]], dtype=torch.long).tolist()
    edge_indices = torch.split(edge_index, split, dim=1)
    num_src = degree(src_batch, dtype=torch.long)
    cum_src = torch.cat([src_batch.new_zeros(1), num_src.cumsum(0)[:-1]])
    if isinstance(batch, Tensor):
        num_nodes = num_src.tolist()
        cumsum = cum_src
    else:
        num_dst = degree(dst_batch, dtype=torch.long)
        cum_dst = torch.cat([dst_batch.new_zeros(1), num_dst.cumsum(0)[:-1]])
        num_nodes = torch.stack([num_src, num_dst], dim=1).tolist()
        cumsum = torch.stack([cum_src, cum_dst], dim=1).unsqueeze(-1)
    neg_edge_indices = []
    for i, edge_index in enumerate(edge_indices):
        edge_index = edge_index - cumsum[i]
        neg_edge_index = negative_sampling(edge_index, num_nodes[i], num_neg_samples, method, force_undirected)
        neg_edge_index += cumsum[i]
        neg_edge_indices.append(neg_edge_index)
    return torch.cat(neg_edge_indices, dim=1)


def sort_edge_index(edge_index: Tensor, edge_attr: Union[Optional[Tensor], List[Tensor]]=None, num_nodes: Optional[int]=None, sort_by_row: bool=True) ->Union[Tensor, Tuple[Tensor, Tensor], Tuple[Tensor, List[Tensor]]]:
    """Row-wise sorts :obj:`edge_index`.

    Args:
        edge_index (LongTensor): The edge indices.
        edge_attr (Tensor or List[Tensor], optional): Edge weights or multi-
            dimensional edge features.
            If given as a list, will re-shuffle and remove duplicates for all
            its entries. (default: :obj:`None`)
        num_nodes (int, optional): The number of nodes, *i.e.*
            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)
        sort_by_row (bool, optional): If set to :obj:`False`, will sort
            :obj:`edge_index` column-wise.

    :rtype: :class:`LongTensor` if :attr:`edge_attr` is :obj:`None`, else
        (:class:`LongTensor`, :obj:`Tensor` or :obj:`List[Tensor]]`)

    Examples:

        >>> edge_index = torch.tensor([[2, 1, 1, 0],
                                [1, 2, 0, 1]])
        >>> edge_attr = torch.tensor([[1], [2], [3], [4]])
        >>> sort_edge_index(edge_index)
        tensor([[0, 1, 1, 2],
                [1, 0, 2, 1]])

        >>> sort_edge_index(edge_index, edge_attr)
        (tensor([[0, 1, 1, 2],
                [1, 0, 2, 1]]),
        tensor([[4],
                [3],
                [2],
                [1]]))
    """
    num_nodes = maybe_num_nodes(edge_index, num_nodes)
    idx = edge_index[1 - int(sort_by_row)] * num_nodes
    idx += edge_index[int(sort_by_row)]
    perm = idx.argsort()
    edge_index = edge_index[:, perm]
    if isinstance(edge_attr, Tensor):
        return edge_index, edge_attr[perm]
    elif isinstance(edge_attr, (list, tuple)):
        return edge_index, [e[perm] for e in edge_attr]
    else:
        return edge_index


def is_undirected(edge_index: Tensor, edge_attr: Union[Optional[Tensor], List[Tensor]]=None, num_nodes: Optional[int]=None) ->bool:
    """Returns :obj:`True` if the graph given by :attr:`edge_index` is
    undirected.

    Args:
        edge_index (LongTensor): The edge indices.
        edge_attr (Tensor or List[Tensor], optional): Edge weights or multi-
            dimensional edge features.
            If given as a list, will check for equivalence in all its entries.
            (default: :obj:`None`)
        num_nodes (int, optional): The number of nodes, *i.e.*
            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)

    :rtype: bool

    Examples:

        >>> edge_index = torch.tensor([[0, 1, 0],
        ...                         [1, 0, 0]])
        >>> weight = torch.tensor([0, 0, 1])
        >>> is_undirected(edge_index, weight)
        True

        >>> weight = torch.tensor([0, 1, 1])
        >>> is_undirected(edge_index, weight)
        False

    """
    num_nodes = maybe_num_nodes(edge_index, num_nodes)
    edge_attrs: List[Tensor] = []
    if isinstance(edge_attr, Tensor):
        edge_attrs.append(edge_attr)
    elif isinstance(edge_attr, (list, tuple)):
        edge_attrs = edge_attr
    edge_index1, edge_attrs1 = sort_edge_index(edge_index, edge_attrs, num_nodes=num_nodes, sort_by_row=True)
    edge_index2, edge_attrs2 = sort_edge_index(edge_index, edge_attrs, num_nodes=num_nodes, sort_by_row=False)
    if not torch.equal(edge_index1[0], edge_index2[1]):
        return False
    if not torch.equal(edge_index1[1], edge_index2[0]):
        return False
    for edge_attr1, edge_attr2 in zip(edge_attrs1, edge_attrs2):
        if not torch.equal(edge_attr1, edge_attr2):
            return False
    return True


class Reshape(torch.nn.Module):

    def __init__(self, *shape):
        super().__init__()
        self.shape = shape

    def forward(self, x: Tensor) ->Tensor:
        """"""
        x = x.view(*self.shape)
        return x

    def __repr__(self) ->str:
        shape = ', '.join([str(dim) for dim in self.shape])
        return f'{self.__class__.__name__}({shape})'


class XConv(torch.nn.Module):
    """The convolutional operator on :math:`\\mathcal{X}`-transformed points
    from the `"PointCNN: Convolution On X-Transformed Points"
    <https://arxiv.org/abs/1801.07791>`_ paper

    .. math::
        \\mathbf{x}^{\\prime}_i = \\mathrm{Conv}\\left(\\mathbf{K},
        \\gamma_{\\mathbf{\\Theta}}(\\mathbf{P}_i - \\mathbf{p}_i) \\times
        \\left( h_\\mathbf{\\Theta}(\\mathbf{P}_i - \\mathbf{p}_i) \\, \\Vert \\,
        \\mathbf{x}_i \\right) \\right),

    where :math:`\\mathbf{K}` and :math:`\\mathbf{P}_i` denote the trainable
    filter and neighboring point positions of :math:`\\mathbf{x}_i`,
    respectively.
    :math:`\\gamma_{\\mathbf{\\Theta}}` and :math:`h_{\\mathbf{\\Theta}}` describe
    neural networks, *i.e.* MLPs, where :math:`h_{\\mathbf{\\Theta}}`
    individually lifts each point into a higher-dimensional space, and
    :math:`\\gamma_{\\mathbf{\\Theta}}` computes the :math:`\\mathcal{X}`-
    transformation matrix based on *all* points in a neighborhood.

    Args:
        in_channels (int): Size of each input sample.
        out_channels (int): Size of each output sample.
        dim (int): Point cloud dimensionality.
        kernel_size (int): Size of the convolving kernel, *i.e.* number of
            neighbors including self-loops.
        hidden_channels (int, optional): Output size of
            :math:`h_{\\mathbf{\\Theta}}`, *i.e.* dimensionality of lifted
            points. If set to :obj:`None`, will be automatically set to
            :obj:`in_channels / 4`. (default: :obj:`None`)
        dilation (int, optional): The factor by which the neighborhood is
            extended, from which :obj:`kernel_size` neighbors are then
            uniformly sampled. Can be interpreted as the dilation rate of
            classical convolutional operators. (default: :obj:`1`)
        bias (bool, optional): If set to :obj:`False`, the layer will not learn
            an additive bias. (default: :obj:`True`)
        num_workers (int): Number of workers to use for k-NN computation.
            Has no effect in case :obj:`batch` is not :obj:`None`, or the input
            lies on the GPU. (default: :obj:`1`)

    Shapes:
        - **input:**
          node features :math:`(|\\mathcal{V}|, F_{in})`,
          positions :math:`(|\\mathcal{V}|, D)`,
          batch vector :math:`(|\\mathcal{V}|)` *(optional)*
        - **output:**
          node features :math:`(|\\mathcal{V}|, F_{out})`
    """

    def __init__(self, in_channels: int, out_channels: int, dim: int, kernel_size: int, hidden_channels: Optional[int]=None, dilation: int=1, bias: bool=True, num_workers: int=1):
        super().__init__()
        if knn_graph is None:
            raise ImportError('`XConv` requires `torch-cluster`.')
        self.in_channels = in_channels
        if hidden_channels is None:
            hidden_channels = in_channels // 4
        assert hidden_channels > 0
        self.hidden_channels = hidden_channels
        self.out_channels = out_channels
        self.dim = dim
        self.kernel_size = kernel_size
        self.dilation = dilation
        self.num_workers = num_workers
        C_in, C_delta, C_out = in_channels, hidden_channels, out_channels
        D, K = dim, kernel_size
        self.mlp1 = S(L(dim, C_delta), ELU(), BN(C_delta), L(C_delta, C_delta), ELU(), BN(C_delta), Reshape(-1, K, C_delta))
        self.mlp2 = S(L(D * K, K ** 2), ELU(), BN(K ** 2), Reshape(-1, K, K), Conv1d(K, K ** 2, K, groups=K), ELU(), BN(K ** 2), Reshape(-1, K, K), Conv1d(K, K ** 2, K, groups=K), BN(K ** 2), Reshape(-1, K, K))
        C_in = C_in + C_delta
        depth_multiplier = int(ceil(C_out / C_in))
        self.conv = S(Conv1d(C_in, C_in * depth_multiplier, K, groups=C_in), Reshape(-1, C_in * depth_multiplier), L(C_in * depth_multiplier, C_out, bias=bias))
        self.reset_parameters()

    def reset_parameters(self):
        reset(self.mlp1)
        reset(self.mlp2)
        reset(self.conv)

    def forward(self, x: Tensor, pos: Tensor, batch: Optional[Tensor]=None):
        """"""
        pos = pos.unsqueeze(-1) if pos.dim() == 1 else pos
        (N, D), K = pos.size(), self.kernel_size
        edge_index = knn_graph(pos, K * self.dilation, batch, loop=True, flow='target_to_source', num_workers=self.num_workers)
        if self.dilation > 1:
            edge_index = edge_index[:, ::self.dilation]
        row, col = edge_index[0], edge_index[1]
        pos = pos[col] - pos[row]
        x_star = self.mlp1(pos)
        if x is not None:
            x = x.unsqueeze(-1) if x.dim() == 1 else x
            x = x[col].view(N, K, self.in_channels)
            x_star = torch.cat([x_star, x], dim=-1)
        x_star = x_star.transpose(1, 2).contiguous()
        transform_matrix = self.mlp2(pos.view(N, K * D))
        x_transformed = torch.matmul(x_star, transform_matrix)
        out = self.conv(x_transformed)
        return out

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}({self.in_channels}, {self.out_channels})'


class DataParallel(torch.nn.DataParallel):
    """Implements data parallelism at the module level.

    This container parallelizes the application of the given :attr:`module` by
    splitting a list of :class:`torch_geometric.data.Data` objects and copying
    them as :class:`torch_geometric.data.Batch` objects to each device.
    In the forward pass, the module is replicated on each device, and each
    replica handles a portion of the input.
    During the backwards pass, gradients from each replica are summed into the
    original module.

    The batch size should be larger than the number of GPUs used.

    The parallelized :attr:`module` must have its parameters and buffers on
    :obj:`device_ids[0]`.

    .. note::

        You need to use the :class:`torch_geometric.loader.DataListLoader` for
        this module.

    Args:
        module (Module): Module to be parallelized.
        device_ids (list of int or torch.device): CUDA devices.
            (default: all devices)
        output_device (int or torch.device): Device location of output.
            (default: :obj:`device_ids[0]`)
        follow_batch (list or tuple, optional): Creates assignment batch
            vectors for each key in the list. (default: :obj:`[]`)
        exclude_keys (list or tuple, optional): Will exclude each key in the
            list. (default: :obj:`[]`)
    """

    def __init__(self, module, device_ids=None, output_device=None, follow_batch=[], exclude_keys=[]):
        super().__init__(module, device_ids, output_device)
        self.src_device = torch.device(f'cuda:{self.device_ids[0]}')
        self.follow_batch = follow_batch
        self.exclude_keys = exclude_keys

    def forward(self, data_list):
        """"""
        if len(data_list) == 0:
            logging.warning('DataParallel received an empty data list, which may result in unexpected behaviour.')
            return None
        if not self.device_ids or len(self.device_ids) == 1:
            data = Batch.from_data_list(data_list, follow_batch=self.follow_batch, exclude_keys=self.exclude_keys)
            return self.module(data)
        for t in chain(self.module.parameters(), self.module.buffers()):
            if t.device != self.src_device:
                raise RuntimeError(f"Module must have its parameters and buffers on device '{self.src_device}' but found one of them on device '{t.device}'")
        inputs = self.scatter(data_list, self.device_ids)
        replicas = self.replicate(self.module, self.device_ids[:len(inputs)])
        outputs = self.parallel_apply(replicas, inputs, None)
        return self.gather(outputs, self.output_device)

    def scatter(self, data_list, device_ids):
        num_devices = min(len(device_ids), len(data_list))
        count = torch.tensor([data.num_nodes for data in data_list])
        cumsum = count.cumsum(0)
        cumsum = torch.cat([cumsum.new_zeros(1), cumsum], dim=0)
        device_id = num_devices * cumsum / cumsum[-1].item()
        device_id = (device_id[:-1] + device_id[1:]) / 2.0
        device_id = device_id
        split = device_id.bincount().cumsum(0)
        split = torch.cat([split.new_zeros(1), split], dim=0)
        split = torch.unique(split, sorted=True)
        split = split.tolist()
        return [Batch.from_data_list(data_list[split[i]:split[i + 1]], follow_batch=self.follow_batch, exclude_keys=self.exclude_keys) for i in range(len(split) - 1)]


class DenseGCNConv(torch.nn.Module):
    """See :class:`torch_geometric.nn.conv.GCNConv`.
    """

    def __init__(self, in_channels: int, out_channels: int, improved: bool=False, bias: bool=True):
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.improved = improved
        self.lin = Linear(in_channels, out_channels, bias=False, weight_initializer='glorot')
        if bias:
            self.bias = Parameter(torch.Tensor(out_channels))
        else:
            self.register_parameter('bias', None)
        self.reset_parameters()

    def reset_parameters(self):
        self.lin.reset_parameters()
        zeros(self.bias)

    def forward(self, x: Tensor, adj: Tensor, mask: OptTensor=None, add_loop: bool=True) ->Tensor:
        """
        Args:
            x (Tensor): Node feature tensor :math:`\\mathbf{X} \\in \\mathbb{R}^{B
                \\times N \\times F}`, with batch-size :math:`B`, (maximum)
                number of nodes :math:`N` for each graph, and feature
                dimension :math:`F`.
            adj (Tensor): Adjacency tensor :math:`\\mathbf{A} \\in \\mathbb{R}^{B
                \\times N \\times N}`. The adjacency tensor is broadcastable in
                the batch dimension, resulting in a shared adjacency matrix for
                the complete batch.
            mask (BoolTensor, optional): Mask matrix
                :math:`\\mathbf{M} \\in {\\{ 0, 1 \\}}^{B \\times N}` indicating
                the valid nodes for each graph. (default: :obj:`None`)
            add_loop (bool, optional): If set to :obj:`False`, the layer will
                not automatically add self-loops to the adjacency matrices.
                (default: :obj:`True`)
        """
        x = x.unsqueeze(0) if x.dim() == 2 else x
        adj = adj.unsqueeze(0) if adj.dim() == 2 else adj
        B, N, _ = adj.size()
        if add_loop:
            adj = adj.clone()
            idx = torch.arange(N, dtype=torch.long, device=adj.device)
            adj[:, idx, idx] = 1 if not self.improved else 2
        out = self.lin(x)
        deg_inv_sqrt = adj.sum(dim=-1).clamp(min=1).pow(-0.5)
        adj = deg_inv_sqrt.unsqueeze(-1) * adj * deg_inv_sqrt.unsqueeze(-2)
        out = torch.matmul(adj, out)
        if self.bias is not None:
            out = out + self.bias
        if mask is not None:
            out = out * mask.view(B, N, 1)
        return out

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}({self.in_channels}, {self.out_channels})'


class DenseGINConv(torch.nn.Module):
    """See :class:`torch_geometric.nn.conv.GINConv`.

    :rtype: :class:`Tensor`
    """

    def __init__(self, nn: Module, eps: float=0.0, train_eps: bool=False):
        super().__init__()
        self.nn = nn
        self.initial_eps = eps
        if train_eps:
            self.eps = torch.nn.Parameter(torch.Tensor([eps]))
        else:
            self.register_buffer('eps', torch.Tensor([eps]))
        self.reset_parameters()

    def reset_parameters(self):
        reset(self.nn)
        self.eps.data.fill_(self.initial_eps)

    def forward(self, x: Tensor, adj: Tensor, mask: Optional[Tensor]=None, add_loop: bool=True) ->Tensor:
        """
        Args:
            x (Tensor): Node feature tensor :math:`\\mathbf{X} \\in \\mathbb{R}^{B
                \\times N \\times F}`, with batch-size :math:`B`, (maximum)
                number of nodes :math:`N` for each graph, and feature
                dimension :math:`F`.
            adj (Tensor): Adjacency tensor :math:`\\mathbf{A} \\in \\mathbb{R}^{B
                \\times N \\times N}`. The adjacency tensor is broadcastable in
                the batch dimension, resulting in a shared adjacency matrix for
                the complete batch.
            mask (BoolTensor, optional): Mask matrix
                :math:`\\mathbf{M} \\in {\\{ 0, 1 \\}}^{B \\times N}` indicating
                the valid nodes for each graph. (default: :obj:`None`)
            add_loop (bool, optional): If set to :obj:`False`, the layer will
                not automatically add self-loops to the adjacency matrices.
                (default: :obj:`True`)
        """
        x = x.unsqueeze(0) if x.dim() == 2 else x
        adj = adj.unsqueeze(0) if adj.dim() == 2 else adj
        B, N, _ = adj.size()
        out = torch.matmul(adj, x)
        if add_loop:
            out = (1 + self.eps) * x + out
        out = self.nn(out)
        if mask is not None:
            out = out * mask.view(B, N, 1)
        return out

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}(nn={self.nn})'


class DenseGraphConv(torch.nn.Module):
    """See :class:`torch_geometric.nn.conv.GraphConv`.
    """

    def __init__(self, in_channels: int, out_channels: int, aggr: str='add', bias: bool=True):
        assert aggr in ['add', 'mean', 'max']
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.aggr = aggr
        self.lin_rel = Linear(in_channels, out_channels, bias=bias)
        self.lin_root = Linear(in_channels, out_channels, bias=False)
        self.reset_parameters()

    def reset_parameters(self):
        self.lin_rel.reset_parameters()
        self.lin_root.reset_parameters()

    def forward(self, x: Tensor, adj: Tensor, mask: Optional[Tensor]=None) ->Tensor:
        """
        Args:
            x (Tensor): Node feature tensor :math:`\\mathbf{X} \\in \\mathbb{R}^{B
                \\times N \\times F}`, with batch-size :math:`B`, (maximum)
                number of nodes :math:`N` for each graph, and feature
                dimension :math:`F`.
            adj (Tensor): Adjacency tensor :math:`\\mathbf{A} \\in \\mathbb{R}^{B
                \\times N \\times N}`. The adjacency tensor is broadcastable in
                the batch dimension, resulting in a shared adjacency matrix for
                the complete batch.
            mask (BoolTensor, optional): Mask matrix
                :math:`\\mathbf{M} \\in {\\{ 0, 1 \\}}^{B \\times N}` indicating
                the valid nodes for each graph. (default: :obj:`None`)
        """
        x = x.unsqueeze(0) if x.dim() == 2 else x
        adj = adj.unsqueeze(0) if adj.dim() == 2 else adj
        B, N, C = x.size()
        if self.aggr == 'add':
            out = torch.matmul(adj, x)
        elif self.aggr == 'mean':
            out = torch.matmul(adj, x)
            out = out / adj.sum(dim=-1, keepdim=True).clamp_(min=1)
        elif self.aggr == 'max':
            out = x.unsqueeze(-2).repeat(1, 1, N, 1)
            adj = adj.unsqueeze(-1).expand(B, N, N, C)
            out[adj == 0] = float('-inf')
            out = out.max(dim=-3)[0]
            out[out == float('-inf')] = 0.0
        else:
            raise NotImplementedError
        out = self.lin_rel(out)
        out = out + self.lin_root(x)
        if mask is not None:
            out = out * mask.view(-1, N, 1)
        return out

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}({self.in_channels}, {self.out_channels})'


EPS = 1e-15


def _rank3_trace(x: Tensor) ->Tensor:
    return torch.einsum('ijj->i', x)


class DMoNPooling(torch.nn.Module):
    """The spectral modularity pooling operator from the `"Graph Clustering
    with Graph Neural Networks" <https://arxiv.org/abs/2006.16904>`_ paper

    .. math::
        \\mathbf{X}^{\\prime} &= {\\mathrm{softmax}(\\mathbf{S})}^{\\top} \\cdot
        \\mathbf{X}

        \\mathbf{A}^{\\prime} &= {\\mathrm{softmax}(\\mathbf{S})}^{\\top} \\cdot
        \\mathbf{A} \\cdot \\mathrm{softmax}(\\mathbf{S})

    based on dense learned assignments :math:`\\mathbf{S} \\in \\mathbb{R}^{B
    \\times N \\times C}`.
    Returns the learned cluster assignment matrix, the pooled node feature
    matrix, the coarsened symmetrically normalized adjacency matrix, and three
    auxiliary objectives: (1) The spectral loss

    .. math::
        \\mathcal{L}_s = - \\frac{1}{2m}
        \\cdot{\\mathrm{Tr}(\\mathbf{S}^{\\top} \\mathbf{B} \\mathbf{S})}

    where :math:`\\mathbf{B}` is the modularity matrix, (2) the orthogonality
    loss

    .. math::
        \\mathcal{L}_o = {\\left\\| \\frac{\\mathbf{S}^{\\top} \\mathbf{S}}
        {{\\|\\mathbf{S}^{\\top} \\mathbf{S}\\|}_F} -\\frac{\\mathbf{I}_C}{\\sqrt{C}}
        \\right\\|}_F

    where :math:`C` is the number of clusters, and (3) the cluster loss

    .. math::
        \\mathcal{L}_c = \\frac{\\sqrt{C}}{n}
        {\\left\\|\\sum_i\\mathbf{C_i}^{\\top}\\right\\|}_F - 1.

    .. note::

        For an example of using :class:`DMoNPooling`, see
        `examples/proteins_dmon_pool.py
        <https://github.com/pyg-team/pytorch_geometric/blob
        /master/examples/proteins_dmon_pool.py>`_.

    Args:
        channels (int or List[int]): Size of each input sample. If given as a
            list, will construct an MLP based on the given feature sizes.
        k (int): The number of clusters.
        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)
    """

    def __init__(self, channels: Union[int, List[int]], k: int, dropout: float=0.0):
        super().__init__()
        if isinstance(channels, int):
            channels = [channels]
        self.mlp = MLP(channels + [k], act='selu', norm=None)
        self.dropout = dropout
        self.reset_parameters()

    def reset_parameters(self):
        self.mlp.reset_parameters()

    def forward(self, x: Tensor, adj: Tensor, mask: Optional[Tensor]=None) ->Tuple[Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]:
        """
        Args:
            x (Tensor): Node feature tensor :math:`\\mathbf{X} \\in
                \\mathbb{R}^{B \\times N \\times F}` with batch-size
                :math:`B`, (maximum) number of nodes :math:`N` for each graph,
                and feature dimension :math:`F`.
                Note that the cluster assignment matrix
                :math:`\\mathbf{S} \\in \\mathbb{R}^{B \\times N \\times C}` is
                being created within this method.
            adj (Tensor): Adjacency tensor
                :math:`\\mathbf{A} \\in \\mathbb{R}^{B \\times N \\times N}`.
            mask (BoolTensor, optional): Mask matrix
                :math:`\\mathbf{M} \\in {\\{ 0, 1 \\}}^{B \\times N}` indicating
                the valid nodes for each graph. (default: :obj:`None`)

        :rtype: (:class:`Tensor`, :class:`Tensor`, :class:`Tensor`,
            :class:`Tensor`, :class:`Tensor`, :class:`Tensor`)
        """
        x = x.unsqueeze(0) if x.dim() == 2 else x
        adj = adj.unsqueeze(0) if adj.dim() == 2 else adj
        s = self.mlp(x)
        s = F.dropout(s, self.dropout, training=self.training)
        s = torch.softmax(s, dim=-1)
        (batch_size, num_nodes, _), k = x.size(), s.size(-1)
        if mask is not None:
            mask = mask.view(batch_size, num_nodes, 1)
            x, s = x * mask, s * mask
        out = F.selu(torch.matmul(s.transpose(1, 2), x))
        out_adj = torch.matmul(torch.matmul(s.transpose(1, 2), adj), s)
        degrees = torch.einsum('ijk->ik', adj).transpose(0, 1)
        m = torch.einsum('ij->', degrees)
        ca = torch.matmul(s.transpose(1, 2), degrees)
        cb = torch.matmul(degrees.transpose(0, 1), s)
        normalizer = torch.matmul(ca, cb) / 2 / m
        decompose = out_adj - normalizer
        spectral_loss = -_rank3_trace(decompose) / 2 / m
        spectral_loss = torch.mean(spectral_loss)
        ss = torch.matmul(s.transpose(1, 2), s)
        i_s = torch.eye(k).type_as(ss)
        ortho_loss = torch.norm(ss / torch.norm(ss, dim=(-1, -2), keepdim=True) - i_s / torch.norm(i_s), dim=(-1, -2))
        ortho_loss = torch.mean(ortho_loss)
        cluster_loss = torch.norm(torch.einsum('ijk->ij', ss)) / adj.size(1) * torch.norm(i_s) - 1
        ind = torch.arange(k, device=out_adj.device)
        out_adj[:, ind, ind] = 0
        d = torch.einsum('ijk->ij', out_adj)
        d = torch.sqrt(d)[:, None] + EPS
        out_adj = out_adj / d / d.transpose(1, 2)
        return s, out, out_adj, spectral_loss, ortho_loss, cluster_loss

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}({self.mlp.in_channels}, num_clusters={self.mlp.out_channels})'


class HeteroLinear(torch.nn.Module):
    """Applies separate linear tranformations to the incoming data according
    to types

    .. math::
        \\mathbf{x}^{\\prime}_{\\kappa} = \\mathbf{x}_{\\kappa}
        \\mathbf{W}^{\\top}_{\\kappa} + \\mathbf{b}_{\\kappa}

    for type :math:`\\kappa`.
    It supports lazy initialization and customizable weight and bias
    initialization.

    Args:
        in_channels (int): Size of each input sample. Will be initialized
            lazily in case it is given as :obj:`-1`.
        out_channels (int): Size of each output sample.
        num_types (int): The number of types.
        is_sorted (bool, optional): If set to :obj:`True`, assumes that
            :obj:`type_vec` is sorted. This avoids internal re-sorting of the
            data and can improve runtime and memory efficiency.
            (default: :obj:`False`)
        **kwargs (optional): Additional arguments of
            :class:`torch_geometric.nn.Linear`.

    Shapes:
        - **input:**
          features :math:`(*, F_{in})`,
          type vector :math:`(*)`
        - **output:** features :math:`(*, F_{out})`
    """

    def __init__(self, in_channels: int, out_channels: int, num_types: int, is_sorted: bool=False, **kwargs):
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.num_types = num_types
        self.is_sorted = is_sorted
        self.kwargs = kwargs
        if torch_geometric.typing.WITH_PYG_LIB:
            self.lins = None
            self.weight = torch.nn.Parameter(torch.Tensor(num_types, in_channels, out_channels))
            if kwargs.get('bias', True):
                self.bias = Parameter(torch.Tensor(num_types, out_channels))
            else:
                self.register_parameter('bias', None)
        else:
            self.lins = torch.nn.ModuleList([Linear(in_channels, out_channels, **kwargs) for _ in range(num_types)])
            self.register_parameter('weight', None)
            self.register_parameter('bias', None)
        self.reset_parameters()

    def reset_parameters(self):
        if torch_geometric.typing.WITH_PYG_LIB:
            reset_weight_(self.weight, self.in_channels, self.kwargs.get('weight_initializer', None))
            reset_weight_(self.bias, self.in_channels, self.kwargs.get('bias_initializer', None))
        else:
            for lin in self.lins:
                lin.reset_parameters()

    def forward(self, x: Tensor, type_vec: Tensor) ->Tensor:
        """
        Args:
            x (Tensor): The input features.
            type_vec (LongTensor): A vector that maps each entry to a type.
        """
        if torch_geometric.typing.WITH_PYG_LIB:
            assert self.weight is not None
            perm: Optional[Tensor] = None
            if not self.is_sorted:
                if (type_vec[1:] < type_vec[:-1]).any():
                    type_vec, perm = type_vec.sort()
                    x = x[perm]
            type_vec_ptr = torch.ops.torch_sparse.ind2ptr(type_vec, self.num_types)
            out = pyg_lib.ops.segment_matmul(x, type_vec_ptr, self.weight)
            if self.bias is not None:
                out += self.bias[type_vec]
            if perm is not None:
                out_unsorted = torch.empty_like(out)
                out_unsorted[perm] = out
                out = out_unsorted
        else:
            assert self.lins is not None
            out = x.new_empty(x.size(0), self.out_channels)
            for i, lin in enumerate(self.lins):
                mask = type_vec == i
                out[mask] = lin(x[mask])
        return out

    def __repr__(self) ->str:
        return f"{self.__class__.__name__}({self.in_channels}, {self.out_channels}, num_types={self.num_types}, bias={self.kwargs.get('bias', True)})"


class PositionalEncoding(torch.nn.Module):
    """The positional encoding scheme from `"Attention Is All You Need"
    <https://arxiv.org/pdf/1706.03762.pdf>`_ paper

    .. math::

        PE(x)_{2 \\cdot i} &= \\sin(x / 10000^{2 \\cdot i / d})

        PE(x)_{2 \\cdot i + 1} &= \\cos(x / 10000^{2 \\cdot i / d})

    where :math:`x` is the position and :math:`i` is the dimension.

    Args:
        out_channels (int): Size :math:`d` of each output sample.
        base_freq (float, optional): The base frequency of sinusoidal
            functions. (default: :obj:`1e-4`)
        granularity (float, optional): The granularity of the positions. If
            set to smaller value, the encoder will capture more fine-grained
            changes in positions. (default: :obj:`1.0`)
    """

    def __init__(self, out_channels: int, base_freq: float=0.0001, granularity: float=1.0):
        super().__init__()
        if out_channels % 2 != 0:
            raise ValueError(f"Cannot use sinusoidal positional encoding with odd 'out_channels' (got {out_channels}).")
        self.out_channels = out_channels
        self.base_freq = base_freq
        self.granularity = granularity
        frequency = torch.logspace(0, 1, out_channels // 2, base_freq)
        self.register_buffer('frequency', frequency)

    def forward(self, x: Tensor) ->Tensor:
        """"""
        x = x / self.granularity if self.granularity != 1.0 else x
        out = x.view(-1, 1) * self.frequency.view(1, -1)
        return torch.cat([torch.sin(out), torch.cos(out)], dim=-1)

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}({self.out_channels})'


class MetaLayer(torch.nn.Module):
    """A meta layer for building any kind of graph network, inspired by the
    `"Relational Inductive Biases, Deep Learning, and Graph Networks"
    <https://arxiv.org/abs/1806.01261>`_ paper.

    A graph network takes a graph as input and returns an updated graph as
    output (with same connectivity).
    The input graph has node features :obj:`x`, edge features :obj:`edge_attr`
    as well as global-level features :obj:`u`.
    The output graph has the same structure, but updated features.

    Edge features, node features as well as global features are updated by
    calling the modules :obj:`edge_model`, :obj:`node_model` and
    :obj:`global_model`, respectively.

    To allow for batch-wise graph processing, all callable functions take an
    additional argument :obj:`batch`, which determines the assignment of
    edges or nodes to their specific graphs.

    Args:
        edge_model (Module, optional): A callable which updates a graph's edge
            features based on its source and target node features, its current
            edge features and its global features. (default: :obj:`None`)
        node_model (Module, optional): A callable which updates a graph's node
            features based on its current node features, its graph
            connectivity, its edge features and its global features.
            (default: :obj:`None`)
        global_model (Module, optional): A callable which updates a graph's
            global features based on its node features, its graph connectivity,
            its edge features and its current global features.

    .. code-block:: python

        from torch.nn import Sequential as Seq, Linear as Lin, ReLU
        from torch_scatter import scatter_mean
        from torch_geometric.nn import MetaLayer

        class EdgeModel(torch.nn.Module):
            def __init__(self):
                super().__init__()
                self.edge_mlp = Seq(Lin(..., ...), ReLU(), Lin(..., ...))

            def forward(self, src, dest, edge_attr, u, batch):
                # src, dest: [E, F_x], where E is the number of edges.
                # edge_attr: [E, F_e]
                # u: [B, F_u], where B is the number of graphs.
                # batch: [E] with max entry B - 1.
                out = torch.cat([src, dest, edge_attr, u[batch]], 1)
                return self.edge_mlp(out)

        class NodeModel(torch.nn.Module):
            def __init__(self):
                super().__init__()
                self.node_mlp_1 = Seq(Lin(..., ...), ReLU(), Lin(..., ...))
                self.node_mlp_2 = Seq(Lin(..., ...), ReLU(), Lin(..., ...))

            def forward(self, x, edge_index, edge_attr, u, batch):
                # x: [N, F_x], where N is the number of nodes.
                # edge_index: [2, E] with max entry N - 1.
                # edge_attr: [E, F_e]
                # u: [B, F_u]
                # batch: [N] with max entry B - 1.
                row, col = edge_index
                out = torch.cat([x[row], edge_attr], dim=1)
                out = self.node_mlp_1(out)
                out = scatter_mean(out, col, dim=0, dim_size=x.size(0))
                out = torch.cat([x, out, u[batch]], dim=1)
                return self.node_mlp_2(out)

        class GlobalModel(torch.nn.Module):
            def __init__(self):
                super().__init__()
                self.global_mlp = Seq(Lin(..., ...), ReLU(), Lin(..., ...))

            def forward(self, x, edge_index, edge_attr, u, batch):
                # x: [N, F_x], where N is the number of nodes.
                # edge_index: [2, E] with max entry N - 1.
                # edge_attr: [E, F_e]
                # u: [B, F_u]
                # batch: [N] with max entry B - 1.
                out = torch.cat([u, scatter_mean(x, batch, dim=0)], dim=1)
                return self.global_mlp(out)

        op = MetaLayer(EdgeModel(), NodeModel(), GlobalModel())
        x, edge_attr, u = op(x, edge_index, edge_attr, u, batch)
    """

    def __init__(self, edge_model: Optional[torch.nn.Module]=None, node_model: Optional[torch.nn.Module]=None, global_model: Optional[torch.nn.Module]=None):
        super().__init__()
        self.edge_model = edge_model
        self.node_model = node_model
        self.global_model = global_model
        self.reset_parameters()

    def reset_parameters(self):
        for item in [self.node_model, self.edge_model, self.global_model]:
            if hasattr(item, 'reset_parameters'):
                item.reset_parameters()

    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Optional[Tensor]=None, u: Optional[Tensor]=None, batch: Optional[Tensor]=None) ->Tuple[Tensor, Optional[Tensor], Optional[Tensor]]:
        """"""
        row = edge_index[0]
        col = edge_index[1]
        if self.edge_model is not None:
            edge_attr = self.edge_model(x[row], x[col], edge_attr, u, batch if batch is None else batch[row])
        if self.node_model is not None:
            x = self.node_model(x, edge_index, edge_attr, u, batch)
        if self.global_model is not None:
            u = self.global_model(x, edge_index, edge_attr, u, batch)
        return x, edge_attr, u

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}(\n  edge_model={self.edge_model},\n  node_model={self.node_model},\n  global_model={self.global_model}\n)'


def global_add_pool(x: Tensor, batch: Optional[Tensor], size: Optional[int]=None) ->Tensor:
    """Returns batch-wise graph-level-outputs by adding node features
    across the node dimension, so that for a single graph
    :math:`\\mathcal{G}_i` its output is computed by

    .. math::
        \\mathbf{r}_i = \\sum_{n=1}^{N_i} \\mathbf{x}_n.

    Functional method of the
    :class:`~torch_geometric.nn.aggr.SumAggregation` module.

    Args:
        x (Tensor): Node feature matrix
            :math:`\\mathbf{X} \\in \\mathbb{R}^{(N_1 + \\ldots + N_B) \\times F}`.
        batch (LongTensor, optional): Batch vector
            :math:`\\mathbf{b} \\in {\\{ 0, \\ldots, B-1\\}}^N`, which assigns each
            node to a specific example.
        size (int, optional): Batch-size :math:`B`.
            Automatically calculated if not given. (default: :obj:`None`)
    """
    if batch is None:
        return x.sum(dim=-2, keepdim=x.dim() == 2)
    size = int(batch.max().item() + 1) if size is None else size
    return scatter(x, batch, dim=-2, dim_size=size, reduce='add')


class AttentiveFP(torch.nn.Module):
    """The Attentive FP model for molecular representation learning from the
    `"Pushing the Boundaries of Molecular Representation for Drug Discovery
    with the Graph Attention Mechanism"
    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on
    graph attention mechanisms.

    Args:
        in_channels (int): Size of each input sample.
        hidden_channels (int): Hidden node feature dimensionality.
        out_channels (int): Size of each output sample.
        edge_dim (int): Edge feature dimensionality.
        num_layers (int): Number of GNN layers.
        num_timesteps (int): Number of iterative refinement steps for global
            readout.
        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)

    """

    def __init__(self, in_channels: int, hidden_channels: int, out_channels: int, edge_dim: int, num_layers: int, num_timesteps: int, dropout: float=0.0):
        super().__init__()
        self.in_channels = in_channels
        self.hidden_channels = hidden_channels
        self.out_channels = out_channels
        self.edge_dim = edge_dim
        self.num_layers = num_layers
        self.num_timesteps = num_timesteps
        self.dropout = dropout
        self.lin1 = Linear(in_channels, hidden_channels)
        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim, dropout)
        self.gru = GRUCell(hidden_channels, hidden_channels)
        self.atom_convs = torch.nn.ModuleList()
        self.atom_grus = torch.nn.ModuleList()
        for _ in range(num_layers - 1):
            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout, add_self_loops=False, negative_slope=0.01)
            self.atom_convs.append(conv)
            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))
        self.mol_conv = GATConv(hidden_channels, hidden_channels, dropout=dropout, add_self_loops=False, negative_slope=0.01)
        self.mol_gru = GRUCell(hidden_channels, hidden_channels)
        self.lin2 = Linear(hidden_channels, out_channels)
        self.reset_parameters()

    def reset_parameters(self) ->None:
        self.lin1.reset_parameters()
        self.gate_conv.reset_parameters()
        self.gru.reset_parameters()
        for conv, gru in zip(self.atom_convs, self.atom_grus):
            conv.reset_parameters()
            gru.reset_parameters()
        self.mol_conv.reset_parameters()
        self.mol_gru.reset_parameters()
        self.lin2.reset_parameters()

    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor, batch: Tensor) ->Tensor:
        """"""
        x = F.leaky_relu_(self.lin1(x))
        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))
        h = F.dropout(h, p=self.dropout, training=self.training)
        x = self.gru(h, x).relu_()
        for conv, gru in zip(self.atom_convs, self.atom_grus):
            h = F.elu_(conv(x, edge_index))
            h = F.dropout(h, p=self.dropout, training=self.training)
            x = gru(h, x).relu_()
        row = torch.arange(batch.size(0), device=batch.device)
        edge_index = torch.stack([row, batch], dim=0)
        out = global_add_pool(x, batch).relu_()
        for t in range(self.num_timesteps):
            h = F.elu_(self.mol_conv((x, out), edge_index))
            h = F.dropout(h, p=self.dropout, training=self.training)
            out = self.mol_gru(h, out).relu_()
        out = F.dropout(out, p=self.dropout, training=self.training)
        return self.lin2(out)

    def jittable(self) ->'AttentiveFP':
        self.gate_conv = self.gate_conv.jittable()
        self.atom_convs = torch.nn.ModuleList([conv.jittable() for conv in self.atom_convs])
        self.mol_conv = self.mol_conv.jittable()
        return self

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}(in_channels={self.in_channels}, hidden_channels={self.hidden_channels}, out_channels={self.out_channels}, edge_dim={self.edge_dim}, num_layers={self.num_layers}, num_timesteps={self.num_timesteps})'


class InnerProductDecoder(torch.nn.Module):
    """The inner product decoder from the `"Variational Graph Auto-Encoders"
    <https://arxiv.org/abs/1611.07308>`_ paper

    .. math::
        \\sigma(\\mathbf{Z}\\mathbf{Z}^{\\top})

    where :math:`\\mathbf{Z} \\in \\mathbb{R}^{N \\times d}` denotes the latent
    space produced by the encoder."""

    def forward(self, z: Tensor, edge_index: Tensor, sigmoid: bool=True) ->Tensor:
        """Decodes the latent variables :obj:`z` into edge probabilities for
        the given node-pairs :obj:`edge_index`.

        Args:
            z (Tensor): The latent space :math:`\\mathbf{Z}`.
            sigmoid (bool, optional): If set to :obj:`False`, does not apply
                the logistic sigmoid function to the output.
                (default: :obj:`True`)
        """
        value = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=1)
        return torch.sigmoid(value) if sigmoid else value

    def forward_all(self, z: Tensor, sigmoid: bool=True) ->Tensor:
        """Decodes the latent variables :obj:`z` into a probabilistic dense
        adjacency matrix.

        Args:
            z (Tensor): The latent space :math:`\\mathbf{Z}`.
            sigmoid (bool, optional): If set to :obj:`False`, does not apply
                the logistic sigmoid function to the output.
                (default: :obj:`True`)
        """
        adj = torch.matmul(z, z.t())
        return torch.sigmoid(adj) if sigmoid else adj


class GAE(torch.nn.Module):
    """The Graph Auto-Encoder model from the
    `"Variational Graph Auto-Encoders" <https://arxiv.org/abs/1611.07308>`_
    paper based on user-defined encoder and decoder models.

    Args:
        encoder (Module): The encoder module.
        decoder (Module, optional): The decoder module. If set to :obj:`None`,
            will default to the
            :class:`torch_geometric.nn.models.InnerProductDecoder`.
            (default: :obj:`None`)
    """

    def __init__(self, encoder: Module, decoder: Optional[Module]=None):
        super().__init__()
        self.encoder = encoder
        self.decoder = InnerProductDecoder() if decoder is None else decoder
        GAE.reset_parameters(self)

    def reset_parameters(self):
        reset(self.encoder)
        reset(self.decoder)

    def encode(self, *args, **kwargs) ->Tensor:
        """Runs the encoder and computes node-wise latent variables."""
        return self.encoder(*args, **kwargs)

    def decode(self, *args, **kwargs) ->Tensor:
        """Runs the decoder and computes edge probabilities."""
        return self.decoder(*args, **kwargs)

    def recon_loss(self, z: Tensor, pos_edge_index: Tensor, neg_edge_index: Optional[Tensor]=None) ->Tensor:
        """Given latent variables :obj:`z`, computes the binary cross
        entropy loss for positive edges :obj:`pos_edge_index` and negative
        sampled edges.

        Args:
            z (Tensor): The latent space :math:`\\mathbf{Z}`.
            pos_edge_index (LongTensor): The positive edges to train against.
            neg_edge_index (LongTensor, optional): The negative edges to train
                against. If not given, uses negative sampling to calculate
                negative edges. (default: :obj:`None`)
        """
        pos_loss = -torch.log(self.decoder(z, pos_edge_index, sigmoid=True) + EPS).mean()
        if neg_edge_index is None:
            neg_edge_index = negative_sampling(pos_edge_index, z.size(0))
        neg_loss = -torch.log(1 - self.decoder(z, neg_edge_index, sigmoid=True) + EPS).mean()
        return pos_loss + neg_loss

    def test(self, z: Tensor, pos_edge_index: Tensor, neg_edge_index: Tensor) ->Tuple[Tensor, Tensor]:
        """Given latent variables :obj:`z`, positive edges
        :obj:`pos_edge_index` and negative edges :obj:`neg_edge_index`,
        computes area under the ROC curve (AUC) and average precision (AP)
        scores.

        Args:
            z (Tensor): The latent space :math:`\\mathbf{Z}`.
            pos_edge_index (LongTensor): The positive edges to evaluate
                against.
            neg_edge_index (LongTensor): The negative edges to evaluate
                against.
        """
        from sklearn.metrics import average_precision_score
        from sklearn.metrics import roc_auc_score
        pos_y = z.new_ones(pos_edge_index.size(1))
        neg_y = z.new_zeros(neg_edge_index.size(1))
        y = torch.cat([pos_y, neg_y], dim=0)
        pos_pred = self.decoder(z, pos_edge_index, sigmoid=True)
        neg_pred = self.decoder(z, neg_edge_index, sigmoid=True)
        pred = torch.cat([pos_pred, neg_pred], dim=0)
        y, pred = y.detach().cpu().numpy(), pred.detach().cpu().numpy()
        return roc_auc_score(y, pred), average_precision_score(y, pred)


MAX_LOGSTD = 10


class VGAE(GAE):
    """The Variational Graph Auto-Encoder model from the
    `"Variational Graph Auto-Encoders" <https://arxiv.org/abs/1611.07308>`_
    paper.

    Args:
        encoder (Module): The encoder module to compute :math:`\\mu` and
            :math:`\\log\\sigma^2`.
        decoder (Module, optional): The decoder module. If set to :obj:`None`,
            will default to the
            :class:`torch_geometric.nn.models.InnerProductDecoder`.
            (default: :obj:`None`)
    """

    def __init__(self, encoder: Module, decoder: Optional[Module]=None):
        super().__init__(encoder, decoder)

    def reparametrize(self, mu: Tensor, logstd: Tensor) ->Tensor:
        if self.training:
            return mu + torch.randn_like(logstd) * torch.exp(logstd)
        else:
            return mu

    def encode(self, *args, **kwargs) ->Tensor:
        """"""
        self.__mu__, self.__logstd__ = self.encoder(*args, **kwargs)
        self.__logstd__ = self.__logstd__.clamp(max=MAX_LOGSTD)
        z = self.reparametrize(self.__mu__, self.__logstd__)
        return z

    def kl_loss(self, mu: Optional[Tensor]=None, logstd: Optional[Tensor]=None) ->Tensor:
        """Computes the KL loss, either for the passed arguments :obj:`mu`
        and :obj:`logstd`, or based on latent variables from last encoding.

        Args:
            mu (Tensor, optional): The latent space for :math:`\\mu`. If set to
                :obj:`None`, uses the last computation of :math:`mu`.
                (default: :obj:`None`)
            logstd (Tensor, optional): The latent space for
                :math:`\\log\\sigma`.  If set to :obj:`None`, uses the last
                computation of :math:`\\log\\sigma^2`.(default: :obj:`None`)
        """
        mu = self.__mu__ if mu is None else mu
        logstd = self.__logstd__ if logstd is None else logstd.clamp(max=MAX_LOGSTD)
        return -0.5 * torch.mean(torch.sum(1 + 2 * logstd - mu ** 2 - logstd.exp() ** 2, dim=1))


class ARGA(GAE):
    """The Adversarially Regularized Graph Auto-Encoder model from the
    `"Adversarially Regularized Graph Autoencoder for Graph Embedding"
    <https://arxiv.org/abs/1802.04407>`_ paper.

    Args:
        encoder (Module): The encoder module.
        discriminator (Module): The discriminator module.
        decoder (Module, optional): The decoder module. If set to :obj:`None`,
            will default to the
            :class:`torch_geometric.nn.models.InnerProductDecoder`.
            (default: :obj:`None`)
    """

    def __init__(self, encoder: Module, discriminator: Module, decoder: Optional[Module]=None):
        super().__init__(encoder, decoder)
        self.discriminator = discriminator
        reset(self.discriminator)

    def reset_parameters(self):
        super().reset_parameters()
        reset(self.discriminator)

    def reg_loss(self, z: Tensor) ->Tensor:
        """Computes the regularization loss of the encoder.

        Args:
            z (Tensor): The latent space :math:`\\mathbf{Z}`.
        """
        real = torch.sigmoid(self.discriminator(z))
        real_loss = -torch.log(real + EPS).mean()
        return real_loss

    def discriminator_loss(self, z: Tensor) ->Tensor:
        """Computes the loss of the discriminator.

        Args:
            z (Tensor): The latent space :math:`\\mathbf{Z}`.
        """
        real = torch.sigmoid(self.discriminator(torch.randn_like(z)))
        fake = torch.sigmoid(self.discriminator(z.detach()))
        real_loss = -torch.log(real + EPS).mean()
        fake_loss = -torch.log(1 - fake + EPS).mean()
        return real_loss + fake_loss


class ARGVA(ARGA):
    """The Adversarially Regularized Variational Graph Auto-Encoder model from
    the `"Adversarially Regularized Graph Autoencoder for Graph Embedding"
    <https://arxiv.org/abs/1802.04407>`_ paper.

    Args:
        encoder (Module): The encoder module to compute :math:`\\mu` and
            :math:`\\log\\sigma^2`.
        discriminator (Module): The discriminator module.
        decoder (Module, optional): The decoder module. If set to :obj:`None`,
            will default to the
            :class:`torch_geometric.nn.models.InnerProductDecoder`.
            (default: :obj:`None`)
    """

    def __init__(self, encoder: Module, discriminator: Module, decoder: Optional[Module]=None):
        super().__init__(encoder, discriminator, decoder)
        self.VGAE = VGAE(encoder, decoder)

    @property
    def __mu__(self) ->Tensor:
        return self.VGAE.__mu__

    @property
    def __logstd__(self) ->Tensor:
        return self.VGAE.__logstd__

    def reparametrize(self, mu: Tensor, logstd: Tensor) ->Tensor:
        return self.VGAE.reparametrize(mu, logstd)

    def encode(self, *args, **kwargs) ->Tensor:
        """"""
        return self.VGAE.encode(*args, **kwargs)

    def kl_loss(self, mu: Optional[Tensor]=None, logstd: Optional[Tensor]=None) ->Tensor:
        return self.VGAE.kl_loss(mu, logstd)


class CaptumModel(torch.nn.Module):

    def __init__(self, model: torch.nn.Module, mask_type: str='edge', output_idx: Optional[int]=None):
        super().__init__()
        assert mask_type in ['edge', 'node', 'node_and_edge']
        self.mask_type = mask_type
        self.model = model
        self.output_idx = output_idx

    def forward(self, mask, *args):
        """"""
        assert mask.shape[0] == 1, 'Dimension 0 of input should be 1'
        if self.mask_type == 'edge':
            assert len(args) >= 2, 'Expects at least x and edge_index as args.'
        if self.mask_type == 'node':
            assert len(args) >= 1, 'Expects at least edge_index as args.'
        if self.mask_type == 'node_and_edge':
            assert args[0].shape[0] == 1, 'Dimension 0 of input should be 1'
            assert len(args[1:]) >= 1, 'Expects at least edge_index as args.'
        if self.mask_type == 'edge':
            set_masks(self.model, mask.squeeze(0), args[1], apply_sigmoid=False)
        elif self.mask_type == 'node_and_edge':
            set_masks(self.model, args[0].squeeze(0), args[1], apply_sigmoid=False)
            args = args[1:]
        if self.mask_type == 'edge':
            x = self.model(*args)
        elif self.mask_type == 'node':
            x = self.model(mask.squeeze(0), *args)
        else:
            x = self.model(mask[0], *args)
        if self.mask_type in ['edge', 'node_and_edge']:
            clear_masks(self.model)
        if self.output_idx is not None:
            x = x[self.output_idx].unsqueeze(0)
        return x


def set_hetero_masks(model: torch.nn.Module, mask_dict: Dict[EdgeType, Tensor], edge_index_dict: Dict[EdgeType, Tensor], apply_sigmoid: bool=True):
    """Apply masks to every heterogeneous graph layer in the :obj:`model`
    according to edge types."""
    for module in model.modules():
        if isinstance(module, torch.nn.ModuleDict):
            for edge_type in mask_dict.keys():
                str_edge_type = '__'.join(edge_type)
                if str_edge_type in module:
                    set_masks(module[str_edge_type], mask_dict[edge_type], edge_index_dict[edge_type], apply_sigmoid=apply_sigmoid)


class CaptumHeteroModel(CaptumModel):

    def __init__(self, model: torch.nn.Module, mask_type: str, output_id: int, metadata: Metadata):
        super().__init__(model, mask_type, output_id)
        self.node_types = metadata[0]
        self.edge_types = metadata[1]
        self.num_node_types = len(self.node_types)
        self.num_edge_types = len(self.edge_types)

    def _captum_data_to_hetero_data(self, *args) ->Tuple[Dict[NodeType, Tensor], Dict[EdgeType, Tensor], Optional[Dict[EdgeType, Tensor]]]:
        """Converts tuple of tensors to `x_dict`, `edge_index_dict` and
        `edge_mask_dict`."""
        if self.mask_type == 'node':
            node_tensors = args[:self.num_node_types]
            node_tensors = [mask.squeeze(0) for mask in node_tensors]
            x_dict = dict(zip(self.node_types, node_tensors))
            edge_index_dict = args[self.num_node_types]
        elif self.mask_type == 'edge':
            edge_mask_tensors = args[:self.num_edge_types]
            x_dict = args[self.num_edge_types]
            edge_index_dict = args[self.num_edge_types + 1]
        else:
            node_tensors = args[:self.num_node_types]
            node_tensors = [mask.squeeze(0) for mask in node_tensors]
            x_dict = dict(zip(self.node_types, node_tensors))
            edge_mask_tensors = args[self.num_node_types:self.num_node_types + self.num_edge_types]
            edge_index_dict = args[self.num_node_types + self.num_edge_types]
        if 'edge' in self.mask_type:
            edge_mask_tensors = [mask.squeeze(0) for mask in edge_mask_tensors]
            edge_mask_dict = dict(zip(self.edge_types, edge_mask_tensors))
        else:
            edge_mask_dict = None
        return x_dict, edge_index_dict, edge_mask_dict

    def forward(self, *args):
        if self.mask_type == 'node':
            assert len(args) >= self.num_node_types + 1
            len_remaining_args = len(args) - (self.num_node_types + 1)
        elif self.mask_type == 'edge':
            assert len(args) >= self.num_edge_types + 2
            len_remaining_args = len(args) - (self.num_edge_types + 2)
        else:
            assert len(args) >= self.num_node_types + self.num_edge_types + 1
            len_remaining_args = len(args) - (self.num_node_types + self.num_edge_types + 1)
        x_dict, edge_index_dict, edge_mask_dict = self._captum_data_to_hetero_data(*args)
        if 'edge' in self.mask_type:
            set_hetero_masks(self.model, edge_mask_dict, edge_index_dict)
        if len_remaining_args > 0:
            x = self.model(x_dict, edge_index_dict, *args[-len_remaining_args:])
        else:
            x = self.model(x_dict, edge_index_dict)
        if 'edge' in self.mask_type:
            clear_masks(self.model)
        if self.output_idx is not None:
            x = x[self.output_idx].unsqueeze(0)
        return x


def get_num_hops(model: torch.nn.Module) ->int:
    """Returns the number of hops the model is aggregating information
    from.

    Example:

        >>> class GNN(torch.nn.Module):
        ...     def __init__(self):
        ...         super().__init__()
        ...         self.conv1 = GCNConv(3, 16)
        ...         self.conv2 = GCNConv(16, 16)
        ...         self.lin = Linear(16, 2)
        ...
        ...     def forward(self, x, edge_index):
        ...         x = torch.F.relu(self.conv1(x, edge_index))
        ...         x = self.conv2(x, edge_index)
        ...         return self.lin(x)
        >>> get_num_hops(GNN())
        2
    """
    num_hops = 0
    for module in model.modules():
        if isinstance(module, MessagePassing):
            num_hops += 1
    return num_hops


def to_networkx(data: 'torch_geometric.data.Data', node_attrs: Optional[Iterable[str]]=None, edge_attrs: Optional[Iterable[str]]=None, graph_attrs: Optional[Iterable[str]]=None, to_undirected: Optional[Union[bool, str]]=False, remove_self_loops: bool=False) ->Any:
    """Converts a :class:`torch_geometric.data.Data` instance to a
    :obj:`networkx.Graph` if :attr:`to_undirected` is set to :obj:`True`, or
    a directed :obj:`networkx.DiGraph` otherwise.

    Args:
        data (torch_geometric.data.Data): The data object.
        node_attrs (iterable of str, optional): The node attributes to be
            copied. (default: :obj:`None`)
        edge_attrs (iterable of str, optional): The edge attributes to be
            copied. (default: :obj:`None`)
        graph_attrs (iterable of str, optional): The graph attributes to be
            copied. (default: :obj:`None`)
        to_undirected (bool or str, optional): If set to :obj:`True` or
            "upper", will return a :obj:`networkx.Graph` instead of a
            :obj:`networkx.DiGraph`. The undirected graph will correspond to
            the upper triangle of the corresponding adjacency matrix.
            Similarly, if set to "lower", the undirected graph will correspond
            to the lower triangle of the adjacency matrix. (default:
            :obj:`False`)
        remove_self_loops (bool, optional): If set to :obj:`True`, will not
            include self loops in the resulting graph. (default: :obj:`False`)

    Examples:

        >>> edge_index = torch.tensor([
        ...     [0, 1, 1, 2, 2, 3],
        ...     [1, 0, 2, 1, 3, 2],
        ... ])
        >>> data = Data(edge_index=edge_index, num_nodes=4)
        >>> to_networkx(data)
        <networkx.classes.digraph.DiGraph at 0x2713fdb40d0>

    """
    G = nx.Graph() if to_undirected else nx.DiGraph()
    G.add_nodes_from(range(data.num_nodes))
    node_attrs = node_attrs or []
    edge_attrs = edge_attrs or []
    graph_attrs = graph_attrs or []
    values = {}
    for key, value in data(*(node_attrs + edge_attrs + graph_attrs)):
        if torch.is_tensor(value):
            value = value if value.dim() <= 1 else value.squeeze(-1)
            values[key] = value.tolist()
        else:
            values[key] = value
    to_undirected = 'upper' if to_undirected is True else to_undirected
    to_undirected_upper = True if to_undirected == 'upper' else False
    to_undirected_lower = True if to_undirected == 'lower' else False
    for i, (u, v) in enumerate(data.edge_index.t().tolist()):
        if to_undirected_upper and u > v:
            continue
        elif to_undirected_lower and u < v:
            continue
        if remove_self_loops and u == v:
            continue
        G.add_edge(u, v)
        for key in edge_attrs:
            G[u][v][key] = values[key][i]
    for key in node_attrs:
        for i, feat_dict in G.nodes(data=True):
            feat_dict.update({key: values[key][i]})
    for key in graph_attrs:
        G.graph[key] = values[key]
    return G


class Explainer(torch.nn.Module):
    """An abstract class for integrating explainability into Graph Neural
    Networks.
    It also provides general visualization methods for graph attributions.

    Args:
        model (torch.nn.Module): The GNN module to explain.
        epochs (int, optional): The number of epochs to train.
            (default: :obj:`None`)
        lr (float, optional): The learning rate to apply.
            (default: :obj:`None`)
        num_hops (int, optional): The number of hops the :obj:`model` is
            aggregating information from.
            If set to :obj:`None`, will automatically try to detect this
            information based on the number of
            :class:`~torch_geometric.nn.conv.message_passing.MessagePassing`
            layers inside :obj:`model`. (default: :obj:`None`)
        return_type (str, optional): Denotes the type of output from
            :obj:`model`. Valid inputs are :obj:`"log_prob"` (the model
            returns the logarithm of probabilities), :obj:`"prob"` (the
            model returns probabilities), :obj:`"raw"` (the model returns raw
            scores) and :obj:`"regression"` (the model returns scalars).
            (default: :obj:`"log_prob"`)
        log (bool, optional): If set to :obj:`False`, will not log any learning
            progress. (default: :obj:`True`)
    """

    def __init__(self, model: torch.nn.Module, lr: Optional[float]=None, epochs: Optional[int]=None, num_hops: Optional[int]=None, return_type: str='log_prob', log: bool=False):
        super().__init__()
        assert return_type in ['log_prob', 'prob', 'raw', 'regression']
        self.model = model
        self.lr = lr
        self.epochs = epochs
        self.num_hops = num_hops or get_num_hops(self.model)
        self.return_type = return_type
        self.log = log

    def _flow(self) ->str:
        for module in self.model.modules():
            if isinstance(module, MessagePassing):
                return module.flow
        return 'source_to_target'

    def subgraph(self, node_idx: int, x: Tensor, edge_index: Tensor, **kwargs):
        """Returns the subgraph of the given node.

        Args:
            node_idx (int): The node to explain.
            x (Tensor): The node feature matrix.
            edge_index (LongTensor): The edge indices.
            **kwargs (optional): Additional arguments passed to the GNN module.

        :rtype: (Tensor, Tensor, LongTensor, LongTensor, LongTensor, dict)
        """
        num_nodes, num_edges = x.size(0), edge_index.size(1)
        subset, edge_index, mapping, edge_mask = k_hop_subgraph(node_idx, self.num_hops, edge_index, relabel_nodes=True, num_nodes=num_nodes, flow=self._flow())
        x = x[subset]
        kwargs_new = {}
        for key, value in kwargs.items():
            if torch.is_tensor(value) and value.size(0) == num_nodes:
                kwargs_new[key] = value[subset]
            elif torch.is_tensor(value) and value.size(0) == num_edges:
                kwargs_new[key] = value[edge_mask]
            else:
                kwargs_new[key] = value
        return x, edge_index, mapping, edge_mask, subset, kwargs_new

    def _to_log_prob(self, x):
        x = x.log_softmax(dim=-1) if self.return_type == 'raw' else x
        x = x.log() if self.return_type == 'prob' else x
        return x

    @torch.no_grad()
    def get_initial_prediction(self, x: Tensor, edge_index: Tensor, batch: Optional[Tensor]=None, **kwargs):
        if batch is not None:
            out = self.model(x, edge_index, batch=batch, **kwargs)
        else:
            out = self.model(x, edge_index, **kwargs)
        if self.return_type == 'regression':
            prediction = out
        else:
            log_logits = self._to_log_prob(out)
            prediction = log_logits.argmax(dim=-1)
        return prediction

    def get_loss(self, out: Tensor, prediction: Tensor, node_idx: Optional[int]=None, **kwargs):
        if self.return_type == 'regression':
            loss = self._loss(out, prediction, node_idx, **kwargs)
        else:
            log_logits = self._to_log_prob(out)
            loss = self._loss(log_logits, prediction, node_idx, **kwargs)
        return loss

    def visualize_subgraph(self, node_idx: Optional[int], edge_index: Tensor, edge_mask: Tensor, y: Optional[Tensor]=None, threshold: Optional[int]=None, edge_y: Optional[Tensor]=None, node_alpha: Optional[Tensor]=None, seed: int=10, **kwargs):
        """Visualizes the subgraph given an edge mask :attr:`edge_mask`.

        Args:
            node_idx (int): The node id to explain.
                Set to :obj:`None` to explain a graph.
            edge_index (LongTensor): The edge indices.
            edge_mask (Tensor): The edge mask.
            y (Tensor, optional): The ground-truth node-prediction labels used
                as node colorings. All nodes will have the same color
                if :attr:`node_idx` is :obj:`-1`.(default: :obj:`None`).
            threshold (float, optional): Sets a threshold for visualizing
                important edges. If set to :obj:`None`, will visualize all
                edges with transparancy indicating the importance of edges.
                (default: :obj:`None`)
            edge_y (Tensor, optional): The edge labels used as edge colorings.
            node_alpha (Tensor, optional): Tensor of floats (0 - 1) indicating
                transparency of each node.
            seed (int, optional): Random seed of the :obj:`networkx` node
                placement algorithm. (default: :obj:`10`)
            **kwargs (optional): Additional arguments passed to
                :func:`nx.draw`.

        :rtype: :class:`matplotlib.axes.Axes`, :class:`networkx.DiGraph`
        """
        import matplotlib.pyplot as plt
        assert edge_mask.size(0) == edge_index.size(1)
        if node_idx is None or node_idx < 0:
            hard_edge_mask = torch.BoolTensor([True] * edge_index.size(1), device=edge_mask.device)
            subset = torch.arange(edge_index.max().item() + 1, device=edge_index.device)
            y = None
        else:
            subset, edge_index, _, hard_edge_mask = k_hop_subgraph(node_idx, self.num_hops, edge_index, relabel_nodes=True, num_nodes=None, flow=self._flow())
        edge_mask = edge_mask[hard_edge_mask]
        if threshold is not None:
            edge_mask = edge_mask >= threshold
        if y is None:
            y = torch.zeros(edge_index.max().item() + 1, device=edge_index.device)
        else:
            y = y[subset] / y.max().item()
        if edge_y is None:
            edge_color = ['black'] * edge_index.size(1)
        else:
            colors = list(plt.rcParams['axes.prop_cycle'])
            edge_color = [colors[i % len(colors)]['color'] for i in edge_y[hard_edge_mask]]
        data = Data(edge_index=edge_index, att=edge_mask, edge_color=edge_color, y=y, num_nodes=y.size(0))
        G = to_networkx(data, node_attrs=['y'], edge_attrs=['att', 'edge_color'])
        mapping = {k: i for k, i in enumerate(subset.tolist())}
        G = nx.relabel_nodes(G, mapping)
        node_args = set(signature(nx.draw_networkx_nodes).parameters.keys())
        node_kwargs = {k: v for k, v in kwargs.items() if k in node_args}
        node_kwargs['node_size'] = kwargs.get('node_size') or 800
        node_kwargs['cmap'] = kwargs.get('cmap') or 'cool'
        label_args = set(signature(nx.draw_networkx_labels).parameters.keys())
        label_kwargs = {k: v for k, v in kwargs.items() if k in label_args}
        label_kwargs['font_size'] = kwargs.get('font_size') or 10
        pos = nx.spring_layout(G, seed=seed)
        ax = plt.gca()
        for source, target, data in G.edges(data=True):
            ax.annotate('', xy=pos[target], xycoords='data', xytext=pos[source], textcoords='data', arrowprops=dict(arrowstyle='->', alpha=max(data['att'], 0.1), color=data['edge_color'], shrinkA=sqrt(node_kwargs['node_size']) / 2.0, shrinkB=sqrt(node_kwargs['node_size']) / 2.0, connectionstyle='arc3,rad=0.1'))
        if node_alpha is None:
            nx.draw_networkx_nodes(G, pos, node_color=y.tolist(), **node_kwargs)
        else:
            node_alpha_subset = node_alpha[subset]
            assert ((node_alpha_subset >= 0) & (node_alpha_subset <= 1)).all()
            nx.draw_networkx_nodes(G, pos, alpha=node_alpha_subset.tolist(), node_color=y.tolist(), **node_kwargs)
        nx.draw_networkx_labels(G, pos, **label_kwargs)
        return ax, G


class DeepGraphInfomax(torch.nn.Module):
    """The Deep Graph Infomax model from the
    `"Deep Graph Infomax" <https://arxiv.org/abs/1809.10341>`_
    paper based on user-defined encoder and summary model :math:`\\mathcal{E}`
    and :math:`\\mathcal{R}` respectively, and a corruption function
    :math:`\\mathcal{C}`.

    Args:
        hidden_channels (int): The latent space dimensionality.
        encoder (Module): The encoder module :math:`\\mathcal{E}`.
        summary (callable): The readout function :math:`\\mathcal{R}`.
        corruption (callable): The corruption function :math:`\\mathcal{C}`.
    """

    def __init__(self, hidden_channels: int, encoder: Module, summary: Callable, corruption: Callable):
        super().__init__()
        self.hidden_channels = hidden_channels
        self.encoder = encoder
        self.summary = summary
        self.corruption = corruption
        self.weight = Parameter(torch.Tensor(hidden_channels, hidden_channels))
        self.reset_parameters()

    def reset_parameters(self):
        reset(self.encoder)
        reset(self.summary)
        uniform(self.hidden_channels, self.weight)

    def forward(self, *args, **kwargs) ->Tuple[Tensor, Tensor, Tensor]:
        """Returns the latent space for the input arguments, their
        corruptions and their summary representation."""
        pos_z = self.encoder(*args, **kwargs)
        cor = self.corruption(*args, **kwargs)
        cor = cor if isinstance(cor, tuple) else (cor,)
        neg_z = self.encoder(*cor)
        summary = self.summary(pos_z, *args, **kwargs)
        return pos_z, neg_z, summary

    def discriminate(self, z: Tensor, summary: Tensor, sigmoid: bool=True) ->Tensor:
        """Given the patch-summary pair :obj:`z` and :obj:`summary`, computes
        the probability scores assigned to this patch-summary pair.

        Args:
            z (Tensor): The latent space.
            summary (Tensor): The summary vector.
            sigmoid (bool, optional): If set to :obj:`False`, does not apply
                the logistic sigmoid function to the output.
                (default: :obj:`True`)
        """
        summary = summary.t() if summary.dim() > 1 else summary
        value = torch.matmul(z, torch.matmul(self.weight, summary))
        return torch.sigmoid(value) if sigmoid else value

    def loss(self, pos_z: Tensor, neg_z: Tensor, summary: Tensor) ->Tensor:
        """Computes the mutual information maximization objective."""
        pos_loss = -torch.log(self.discriminate(pos_z, summary, sigmoid=True) + EPS).mean()
        neg_loss = -torch.log(1 - self.discriminate(neg_z, summary, sigmoid=True) + EPS).mean()
        return pos_loss + neg_loss

    def test(self, train_z: Tensor, train_y: Tensor, test_z: Tensor, test_y: Tensor, solver: str='lbfgs', multi_class: str='auto', *args, **kwargs) ->float:
        """Evaluates latent space quality via a logistic regression downstream
        task."""
        from sklearn.linear_model import LogisticRegression
        clf = LogisticRegression(*args, solver=solver, multi_class=multi_class, **kwargs).fit(train_z.detach().cpu().numpy(), train_y.detach().cpu().numpy())
        return clf.score(test_z.detach().cpu().numpy(), test_y.detach().cpu().numpy())

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}({self.hidden_channels})'


class Envelope(torch.nn.Module):

    def __init__(self, exponent: int):
        super().__init__()
        self.p = exponent + 1
        self.a = -(self.p + 1) * (self.p + 2) / 2
        self.b = self.p * (self.p + 2)
        self.c = -self.p * (self.p + 1) / 2

    def forward(self, x: Tensor) ->Tensor:
        p, a, b, c = self.p, self.a, self.b, self.c
        x_pow_p0 = x.pow(p - 1)
        x_pow_p1 = x_pow_p0 * x
        x_pow_p2 = x_pow_p1 * x
        return (1.0 / x + a * x_pow_p0 + b * x_pow_p1 + c * x_pow_p2) * (x < 1.0)


class BesselBasisLayer(torch.nn.Module):

    def __init__(self, num_radial: int, cutoff: float=5.0, envelope_exponent: int=5):
        super().__init__()
        self.cutoff = cutoff
        self.envelope = Envelope(envelope_exponent)
        self.freq = torch.nn.Parameter(torch.Tensor(num_radial))
        self.reset_parameters()

    def reset_parameters(self):
        with torch.no_grad():
            torch.arange(1, self.freq.numel() + 1, out=self.freq).mul_(PI)
        self.freq.requires_grad_()

    def forward(self, dist: Tensor) ->Tensor:
        dist = dist.unsqueeze(-1) / self.cutoff
        return self.envelope(dist) * (self.freq * dist).sin()


class SphericalBasisLayer(torch.nn.Module):

    def __init__(self, num_spherical: int, num_radial: int, cutoff: float=5.0, envelope_exponent: int=5):
        super().__init__()
        assert num_radial <= 64
        self.num_spherical = num_spherical
        self.num_radial = num_radial
        self.cutoff = cutoff
        self.envelope = Envelope(envelope_exponent)
        bessel_forms = bessel_basis(num_spherical, num_radial)
        sph_harm_forms = real_sph_harm(num_spherical)
        self.sph_funcs = []
        self.bessel_funcs = []
        x, theta = sym.symbols('x theta')
        modules = {'sin': torch.sin, 'cos': torch.cos}
        for i in range(num_spherical):
            if i == 0:
                sph1 = sym.lambdify([theta], sph_harm_forms[i][0], modules)(0)
                self.sph_funcs.append(lambda x: torch.zeros_like(x) + sph1)
            else:
                sph = sym.lambdify([theta], sph_harm_forms[i][0], modules)
                self.sph_funcs.append(sph)
            for j in range(num_radial):
                bessel = sym.lambdify([x], bessel_forms[i][j], modules)
                self.bessel_funcs.append(bessel)

    def forward(self, dist: Tensor, angle: Tensor, idx_kj: Tensor) ->Tensor:
        dist = dist / self.cutoff
        rbf = torch.stack([f(dist) for f in self.bessel_funcs], dim=1)
        rbf = self.envelope(dist).unsqueeze(-1) * rbf
        cbf = torch.stack([f(angle) for f in self.sph_funcs], dim=1)
        n, k = self.num_spherical, self.num_radial
        out = (rbf[idx_kj].view(-1, n, k) * cbf.view(-1, n, 1)).view(-1, n * k)
        return out


class EmbeddingBlock(torch.nn.Module):

    def __init__(self, num_radial: int, hidden_channels: int, act: Callable):
        super().__init__()
        self.act = act
        self.emb = Embedding(95, hidden_channels)
        self.lin_rbf = Linear(num_radial, hidden_channels)
        self.lin = Linear(3 * hidden_channels, hidden_channels)
        self.reset_parameters()

    def reset_parameters(self):
        self.emb.weight.data.uniform_(-sqrt(3), sqrt(3))
        self.lin_rbf.reset_parameters()
        self.lin.reset_parameters()

    def forward(self, x: Tensor, rbf: Tensor, i: Tensor, j: Tensor) ->Tensor:
        x = self.emb(x)
        rbf = self.act(self.lin_rbf(rbf))
        return self.act(self.lin(torch.cat([x[i], x[j], rbf], dim=-1)))


def glorot_orthogonal(tensor, scale):
    if tensor is not None:
        torch.nn.init.orthogonal_(tensor.data)
        scale /= (tensor.size(-2) + tensor.size(-1)) * tensor.var()
        tensor.data *= scale.sqrt()


class ResidualLayer(torch.nn.Module):

    def __init__(self, hidden_channels: int, act: Callable):
        super().__init__()
        self.act = act
        self.lin1 = Linear(hidden_channels, hidden_channels)
        self.lin2 = Linear(hidden_channels, hidden_channels)
        self.reset_parameters()

    def reset_parameters(self):
        glorot_orthogonal(self.lin1.weight, scale=2.0)
        self.lin1.bias.data.fill_(0)
        glorot_orthogonal(self.lin2.weight, scale=2.0)
        self.lin2.bias.data.fill_(0)

    def forward(self, x: Tensor) ->Tensor:
        return x + self.act(self.lin2(self.act(self.lin1(x))))


class ShiftedSoftplus(torch.nn.Module):

    def __init__(self):
        super().__init__()
        self.shift = torch.log(torch.tensor(2.0)).item()

    def forward(self, x: Tensor) ->Tensor:
        return F.softplus(x) - self.shift


class InteractionBlock(torch.nn.Module):

    def __init__(self, hidden_channels: int, num_gaussians: int, num_filters: int, cutoff: float):
        super().__init__()
        self.mlp = Sequential(Linear(num_gaussians, num_filters), ShiftedSoftplus(), Linear(num_filters, num_filters))
        self.conv = CFConv(hidden_channels, hidden_channels, num_filters, self.mlp, cutoff)
        self.act = ShiftedSoftplus()
        self.lin = Linear(hidden_channels, hidden_channels)
        self.reset_parameters()

    def reset_parameters(self):
        torch.nn.init.xavier_uniform_(self.mlp[0].weight)
        self.mlp[0].bias.data.fill_(0)
        torch.nn.init.xavier_uniform_(self.mlp[2].weight)
        self.mlp[2].bias.data.fill_(0)
        self.conv.reset_parameters()
        torch.nn.init.xavier_uniform_(self.lin.weight)
        self.lin.bias.data.fill_(0)

    def forward(self, x: Tensor, edge_index: Tensor, edge_weight: Tensor, edge_attr: Tensor) ->Tensor:
        x = self.conv(x, edge_index, edge_weight, edge_attr)
        x = self.act(x)
        x = self.lin(x)
        return x


class InteractionPPBlock(torch.nn.Module):

    def __init__(self, hidden_channels: int, int_emb_size: int, basis_emb_size: int, num_spherical: int, num_radial: int, num_before_skip: int, num_after_skip: int, act: Callable):
        super().__init__()
        self.act = act
        self.lin_rbf1 = Linear(num_radial, basis_emb_size, bias=False)
        self.lin_rbf2 = Linear(basis_emb_size, hidden_channels, bias=False)
        self.lin_sbf1 = Linear(num_spherical * num_radial, basis_emb_size, bias=False)
        self.lin_sbf2 = Linear(basis_emb_size, int_emb_size, bias=False)
        self.lin_kj = Linear(hidden_channels, hidden_channels)
        self.lin_ji = Linear(hidden_channels, hidden_channels)
        self.lin_down = Linear(hidden_channels, int_emb_size, bias=False)
        self.lin_up = Linear(int_emb_size, hidden_channels, bias=False)
        self.layers_before_skip = torch.nn.ModuleList([ResidualLayer(hidden_channels, act) for _ in range(num_before_skip)])
        self.lin = Linear(hidden_channels, hidden_channels)
        self.layers_after_skip = torch.nn.ModuleList([ResidualLayer(hidden_channels, act) for _ in range(num_before_skip)])
        self.reset_parameters()

    def reset_parameters(self):
        glorot_orthogonal(self.lin_rbf1.weight, scale=2.0)
        glorot_orthogonal(self.lin_rbf2.weight, scale=2.0)
        glorot_orthogonal(self.lin_sbf1.weight, scale=2.0)
        glorot_orthogonal(self.lin_sbf2.weight, scale=2.0)
        glorot_orthogonal(self.lin_kj.weight, scale=2.0)
        self.lin_kj.bias.data.fill_(0)
        glorot_orthogonal(self.lin_ji.weight, scale=2.0)
        self.lin_ji.bias.data.fill_(0)
        glorot_orthogonal(self.lin_down.weight, scale=2.0)
        glorot_orthogonal(self.lin_up.weight, scale=2.0)
        for res_layer in self.layers_before_skip:
            res_layer.reset_parameters()
        glorot_orthogonal(self.lin.weight, scale=2.0)
        self.lin.bias.data.fill_(0)
        for res_layer in self.layers_before_skip:
            res_layer.reset_parameters()

    def forward(self, x: Tensor, rbf: Tensor, sbf: Tensor, idx_kj: Tensor, idx_ji: Tensor) ->Tensor:
        x_ji = self.act(self.lin_ji(x))
        x_kj = self.act(self.lin_kj(x))
        rbf = self.lin_rbf1(rbf)
        rbf = self.lin_rbf2(rbf)
        x_kj = x_kj * rbf
        x_kj = self.act(self.lin_down(x_kj))
        sbf = self.lin_sbf1(sbf)
        sbf = self.lin_sbf2(sbf)
        x_kj = x_kj[idx_kj] * sbf
        x_kj = scatter(x_kj, idx_ji, dim=0, dim_size=x.size(0))
        x_kj = self.act(self.lin_up(x_kj))
        h = x_ji + x_kj
        for layer in self.layers_before_skip:
            h = layer(h)
        h = self.act(self.lin(h)) + x
        for layer in self.layers_after_skip:
            h = layer(h)
        return h


class OutputBlock(torch.nn.Module):

    def __init__(self, num_radial: int, hidden_channels: int, out_channels: int, num_layers: int, act: Callable):
        super().__init__()
        self.act = act
        self.lin_rbf = Linear(num_radial, hidden_channels, bias=False)
        self.lins = torch.nn.ModuleList()
        for _ in range(num_layers):
            self.lins.append(Linear(hidden_channels, hidden_channels))
        self.lin = Linear(hidden_channels, out_channels, bias=False)
        self.reset_parameters()

    def reset_parameters(self):
        glorot_orthogonal(self.lin_rbf.weight, scale=2.0)
        for lin in self.lins:
            glorot_orthogonal(lin.weight, scale=2.0)
            lin.bias.data.fill_(0)
        self.lin.weight.data.fill_(0)

    def forward(self, x: Tensor, rbf: Tensor, i: Tensor, num_nodes: Optional[int]=None) ->Tensor:
        x = self.lin_rbf(rbf) * x
        x = scatter(x, i, dim=0, dim_size=num_nodes)
        for lin in self.lins:
            x = self.act(lin(x))
        return self.lin(x)


class OutputPPBlock(torch.nn.Module):

    def __init__(self, num_radial: int, hidden_channels: int, out_emb_channels: int, out_channels: int, num_layers: int, act: Callable):
        super().__init__()
        self.act = act
        self.lin_rbf = Linear(num_radial, hidden_channels, bias=False)
        self.lin_up = Linear(hidden_channels, out_emb_channels, bias=False)
        self.lins = torch.nn.ModuleList()
        for _ in range(num_layers):
            self.lins.append(Linear(out_emb_channels, out_emb_channels))
        self.lin = Linear(out_emb_channels, out_channels, bias=False)
        self.reset_parameters()

    def reset_parameters(self):
        glorot_orthogonal(self.lin_rbf.weight, scale=2.0)
        glorot_orthogonal(self.lin_up.weight, scale=2.0)
        for lin in self.lins:
            glorot_orthogonal(lin.weight, scale=2.0)
            lin.bias.data.fill_(0)
        self.lin.weight.data.fill_(0)

    def forward(self, x: Tensor, rbf: Tensor, i: Tensor, num_nodes: Optional[int]=None) ->Tensor:
        x = self.lin_rbf(rbf) * x
        x = scatter(x, i, dim=0, dim_size=num_nodes)
        x = self.lin_up(x)
        for lin in self.lins:
            x = self.act(lin(x))
        return self.lin(x)


qm9_target_dict = {(0): 'dipole_moment', (1): 'isotropic_polarizability', (2): 'homo', (3): 'lumo', (4): 'gap', (5): 'electronic_spatial_extent', (6): 'zpve', (7): 'energy_U0', (8): 'energy_U', (9): 'enthalpy_H', (10): 'free_energy', (11): 'heat_capacity'}


def radius_graph(x: Tensor, r: float, batch: OptTensor=None, loop: bool=False, max_num_neighbors: int=32, flow: str='source_to_target', num_workers: int=1) ->Tensor:
    """Computes graph edges to all points within a given distance.

    Args:
        x (Tensor): Node feature matrix
            :math:`\\mathbf{X} \\in \\mathbb{R}^{N \\times F}`.
        r (float): The radius.
        batch (LongTensor, optional): Batch vector
            :math:`\\mathbf{b} \\in {\\{ 0, \\ldots, B-1\\}}^N`, which assigns each
            node to a specific example. (default: :obj:`None`)
        loop (bool, optional): If :obj:`True`, the graph will contain
            self-loops. (default: :obj:`False`)
        max_num_neighbors (int, optional): The maximum number of neighbors to
            return for each element in :obj:`y`. (default: :obj:`32`)
        flow (string, optional): The flow direction when using in combination
            with message passing (:obj:`"source_to_target"` or
            :obj:`"target_to_source"`). (default: :obj:`"source_to_target"`)
        num_workers (int): Number of workers to use for computation. Has no
            effect in case :obj:`batch` is not :obj:`None`, or the input lies
            on the GPU. (default: :obj:`1`)

    :rtype: :class:`LongTensor`

    .. code-block:: python

        import torch
        from torch_geometric.nn import radius_graph

        x = torch.Tensor([[-1, -1], [-1, 1], [1, -1], [1, 1]])
        batch = torch.tensor([0, 0, 0, 0])
        edge_index = radius_graph(x, r=1.5, batch=batch, loop=False)
    """
    return torch_cluster.radius_graph(x, r, batch, loop, max_num_neighbors, flow, num_workers)


class GraphUNet(torch.nn.Module):
    """The Graph U-Net model from the `"Graph U-Nets"
    <https://arxiv.org/abs/1905.05178>`_ paper which implements a U-Net like
    architecture with graph pooling and unpooling operations.

    Args:
        in_channels (int): Size of each input sample.
        hidden_channels (int): Size of each hidden sample.
        out_channels (int): Size of each output sample.
        depth (int): The depth of the U-Net architecture.
        pool_ratios (float or [float], optional): Graph pooling ratio for each
            depth. (default: :obj:`0.5`)
        sum_res (bool, optional): If set to :obj:`False`, will use
            concatenation for integration of skip connections instead
            summation. (default: :obj:`True`)
        act (torch.nn.functional, optional): The nonlinearity to use.
            (default: :obj:`torch.nn.functional.relu`)
    """

    def __init__(self, in_channels: int, hidden_channels: int, out_channels: int, depth: int, pool_ratios: Union[float, List[float]]=0.5, sum_res: bool=True, act: Callable=F.relu) ->None:
        super().__init__()
        assert depth >= 1
        self.in_channels = in_channels
        self.hidden_channels = hidden_channels
        self.out_channels = out_channels
        self.depth = depth
        self.pool_ratios = repeat(pool_ratios, depth)
        self.act = act
        self.sum_res = sum_res
        channels = hidden_channels
        self.down_convs = torch.nn.ModuleList()
        self.pools = torch.nn.ModuleList()
        self.down_convs.append(GCNConv(in_channels, channels, improved=True))
        for i in range(depth):
            self.pools.append(TopKPooling(channels, self.pool_ratios[i]))
            self.down_convs.append(GCNConv(channels, channels, improved=True))
        in_channels = channels if sum_res else 2 * channels
        self.up_convs = torch.nn.ModuleList()
        for i in range(depth - 1):
            self.up_convs.append(GCNConv(in_channels, channels, improved=True))
        self.up_convs.append(GCNConv(in_channels, out_channels, improved=True))
        self.reset_parameters()

    def reset_parameters(self):
        for conv in self.down_convs:
            conv.reset_parameters()
        for pool in self.pools:
            pool.reset_parameters()
        for conv in self.up_convs:
            conv.reset_parameters()

    def forward(self, x: Tensor, edge_index: Tensor, batch: OptTensor=None) ->Tensor:
        """"""
        if batch is None:
            batch = edge_index.new_zeros(x.size(0))
        edge_weight = x.new_ones(edge_index.size(1))
        x = self.down_convs[0](x, edge_index, edge_weight)
        x = self.act(x)
        xs = [x]
        edge_indices = [edge_index]
        edge_weights = [edge_weight]
        perms = []
        for i in range(1, self.depth + 1):
            edge_index, edge_weight = self.augment_adj(edge_index, edge_weight, x.size(0))
            x, edge_index, edge_weight, batch, perm, _ = self.pools[i - 1](x, edge_index, edge_weight, batch)
            x = self.down_convs[i](x, edge_index, edge_weight)
            x = self.act(x)
            if i < self.depth:
                xs += [x]
                edge_indices += [edge_index]
                edge_weights += [edge_weight]
            perms += [perm]
        for i in range(self.depth):
            j = self.depth - 1 - i
            res = xs[j]
            edge_index = edge_indices[j]
            edge_weight = edge_weights[j]
            perm = perms[j]
            up = torch.zeros_like(res)
            up[perm] = x
            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)
            x = self.up_convs[i](x, edge_index, edge_weight)
            x = self.act(x) if i < self.depth - 1 else x
        return x

    def augment_adj(self, edge_index: Tensor, edge_weight: Tensor, num_nodes: int) ->PairTensor:
        edge_index, edge_weight = remove_self_loops(edge_index, edge_weight)
        edge_index, edge_weight = add_self_loops(edge_index, edge_weight, num_nodes=num_nodes)
        edge_index, edge_weight = sort_edge_index(edge_index, edge_weight, num_nodes)
        edge_index, edge_weight = spspmm(edge_index, edge_weight, edge_index, edge_weight, num_nodes, num_nodes, num_nodes)
        edge_index, edge_weight = remove_self_loops(edge_index, edge_weight)
        return edge_index, edge_weight

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}({self.in_channels}, {self.hidden_channels}, {self.out_channels}, depth={self.depth}, pool_ratios={self.pool_ratios})'


class BPRLoss(_Loss):
    """The Bayesian Personalized Ranking (BPR) loss.

    The BPR loss is a pairwise loss that encourages the prediction of an
    observed entry to be higher than its unobserved counterparts
    (see `here <https://arxiv.org/abs/2002.02126>`__).

    .. math::
        L_{\\text{BPR}} = - \\sum_{u=1}^{M} \\sum_{i \\in \\mathcal{N}_u}
        \\sum_{j \\not\\in \\mathcal{N}_u} \\ln \\sigma(\\hat{y}_{ui} - \\hat{y}_{uj})
        + \\lambda \\vert\\vert \\textbf{x}^{(0)} \\vert\\vert^2

    where :math:`lambda` controls the :math:`L_2` regularization strength.
    We compute the mean BPR loss for simplicity.

    Args:
        lambda_reg (float, optional): The :math:`L_2` regularization strength
            (default: 0).
        **kwargs (optional): Additional arguments of the underlying
            :class:`torch.nn.modules.loss._Loss` class.
    """
    __constants__ = ['lambda_reg']
    lambda_reg: float

    def __init__(self, lambda_reg: float=0, **kwargs) ->None:
        super().__init__(None, None, 'sum', **kwargs)
        self.lambda_reg = lambda_reg

    def forward(self, positives: Tensor, negatives: Tensor, parameters: Tensor=None) ->Tensor:
        """Compute the mean Bayesian Personalized Ranking (BPR) loss.

        .. note::

            The i-th entry in the :obj:`positives` vector and i-th entry
            in the :obj:`negatives` entry should correspond to the same
            entity (*.e.g*, user), as the BPR is a personalized ranking loss.

        Args:
            positives (Tensor): The vector of positive-pair rankings.
            negatives (Tensor): The vector of negative-pair rankings.
            parameters (Tensor, optional): The tensor of parameters which
                should be used for :math:`L_2` regularization
                (default: :obj:`None`).
        """
        n_pairs = positives.size(0)
        log_prob = F.logsigmoid(positives - negatives).mean()
        regularization = 0
        if self.lambda_reg != 0:
            regularization = self.lambda_reg * parameters.norm(p=2).pow(2)
        return (-log_prob + regularization) / n_pairs


class MetaPath2Vec(torch.nn.Module):
    """The MetaPath2Vec model from the `"metapath2vec: Scalable Representation
    Learning for Heterogeneous Networks"
    <https://ericdongyx.github.io/papers/
    KDD17-dong-chawla-swami-metapath2vec.pdf>`_ paper where random walks based
    on a given :obj:`metapath` are sampled in a heterogeneous graph, and node
    embeddings are learned via negative sampling optimization.

    .. note::

        For an example of using MetaPath2Vec, see
        `examples/hetero/metapath2vec.py
        <https://github.com/pyg-team/pytorch_geometric/blob/master/examples/
        hetero/metapath2vec.py>`_.

    Args:
        edge_index_dict (Dict[Tuple[str, str, str], Tensor]): Dictionary
            holding edge indices for each
            :obj:`(src_node_type, rel_type, dst_node_type)` present in the
            heterogeneous graph.
        embedding_dim (int): The size of each embedding vector.
        metapath (List[Tuple[str, str, str]]): The metapath described as a list
            of :obj:`(src_node_type, rel_type, dst_node_type)` tuples.
        walk_length (int): The walk length.
        context_size (int): The actual context size which is considered for
            positive samples. This parameter increases the effective sampling
            rate by reusing samples across different source nodes.
        walks_per_node (int, optional): The number of walks to sample for each
            node. (default: :obj:`1`)
        num_negative_samples (int, optional): The number of negative samples to
            use for each positive sample. (default: :obj:`1`)
        num_nodes_dict (Dict[str, int], optional): Dictionary holding the
            number of nodes for each node type. (default: :obj:`None`)
        sparse (bool, optional): If set to :obj:`True`, gradients w.r.t. to the
            weight matrix will be sparse. (default: :obj:`False`)
    """

    def __init__(self, edge_index_dict: Dict[EdgeType, Tensor], embedding_dim: int, metapath: List[EdgeType], walk_length: int, context_size: int, walks_per_node: int=1, num_negative_samples: int=1, num_nodes_dict: Optional[Dict[NodeType, int]]=None, sparse: bool=False):
        super().__init__()
        if num_nodes_dict is None:
            num_nodes_dict = {}
            for keys, edge_index in edge_index_dict.items():
                key = keys[0]
                N = int(edge_index[0].max() + 1)
                num_nodes_dict[key] = max(N, num_nodes_dict.get(key, N))
                key = keys[-1]
                N = int(edge_index[1].max() + 1)
                num_nodes_dict[key] = max(N, num_nodes_dict.get(key, N))
        adj_dict = {}
        for keys, edge_index in edge_index_dict.items():
            sizes = num_nodes_dict[keys[0]], num_nodes_dict[keys[-1]]
            row, col = edge_index
            adj = SparseTensor(row=row, col=col, sparse_sizes=sizes)
            adj = adj
            adj_dict[keys] = adj
        assert walk_length + 1 >= context_size
        if walk_length > len(metapath) and metapath[0][0] != metapath[-1][-1]:
            raise AttributeError("The 'walk_length' is longer than the given 'metapath', but the 'metapath' does not denote a cycle")
        self.adj_dict = adj_dict
        self.embedding_dim = embedding_dim
        self.metapath = metapath
        self.walk_length = walk_length
        self.context_size = context_size
        self.walks_per_node = walks_per_node
        self.num_negative_samples = num_negative_samples
        self.num_nodes_dict = num_nodes_dict
        types = set([x[0] for x in metapath]) | set([x[-1] for x in metapath])
        types = sorted(list(types))
        count = 0
        self.start, self.end = {}, {}
        for key in types:
            self.start[key] = count
            count += num_nodes_dict[key]
            self.end[key] = count
        offset = [self.start[metapath[0][0]]]
        offset += [self.start[keys[-1]] for keys in metapath] * int(walk_length / len(metapath) + 1)
        offset = offset[:walk_length + 1]
        assert len(offset) == walk_length + 1
        self.offset = torch.tensor(offset)
        self.embedding = Embedding(count + 1, embedding_dim, sparse=sparse)
        self.dummy_idx = count
        self.reset_parameters()

    def reset_parameters(self):
        self.embedding.reset_parameters()

    def forward(self, node_type: str, batch: OptTensor=None) ->Tensor:
        """Returns the embeddings for the nodes in :obj:`batch` of type
        :obj:`node_type`."""
        emb = self.embedding.weight[self.start[node_type]:self.end[node_type]]
        return emb if batch is None else emb.index_select(0, batch)

    def loader(self, **kwargs):
        """Returns the data loader that creates both positive and negative
        random walks on the heterogeneous graph.

        Args:
            **kwargs (optional): Arguments of
                :class:`torch.utils.data.DataLoader`, such as
                :obj:`batch_size`, :obj:`shuffle`, :obj:`drop_last` or
                :obj:`num_workers`.
        """
        return DataLoader(range(self.num_nodes_dict[self.metapath[0][0]]), collate_fn=self._sample, **kwargs)

    def _pos_sample(self, batch: Tensor) ->Tensor:
        batch = batch.repeat(self.walks_per_node)
        rws = [batch]
        for i in range(self.walk_length):
            keys = self.metapath[i % len(self.metapath)]
            adj = self.adj_dict[keys]
            batch = sample(adj, batch, num_neighbors=1, dummy_idx=self.dummy_idx).view(-1)
            rws.append(batch)
        rw = torch.stack(rws, dim=-1)
        rw.add_(self.offset.view(1, -1))
        rw[rw > self.dummy_idx] = self.dummy_idx
        walks = []
        num_walks_per_rw = 1 + self.walk_length + 1 - self.context_size
        for j in range(num_walks_per_rw):
            walks.append(rw[:, j:j + self.context_size])
        return torch.cat(walks, dim=0)

    def _neg_sample(self, batch: Tensor) ->Tensor:
        batch = batch.repeat(self.walks_per_node * self.num_negative_samples)
        rws = [batch]
        for i in range(self.walk_length):
            keys = self.metapath[i % len(self.metapath)]
            batch = torch.randint(0, self.num_nodes_dict[keys[-1]], (batch.size(0),), dtype=torch.long)
            rws.append(batch)
        rw = torch.stack(rws, dim=-1)
        rw.add_(self.offset.view(1, -1))
        walks = []
        num_walks_per_rw = 1 + self.walk_length + 1 - self.context_size
        for j in range(num_walks_per_rw):
            walks.append(rw[:, j:j + self.context_size])
        return torch.cat(walks, dim=0)

    def _sample(self, batch: List[int]) ->Tuple[Tensor, Tensor]:
        if not isinstance(batch, Tensor):
            batch = torch.tensor(batch, dtype=torch.long)
        return self._pos_sample(batch), self._neg_sample(batch)

    def loss(self, pos_rw: Tensor, neg_rw: Tensor) ->Tensor:
        """Computes the loss given positive and negative random walks."""
        start, rest = pos_rw[:, 0], pos_rw[:, 1:].contiguous()
        h_start = self.embedding(start).view(pos_rw.size(0), 1, self.embedding_dim)
        h_rest = self.embedding(rest.view(-1)).view(pos_rw.size(0), -1, self.embedding_dim)
        out = (h_start * h_rest).sum(dim=-1).view(-1)
        pos_loss = -torch.log(torch.sigmoid(out) + EPS).mean()
        start, rest = neg_rw[:, 0], neg_rw[:, 1:].contiguous()
        h_start = self.embedding(start).view(neg_rw.size(0), 1, self.embedding_dim)
        h_rest = self.embedding(rest.view(-1)).view(neg_rw.size(0), -1, self.embedding_dim)
        out = (h_start * h_rest).sum(dim=-1).view(-1)
        neg_loss = -torch.log(1 - torch.sigmoid(out) + EPS).mean()
        return pos_loss + neg_loss

    def test(self, train_z: Tensor, train_y: Tensor, test_z: Tensor, test_y: Tensor, solver: str='lbfgs', multi_class: str='auto', *args, **kwargs) ->float:
        """Evaluates latent space quality via a logistic regression downstream
        task."""
        from sklearn.linear_model import LogisticRegression
        clf = LogisticRegression(*args, solver=solver, multi_class=multi_class, **kwargs).fit(train_z.detach().cpu().numpy(), train_y.detach().cpu().numpy())
        return clf.score(test_z.detach().cpu().numpy(), test_y.detach().cpu().numpy())

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}({self.embedding.weight.size(0) - 1}, {self.embedding.weight.size(1)})'


class Node2Vec(torch.nn.Module):
    """The Node2Vec model from the
    `"node2vec: Scalable Feature Learning for Networks"
    <https://arxiv.org/abs/1607.00653>`_ paper where random walks of
    length :obj:`walk_length` are sampled in a given graph, and node embeddings
    are learned via negative sampling optimization.

    .. note::

        For an example of using Node2Vec, see `examples/node2vec.py
        <https://github.com/pyg-team/pytorch_geometric/blob/master/examples/
        node2vec.py>`_.

    Args:
        edge_index (LongTensor): The edge indices.
        embedding_dim (int): The size of each embedding vector.
        walk_length (int): The walk length.
        context_size (int): The actual context size which is considered for
            positive samples. This parameter increases the effective sampling
            rate by reusing samples across different source nodes.
        walks_per_node (int, optional): The number of walks to sample for each
            node. (default: :obj:`1`)
        p (float, optional): Likelihood of immediately revisiting a node in the
            walk. (default: :obj:`1`)
        q (float, optional): Control parameter to interpolate between
            breadth-first strategy and depth-first strategy (default: :obj:`1`)
        num_negative_samples (int, optional): The number of negative samples to
            use for each positive sample. (default: :obj:`1`)
        num_nodes (int, optional): The number of nodes. (default: :obj:`None`)
        sparse (bool, optional): If set to :obj:`True`, gradients w.r.t. to the
            weight matrix will be sparse. (default: :obj:`False`)
    """

    def __init__(self, edge_index: Tensor, embedding_dim: int, walk_length: int, context_size: int, walks_per_node: int=1, p: float=1.0, q: float=1.0, num_negative_samples: int=1, num_nodes: Optional[int]=None, sparse: bool=False):
        super().__init__()
        if random_walk is None:
            raise ImportError('`Node2Vec` requires `torch-cluster`.')
        N = maybe_num_nodes(edge_index, num_nodes)
        row, col = edge_index
        self.adj = SparseTensor(row=row, col=col, sparse_sizes=(N, N))
        self.adj = self.adj
        assert walk_length >= context_size
        self.embedding_dim = embedding_dim
        self.walk_length = walk_length - 1
        self.context_size = context_size
        self.walks_per_node = walks_per_node
        self.p = p
        self.q = q
        self.num_negative_samples = num_negative_samples
        self.embedding = Embedding(N, embedding_dim, sparse=sparse)
        self.reset_parameters()

    def reset_parameters(self):
        self.embedding.reset_parameters()

    def forward(self, batch: OptTensor=None) ->Tensor:
        """Returns the embeddings for the nodes in :obj:`batch`."""
        emb = self.embedding.weight
        return emb if batch is None else emb.index_select(0, batch)

    def loader(self, **kwargs) ->DataLoader:
        return DataLoader(range(self.adj.sparse_size(0)), collate_fn=self.sample, **kwargs)

    def pos_sample(self, batch: Tensor) ->Tensor:
        batch = batch.repeat(self.walks_per_node)
        rowptr, col, _ = self.adj.csr()
        rw = random_walk(rowptr, col, batch, self.walk_length, self.p, self.q)
        if not isinstance(rw, Tensor):
            rw = rw[0]
        walks = []
        num_walks_per_rw = 1 + self.walk_length + 1 - self.context_size
        for j in range(num_walks_per_rw):
            walks.append(rw[:, j:j + self.context_size])
        return torch.cat(walks, dim=0)

    def neg_sample(self, batch: Tensor) ->Tensor:
        batch = batch.repeat(self.walks_per_node * self.num_negative_samples)
        rw = torch.randint(self.adj.sparse_size(0), (batch.size(0), self.walk_length))
        rw = torch.cat([batch.view(-1, 1), rw], dim=-1)
        walks = []
        num_walks_per_rw = 1 + self.walk_length + 1 - self.context_size
        for j in range(num_walks_per_rw):
            walks.append(rw[:, j:j + self.context_size])
        return torch.cat(walks, dim=0)

    def sample(self, batch: Tensor) ->Tuple[Tensor, Tensor]:
        if not isinstance(batch, Tensor):
            batch = torch.tensor(batch)
        return self.pos_sample(batch), self.neg_sample(batch)

    def loss(self, pos_rw: Tensor, neg_rw: Tensor) ->Tensor:
        """Computes the loss given positive and negative random walks."""
        start, rest = pos_rw[:, 0], pos_rw[:, 1:].contiguous()
        h_start = self.embedding(start).view(pos_rw.size(0), 1, self.embedding_dim)
        h_rest = self.embedding(rest.view(-1)).view(pos_rw.size(0), -1, self.embedding_dim)
        out = (h_start * h_rest).sum(dim=-1).view(-1)
        pos_loss = -torch.log(torch.sigmoid(out) + EPS).mean()
        start, rest = neg_rw[:, 0], neg_rw[:, 1:].contiguous()
        h_start = self.embedding(start).view(neg_rw.size(0), 1, self.embedding_dim)
        h_rest = self.embedding(rest.view(-1)).view(neg_rw.size(0), -1, self.embedding_dim)
        out = (h_start * h_rest).sum(dim=-1).view(-1)
        neg_loss = -torch.log(1 - torch.sigmoid(out) + EPS).mean()
        return pos_loss + neg_loss

    def test(self, train_z: Tensor, train_y: Tensor, test_z: Tensor, test_y: Tensor, solver: str='lbfgs', multi_class: str='auto', *args, **kwargs) ->float:
        """Evaluates latent space quality via a logistic regression downstream
        task."""
        from sklearn.linear_model import LogisticRegression
        clf = LogisticRegression(*args, solver=solver, multi_class=multi_class, **kwargs).fit(train_z.detach().cpu().numpy(), train_y.detach().cpu().numpy())
        return clf.score(test_z.detach().cpu().numpy(), test_y.detach().cpu().numpy())

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}({self.embedding.weight.size(0)}, {self.embedding.weight.size(1)})'


class GaussianSmearing(torch.nn.Module):

    def __init__(self, start: float=0.0, stop: float=5.0, num_gaussians: int=50):
        super().__init__()
        offset = torch.linspace(start, stop, num_gaussians)
        self.coeff = -0.5 / (offset[1] - offset[0]).item() ** 2
        self.register_buffer('offset', offset)

    def forward(self, dist: Tensor) ->Tensor:
        dist = dist.view(-1, 1) - self.offset.view(1, -1)
        return torch.exp(self.coeff * torch.pow(dist, 2))


class RadiusInteractionGraph(torch.nn.Module):
    """Creates edges based on atom positions :obj:`pos` to all points within
    the cutoff distance.

    Args:
        cutoff (float, optional): Cutoff distance for interatomic interactions.
            (default: :obj:`10.0`)
        max_num_neighbors (int, optional): The maximum number of neighbors to
            collect for each node within the :attr:`cutoff` distance with the
            default interaction graph method.
            (default: :obj:`32`)
    """

    def __init__(self, cutoff: float=10.0, max_num_neighbors: int=32):
        super().__init__()
        self.cutoff = cutoff
        self.max_num_neighbors = max_num_neighbors

    def forward(self, pos: Tensor, batch: Tensor) ->Tuple[Tensor, Tensor]:
        """
        Args:
            pos (Tensor): Coordinates of each atom.
            batch (LongTensor, optional): Batch indices assigning each atom to
                a separate molecule.

        :rtype: (:class:`LongTensor`, :class:`Tensor`)
        """
        edge_index = radius_graph(pos, r=self.cutoff, batch=batch, max_num_neighbors=self.max_num_neighbors)
        row, col = edge_index
        edge_weight = (pos[row] - pos[col]).norm(dim=-1)
        return edge_index, edge_weight


def structured_negative_sampling(edge_index, num_nodes: Optional[int]=None, contains_neg_self_loops: bool=True):
    """Samples a negative edge :obj:`(i,k)` for every positive edge
    :obj:`(i,j)` in the graph given by :attr:`edge_index`, and returns it as a
    tuple of the form :obj:`(i,j,k)`.

    Args:
        edge_index (LongTensor): The edge indices.
        num_nodes (int, optional): The number of nodes, *i.e.*
            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)
        contains_neg_self_loops (bool, optional): If set to
            :obj:`False`, sampled negative edges will not contain self loops.
            (default: :obj:`True`)

    :rtype: (LongTensor, LongTensor, LongTensor)

    Example:

        >>> edge_index = torch.as_tensor([[0, 0, 1, 2],
        ...                               [0, 1, 2, 3]])
        >>> structured_negative_sampling(edge_index)
        (tensor([0, 0, 1, 2]), tensor([0, 1, 2, 3]), tensor([2, 3, 0, 2]))

    """
    num_nodes = maybe_num_nodes(edge_index, num_nodes)
    row, col = edge_index.cpu()
    pos_idx = row * num_nodes + col
    if not contains_neg_self_loops:
        loop_idx = torch.arange(num_nodes) * (num_nodes + 1)
        pos_idx = torch.cat([pos_idx, loop_idx], dim=0)
    rand = torch.randint(num_nodes, (row.size(0),), dtype=torch.long)
    neg_idx = row * num_nodes + rand
    mask = torch.from_numpy(np.isin(neg_idx, pos_idx))
    rest = mask.nonzero(as_tuple=False).view(-1)
    while rest.numel() > 0:
        tmp = torch.randint(num_nodes, (rest.size(0),), dtype=torch.long)
        rand[rest] = tmp
        neg_idx = row[rest] * num_nodes + tmp
        mask = torch.from_numpy(np.isin(neg_idx, pos_idx))
        rest = rest[mask]
    return edge_index[0], edge_index[1], rand


class SignedGCN(torch.nn.Module):
    """The signed graph convolutional network model from the `"Signed Graph
    Convolutional Network" <https://arxiv.org/abs/1808.06354>`_ paper.
    Internally, this module uses the
    :class:`torch_geometric.nn.conv.SignedConv` operator.

    Args:
        in_channels (int): Size of each input sample.
        hidden_channels (int): Size of each hidden sample.
        num_layers (int): Number of layers.
        lamb (float, optional): Balances the contributions of the overall
            objective. (default: :obj:`5`)
        bias (bool, optional): If set to :obj:`False`, all layers will not
            learn an additive bias. (default: :obj:`True`)
    """

    def __init__(self, in_channels: int, hidden_channels: int, num_layers: int, lamb: float=5, bias: bool=True):
        super().__init__()
        self.in_channels = in_channels
        self.hidden_channels = hidden_channels
        self.num_layers = num_layers
        self.lamb = lamb
        self.conv1 = SignedConv(in_channels, hidden_channels // 2, first_aggr=True)
        self.convs = torch.nn.ModuleList()
        for i in range(num_layers - 1):
            self.convs.append(SignedConv(hidden_channels // 2, hidden_channels // 2, first_aggr=False))
        self.lin = torch.nn.Linear(2 * hidden_channels, 3)
        self.reset_parameters()

    def reset_parameters(self):
        self.conv1.reset_parameters()
        for conv in self.convs:
            conv.reset_parameters()
        self.lin.reset_parameters()

    def split_edges(self, edge_index: Tensor, test_ratio: float=0.2) ->Tuple[Tensor, Tensor]:
        """Splits the edges :obj:`edge_index` into train and test edges.

        Args:
            edge_index (LongTensor): The edge indices.
            test_ratio (float, optional): The ratio of test edges.
                (default: :obj:`0.2`)
        """
        mask = torch.ones(edge_index.size(1), dtype=torch.bool)
        mask[torch.randperm(mask.size(0))[:int(test_ratio * mask.size(0))]] = 0
        train_edge_index = edge_index[:, mask]
        test_edge_index = edge_index[:, ~mask]
        return train_edge_index, test_edge_index

    def create_spectral_features(self, pos_edge_index: Tensor, neg_edge_index: Tensor, num_nodes: Optional[int]=None) ->Tensor:
        """Creates :obj:`in_channels` spectral node features based on
        positive and negative edges.

        Args:
            pos_edge_index (LongTensor): The positive edge indices.
            neg_edge_index (LongTensor): The negative edge indices.
            num_nodes (int, optional): The number of nodes, *i.e.*
                :obj:`max_val + 1` of :attr:`pos_edge_index` and
                :attr:`neg_edge_index`. (default: :obj:`None`)
        """
        from sklearn.decomposition import TruncatedSVD
        edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=1)
        N = edge_index.max().item() + 1 if num_nodes is None else num_nodes
        edge_index = edge_index
        pos_val = torch.full((pos_edge_index.size(1),), 2, dtype=torch.float)
        neg_val = torch.full((neg_edge_index.size(1),), 0, dtype=torch.float)
        val = torch.cat([pos_val, neg_val], dim=0)
        row, col = edge_index
        edge_index = torch.cat([edge_index, torch.stack([col, row])], dim=1)
        val = torch.cat([val, val], dim=0)
        edge_index, val = coalesce(edge_index, val, N, N)
        val = val - 1
        edge_index = edge_index.detach().numpy()
        val = val.detach().numpy()
        A = scipy.sparse.coo_matrix((val, edge_index), shape=(N, N))
        svd = TruncatedSVD(n_components=self.in_channels, n_iter=128)
        svd.fit(A)
        x = svd.components_.T
        return torch.from_numpy(x).to(torch.float)

    def forward(self, x: Tensor, pos_edge_index: Tensor, neg_edge_index: Tensor) ->Tensor:
        """Computes node embeddings :obj:`z` based on positive edges
        :obj:`pos_edge_index` and negative edges :obj:`neg_edge_index`.

        Args:
            x (Tensor): The input node features.
            pos_edge_index (LongTensor): The positive edge indices.
            neg_edge_index (LongTensor): The negative edge indices.
        """
        z = F.relu(self.conv1(x, pos_edge_index, neg_edge_index))
        for conv in self.convs:
            z = F.relu(conv(z, pos_edge_index, neg_edge_index))
        return z

    def discriminate(self, z: Tensor, edge_index: Tensor) ->Tensor:
        """Given node embeddings :obj:`z`, classifies the link relation
        between node pairs :obj:`edge_index` to be either positive,
        negative or non-existent.

        Args:
            x (Tensor): The input node features.
            edge_index (LongTensor): The edge indices.
        """
        value = torch.cat([z[edge_index[0]], z[edge_index[1]]], dim=1)
        value = self.lin(value)
        return torch.log_softmax(value, dim=1)

    def nll_loss(self, z: Tensor, pos_edge_index: Tensor, neg_edge_index: Tensor) ->Tensor:
        """Computes the discriminator loss based on node embeddings :obj:`z`,
        and positive edges :obj:`pos_edge_index` and negative nedges
        :obj:`neg_edge_index`.

        Args:
            z (Tensor): The node embeddings.
            pos_edge_index (LongTensor): The positive edge indices.
            neg_edge_index (LongTensor): The negative edge indices.
        """
        edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=1)
        none_edge_index = negative_sampling(edge_index, z.size(0))
        nll_loss = 0
        nll_loss += F.nll_loss(self.discriminate(z, pos_edge_index), pos_edge_index.new_full((pos_edge_index.size(1),), 0))
        nll_loss += F.nll_loss(self.discriminate(z, neg_edge_index), neg_edge_index.new_full((neg_edge_index.size(1),), 1))
        nll_loss += F.nll_loss(self.discriminate(z, none_edge_index), none_edge_index.new_full((none_edge_index.size(1),), 2))
        return nll_loss / 3.0

    def pos_embedding_loss(self, z: Tensor, pos_edge_index: Tensor) ->Tensor:
        """Computes the triplet loss between positive node pairs and sampled
        non-node pairs.

        Args:
            z (Tensor): The node embeddings.
            pos_edge_index (LongTensor): The positive edge indices.
        """
        i, j, k = structured_negative_sampling(pos_edge_index, z.size(0))
        out = (z[i] - z[j]).pow(2).sum(dim=1) - (z[i] - z[k]).pow(2).sum(dim=1)
        return torch.clamp(out, min=0).mean()

    def neg_embedding_loss(self, z: Tensor, neg_edge_index: Tensor) ->Tensor:
        """Computes the triplet loss between negative node pairs and sampled
        non-node pairs.

        Args:
            z (Tensor): The node embeddings.
            neg_edge_index (LongTensor): The negative edge indices.
        """
        i, j, k = structured_negative_sampling(neg_edge_index, z.size(0))
        out = (z[i] - z[k]).pow(2).sum(dim=1) - (z[i] - z[j]).pow(2).sum(dim=1)
        return torch.clamp(out, min=0).mean()

    def loss(self, z: Tensor, pos_edge_index: Tensor, neg_edge_index: Tensor) ->Tensor:
        """Computes the overall objective.

        Args:
            z (Tensor): The node embeddings.
            pos_edge_index (LongTensor): The positive edge indices.
            neg_edge_index (LongTensor): The negative edge indices.
        """
        nll_loss = self.nll_loss(z, pos_edge_index, neg_edge_index)
        loss_1 = self.pos_embedding_loss(z, pos_edge_index)
        loss_2 = self.neg_embedding_loss(z, neg_edge_index)
        return nll_loss + self.lamb * (loss_1 + loss_2)

    def test(self, z: Tensor, pos_edge_index: Tensor, neg_edge_index: Tensor) ->Tuple[float, float]:
        """Evaluates node embeddings :obj:`z` on positive and negative test
        edges by computing AUC and F1 scores.

        Args:
            z (Tensor): The node embeddings.
            pos_edge_index (LongTensor): The positive edge indices.
            neg_edge_index (LongTensor): The negative edge indices.
        """
        from sklearn.metrics import f1_score
        from sklearn.metrics import roc_auc_score
        with torch.no_grad():
            pos_p = self.discriminate(z, pos_edge_index)[:, :2].max(dim=1)[1]
            neg_p = self.discriminate(z, neg_edge_index)[:, :2].max(dim=1)[1]
        pred = (1 - torch.cat([pos_p, neg_p])).cpu()
        y = torch.cat([pred.new_ones(pos_p.size(0)), pred.new_zeros(neg_p.size(0))])
        pred, y = pred.numpy(), y.numpy()
        auc = roc_auc_score(y, pred)
        f1 = f1_score(y, pred, average='binary') if pred.sum() > 0 else 0
        return auc, f1

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}({self.in_channels}, {self.hidden_channels}, num_layers={self.num_layers})'


class TimeEncoder(torch.nn.Module):

    def __init__(self, out_channels):
        super().__init__()
        self.out_channels = out_channels
        self.lin = Linear(1, out_channels)

    def reset_parameters(self):
        self.lin.reset_parameters()

    def forward(self, t):
        return self.lin(t.view(-1, 1)).cos()


class TGNMemory(torch.nn.Module):
    """The Temporal Graph Network (TGN) memory model from the
    `"Temporal Graph Networks for Deep Learning on Dynamic Graphs"
    <https://arxiv.org/abs/2006.10637>`_ paper.

    .. note::

        For an example of using TGN, see `examples/tgn.py
        <https://github.com/pyg-team/pytorch_geometric/blob/master/examples/
        tgn.py>`_.

    Args:
        num_nodes (int): The number of nodes to save memories for.
        raw_msg_dim (int): The raw message dimensionality.
        memory_dim (int): The hidden memory dimensionality.
        time_dim (int): The time encoding dimensionality.
        message_module (torch.nn.Module): The message function which
            combines source and destination node memory embeddings, the raw
            message and the time encoding.
        aggregator_module (torch.nn.Module): The message aggregator function
            which aggregates messages to the same destination into a single
            representation.
    """

    def __init__(self, num_nodes: int, raw_msg_dim: int, memory_dim: int, time_dim: int, message_module: Callable, aggregator_module: Callable):
        super().__init__()
        self.num_nodes = num_nodes
        self.raw_msg_dim = raw_msg_dim
        self.memory_dim = memory_dim
        self.time_dim = time_dim
        self.msg_s_module = message_module
        self.msg_d_module = copy.deepcopy(message_module)
        self.aggr_module = aggregator_module
        self.time_enc = TimeEncoder(time_dim)
        self.gru = GRUCell(message_module.out_channels, memory_dim)
        self.register_buffer('memory', torch.empty(num_nodes, memory_dim))
        last_update = torch.empty(self.num_nodes, dtype=torch.long)
        self.register_buffer('last_update', last_update)
        self.register_buffer('__assoc__', torch.empty(num_nodes, dtype=torch.long))
        self.msg_s_store = {}
        self.msg_d_store = {}
        self.reset_parameters()

    def reset_parameters(self):
        if hasattr(self.msg_s_module, 'reset_parameters'):
            self.msg_s_module.reset_parameters()
        if hasattr(self.msg_d_module, 'reset_parameters'):
            self.msg_d_module.reset_parameters()
        if hasattr(self.aggr_module, 'reset_parameters'):
            self.aggr_module.reset_parameters()
        self.time_enc.reset_parameters()
        self.gru.reset_parameters()
        self.reset_state()

    def reset_state(self):
        """Resets the memory to its initial state."""
        zeros(self.memory)
        zeros(self.last_update)
        self.__reset_message_store__()

    def detach(self):
        """Detachs the memory from gradient computation."""
        self.memory.detach_()

    def forward(self, n_id: Tensor) ->Tuple[Tensor, Tensor]:
        """Returns, for all nodes :obj:`n_id`, their current memory and their
        last updated timestamp."""
        if self.training:
            memory, last_update = self.__get_updated_memory__(n_id)
        else:
            memory, last_update = self.memory[n_id], self.last_update[n_id]
        return memory, last_update

    def update_state(self, src, dst, t, raw_msg):
        """Updates the memory with newly encountered interactions
        :obj:`(src, dst, t, raw_msg)`."""
        n_id = torch.cat([src, dst]).unique()
        if self.training:
            self.__update_memory__(n_id)
            self.__update_msg_store__(src, dst, t, raw_msg, self.msg_s_store)
            self.__update_msg_store__(dst, src, t, raw_msg, self.msg_d_store)
        else:
            self.__update_msg_store__(src, dst, t, raw_msg, self.msg_s_store)
            self.__update_msg_store__(dst, src, t, raw_msg, self.msg_d_store)
            self.__update_memory__(n_id)

    def __reset_message_store__(self):
        i = self.memory.new_empty((0,), dtype=torch.long)
        msg = self.memory.new_empty((0, self.raw_msg_dim))
        self.msg_s_store = {j: (i, i, i, msg) for j in range(self.num_nodes)}
        self.msg_d_store = {j: (i, i, i, msg) for j in range(self.num_nodes)}

    def __update_memory__(self, n_id):
        memory, last_update = self.__get_updated_memory__(n_id)
        self.memory[n_id] = memory
        self.last_update[n_id] = last_update

    def __get_updated_memory__(self, n_id):
        self.__assoc__[n_id] = torch.arange(n_id.size(0), device=n_id.device)
        msg_s, t_s, src_s, dst_s = self.__compute_msg__(n_id, self.msg_s_store, self.msg_s_module)
        msg_d, t_d, src_d, dst_d = self.__compute_msg__(n_id, self.msg_d_store, self.msg_d_module)
        idx = torch.cat([src_s, src_d], dim=0)
        msg = torch.cat([msg_s, msg_d], dim=0)
        t = torch.cat([t_s, t_d], dim=0)
        aggr = self.aggr_module(msg, self.__assoc__[idx], t, n_id.size(0))
        memory = self.gru(aggr, self.memory[n_id])
        dim_size = self.last_update.size(0)
        last_update = scatter_max(t, idx, dim=0, dim_size=dim_size)[0][n_id]
        return memory, last_update

    def __update_msg_store__(self, src, dst, t, raw_msg, msg_store):
        n_id, perm = src.sort()
        n_id, count = n_id.unique_consecutive(return_counts=True)
        for i, idx in zip(n_id.tolist(), perm.split(count.tolist())):
            msg_store[i] = src[idx], dst[idx], t[idx], raw_msg[idx]

    def __compute_msg__(self, n_id, msg_store, msg_module):
        data = [msg_store[i] for i in n_id.tolist()]
        src, dst, t, raw_msg = list(zip(*data))
        src = torch.cat(src, dim=0)
        dst = torch.cat(dst, dim=0)
        t = torch.cat(t, dim=0)
        raw_msg = torch.cat(raw_msg, dim=0)
        t_rel = t - self.last_update[src]
        t_enc = self.time_enc(t_rel)
        msg = msg_module(self.memory[src], self.memory[dst], raw_msg, t_enc)
        return msg, t, src, dst

    def train(self, mode: bool=True):
        """Sets the module in training mode."""
        if self.training and not mode:
            self.__update_memory__(torch.arange(self.num_nodes, device=self.memory.device))
            self.__reset_message_store__()
        super().train(mode)


class IdentityMessage(torch.nn.Module):

    def __init__(self, raw_msg_dim: int, memory_dim: int, time_dim: int):
        super().__init__()
        self.out_channels = raw_msg_dim + 2 * memory_dim + time_dim

    def forward(self, z_src, z_dst, raw_msg, t_enc):
        return torch.cat([z_src, z_dst, raw_msg, t_enc], dim=-1)


class LastAggregator(torch.nn.Module):

    def forward(self, msg, index, t, dim_size):
        _, argmax = scatter_max(t, index, dim=0, dim_size=dim_size)
        out = msg.new_zeros((dim_size, msg.size(-1)))
        mask = argmax < msg.size(0)
        out[mask] = msg[argmax[mask]]
        return out


class MeanAggregator(torch.nn.Module):

    def forward(self, msg, index, t, dim_size):
        return scatter(msg, index, dim=0, dim_size=dim_size, reduce='mean')


class ModuleDict(torch.nn.ModuleDict):

    def __init__(self, modules: Optional[Mapping[str, Module]]=None):
        if modules:
            modules = {self.to_internal_key(key): module for key, module in modules.items()}
        super().__init__(modules)

    @staticmethod
    def to_internal_key(key: str) ->str:
        return key.replace('.', '#')

    @staticmethod
    def to_external_key(key: str) ->str:
        return key.replace('#', '.')

    def __getitem__(self, key: str) ->Module:
        return super().__getitem__(self.to_internal_key(key))

    def __setitem__(self, key: str, module: Module) ->None:
        return super().__setitem__(self.to_internal_key(key), module)

    def __delitem__(self, key: str) ->None:
        return super().__delitem__(self.to_internal_key(key))

    def __contains__(self, key: str) ->bool:
        return super().__contains__(self.to_internal_key(key))

    def keys(self) ->Iterable[str]:
        return [self.to_external_key(key) for key in super().keys()]


class BatchNorm(torch.nn.Module):
    """Applies batch normalization over a batch of node features as described
    in the `"Batch Normalization: Accelerating Deep Network Training by
    Reducing Internal Covariate Shift" <https://arxiv.org/abs/1502.03167>`_
    paper

    .. math::
        \\mathbf{x}^{\\prime}_i = \\frac{\\mathbf{x} -
        \\textrm{E}[\\mathbf{x}]}{\\sqrt{\\textrm{Var}[\\mathbf{x}] + \\epsilon}}
        \\odot \\gamma + \\beta

    The mean and standard-deviation are calculated per-dimension over all nodes
    inside the mini-batch.

    Args:
        in_channels (int): Size of each input sample.
        eps (float, optional): A value added to the denominator for numerical
            stability. (default: :obj:`1e-5`)
        momentum (float, optional): The value used for the running mean and
            running variance computation. (default: :obj:`0.1`)
        affine (bool, optional): If set to :obj:`True`, this module has
            learnable affine parameters :math:`\\gamma` and :math:`\\beta`.
            (default: :obj:`True`)
        track_running_stats (bool, optional): If set to :obj:`True`, this
            module tracks the running mean and variance, and when set to
            :obj:`False`, this module does not track such statistics and always
            uses batch statistics in both training and eval modes.
            (default: :obj:`True`)
        allow_single_element (bool, optional): If set to :obj:`True`, batches
            with only a single element will work as during in evaluation.
            That is the running mean and variance will be used.
            Requires :obj:`track_running_stats=True`. (default: :obj:`False`)
    """

    def __init__(self, in_channels: int, eps: float=1e-05, momentum: float=0.1, affine: bool=True, track_running_stats: bool=True, allow_single_element: bool=False):
        super().__init__()
        if allow_single_element and not track_running_stats:
            raise ValueError("'allow_single_element' requires 'track_running_stats' to be set to `True`")
        self.module = torch.nn.BatchNorm1d(in_channels, eps, momentum, affine, track_running_stats)
        self.in_channels = in_channels
        self.allow_single_element = allow_single_element

    def reset_parameters(self):
        self.module.reset_parameters()

    def forward(self, x: Tensor) ->Tensor:
        """"""
        if self.allow_single_element and x.size(0) <= 1:
            return torch.nn.functional.batch_norm(x, self.module.running_mean, self.module.running_var, self.module.weight, self.module.bias, False, 0.0, self.module.eps)
        return self.module(x)

    def __repr__(self):
        return f'{self.__class__.__name__}({self.module.num_features})'


class DiffGroupNorm(torch.nn.Module):
    """The differentiable group normalization layer from the `"Towards Deeper
    Graph Neural Networks with Differentiable Group Normalization"
    <https://arxiv.org/abs/2006.06972>`_ paper, which normalizes node features
    group-wise via a learnable soft cluster assignment

    .. math::

        \\mathbf{S} = \\text{softmax} (\\mathbf{X} \\mathbf{W})

    where :math:`\\mathbf{W} \\in \\mathbb{R}^{F \\times G}` denotes a trainable
    weight matrix mapping each node into one of :math:`G` clusters.
    Normalization is then performed group-wise via:

    .. math::

        \\mathbf{X}^{\\prime} = \\mathbf{X} + \\lambda \\sum_{i = 1}^G
        \\text{BatchNorm}(\\mathbf{S}[:, i] \\odot \\mathbf{X})

    Args:
        in_channels (int): Size of each input sample :math:`F`.
        groups (int): The number of groups :math:`G`.
        lamda (float, optional): The balancing factor :math:`\\lambda` between
            input embeddings and normalized embeddings. (default: :obj:`0.01`)
        eps (float, optional): A value added to the denominator for numerical
            stability. (default: :obj:`1e-5`)
        momentum (float, optional): The value used for the running mean and
            running variance computation. (default: :obj:`0.1`)
        affine (bool, optional): If set to :obj:`True`, this module has
            learnable affine parameters :math:`\\gamma` and :math:`\\beta`.
            (default: :obj:`True`)
        track_running_stats (bool, optional): If set to :obj:`True`, this
            module tracks the running mean and variance, and when set to
            :obj:`False`, this module does not track such statistics and always
            uses batch statistics in both training and eval modes.
            (default: :obj:`True`)
    """

    def __init__(self, in_channels: int, groups: int, lamda: float=0.01, eps: float=1e-05, momentum: float=0.1, affine: bool=True, track_running_stats: bool=True):
        super().__init__()
        self.in_channels = in_channels
        self.groups = groups
        self.lamda = lamda
        self.lin = Linear(in_channels, groups, bias=False)
        self.norm = BatchNorm1d(groups * in_channels, eps, momentum, affine, track_running_stats)
        self.reset_parameters()

    def reset_parameters(self):
        self.lin.reset_parameters()
        self.norm.reset_parameters()

    def forward(self, x: Tensor) ->Tensor:
        """"""
        F, G = self.in_channels, self.groups
        s = self.lin(x).softmax(dim=-1)
        out = s.unsqueeze(-1) * x.unsqueeze(-2)
        out = self.norm(out.view(-1, G * F)).view(-1, G, F).sum(-2)
        return x + self.lamda * out

    @staticmethod
    def group_distance_ratio(x: Tensor, y: Tensor, eps: float=1e-05) ->float:
        """Measures the ratio of inter-group distance over intra-group
        distance

        .. math::
            R_{\\text{Group}} = \\frac{\\frac{1}{(C-1)^2} \\sum_{i!=j}
            \\frac{1}{|\\mathbf{X}_i||\\mathbf{X}_j|} \\sum_{\\mathbf{x}_{iv}
            \\in \\mathbf{X}_i } \\sum_{\\mathbf{x}_{jv^{\\prime}} \\in \\mathbf{X}_j}
            {\\| \\mathbf{x}_{iv} - \\mathbf{x}_{jv^{\\prime}} \\|}_2 }{
            \\frac{1}{C} \\sum_{i} \\frac{1}{{|\\mathbf{X}_i|}^2}
            \\sum_{\\mathbf{x}_{iv}, \\mathbf{x}_{iv^{\\prime}} \\in \\mathbf{X}_i }
            {\\| \\mathbf{x}_{iv} - \\mathbf{x}_{iv^{\\prime}} \\|}_2 }

        where :math:`\\mathbf{X}_i` denotes the set of all nodes that belong to
        class :math:`i`, and :math:`C` denotes the total number of classes in
        :obj:`y`.
        """
        num_classes = int(y.max()) + 1
        numerator = 0.0
        for i in range(num_classes):
            mask = y == i
            dist = torch.cdist(x[mask].unsqueeze(0), x[~mask].unsqueeze(0))
            numerator += 1 / dist.numel() * float(dist.sum())
        numerator *= 1 / (num_classes - 1) ** 2
        denominator = 0.0
        for i in range(num_classes):
            mask = y == i
            dist = torch.cdist(x[mask].unsqueeze(0), x[mask].unsqueeze(0))
            denominator += 1 / dist.numel() * float(dist.sum())
        denominator *= 1 / num_classes
        return numerator / (denominator + eps)

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}({self.in_channels}, groups={self.groups})'


class GraphNorm(torch.nn.Module):
    """Applies graph normalization over individual graphs as described in the
    `"GraphNorm: A Principled Approach to Accelerating Graph Neural Network
    Training" <https://arxiv.org/abs/2009.03294>`_ paper

    .. math::
        \\mathbf{x}^{\\prime}_i = \\frac{\\mathbf{x} - \\alpha \\odot
        \\textrm{E}[\\mathbf{x}]}
        {\\sqrt{\\textrm{Var}[\\mathbf{x} - \\alpha \\odot \\textrm{E}[\\mathbf{x}]]
        + \\epsilon}} \\odot \\gamma + \\beta

    where :math:`\\alpha` denotes parameters that learn how much information
    to keep in the mean.

    Args:
        in_channels (int): Size of each input sample.
        eps (float, optional): A value added to the denominator for numerical
            stability. (default: :obj:`1e-5`)
    """

    def __init__(self, in_channels: int, eps: float=1e-05):
        super().__init__()
        self.in_channels = in_channels
        self.eps = eps
        self.weight = torch.nn.Parameter(torch.Tensor(in_channels))
        self.bias = torch.nn.Parameter(torch.Tensor(in_channels))
        self.mean_scale = torch.nn.Parameter(torch.Tensor(in_channels))
        self.reset_parameters()

    def reset_parameters(self):
        ones(self.weight)
        zeros(self.bias)
        ones(self.mean_scale)

    def forward(self, x: Tensor, batch: Optional[Tensor]=None) ->Tensor:
        """"""
        if batch is None:
            batch = x.new_zeros(x.size(0), dtype=torch.long)
        batch_size = int(batch.max()) + 1
        mean = scatter_mean(x, batch, dim=0, dim_size=batch_size)
        out = x - mean.index_select(0, batch) * self.mean_scale
        var = scatter_mean(out.pow(2), batch, dim=0, dim_size=batch_size)
        std = (var + self.eps).sqrt().index_select(0, batch)
        return self.weight * out / std + self.bias

    def __repr__(self):
        return f'{self.__class__.__name__}({self.in_channels})'


class GraphSizeNorm(nn.Module):
    """Applies Graph Size Normalization over each individual graph in a batch
    of node features as described in the
    `"Benchmarking Graph Neural Networks" <https://arxiv.org/abs/2003.00982>`_
    paper

    .. math::
        \\mathbf{x}^{\\prime}_i = \\frac{\\mathbf{x}_i}{\\sqrt{|\\mathcal{V}|}}
    """

    def __init__(self):
        super().__init__()

    def forward(self, x: Tensor, batch: OptTensor=None) ->Tensor:
        """"""
        if batch is None:
            batch = torch.zeros(x.size(0), dtype=torch.long, device=x.device)
        inv_sqrt_deg = degree(batch, dtype=x.dtype).pow(-0.5)
        return x * inv_sqrt_deg.index_select(0, batch).view(-1, 1)

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}()'


class InstanceNorm(_InstanceNorm):
    """Applies instance normalization over each individual example in a batch
    of node features as described in the `"Instance Normalization: The Missing
    Ingredient for Fast Stylization" <https://arxiv.org/abs/1607.08022>`_
    paper

    .. math::
        \\mathbf{x}^{\\prime}_i = \\frac{\\mathbf{x} -
        \\textrm{E}[\\mathbf{x}]}{\\sqrt{\\textrm{Var}[\\mathbf{x}] + \\epsilon}}
        \\odot \\gamma + \\beta

    The mean and standard-deviation are calculated per-dimension separately for
    each object in a mini-batch.

    Args:
        in_channels (int): Size of each input sample.
        eps (float, optional): A value added to the denominator for numerical
            stability. (default: :obj:`1e-5`)
        momentum (float, optional): The value used for the running mean and
            running variance computation. (default: :obj:`0.1`)
        affine (bool, optional): If set to :obj:`True`, this module has
            learnable affine parameters :math:`\\gamma` and :math:`\\beta`.
            (default: :obj:`False`)
        track_running_stats (bool, optional): If set to :obj:`True`, this
            module tracks the running mean and variance, and when set to
            :obj:`False`, this module does not track such statistics and always
            uses instance statistics in both training and eval modes.
            (default: :obj:`False`)
    """

    def __init__(self, in_channels: int, eps: float=1e-05, momentum: float=0.1, affine: bool=False, track_running_stats: bool=False):
        super().__init__(in_channels, eps, momentum, affine, track_running_stats)

    def forward(self, x: Tensor, batch: OptTensor=None) ->Tensor:
        """"""
        if batch is None:
            out = F.instance_norm(x.t().unsqueeze(0), self.running_mean, self.running_var, self.weight, self.bias, self.training or not self.track_running_stats, self.momentum, self.eps)
            return out.squeeze(0).t()
        batch_size = int(batch.max()) + 1
        mean = var = unbiased_var = x
        if self.training or not self.track_running_stats:
            norm = degree(batch, batch_size, dtype=x.dtype).clamp_(min=1)
            norm = norm.view(-1, 1)
            unbiased_norm = (norm - 1).clamp_(min=1)
            mean = scatter(x, batch, dim=0, dim_size=batch_size, reduce='add') / norm
            x = x - mean.index_select(0, batch)
            var = scatter(x * x, batch, dim=0, dim_size=batch_size, reduce='add')
            unbiased_var = var / unbiased_norm
            var = var / norm
            momentum = self.momentum
            if self.running_mean is not None:
                self.running_mean = (1 - momentum) * self.running_mean + momentum * mean.mean(0)
            if self.running_var is not None:
                self.running_var = (1 - momentum) * self.running_var + momentum * unbiased_var.mean(0)
        else:
            if self.running_mean is not None:
                mean = self.running_mean.view(1, -1).expand(batch_size, -1)
            if self.running_var is not None:
                var = self.running_var.view(1, -1).expand(batch_size, -1)
            x = x - mean.index_select(0, batch)
        out = x / (var + self.eps).sqrt().index_select(0, batch)
        if self.weight is not None and self.bias is not None:
            out = out * self.weight.view(1, -1) + self.bias.view(1, -1)
        return out

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}({self.num_features})'


class LayerNorm(torch.nn.Module):
    """Applies layer normalization over each individual example in a batch
    of node features as described in the `"Layer Normalization"
    <https://arxiv.org/abs/1607.06450>`_ paper

    .. math::
        \\mathbf{x}^{\\prime}_i = \\frac{\\mathbf{x} -
        \\textrm{E}[\\mathbf{x}]}{\\sqrt{\\textrm{Var}[\\mathbf{x}] + \\epsilon}}
        \\odot \\gamma + \\beta

    The mean and standard-deviation are calculated across all nodes and all
    node channels separately for each object in a mini-batch.

    Args:
        in_channels (int): Size of each input sample.
        eps (float, optional): A value added to the denominator for numerical
            stability. (default: :obj:`1e-5`)
        affine (bool, optional): If set to :obj:`True`, this module has
            learnable affine parameters :math:`\\gamma` and :math:`\\beta`.
            (default: :obj:`True`)
        mode (str, optinal): The normalization mode to use for layer
            normalization. (:obj:`"graph"` or :obj:`"node"`). If :obj:`"graph"`
            is used, each graph will be considered as an element to be
            normalized. If `"node"` is used, each node will be considered as
            an element to be normalized. (default: :obj:`"graph"`)
    """

    def __init__(self, in_channels: int, eps: float=1e-05, affine: bool=True, mode: str='graph'):
        super().__init__()
        self.in_channels = in_channels
        self.eps = eps
        self.affine = affine
        self.mode = mode
        if affine:
            self.weight = Parameter(torch.Tensor(in_channels))
            self.bias = Parameter(torch.Tensor(in_channels))
        else:
            self.register_parameter('weight', None)
            self.register_parameter('bias', None)
        self.reset_parameters()

    def reset_parameters(self):
        ones(self.weight)
        zeros(self.bias)

    def forward(self, x: Tensor, batch: OptTensor=None) ->Tensor:
        """"""
        if self.mode == 'graph':
            if batch is None:
                x = x - x.mean()
                out = x / (x.std(unbiased=False) + self.eps)
            else:
                batch_size = int(batch.max()) + 1
                norm = degree(batch, batch_size, dtype=x.dtype).clamp_(min=1)
                norm = norm.mul_(x.size(-1)).view(-1, 1)
                mean = scatter(x, batch, dim=0, dim_size=batch_size, reduce='add').sum(dim=-1, keepdim=True) / norm
                x = x - mean.index_select(0, batch)
                var = scatter(x * x, batch, dim=0, dim_size=batch_size, reduce='add').sum(dim=-1, keepdim=True)
                var = var / norm
                out = x / (var + self.eps).sqrt().index_select(0, batch)
            if self.weight is not None and self.bias is not None:
                out = out * self.weight + self.bias
            return out
        if self.mode == 'node':
            return F.layer_norm(x, (self.in_channels,), self.weight, self.bias, self.eps)
        raise ValueError(f'Unknow normalization mode: {self.mode}')

    def __repr__(self):
        return f'{self.__class__.__name__}({self.in_channels}, affine={self.affine}, mode={self.mode})'


class MeanSubtractionNorm(torch.nn.Module):
    """Applies layer normalization by subtracting the mean from the inputs
    as described in the  `"Revisiting 'Over-smoothing' in Deep GCNs"
    <https://arxiv.org/pdf/2003.13663.pdf>`_ paper

    .. math::
        \\mathbf{x}_i = \\mathbf{x}_i - \\frac{1}{|\\mathcal{V}|}
        \\sum_{j \\in \\mathcal{V}} \\mathbf{x}_j
    """

    def reset_parameters(self):
        pass

    def forward(self, x: Tensor, batch: Optional[Tensor]=None, dim_size: Optional[int]=None) ->Tensor:
        """"""
        if batch is None:
            return x - x.mean(dim=0, keepdim=True)
        mean = scatter(x, batch, dim=0, dim_size=dim_size, reduce='mean')
        return x - mean[batch]

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}()'


class PairNorm(torch.nn.Module):
    """Applies pair normalization over node features as described in the
    `"PairNorm: Tackling Oversmoothing in GNNs"
    <https://arxiv.org/abs/1909.12223>`_ paper

    .. math::
        \\mathbf{x}_i^c &= \\mathbf{x}_i - \\frac{1}{n}
        \\sum_{i=1}^n \\mathbf{x}_i \\\\

        \\mathbf{x}_i^{\\prime} &= s \\cdot
        \\frac{\\mathbf{x}_i^c}{\\sqrt{\\frac{1}{n} \\sum_{i=1}^n
        {\\| \\mathbf{x}_i^c \\|}^2_2}}

    Args:
        scale (float, optional): Scaling factor :math:`s` of normalization.
            (default, :obj:`1.`)
        scale_individually (bool, optional): If set to :obj:`True`, will
            compute the scaling step as :math:`\\mathbf{x}^{\\prime}_i = s \\cdot
            \\frac{\\mathbf{x}_i^c}{{\\| \\mathbf{x}_i^c \\|}_2}`.
            (default: :obj:`False`)
        eps (float, optional): A value added to the denominator for numerical
            stability. (default: :obj:`1e-5`)
    """

    def __init__(self, scale: float=1.0, scale_individually: bool=False, eps: float=1e-05):
        super().__init__()
        self.scale = scale
        self.scale_individually = scale_individually
        self.eps = eps

    def forward(self, x: Tensor, batch: OptTensor=None) ->Tensor:
        """"""
        scale = self.scale
        if batch is None:
            x = x - x.mean(dim=0, keepdim=True)
            if not self.scale_individually:
                return scale * x / (self.eps + x.pow(2).sum(-1).mean()).sqrt()
            else:
                return scale * x / (self.eps + x.norm(2, -1, keepdim=True))
        else:
            mean = scatter(x, batch, dim=0, reduce='mean')
            x = x - mean.index_select(0, batch)
            if not self.scale_individually:
                return scale * x / torch.sqrt(self.eps + scatter(x.pow(2).sum(-1, keepdim=True), batch, dim=0, reduce='mean').index_select(0, batch))
            else:
                return scale * x / (self.eps + x.norm(2, -1, keepdim=True))

    def __repr__(self):
        return f'{self.__class__.__name__}()'


class MemPooling(torch.nn.Module):
    """Memory based pooling layer from `"Memory-Based Graph Networks"
    <https://arxiv.org/abs/2002.09518>`_ paper, which learns a coarsened graph
    representation based on soft cluster assignments

    .. math::
        S_{i,j}^{(h)} &= \\frac{
        (1+{\\| \\mathbf{x}_i-\\mathbf{k}^{(h)}_j \\|}^2 / \\tau)^{
        -\\frac{1+\\tau}{2}}}{
        \\sum_{k=1}^K (1 + {\\| \\mathbf{x}_i-\\mathbf{k}^{(h)}_k \\|}^2 / \\tau)^{
        -\\frac{1+\\tau}{2}}}

        \\mathbf{S} &= \\textrm{softmax}(\\textrm{Conv2d}
        (\\Vert_{h=1}^H \\mathbf{S}^{(h)})) \\in \\mathbb{R}^{N \\times K}

        \\mathbf{X}^{\\prime} &= \\mathbf{S}^{\\top} \\mathbf{X} \\mathbf{W} \\in
        \\mathbb{R}^{K \\times F^{\\prime}}

    Where :math:`H` denotes the number of heads, and :math:`K` denotes the
    number of clusters.

    Args:
        in_channels (int): Size of each input sample :math:`F`.
        out_channels (int): Size of each output sample :math:`F^{\\prime}`.
        heads (int): The number of heads :math:`H`.
        num_clusters (int): number of clusters :math:`K` per head.
        tau (int, optional): The temperature :math:`\\tau`. (default: :obj:`1.`)
    """

    def __init__(self, in_channels: int, out_channels: int, heads: int, num_clusters: int, tau: float=1.0):
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.heads = heads
        self.num_clusters = num_clusters
        self.tau = tau
        self.k = Parameter(torch.Tensor(heads, num_clusters, in_channels))
        self.conv = Conv2d(heads, 1, kernel_size=1, padding=0, bias=False)
        self.lin = Linear(in_channels, out_channels, bias=False)
        self.reset_parameters()

    def reset_parameters(self):
        torch.nn.init.uniform_(self.k.data, -1.0, 1.0)
        self.conv.reset_parameters()
        self.lin.reset_parameters()

    @staticmethod
    def kl_loss(S: Tensor) ->Tensor:
        """The additional KL divergence-based loss

        .. math::
            P_{i,j} &= \\frac{S_{i,j}^2 / \\sum_{n=1}^N S_{n,j}}{\\sum_{k=1}^K
            S_{i,k}^2 / \\sum_{n=1}^N S_{n,k}}

            \\mathcal{L}_{\\textrm{KL}} &= \\textrm{KLDiv}(\\mathbf{P} \\Vert
            \\mathbf{S})
        """
        S_2 = S ** 2
        P = S_2 / S.sum(dim=1, keepdim=True)
        denom = P.sum(dim=2, keepdim=True)
        denom[S.sum(dim=2, keepdim=True) == 0.0] = 1.0
        P /= denom
        loss = KLDivLoss(reduction='batchmean', log_target=False)
        return loss(S.clamp(EPS).log(), P.clamp(EPS))

    def forward(self, x: Tensor, batch: Optional[Tensor]=None, mask: Optional[Tensor]=None) ->Tuple[Tensor, Tensor]:
        """
        Args:
            x (Tensor): Dense or sparse node feature tensor
                :math:`\\mathbf{X} \\in \\mathbb{R}^{N \\times F}` or
                :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times N \\times F}`,
                respectively.
            batch (LongTensor, optional): Batch vector :math:`\\mathbf{b} \\in
                {\\{ 0, \\ldots, B-1\\}}^N`, which assigns each node to a
                specific example.
                This argument should be just to separate graphs when using
                sparse node features. (default: :obj:`None`)
            mask (BoolTensor, optional): Mask matrix
                :math:`\\mathbf{M} \\in {\\{ 0, 1 \\}}^{B \\times N}`, which
                indicates valid nodes for each graph when using dense node
                features. (default: :obj:`None`)
        """
        if x.dim() <= 2:
            x, mask = to_dense_batch(x, batch)
        elif mask is None:
            mask = x.new_ones((x.size(0), x.size(1)), dtype=torch.bool)
        (B, N, _), H, K = x.size(), self.heads, self.num_clusters
        dist = torch.cdist(self.k.view(H * K, -1), x.view(B * N, -1), p=2) ** 2
        dist = (1.0 + dist / self.tau).pow(-(self.tau + 1.0) / 2.0)
        dist = dist.view(H, K, B, N).permute(2, 0, 3, 1)
        S = dist / dist.sum(dim=-1, keepdim=True)
        S = self.conv(S).squeeze(dim=1).softmax(dim=-1)
        S = S * mask.view(B, N, 1)
        x = self.lin(S.transpose(1, 2) @ x)
        return x, S

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}({self.in_channels}, {self.out_channels}, heads={self.heads}, num_clusters={self.num_clusters})'


class LinearAlign(torch.nn.Module):

    def __init__(self, keys: List[Union[NodeType, EdgeType]], out_channels: int):
        super().__init__()
        self.out_channels = out_channels
        self.lins = torch.nn.ModuleDict()
        for key in keys:
            self.lins[key2str(key)] = Linear(-1, out_channels, bias=False)

    def forward(self, x_dict: Dict[Union[NodeType, EdgeType], Tensor]) ->Dict[Union[NodeType, EdgeType], Tensor]:
        for key, x in x_dict.items():
            x_dict[key] = self.lins[key2str(key)](x)
        return x_dict

    def __repr__(self) ->str:
        return f'{self.__class__.__name__}(num_relations={len(self.lins)}, out_channels={self.out_channels})'


import torch
from torch.nn import MSELoss, ReLU
from _paritybench_helpers import _mock_config, _mock_layer, _paritybench_base, _fails_compile


TESTCASES = [
    # (nn.Module, init_args, forward_args, jit_compiles)
    (Aggregation,
     lambda: ([], {}),
     lambda: ([torch.rand([4, 4, 4, 4])], {}),
     False),
    (Attention,
     lambda: ([], {}),
     lambda: ([torch.rand([4, 4, 4, 4]), torch.rand([4, 4, 4, 4]), torch.rand([4, 4, 4, 4])], {}),
     False),
    (BPRLoss,
     lambda: ([], {}),
     lambda: ([torch.rand([4, 4, 4, 4]), torch.rand([4, 4, 4, 4])], {}),
     True),
    (BatchNorm,
     lambda: ([], {'in_channels': 4}),
     lambda: ([torch.rand([4, 4, 4])], {}),
     True),
    (BesselBasisLayer,
     lambda: ([], {'num_radial': 4}),
     lambda: ([torch.rand([4, 4, 4, 4])], {}),
     True),
    (DenseGINConv,
     lambda: ([], {'nn': _mock_layer()}),
     lambda: ([torch.rand([4, 4, 4, 4]), torch.rand([4, 4, 4])], {}),
     True),
    (Envelope,
     lambda: ([], {'exponent': 4}),
     lambda: ([torch.rand([4, 4, 4, 4])], {}),
     True),
    (GaussianSmearing,
     lambda: ([], {}),
     lambda: ([torch.rand([4, 4, 4, 4])], {}),
     True),
    (GraphSizeNorm,
     lambda: ([], {}),
     lambda: ([torch.rand([4, 4, 4, 4])], {}),
     False),
    (IdentityMessage,
     lambda: ([], {'raw_msg_dim': 4, 'memory_dim': 4, 'time_dim': 4}),
     lambda: ([torch.rand([4, 4, 4, 4]), torch.rand([4, 4, 4, 4]), torch.rand([4, 4, 4, 4]), torch.rand([4, 4, 4, 4])], {}),
     True),
    (InnerProductDecoder,
     lambda: ([], {}),
     lambda: ([torch.ones([4, 4], dtype=torch.int64), torch.ones([4, 4], dtype=torch.int64)], {}),
     True),
    (InstanceNorm,
     lambda: ([], {'in_channels': 4}),
     lambda: ([torch.rand([4, 4])], {}),
     False),
    (MeanSubtractionNorm,
     lambda: ([], {}),
     lambda: ([torch.rand([4, 4, 4, 4])], {}),
     False),
    (MedianAggregation,
     lambda: ([], {}),
     lambda: ([torch.rand([4, 4, 4, 4])], {}),
     False),
    (MetaLayer,
     lambda: ([], {}),
     lambda: ([torch.rand([4, 4, 4, 4]), torch.rand([4, 4, 4, 4])], {}),
     True),
    (PairNorm,
     lambda: ([], {}),
     lambda: ([torch.rand([4, 4, 4, 4])], {}),
     False),
    (PositionalEncoding,
     lambda: ([], {'out_channels': 4}),
     lambda: ([torch.rand([4, 4, 4, 4])], {}),
     True),
    (SWISH,
     lambda: ([], {}),
     lambda: ([torch.rand([4, 4, 4, 4])], {}),
     True),
    (ShiftedSoftplus,
     lambda: ([], {}),
     lambda: ([torch.rand([4, 4, 4, 4])], {}),
     True),
]

class Test_pyg_team_pytorch_geometric(_paritybench_base):
    def test_000(self):
        self._check(*TESTCASES[0])

    def test_001(self):
        self._check(*TESTCASES[1])

    def test_002(self):
        self._check(*TESTCASES[2])

    def test_003(self):
        self._check(*TESTCASES[3])

    def test_004(self):
        self._check(*TESTCASES[4])

    def test_005(self):
        self._check(*TESTCASES[5])

    def test_006(self):
        self._check(*TESTCASES[6])

    def test_007(self):
        self._check(*TESTCASES[7])

    def test_008(self):
        self._check(*TESTCASES[8])

    def test_009(self):
        self._check(*TESTCASES[9])

    def test_010(self):
        self._check(*TESTCASES[10])

    def test_011(self):
        self._check(*TESTCASES[11])

    def test_012(self):
        self._check(*TESTCASES[12])

    def test_013(self):
        self._check(*TESTCASES[13])

    def test_014(self):
        self._check(*TESTCASES[14])

    def test_015(self):
        self._check(*TESTCASES[15])

    def test_016(self):
        self._check(*TESTCASES[16])

    def test_017(self):
        self._check(*TESTCASES[17])

    def test_018(self):
        self._check(*TESTCASES[18])

