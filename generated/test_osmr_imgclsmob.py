import sys
_module = sys.modules[__name__]
del sys
master = _module
chainer_ = _module
chainercv2 = _module
model_provider = _module
models = _module
airnet = _module
airnext = _module
alexnet = _module
alphapose_coco = _module
bagnet = _module
bamresnet = _module
bisenet = _module
bninception = _module
cbamresnet = _module
centernet = _module
channelnet = _module
common = _module
condensenet = _module
darknet = _module
darknet53 = _module
darts = _module
deeplabv3 = _module
densenet = _module
densenet_cifar = _module
diapreresnet = _module
diapreresnet_cifar = _module
diaresnet = _module
diaresnet_cifar = _module
diracnetv2 = _module
dla = _module
dpn = _module
drn = _module
efficientnet = _module
efficientnetedge = _module
espnetv2 = _module
fastseresnet = _module
fbnet = _module
fcn8sd = _module
fdmobilenet = _module
fishnet = _module
ghostnet = _module
hardnet = _module
hrnet = _module
ibppose_coco = _module
icnet = _module
igcv3 = _module
inceptionresnetv2 = _module
inceptionv3 = _module
inceptionv4 = _module
irevnet = _module
lffd = _module
lwopenpose_cmupan = _module
menet = _module
mixnet = _module
mnasnet = _module
mobilenet = _module
mobilenet_cub = _module
mobilenetv2 = _module
mobilenetv3 = _module
model_store = _module
nasnet = _module
nin_cifar = _module
ntsnet_cub = _module
octresnet = _module
others = _module
peleenet = _module
pnasnet = _module
polynet = _module
preresnet = _module
preresnet_cifar = _module
proxylessnas = _module
proxylessnas_cub = _module
pspnet = _module
pyramidnet = _module
pyramidnet_cifar = _module
resattnet = _module
resdropresnet_cifar = _module
resnet = _module
resnet_cifar = _module
resnet_cub = _module
resneta = _module
resnetd = _module
resnext = _module
resnext_cifar = _module
rir_cifar = _module
ror_cifar = _module
selecsls = _module
senet = _module
sepreresnet = _module
sepreresnet_cifar = _module
seresnet = _module
seresnet_cifar = _module
seresnet_cub = _module
seresnext = _module
shakedropresnet_cifar = _module
shakeshakeresnet_cifar = _module
sharesnet = _module
shufflenet = _module
shufflenetv2 = _module
shufflenetv2b = _module
simplepose_coco = _module
simpleposemobile_coco = _module
sinet = _module
sknet = _module
sparsenet = _module
spnasnet = _module
squeezenet = _module
squeezenext = _module
vgg = _module
voca = _module
vovnet = _module
wrn = _module
wrn1bit_cifar = _module
wrn_cifar = _module
xception = _module
xdensenet = _module
xdensenet_cifar = _module
zfnet = _module
dataset_utils = _module
datasets = _module
ade20k_seg_dataset = _module
cifar100_cls_dataset = _module
cifar10_cls_dataset = _module
cityscapes_seg_dataset = _module
coco_hpe1_dataset = _module
coco_hpe2_dataset = _module
coco_hpe3_dataset = _module
coco_seg_dataset = _module
cub200_2011_cls_dataset = _module
dataset_metainfo = _module
imagenet1k_cls_dataset = _module
seg_dataset = _module
svhn_cls_dataset = _module
voc_seg_dataset = _module
metrics = _module
cls_metrics = _module
det_metrics = _module
hpe_metrics = _module
metric = _module
seg_metrics = _module
seg_metrics_np = _module
setup = _module
utils = _module
env_stats = _module
logger_utils = _module
train_log_param_saver = _module
convert_models = _module
eval_ch = _module
eval_gl = _module
eval_gl_det = _module
eval_ke = _module
eval_pt = _module
eval_tf = _module
eval_tf2 = _module
convert_tf2_to_tfl = _module
demo_gl = _module
demo_pt = _module
demo_tf2 = _module
gluon = _module
coco_det_dataset = _module
coco_hpe3_dataset = _module
hpatches_mch_dataset = _module
imagenet1k_rec_cls_dataset = _module
widerface_det_dataset = _module
gluoncv2 = _module
crunet = _module
crunetb = _module
diapreresnet = _module
diaresnet = _module
dla = _module
fractalnet_cifar = _module
ibnbresnet = _module
ibndensenet = _module
ibnresnet = _module
ibnresnext = _module
isqrtcovresnet = _module
msdnet = _module
octresnet_cifar = _module
oth_alpha_pose = _module
oth_centernet = _module
oth_centernet2 = _module
oth_icnet = _module
oth_mobile_pose = _module
oth_simple_pose_resnet = _module
res2net = _module
sinet = _module
superpointnet = _module
losses = _module
lr_scheduler = _module
seg_metrics_nd = _module
model_stats = _module
weighted_random_sampler = _module
keras_ = _module
kerascv = _module
other = _module
cifar1 = _module
imagenet1k1 = _module
seg_utils1 = _module
top_k_accuracy1 = _module
train_ch_cifar = _module
train_ch_in1k = _module
eval_gl_mch = _module
eval_pt_mch = _module
khpa = _module
eval_gl_khpa = _module
khpa_cls_dataset = _module
khpa_utils = _module
train_gl_khpa = _module
pytorch = _module
cub200_2011_utils1 = _module
seg_utils = _module
train_gl_seg = _module
coco_hpe3_dataset = _module
hpe_dataset = _module
mpii_hpe_dataset = _module
ret_metrics = _module
model_stats = _module
pytorchcv = _module
airnet = _module
airnext = _module
alexnet = _module
alphapose_coco = _module
bagnet = _module
bamresnet = _module
bisenet = _module
bninception = _module
cbamresnet = _module
centernet = _module
channelnet = _module
common = _module
condensenet = _module
darknet = _module
darknet53 = _module
darts = _module
deeplabv3 = _module
densenet = _module
densenet_cifar = _module
diapreresnet = _module
diapreresnet_cifar = _module
diaresnet = _module
diaresnet_cifar = _module
diracnetv2 = _module
dla = _module
dpn = _module
drn = _module
efficientnet = _module
efficientnetedge = _module
espnetv2 = _module
fastseresnet = _module
fbnet = _module
fcn8sd = _module
fishnet = _module
fractalnet_cifar = _module
ghostnet = _module
hardnet = _module
hrnet = _module
ibnbresnet = _module
ibndensenet = _module
ibnresnet = _module
ibnresnext = _module
ibppose_coco = _module
icnet = _module
igcv3 = _module
inceptionresnetv2 = _module
inceptionv3 = _module
inceptionv4 = _module
irevnet = _module
isqrtcovresnet = _module
lffd = _module
lwopenpose_cmupan = _module
menet = _module
mixnet = _module
mnasnet = _module
mobilenet = _module
mobilenetv2 = _module
mobilenetv3 = _module
msdnet = _module
msdnet_cifar10 = _module
nasnet = _module
nin_cifar = _module
ntsnet_cub = _module
octresnet = _module
oth_bisenet1 = _module
oth_ibppose = _module
oth_ibppose1 = _module
oth_lffd = _module
oth_lffd25 = _module
oth_lwopenpose2d = _module
oth_lwopenpose3d = _module
oth_naivenet = _module
oth_pose_resnet = _module
oth_prnet = _module
oth_sinet = _module
peleenet = _module
pnasnet = _module
polynet = _module
preresnet = _module
preresnet_cifar = _module
prnet = _module
proxylessnas = _module
pspnet = _module
pyramidnet = _module
pyramidnet_cifar = _module
resattnet = _module
resdropresnet_cifar = _module
resnet = _module
resnet_cifar = _module
resneta = _module
resnetd = _module
resnext = _module
resnext_cifar = _module
revnet = _module
rir_cifar = _module
ror_cifar = _module
selecsls = _module
senet = _module
sepreresnet = _module
sepreresnet_cifar = _module
seresnet = _module
seresnet_cifar = _module
seresnext = _module
shakedropresnet_cifar = _module
shakeshakeresnet_cifar = _module
sharesnet = _module
shufflenet = _module
shufflenetv2 = _module
shufflenetv2b = _module
simplepose_coco = _module
simpleposemobile_coco = _module
sinet = _module
sknet = _module
sparsenet = _module
spnasnet = _module
squeezenet = _module
squeezenext = _module
superpointnet = _module
vgg = _module
voca = _module
vovnet = _module
wrn = _module
wrn1bit_cifar = _module
wrn_cifar = _module
xception = _module
xdensenet = _module
xdensenet_cifar = _module
utils = _module
sotabench = _module
tensorflow2 = _module
cls_dataset = _module
coco_hpe3_dataset = _module
tf2cv = _module
dla = _module
grmiposelite_coco = _module
sinet = _module
tensorflow_ = _module
tensorflowcv = _module
utils_tp = _module
tests = _module
convert_gl2pt_batchnorm = _module
convert_gl2pt_conv2d = _module
convert_gl2pt_dense = _module
convert_gl2tf2_avgpool2d = _module
convert_gl2tf2_batchnorm = _module
convert_gl2tf2_conv2d = _module
convert_gl2tf2_conv2d_b = _module
convert_gl2tf2_dwconv2d = _module
convert_gl2tf_avgpool2d = _module
convert_gl2tf_batchnorm = _module
convert_gl2tf_conv1x1 = _module
convert_gl2tf_conv2d = _module
convert_gl2tf_dense = _module
convert_gl2tf_dwconv2d = _module
convert_gl2tf_gconv2d = _module
convert_gl2tf_maxpool2d = _module
train_ch = _module
train_gl = _module
train_ke = _module
train_pt = _module
train_tf = _module
train_tf2 = _module

from _paritybench_helpers import _mock_config
from unittest.mock import mock_open, MagicMock
from torch.autograd import Function
from torch.nn import Module
open = mock_open()
logging = sys = argparse = MagicMock()
ArgumentParser = argparse.ArgumentParser
_global_config = args = argv = cfg = config = params = _mock_config()
argparse.ArgumentParser.return_value.parse_args.return_value = _global_config
sys.argv = _global_config
__version__ = '1.0.0'


from functools import partial


import math


import numpy as np


import torch


import logging


import warnings


import random


import torch.nn as nn


import torch.backends.cudnn as cudnn


import torch.utils.data


from torch.nn import functional as F


import torch.utils.data as data


from torch.autograd import Variable


import torch.nn.functional as F


import torch.nn.init as init


from inspect import isfunction


from torch import nn


from collections import OrderedDict


def conv3x3_block(in_channels, out_channels, stride=1, padding=1, dilation=
    1, groups=1, bias=False, use_bn=True, bn_eps=1e-05, activation=lambda :
    nn.ReLU(inplace=True)):
    """
    3x3 version of the standard convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    padding : int, or tuple/list of 2 int, or tuple/list of 4 int, default 1
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    use_bn : bool, default True
        Whether to use BatchNorm layer.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function or name of activation function.
    """
    return ConvBlock(in_channels=in_channels, out_channels=out_channels,
        kernel_size=3, stride=stride, padding=padding, dilation=dilation,
        groups=groups, bias=bias, use_bn=use_bn, bn_eps=bn_eps, activation=
        activation)


class AirInitBlock(nn.Module):
    """
    AirNet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(AirInitBlock, self).__init__()
        mid_channels = out_channels // 2
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            mid_channels, stride=2)
        self.conv2 = conv3x3_block(in_channels=mid_channels, out_channels=
            mid_channels)
        self.conv3 = conv3x3_block(in_channels=mid_channels, out_channels=
            out_channels)
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.pool(x)
        return x


class AirNeXtBottleneck(nn.Module):
    """
    AirNet bottleneck block for residual path in ResNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    cardinality: int
        Number of groups.
    bottleneck_width: int
        Width of bottleneck block.
    ratio: int
        Air compression ratio.
    """

    def __init__(self, in_channels, out_channels, stride, cardinality,
        bottleneck_width, ratio):
        super(AirNeXtBottleneck, self).__init__()
        mid_channels = out_channels // 4
        D = int(math.floor(mid_channels * (bottleneck_width / 64.0)))
        group_width = cardinality * D
        self.use_air_block = stride == 1 and mid_channels < 512
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            group_width)
        self.conv2 = conv3x3_block(in_channels=group_width, out_channels=
            group_width, stride=stride, groups=cardinality)
        self.conv3 = conv1x1_block(in_channels=group_width, out_channels=
            out_channels, activation=None)
        if self.use_air_block:
            self.air = AirBlock(in_channels=in_channels, out_channels=
                group_width, groups=cardinality // ratio, ratio=ratio)

    def forward(self, x):
        if self.use_air_block:
            att = self.air(x)
        x = self.conv1(x)
        x = self.conv2(x)
        if self.use_air_block:
            x = x * att
        x = self.conv3(x)
        return x


class AirNeXtUnit(nn.Module):
    """
    AirNet unit with residual connection.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    cardinality: int
        Number of groups.
    bottleneck_width: int
        Width of bottleneck block.
    ratio: int
        Air compression ratio.
    """

    def __init__(self, in_channels, out_channels, stride, cardinality,
        bottleneck_width, ratio):
        super(AirNeXtUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        self.body = AirNeXtBottleneck(in_channels=in_channels, out_channels
            =out_channels, stride=stride, cardinality=cardinality,
            bottleneck_width=bottleneck_width, ratio=ratio)
        if self.resize_identity:
            self.identity_conv = conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride, activation=None)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        x = x + identity
        x = self.activ(x)
        return x


class AirNeXt(nn.Module):
    """
    AirNet model from 'Attention Inspiring Receptive-Fields Network for Learning Invariant Representations,'
    https://ieeexplore.ieee.org/document/8510896.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    cardinality: int
        Number of groups.
    bottleneck_width: int
        Width of bottleneck block.
    ratio: int
        Air compression ratio.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, cardinality,
        bottleneck_width, ratio, in_channels=3, in_size=(224, 224),
        num_classes=1000):
        super(AirNeXt, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', AirInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), AirNeXtUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, cardinality=cardinality,
                    bottleneck_width=bottleneck_width, ratio=ratio))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class AlexDense(nn.Module):
    """
    AlexNet specific dense block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(AlexDense, self).__init__()
        self.fc = nn.Linear(in_features=in_channels, out_features=out_channels)
        self.activ = nn.ReLU(inplace=True)
        self.dropout = nn.Dropout(p=0.5)

    def forward(self, x):
        x = self.fc(x)
        x = self.activ(x)
        x = self.dropout(x)
        return x


class AlexOutputBlock(nn.Module):
    """
    AlexNet specific output block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    classes : int
        Number of classification classes.
    """

    def __init__(self, in_channels, classes):
        super(AlexOutputBlock, self).__init__()
        mid_channels = 4096
        self.fc1 = AlexDense(in_channels=in_channels, out_channels=mid_channels
            )
        self.fc2 = AlexDense(in_channels=mid_channels, out_channels=
            mid_channels)
        self.fc3 = nn.Linear(in_features=mid_channels, out_features=classes)

    def forward(self, x):
        x = self.fc1(x)
        x = self.fc2(x)
        x = self.fc3(x)
        return x


class BagNetBottleneck(nn.Module):
    """
    BagNet bottleneck block for residual path in BagNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size of the second convolution.
    stride : int or tuple/list of 2 int
        Strides of the second convolution.
    bottleneck_factor : int, default 4
        Bottleneck factor.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        bottleneck_factor=4):
        super(BagNetBottleneck, self).__init__()
        mid_channels = out_channels // bottleneck_factor
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            mid_channels)
        self.conv2 = ConvBlock(in_channels=mid_channels, out_channels=
            mid_channels, kernel_size=kernel_size, stride=stride, padding=0)
        self.conv3 = conv1x1_block(in_channels=mid_channels, out_channels=
            out_channels, activation=None)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class BagNetUnit(nn.Module):
    """
    BagNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size of the second body convolution.
    stride : int or tuple/list of 2 int
        Strides of the second body convolution.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride):
        super(BagNetUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        self.body = BagNetBottleneck(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride)
        if self.resize_identity:
            self.identity_conv = conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride, activation=None)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        if x.size(-1) != identity.size(-1):
            diff = identity.size(-1) - x.size(-1)
            identity = identity[:, :, :-diff, :-diff]
        x = x + identity
        x = self.activ(x)
        return x


def conv1x1(in_channels, out_channels):
    """1x1 convolution"""
    return nn.Conv2d(in_channels, out_channels, 1, bias=True)


class BagNetInitBlock(nn.Module):
    """
    BagNet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(BagNetInitBlock, self).__init__()
        self.conv1 = conv1x1(in_channels=in_channels, out_channels=out_channels
            )
        self.conv2 = conv3x3_block(in_channels=out_channels, out_channels=
            out_channels, padding=0)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class BagNet(nn.Module):
    """
    BagNet model from 'Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet,'
    https://openreview.net/pdf?id=SkfMWhAqYQ.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    final_pool_size : int
        Size of the pooling windows for final pool.
    normal_kernel_sizes : list of int
        Count of the first units with 3x3 convolution window size for each stage.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, final_pool_size,
        normal_kernel_sizes, in_channels=3, in_size=(224, 224), num_classes
        =1000):
        super(BagNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', BagNetInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != len(channels) - 1 else 1
                kernel_size = 3 if j < normal_kernel_sizes[i] else 1
                stage.add_module('unit{}'.format(j + 1), BagNetUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    kernel_size=kernel_size, stride=stride))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=
            final_pool_size, stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class DenseBlock(nn.Module):
    """
    Standard dense block with Batch normalization and ReLU activation.

    Parameters:
    ----------
    in_features : int
        Number of input features.
    out_features : int
        Number of output features.
    """

    def __init__(self, in_features, out_features):
        super(DenseBlock, self).__init__()
        self.fc = nn.Linear(in_features=in_features, out_features=out_features)
        self.bn = nn.BatchNorm1d(num_features=out_features)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.fc(x)
        x = self.bn(x)
        x = self.activ(x)
        return x


class ChannelGate(nn.Module):
    """
    BAM channel gate block.

    Parameters:
    ----------
    channels : int
        Number of input/output channels.
    reduction_ratio : int, default 16
        Channel reduction ratio.
    num_layers : int, default 1
        Number of dense blocks.
    """

    def __init__(self, channels, reduction_ratio=16, num_layers=1):
        super(ChannelGate, self).__init__()
        mid_channels = channels // reduction_ratio
        self.pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))
        self.init_fc = DenseBlock(in_features=channels, out_features=
            mid_channels)
        self.main_fcs = nn.Sequential()
        for i in range(num_layers - 1):
            self.main_fcs.add_module('fc{}'.format(i + 1), DenseBlock(
                in_features=mid_channels, out_features=mid_channels))
        self.final_fc = nn.Linear(in_features=mid_channels, out_features=
            channels)

    def forward(self, x):
        input = x
        x = self.pool(x)
        x = x.view(x.size(0), -1)
        x = self.init_fc(x)
        x = self.main_fcs(x)
        x = self.final_fc(x)
        x = x.unsqueeze(2).unsqueeze(3).expand_as(input)
        return x


class SpatialGate(nn.Module):
    """
    BAM spatial gate block.

    Parameters:
    ----------
    channels : int
        Number of input/output channels.
    reduction_ratio : int, default 16
        Channel reduction ratio.
    num_dil_convs : int, default 2
        Number of dilated convolutions.
    dilation : int, default 4
        Dilation/padding value for corresponding convolutions.
    """

    def __init__(self, channels, reduction_ratio=16, num_dil_convs=2,
        dilation=4):
        super(SpatialGate, self).__init__()
        mid_channels = channels // reduction_ratio
        self.init_conv = conv1x1_block(in_channels=channels, out_channels=
            mid_channels, stride=1, bias=True)
        self.dil_convs = nn.Sequential()
        for i in range(num_dil_convs):
            self.dil_convs.add_module('conv{}'.format(i + 1), conv3x3_block
                (in_channels=mid_channels, out_channels=mid_channels,
                stride=1, padding=dilation, dilation=dilation, bias=True))
        self.final_conv = conv1x1(in_channels=mid_channels, out_channels=1,
            stride=1, bias=True)

    def forward(self, x):
        input = x
        x = self.init_conv(x)
        x = self.dil_convs(x)
        x = self.final_conv(x)
        x = x.expand_as(input)
        return x


class BamBlock(nn.Module):
    """
    BAM attention block for BAM-ResNet.

    Parameters:
    ----------
    channels : int
        Number of input/output channels.
    """

    def __init__(self, channels):
        super(BamBlock, self).__init__()
        self.ch_att = ChannelGate(channels=channels)
        self.sp_att = SpatialGate(channels=channels)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        att = 1 + self.sigmoid(self.ch_att(x) * self.sp_att(x))
        x = x * att
        return x


class AttentionRefinementBlock(nn.Module):
    """
    Attention refinement block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(AttentionRefinementBlock, self).__init__()
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            out_channels)
        self.pool = nn.AdaptiveAvgPool2d(1)
        self.conv2 = conv1x1_block(in_channels=out_channels, out_channels=
            out_channels, activation=lambda : nn.Sigmoid())

    def forward(self, x):
        x = self.conv1(x)
        w = self.pool(x)
        w = self.conv2(w)
        x = x * w
        return x


class PyramidPoolingMainBranch(nn.Module):
    """
    Pyramid pooling main branch.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    scale_factor : float
        Multiplier for spatial size.
    """

    def __init__(self, in_channels, out_channels, scale_factor):
        super(PyramidPoolingMainBranch, self).__init__()
        self.att = AttentionRefinementBlock(in_channels=in_channels,
            out_channels=out_channels)
        self.up = InterpolationBlock(scale_factor=scale_factor, mode=
            'nearest', align_corners=None)
        self.conv = conv3x3_block(in_channels=out_channels, out_channels=
            out_channels)

    def forward(self, x, y):
        x = self.att(x)
        x = x + y
        x = self.up(x)
        x = self.conv(x)
        return x


class FeatureFusion(nn.Module):
    """
    Feature fusion block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    reduction : int, default 4
        Squeeze reduction value.
    """

    def __init__(self, in_channels, out_channels, reduction=4):
        super(FeatureFusion, self).__init__()
        mid_channels = out_channels // reduction
        self.conv_merge = conv1x1_block(in_channels=in_channels,
            out_channels=out_channels)
        self.pool = nn.AdaptiveAvgPool2d(1)
        self.conv1 = conv1x1(in_channels=out_channels, out_channels=
            mid_channels)
        self.activ = nn.ReLU(inplace=True)
        self.conv2 = conv1x1(in_channels=mid_channels, out_channels=
            out_channels)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x, y):
        x = torch.cat((x, y), dim=1)
        x = self.conv_merge(x)
        w = self.pool(x)
        w = self.conv1(w)
        w = self.activ(w)
        w = self.conv2(w)
        w = self.sigmoid(w)
        x_att = x * w
        x = x + x_att
        return x


class BiSeHead(nn.Module):
    """
    BiSeNet head (final) block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    mid_channels : int
        Number of middle channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, mid_channels, out_channels):
        super(BiSeHead, self).__init__()
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            mid_channels)
        self.conv2 = conv1x1(in_channels=mid_channels, out_channels=
            out_channels)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class Inception3x3Branch(nn.Module):
    """
    BN-Inception 3x3 branch block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    mid_channels : int
        Number of intermediate channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the second convolution.
    bias : bool, default True
        Whether the convolution layer uses a bias vector.
    use_bn : bool, default True
        Whether to use BatchNorm layers.
    """

    def __init__(self, in_channels, out_channels, mid_channels, stride=1,
        bias=True, use_bn=True):
        super(Inception3x3Branch, self).__init__()
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            mid_channels, bias=bias, use_bn=use_bn)
        self.conv2 = conv3x3_block(in_channels=mid_channels, out_channels=
            out_channels, stride=stride, bias=bias, use_bn=use_bn)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class InceptionDouble3x3Branch(nn.Module):
    """
    BN-Inception double 3x3 branch block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    mid_channels : int
        Number of intermediate channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the second convolution.
    bias : bool, default True
        Whether the convolution layer uses a bias vector.
    use_bn : bool, default True
        Whether to use BatchNorm layers.
    """

    def __init__(self, in_channels, out_channels, mid_channels, stride=1,
        bias=True, use_bn=True):
        super(InceptionDouble3x3Branch, self).__init__()
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            mid_channels, bias=bias, use_bn=use_bn)
        self.conv2 = conv3x3_block(in_channels=mid_channels, out_channels=
            out_channels, bias=bias, use_bn=use_bn)
        self.conv3 = conv3x3_block(in_channels=out_channels, out_channels=
            out_channels, stride=stride, bias=bias, use_bn=use_bn)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class InceptionPoolBranch(nn.Module):
    """
    BN-Inception avg-pool branch block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    avg_pool : bool
        Whether use average pooling or max pooling.
    bias : bool
        Whether the convolution layer uses a bias vector.
    use_bn : bool
        Whether to use BatchNorm layers.
    """

    def __init__(self, in_channels, out_channels, avg_pool, bias, use_bn):
        super(InceptionPoolBranch, self).__init__()
        if avg_pool:
            self.pool = nn.AvgPool2d(kernel_size=3, stride=1, padding=1,
                ceil_mode=True, count_include_pad=True)
        else:
            self.pool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1,
                ceil_mode=True)
        self.conv = conv1x1_block(in_channels=in_channels, out_channels=
            out_channels, bias=bias, use_bn=use_bn)

    def forward(self, x):
        x = self.pool(x)
        x = self.conv(x)
        return x


def conv7x7_block(in_channels, out_channels, stride=1, padding=3, bias=
    False, use_bn=True, activation=lambda : nn.ReLU(inplace=True)):
    """
    7x7 version of the standard convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    padding : int, or tuple/list of 2 int, or tuple/list of 4 int, default 1
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 3
        Padding value for convolution layer.
    bias : bool, default False
        Whether the layer uses a bias vector.
    use_bn : bool, default True
        Whether to use BatchNorm layer.
    activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function or name of activation function.
    """
    return ConvBlock(in_channels=in_channels, out_channels=out_channels,
        kernel_size=7, stride=stride, padding=padding, bias=bias, use_bn=
        use_bn, activation=activation)


class StemBlock(nn.Module):
    """
    BN-Inception stem block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    mid_channels : int
        Number of intermediate channels.
    bias : bool
        Whether the convolution layer uses a bias vector.
    use_bn : bool
        Whether to use BatchNorm layers.
    """

    def __init__(self, in_channels, out_channels, mid_channels, bias, use_bn):
        super(StemBlock, self).__init__()
        self.conv1 = conv7x7_block(in_channels=in_channels, out_channels=
            mid_channels, stride=2, bias=bias, use_bn=use_bn)
        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0,
            ceil_mode=True)
        self.conv2 = Inception3x3Branch(in_channels=mid_channels,
            out_channels=out_channels, mid_channels=mid_channels)
        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0,
            ceil_mode=True)

    def forward(self, x):
        x = self.conv1(x)
        x = self.pool1(x)
        x = self.conv2(x)
        x = self.pool2(x)
        return x


class ReductionBlock(nn.Module):
    """
    BN-Inception reduction block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    mid1_channels_list : list of int
        Number of pre-middle channels for branches.
    mid2_channels_list : list of int
        Number of middle channels for branches.
    bias : bool
        Whether the convolution layer uses a bias vector.
    use_bn : bool
        Whether to use BatchNorm layers.
    """

    def __init__(self, in_channels, mid1_channels_list, mid2_channels_list,
        bias, use_bn):
        super(ReductionBlock, self).__init__()
        assert len(mid1_channels_list) == 2
        assert len(mid2_channels_list) == 4
        self.branches = Concurrent()
        self.branches.add_module('branch1', Inception3x3Branch(in_channels=
            in_channels, out_channels=mid2_channels_list[1], mid_channels=
            mid1_channels_list[0], stride=2, bias=bias, use_bn=use_bn))
        self.branches.add_module('branch2', InceptionDouble3x3Branch(
            in_channels=in_channels, out_channels=mid2_channels_list[2],
            mid_channels=mid1_channels_list[1], stride=2, bias=bias, use_bn
            =use_bn))
        self.branches.add_module('branch3', nn.MaxPool2d(kernel_size=3,
            stride=2, padding=0, ceil_mode=True))

    def forward(self, x):
        x = self.branches(x)
        return x


class MLP(nn.Module):
    """
    Multilayer perceptron block.

    Parameters:
    ----------
    channels : int
        Number of input/output channels.
    reduction_ratio : int, default 16
        Channel reduction ratio.
    """

    def __init__(self, channels, reduction_ratio=16):
        super(MLP, self).__init__()
        mid_channels = channels // reduction_ratio
        self.fc1 = nn.Linear(in_features=channels, out_features=mid_channels)
        self.activ = nn.ReLU(inplace=True)
        self.fc2 = nn.Linear(in_features=mid_channels, out_features=channels)

    def forward(self, x):
        x = x.view(x.size(0), -1)
        x = self.fc1(x)
        x = self.activ(x)
        x = self.fc2(x)
        return x


class ChannelGate(nn.Module):
    """
    CBAM channel gate block.

    Parameters:
    ----------
    channels : int
        Number of input/output channels.
    reduction_ratio : int, default 16
        Channel reduction ratio.
    """

    def __init__(self, channels, reduction_ratio=16):
        super(ChannelGate, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))
        self.max_pool = nn.AdaptiveMaxPool2d(output_size=(1, 1))
        self.mlp = MLP(channels=channels, reduction_ratio=reduction_ratio)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        att1 = self.avg_pool(x)
        att1 = self.mlp(att1)
        att2 = self.max_pool(x)
        att2 = self.mlp(att2)
        att = att1 + att2
        att = self.sigmoid(att)
        att = att.unsqueeze(2).unsqueeze(3).expand_as(x)
        x = x * att
        return x


class SpatialGate(nn.Module):
    """
    CBAM spatial gate block.
    """

    def __init__(self):
        super(SpatialGate, self).__init__()
        self.conv = conv7x7_block(in_channels=2, out_channels=1, activation
            =None)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        att1 = x.max(dim=1)[0].unsqueeze(1)
        att2 = x.mean(dim=1).unsqueeze(1)
        att = torch.cat((att1, att2), dim=1)
        att = self.conv(att)
        att = self.sigmoid(att)
        x = x * att
        return x


class CbamBlock(nn.Module):
    """
    CBAM attention block for CBAM-ResNet.

    Parameters:
    ----------
    channels : int
        Number of input/output channels.
    reduction_ratio : int, default 16
        Channel reduction ratio.
    """

    def __init__(self, channels, reduction_ratio=16):
        super(CbamBlock, self).__init__()
        self.ch_gate = ChannelGate(channels=channels, reduction_ratio=
            reduction_ratio)
        self.sp_gate = SpatialGate()

    def forward(self, x):
        x = self.ch_gate(x)
        x = self.sp_gate(x)
        return x


class CenterNetHeadBlock(nn.Module):
    """
    CenterNet simple head block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(CenterNetHeadBlock, self).__init__()
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            in_channels, bias=True, use_bn=False)
        self.conv2 = conv1x1(in_channels=in_channels, out_channels=
            out_channels, bias=True)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class CenterNetHeatmapBlock(nn.Module):
    """
    CenterNet heatmap block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    do_nms : bool
        Whether do NMS (or simply clip for training otherwise).
    """

    def __init__(self, in_channels, out_channels, do_nms):
        super(CenterNetHeatmapBlock, self).__init__()
        self.do_nms = do_nms
        self.head = CenterNetHeadBlock(in_channels=in_channels,
            out_channels=out_channels)
        self.sigmoid = nn.Sigmoid()
        if self.do_nms:
            self.pool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)

    def forward(self, x):
        x = self.head(x)
        x = self.sigmoid(x)
        if self.do_nms:
            y = self.pool(x)
            x = x * (y == x)
        else:
            eps = 0.0001
            x = x.clamp(min=eps, max=1.0 - eps)
        return x


class CenterNetHeatmapMaxDet(nn.Module):
    """
    CenterNet decoder for heads (heatmap, wh, reg).

    Parameters
    ----------
    topk : int, default 40
        Keep only `topk` detections.
    scale : int, default is 4
        Downsampling scale factor.
    """

    def __init__(self, topk=40, scale=4):
        super(CenterNetHeatmapMaxDet, self).__init__()
        self.topk = topk
        self.scale = scale

    def forward(self, x):
        heatmap = x[:, :-4]
        wh = x[:, -4:-2]
        reg = x[:, -2:]
        batch, _, out_h, out_w = heatmap.shape
        scores, indices = heatmap.view((batch, -1)).topk(k=self.topk)
        topk_classes = (indices / (out_h * out_w)).type(torch.float32)
        topk_indices = indices.fmod(out_h * out_w)
        topk_ys = (topk_indices / out_w).type(torch.float32)
        topk_xs = topk_indices.fmod(out_w).type(torch.float32)
        center = reg.permute(0, 2, 3, 1).view((batch, -1, 2))
        wh = wh.permute(0, 2, 3, 1).view((batch, -1, 2))
        xs = torch.gather(center[:, :, (0)], dim=-1, index=topk_indices)
        ys = torch.gather(center[:, :, (1)], dim=-1, index=topk_indices)
        topk_xs = topk_xs + xs
        topk_ys = topk_ys + ys
        w = torch.gather(wh[:, :, (0)], dim=-1, index=topk_indices)
        h = torch.gather(wh[:, :, (1)], dim=-1, index=topk_indices)
        half_w = 0.5 * w
        half_h = 0.5 * h
        bboxes = torch.stack((topk_xs - half_w, topk_ys - half_h, topk_xs +
            half_w, topk_ys + half_h), dim=-1)
        bboxes = bboxes * self.scale
        topk_classes = topk_classes.unsqueeze(dim=-1)
        scores = scores.unsqueeze(dim=-1)
        result = torch.cat((bboxes, topk_classes, scores), dim=-1)
        return result

    def __repr__(self):
        s = '{name}(topk={topk}, scale={scale})'
        return s.format(name=self.__class__.__name__, topk=self.topk, scale
            =self.scale)

    def calc_flops(self, x):
        assert x.shape[0] == 1
        num_flops = 10 * x.size
        num_macs = 0
        return num_flops, num_macs


class ChannetConv(nn.Module):
    """
    ChannelNet specific convolution block with Batch normalization and ReLU6 activation.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    dropout_rate : float, default 0.0
        Dropout rate.
    activate : bool, default True
        Whether activate the convolution block.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, dilation=1, groups=1, bias=False, dropout_rate=0.0,
        activate=True):
        super(ChannetConv, self).__init__()
        self.use_dropout = dropout_rate > 0.0
        self.activate = activate
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, dilation=dilation, groups=groups, bias=bias)
        if self.use_dropout:
            self.dropout = nn.Dropout(p=dropout_rate)
        self.bn = nn.BatchNorm2d(num_features=out_channels)
        if self.activate:
            self.activ = nn.ReLU6(inplace=True)

    def forward(self, x):
        x = self.conv(x)
        if self.use_dropout:
            x = self.dropout(x)
        x = self.bn(x)
        if self.activate:
            x = self.activ(x)
        return x


def channet_conv1x1(in_channels, out_channels, stride=1, groups=1, bias=
    False, dropout_rate=0.0, activate=True):
    """
    1x1 version of ChannelNet specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    dropout_rate : float, default 0.0
        Dropout rate.
    activate : bool, default True
        Whether activate the convolution block.
    """
    return ChannetConv(in_channels=in_channels, out_channels=out_channels,
        kernel_size=1, stride=stride, padding=0, groups=groups, bias=bias,
        dropout_rate=dropout_rate, activate=activate)


def dwconv3x3(in_channels, out_channels, stride, bias=False):
    """
    3x3 depthwise version of the standard convolution layer.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    bias : bool, default False
        Whether the layer uses a bias vector.
    """
    return nn.Conv2d(in_channels=in_channels, out_channels=out_channels,
        kernel_size=3, stride=stride, padding=1, groups=out_channels, bias=bias
        )


class ChannetDwsConvBlock(nn.Module):
    """
    ChannelNet specific depthwise separable convolution block with BatchNorms and activations at last convolution
    layers.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    groups : int, default 1
        Number of groups.
    dropout_rate : float, default 0.0
        Dropout rate.
    """

    def __init__(self, in_channels, out_channels, stride, groups=1,
        dropout_rate=0.0):
        super(ChannetDwsConvBlock, self).__init__()
        self.dw_conv = dwconv3x3(in_channels=in_channels, out_channels=
            in_channels, stride=stride)
        self.pw_conv = channet_conv1x1(in_channels=in_channels,
            out_channels=out_channels, groups=groups, dropout_rate=dropout_rate
            )

    def forward(self, x):
        x = self.dw_conv(x)
        x = self.pw_conv(x)
        return x


class SimpleGroupBlock(nn.Module):
    """
    ChannelNet specific block with a sequence of depthwise separable group convolution layers.

    Parameters:
    ----------
    channels : int
        Number of input/output channels.
    multi_blocks : int
        Number of DWS layers in the sequence.
    groups : int
        Number of groups.
    dropout_rate : float
        Dropout rate.
    """

    def __init__(self, channels, multi_blocks, groups, dropout_rate):
        super(SimpleGroupBlock, self).__init__()
        self.blocks = nn.Sequential()
        for i in range(multi_blocks):
            self.blocks.add_module('block{}'.format(i + 1),
                ChannetDwsConvBlock(in_channels=channels, out_channels=
                channels, stride=1, groups=groups, dropout_rate=dropout_rate))

    def forward(self, x):
        x = self.blocks(x)
        return x


class ChannelwiseConv2d(nn.Module):
    """
    ChannelNet specific block with channel-wise convolution.

    Parameters:
    ----------
    groups : int
        Number of groups.
    dropout_rate : float
        Dropout rate.
    """

    def __init__(self, groups, dropout_rate):
        super(ChannelwiseConv2d, self).__init__()
        self.use_dropout = dropout_rate > 0.0
        self.conv = nn.Conv3d(in_channels=1, out_channels=groups,
            kernel_size=(4 * groups, 1, 1), stride=(groups, 1, 1), padding=
            (2 * groups - 1, 0, 0), bias=False)
        if self.use_dropout:
            self.dropout = nn.Dropout(p=dropout_rate)

    def forward(self, x):
        batch, channels, height, width = x.size()
        x = x.unsqueeze(dim=1)
        x = self.conv(x)
        if self.use_dropout:
            x = self.dropout(x)
        x = x.view(batch, channels, height, width)
        return x


class ConvGroupBlock(nn.Module):
    """
    ChannelNet specific block with a combination of channel-wise convolution, depthwise separable group convolutions.

    Parameters:
    ----------
    channels : int
        Number of input/output channels.
    multi_blocks : int
        Number of DWS layers in the sequence.
    groups : int
        Number of groups.
    dropout_rate : float
        Dropout rate.
    """

    def __init__(self, channels, multi_blocks, groups, dropout_rate):
        super(ConvGroupBlock, self).__init__()
        self.conv = ChannelwiseConv2d(groups=groups, dropout_rate=dropout_rate)
        self.block = SimpleGroupBlock(channels=channels, multi_blocks=
            multi_blocks, groups=groups, dropout_rate=dropout_rate)

    def forward(self, x):
        x = self.conv(x)
        x = self.block(x)
        return x


def channet_conv3x3(in_channels, out_channels, stride, padding=1, dilation=
    1, groups=1, bias=False, dropout_rate=0.0, activate=True):
    """
    3x3 version of the standard convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 1
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    dropout_rate : float, default 0.0
        Dropout rate.
    activate : bool, default True
        Whether activate the convolution block.
    """
    return ChannetConv(in_channels=in_channels, out_channels=out_channels,
        kernel_size=3, stride=stride, padding=padding, dilation=dilation,
        groups=groups, bias=bias, dropout_rate=dropout_rate, activate=activate)


class ChannetUnit(nn.Module):
    """
    ChannelNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels_list : tuple/list of 2 int
        Number of output channels for each sub-block.
    strides : int or tuple/list of 2 int
        Strides of the convolution.
    multi_blocks : int
        Number of DWS layers in the sequence.
    groups : int
        Number of groups.
    dropout_rate : float
        Dropout rate.
    block_names : tuple/list of 2 str
        Sub-block names.
    merge_type : str
        Type of sub-block output merging.
    """

    def __init__(self, in_channels, out_channels_list, strides,
        multi_blocks, groups, dropout_rate, block_names, merge_type):
        super(ChannetUnit, self).__init__()
        assert len(block_names) == 2
        assert merge_type in ['seq', 'add', 'cat']
        self.merge_type = merge_type
        self.blocks = nn.Sequential()
        for i, (out_channels, block_name) in enumerate(zip(
            out_channels_list, block_names)):
            stride_i = strides if i == 0 else 1
            if block_name == 'channet_conv3x3':
                self.blocks.add_module('block{}'.format(i + 1),
                    channet_conv3x3(in_channels=in_channels, out_channels=
                    out_channels, stride=stride_i, dropout_rate=
                    dropout_rate, activate=False))
            elif block_name == 'channet_dws_conv_block':
                self.blocks.add_module('block{}'.format(i + 1),
                    ChannetDwsConvBlock(in_channels=in_channels,
                    out_channels=out_channels, stride=stride_i,
                    dropout_rate=dropout_rate))
            elif block_name == 'simple_group_block':
                self.blocks.add_module('block{}'.format(i + 1),
                    SimpleGroupBlock(channels=in_channels, multi_blocks=
                    multi_blocks, groups=groups, dropout_rate=dropout_rate))
            elif block_name == 'conv_group_block':
                self.blocks.add_module('block{}'.format(i + 1),
                    ConvGroupBlock(channels=in_channels, multi_blocks=
                    multi_blocks, groups=groups, dropout_rate=dropout_rate))
            else:
                raise NotImplementedError()
            in_channels = out_channels

    def forward(self, x):
        x_outs = []
        for block in self.blocks._modules.values():
            x = block(x)
            x_outs.append(x)
        if self.merge_type == 'add':
            for i in range(len(x_outs) - 1):
                x = x + x_outs[i]
        elif self.merge_type == 'cat':
            x = torch.cat(tuple(x_outs), dim=1)
        return x


class ChannelNet(nn.Module):
    """
    ChannelNet model from 'ChannelNets: Compact and Efficient Convolutional Neural Networks via Channel-Wise
    Convolutions,' https://arxiv.org/abs/1809.01330.

    Parameters:
    ----------
    channels : list of list of list of int
        Number of output channels for each unit.
    block_names : list of list of list of str
        Names of blocks for each unit.
    block_names : list of list of str
        Merge types for each unit.
    dropout_rate : float, default 0.0001
        Dropout rate.
    multi_blocks : int, default 2
        Block count architectural parameter.
    groups : int, default 2
        Group count architectural parameter.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, block_names, merge_types, dropout_rate=
        0.0001, multi_blocks=2, groups=2, in_channels=3, in_size=(224, 224),
        num_classes=1000):
        super(ChannelNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                strides = 2 if j == 0 else 1
                stage.add_module('unit{}'.format(j + 1), ChannetUnit(
                    in_channels=in_channels, out_channels_list=out_channels,
                    strides=strides, multi_blocks=multi_blocks, groups=
                    groups, dropout_rate=dropout_rate, block_names=
                    block_names[i][j], merge_type=merge_types[i][j]))
                if merge_types[i][j] == 'cat':
                    in_channels = sum(out_channels)
                else:
                    in_channels = out_channels[-1]
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class Identity(nn.Module):
    """
    Identity block.
    """

    def __init__(self):
        super(Identity, self).__init__()

    def forward(self, x):
        return x


class Swish(nn.Module):
    """
    Swish activation function from 'Searching for Activation Functions,' https://arxiv.org/abs/1710.05941.
    """

    def forward(self, x):
        return x * torch.sigmoid(x)


class HSigmoid(nn.Module):
    """
    Approximated sigmoid function, so-called hard-version of sigmoid from 'Searching for MobileNetV3,'
    https://arxiv.org/abs/1905.02244.
    """

    def forward(self, x):
        return F.relu6(x + 3.0, inplace=True) / 6.0


class HSwish(nn.Module):
    """
    H-Swish activation function from 'Searching for MobileNetV3,' https://arxiv.org/abs/1905.02244.

    Parameters:
    ----------
    inplace : bool
        Whether to use inplace version of the module.
    """

    def __init__(self, inplace=False):
        super(HSwish, self).__init__()
        self.inplace = inplace

    def forward(self, x):
        return x * F.relu6(x + 3.0, inplace=self.inplace) / 6.0


class ConvBlock(nn.Module):
    """
    Standard convolution block with Batch normalization and activation.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int, or tuple/list of 2 int, or tuple/list of 4 int
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    use_bn : bool, default True
        Whether to use BatchNorm layer.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function or name of activation function.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, dilation=1, groups=1, bias=False, use_bn=True, bn_eps=
        1e-05, activation=lambda : nn.ReLU(inplace=True)):
        super(ConvBlock, self).__init__()
        self.activate = activation is not None
        self.use_bn = use_bn
        self.use_pad = isinstance(padding, (list, tuple)) and len(padding) == 4
        if self.use_pad:
            self.pad = nn.ZeroPad2d(padding=padding)
            padding = 0
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, dilation=dilation, groups=groups, bias=bias)
        if self.use_bn:
            self.bn = nn.BatchNorm2d(num_features=out_channels, eps=bn_eps)
        if self.activate:
            self.activ = get_activation_layer(activation)

    def forward(self, x):
        if self.use_pad:
            x = self.pad(x)
        x = self.conv(x)
        if self.use_bn:
            x = self.bn(x)
        if self.activate:
            x = self.activ(x)
        return x


def dwconv_block(in_channels, out_channels, kernel_size, stride=1, padding=
    1, dilation=1, bias=False, use_bn=True, bn_eps=1e-05, activation=lambda :
    nn.ReLU(inplace=True)):
    """
    Depthwise version of the standard convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    padding : int, or tuple/list of 2 int, or tuple/list of 4 int, default 1
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    bias : bool, default False
        Whether the layer uses a bias vector.
    use_bn : bool, default True
        Whether to use BatchNorm layer.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function or name of activation function.
    """
    return ConvBlock(in_channels=in_channels, out_channels=out_channels,
        kernel_size=kernel_size, stride=stride, padding=padding, dilation=
        dilation, groups=out_channels, bias=bias, use_bn=use_bn, bn_eps=
        bn_eps, activation=activation)


class DwsConvBlock(nn.Module):
    """
    Depthwise separable convolution block with BatchNorms and activations at each convolution layers.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int, or tuple/list of 2 int, or tuple/list of 4 int
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    bias : bool, default False
        Whether the layer uses a bias vector.
    use_bn : bool, default True
        Whether to use BatchNorm layer.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    dw_activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function after the depthwise convolution block.
    pw_activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function after the pointwise convolution block.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, dilation=1, bias=False, use_bn=True, bn_eps=1e-05,
        dw_activation=lambda : nn.ReLU(inplace=True), pw_activation=lambda :
        nn.ReLU(inplace=True)):
        super(DwsConvBlock, self).__init__()
        self.dw_conv = dwconv_block(in_channels=in_channels, out_channels=
            in_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, dilation=dilation, bias=bias, use_bn=use_bn, bn_eps=
            bn_eps, activation=dw_activation)
        self.pw_conv = conv1x1_block(in_channels=in_channels, out_channels=
            out_channels, bias=bias, use_bn=use_bn, bn_eps=bn_eps,
            activation=pw_activation)

    def forward(self, x):
        x = self.dw_conv(x)
        x = self.pw_conv(x)
        return x


class PreConvBlock(nn.Module):
    """
    Convolution block with Batch normalization and ReLU pre-activation.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    bias : bool, default False
        Whether the layer uses a bias vector.
    use_bn : bool, default True
        Whether to use BatchNorm layer.
    return_preact : bool, default False
        Whether return pre-activation. It's used by PreResNet.
    activate : bool, default True
        Whether activate the convolution block.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, dilation=1, bias=False, use_bn=True, return_preact=False,
        activate=True):
        super(PreConvBlock, self).__init__()
        self.return_preact = return_preact
        self.activate = activate
        self.use_bn = use_bn
        if self.use_bn:
            self.bn = nn.BatchNorm2d(num_features=in_channels)
        if self.activate:
            self.activ = nn.ReLU(inplace=True)
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, dilation=dilation, bias=bias)

    def forward(self, x):
        if self.use_bn:
            x = self.bn(x)
        if self.activate:
            x = self.activ(x)
        if self.return_preact:
            x_pre_activ = x
        x = self.conv(x)
        if self.return_preact:
            return x, x_pre_activ
        else:
            return x


class DeconvBlock(nn.Module):
    """
    Deconvolution block with batch normalization and activation.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the deconvolution.
    padding : int or tuple/list of 2 int
        Padding value for deconvolution layer.
    ext_padding : tuple/list of 4 int, default None
        Extra padding value for deconvolution layer.
    out_padding : int or tuple/list of 2 int
        Output padding value for deconvolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for deconvolution layer.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    use_bn : bool, default True
        Whether to use BatchNorm layer.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function or name of activation function.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, ext_padding=None, out_padding=0, dilation=1, groups=1,
        bias=False, use_bn=True, bn_eps=1e-05, activation=lambda : nn.ReLU(
        inplace=True)):
        super(DeconvBlock, self).__init__()
        self.activate = activation is not None
        self.use_bn = use_bn
        self.use_pad = ext_padding is not None
        if self.use_pad:
            self.pad = nn.ZeroPad2d(padding=ext_padding)
        self.conv = nn.ConvTranspose2d(in_channels=in_channels,
            out_channels=out_channels, kernel_size=kernel_size, stride=
            stride, padding=padding, output_padding=out_padding, dilation=
            dilation, groups=groups, bias=bias)
        if self.use_bn:
            self.bn = nn.BatchNorm2d(num_features=out_channels, eps=bn_eps)
        if self.activate:
            self.activ = get_activation_layer(activation)

    def forward(self, x):
        if self.use_pad:
            x = self.pad(x)
        x = self.conv(x)
        if self.use_bn:
            x = self.bn(x)
        if self.activate:
            x = self.activ(x)
        return x


class NormActivation(nn.Module):
    """
    Activation block with preliminary batch normalization. It's used by itself as the final block in PreResNet.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    """

    def __init__(self, in_channels, bn_eps=1e-05):
        super(NormActivation, self).__init__()
        self.bn = nn.BatchNorm2d(num_features=in_channels, eps=bn_eps)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.bn(x)
        x = self.activ(x)
        return x


class InterpolationBlock(nn.Module):
    """
    Interpolation upsampling block.

    Parameters:
    ----------
    scale_factor : float
        Multiplier for spatial size.
    out_size : tuple of 2 int, default None
        Spatial size of the output tensor for the bilinear interpolation operation.
    mode : str, default 'bilinear'
        Algorithm used for upsampling.
    align_corners : bool, default True
        Whether to align the corner pixels of the input and output tensors.
    up : bool, default True
        Whether to upsample or downsample.
    """

    def __init__(self, scale_factor, out_size=None, mode='bilinear',
        align_corners=True, up=True):
        super(InterpolationBlock, self).__init__()
        self.scale_factor = scale_factor
        self.out_size = out_size
        self.mode = mode
        self.align_corners = align_corners
        self.up = up

    def forward(self, x, size=None):
        if self.mode == 'bilinear' or size is not None:
            out_size = self.calc_out_size(x) if size is None else size
            return F.interpolate(input=x, size=out_size, mode=self.mode,
                align_corners=self.align_corners)
        else:
            return F.interpolate(input=x, scale_factor=self.scale_factor,
                mode=self.mode, align_corners=self.align_corners)

    def calc_out_size(self, x):
        if self.out_size is not None:
            return self.out_size
        if self.up:
            return tuple(s * self.scale_factor for s in x.shape[2:])
        else:
            return tuple(s // self.scale_factor for s in x.shape[2:])

    def __repr__(self):
        s = (
            '{name}(scale_factor={scale_factor}, out_size={out_size}, mode={mode}, align_corners={align_corners}, up={up})'
            )
        return s.format(name=self.__class__.__name__, scale_factor=self.
            scale_factor, out_size=self.out_size, mode=self.mode,
            align_corners=self.align_corners, up=self.up)

    def calc_flops(self, x):
        assert x.shape[0] == 1
        if self.mode == 'bilinear':
            num_flops = 9 * x.numel()
        else:
            num_flops = 4 * x.numel()
        num_macs = 0
        return num_flops, num_macs


def channel_shuffle(x, groups):
    batchsize, num_channels, height, width = x.data.size()
    channels_per_group = num_channels // groups
    x = x.view(batchsize, groups, channels_per_group, height, width)
    x = torch.transpose(x, 1, 2).contiguous()
    x = x.view(batchsize, -1, height, width)
    return x


class ChannelShuffle(nn.Module):
    """
    Channel shuffle layer. This is a wrapper over the same operation. It is designed to save the number of groups.

    Parameters:
    ----------
    channels : int
        Number of channels.
    groups : int
        Number of groups.
    """

    def __init__(self, channels, groups):
        super(ChannelShuffle, self).__init__()
        if channels % groups != 0:
            raise ValueError('channels must be divisible by groups')
        self.groups = groups

    def forward(self, x):
        return channel_shuffle(x, self.groups)


def channel_shuffle2(x, groups):
    """
    Channel shuffle operation from 'ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices,'
    https://arxiv.org/abs/1707.01083. The alternative version.

    Parameters:
    ----------
    x : Tensor
        Input tensor.
    groups : int
        Number of groups.

    Returns
    -------
    Tensor
        Resulted tensor.
    """
    batch, channels, height, width = x.size()
    channels_per_group = channels // groups
    x = x.view(batch, channels_per_group, groups, height, width)
    x = torch.transpose(x, 1, 2).contiguous()
    x = x.view(batch, channels, height, width)
    return x


class ChannelShuffle2(nn.Module):
    """
    Channel shuffle layer. This is a wrapper over the same operation. It is designed to save the number of groups.
    The alternative version.

    Parameters:
    ----------
    channels : int
        Number of channels.
    groups : int
        Number of groups.
    """

    def __init__(self, channels, groups):
        super(ChannelShuffle2, self).__init__()
        if channels % groups != 0:
            raise ValueError('channels must be divisible by groups')
        self.groups = groups

    def forward(self, x):
        return channel_shuffle2(x, self.groups)


def round_channels(channels, divisor=8):
    """
    Round weighted channel number (make divisible operation).

    Parameters:
    ----------
    channels : int or float
        Original number of channels.
    divisor : int, default 8
        Alignment value.

    Returns
    -------
    int
        Weighted number of channels.
    """
    rounded_channels = max(int(channels + divisor / 2.0) // divisor *
        divisor, divisor)
    if float(rounded_channels) < 0.9 * channels:
        rounded_channels += divisor
    return rounded_channels


class SEBlock(nn.Module):
    """
    Squeeze-and-Excitation block from 'Squeeze-and-Excitation Networks,' https://arxiv.org/abs/1709.01507.

    Parameters:
    ----------
    channels : int
        Number of channels.
    reduction : int, default 16
        Squeeze reduction value.
    round_mid : bool, default False
        Whether to round middle channel number (make divisible by 8).
    use_conv : bool, default True
        Whether to convolutional layers instead of fully-connected ones.
    activation : function, or str, or nn.Module, default 'relu'
        Activation function after the first convolution.
    out_activation : function, or str, or nn.Module, default 'sigmoid'
        Activation function after the last convolution.
    """

    def __init__(self, channels, reduction=16, round_mid=False, use_conv=
        True, mid_activation=lambda : nn.ReLU(inplace=True), out_activation
        =lambda : nn.Sigmoid()):
        super(SEBlock, self).__init__()
        self.use_conv = use_conv
        mid_channels = (channels // reduction if not round_mid else
            round_channels(float(channels) / reduction))
        self.pool = nn.AdaptiveAvgPool2d(output_size=1)
        if use_conv:
            self.conv1 = conv1x1(in_channels=channels, out_channels=
                mid_channels, bias=True)
        else:
            self.fc1 = nn.Linear(in_features=channels, out_features=
                mid_channels)
        self.activ = get_activation_layer(mid_activation)
        if use_conv:
            self.conv2 = conv1x1(in_channels=mid_channels, out_channels=
                channels, bias=True)
        else:
            self.fc2 = nn.Linear(in_features=mid_channels, out_features=
                channels)
        self.sigmoid = get_activation_layer(out_activation)

    def forward(self, x):
        w = self.pool(x)
        if not self.use_conv:
            w = w.view(x.size(0), -1)
        w = self.conv1(w) if self.use_conv else self.fc1(w)
        w = self.activ(w)
        w = self.conv2(w) if self.use_conv else self.fc2(w)
        w = self.sigmoid(w)
        if not self.use_conv:
            w = w.unsqueeze(2).unsqueeze(3)
        x = x * w
        return x


class DucBlock(nn.Module):
    """
    Dense Upsampling Convolution (DUC) block from 'Understanding Convolution for Semantic Segmentation,'
    https://arxiv.org/abs/1702.08502.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    scale_factor : int
        Multiplier for spatial size.
    """

    def __init__(self, in_channels, out_channels, scale_factor):
        super(DucBlock, self).__init__()
        mid_channels = scale_factor * scale_factor * out_channels
        self.conv = conv3x3_block(in_channels=in_channels, out_channels=
            mid_channels)
        self.pix_shuffle = nn.PixelShuffle(upscale_factor=scale_factor)

    def forward(self, x):
        x = self.conv(x)
        x = self.pix_shuffle(x)
        return x


class IBN(nn.Module):
    """
    Instance-Batch Normalization block from 'Two at Once: Enhancing Learning and Generalization Capacities via IBN-Net,'
    https://arxiv.org/abs/1807.09441.

    Parameters:
    ----------
    channels : int
        Number of channels.
    inst_fraction : float, default 0.5
        The first fraction of channels for normalization.
    inst_first : bool, default True
        Whether instance normalization be on the first part of channels.
    """

    def __init__(self, channels, first_fraction=0.5, inst_first=True):
        super(IBN, self).__init__()
        self.inst_first = inst_first
        h1_channels = int(math.floor(channels * first_fraction))
        h2_channels = channels - h1_channels
        self.split_sections = [h1_channels, h2_channels]
        if self.inst_first:
            self.inst_norm = nn.InstanceNorm2d(num_features=h1_channels,
                affine=True)
            self.batch_norm = nn.BatchNorm2d(num_features=h2_channels)
        else:
            self.batch_norm = nn.BatchNorm2d(num_features=h1_channels)
            self.inst_norm = nn.InstanceNorm2d(num_features=h2_channels,
                affine=True)

    def forward(self, x):
        x1, x2 = torch.split(x, split_size_or_sections=self.split_sections,
            dim=1)
        if self.inst_first:
            x1 = self.inst_norm(x1.contiguous())
            x2 = self.batch_norm(x2.contiguous())
        else:
            x1 = self.batch_norm(x1.contiguous())
            x2 = self.inst_norm(x2.contiguous())
        x = torch.cat((x1, x2), dim=1)
        return x


class DualPathSequential(nn.Sequential):
    """
    A sequential container for modules with dual inputs/outputs.
    Modules will be executed in the order they are added.

    Parameters:
    ----------
    return_two : bool, default True
        Whether to return two output after execution.
    first_ordinals : int, default 0
        Number of the first modules with single input/output.
    last_ordinals : int, default 0
        Number of the final modules with single input/output.
    dual_path_scheme : function
        Scheme of dual path response for a module.
    dual_path_scheme_ordinal : function
        Scheme of dual path response for an ordinal module.
    """

    def __init__(self, return_two=True, first_ordinals=0, last_ordinals=0,
        dual_path_scheme=lambda module, x1, x2: module(x1, x2),
        dual_path_scheme_ordinal=lambda module, x1, x2: (module(x1), x2)):
        super(DualPathSequential, self).__init__()
        self.return_two = return_two
        self.first_ordinals = first_ordinals
        self.last_ordinals = last_ordinals
        self.dual_path_scheme = dual_path_scheme
        self.dual_path_scheme_ordinal = dual_path_scheme_ordinal

    def forward(self, x1, x2=None):
        length = len(self._modules.values())
        for i, module in enumerate(self._modules.values()):
            if i < self.first_ordinals or i >= length - self.last_ordinals:
                x1, x2 = self.dual_path_scheme_ordinal(module, x1, x2)
            else:
                x1, x2 = self.dual_path_scheme(module, x1, x2)
        if self.return_two:
            return x1, x2
        else:
            return x1


class Concurrent(nn.Sequential):
    """
    A container for concatenation of modules on the base of the sequential container.

    Parameters:
    ----------
    axis : int, default 1
        The axis on which to concatenate the outputs.
    stack : bool, default False
        Whether to concatenate tensors along a new dimension.
    """

    def __init__(self, axis=1, stack=False):
        super(Concurrent, self).__init__()
        self.axis = axis
        self.stack = stack

    def forward(self, x):
        out = []
        for module in self._modules.values():
            out.append(module(x))
        if self.stack:
            out = torch.stack(tuple(out), dim=self.axis)
        else:
            out = torch.cat(tuple(out), dim=self.axis)
        return out


class SequentialConcurrent(nn.Sequential):
    """
    A sequential container with concatenated outputs.
    Modules will be executed in the order they are added.

    Parameters:
    ----------
    axis : int, default 1
        The axis on which to concatenate the outputs.
    stack : bool, default False
        Whether to concatenate tensors along a new dimension.
    cat_input : bool, default True
        Whether to concatenate input tensor.
    """

    def __init__(self, axis=1, stack=False, cat_input=True):
        super(SequentialConcurrent, self).__init__()
        self.axis = axis
        self.stack = stack
        self.cat_input = cat_input

    def forward(self, x):
        out = [x] if self.cat_input else []
        for module in self._modules.values():
            x = module(x)
            out.append(x)
        if self.stack:
            out = torch.stack(tuple(out), dim=self.axis)
        else:
            out = torch.cat(tuple(out), dim=self.axis)
        return out


class ParametricSequential(nn.Sequential):
    """
    A sequential container for modules with parameters.
    Modules will be executed in the order they are added.
    """

    def __init__(self, *args):
        super(ParametricSequential, self).__init__(*args)

    def forward(self, x, **kwargs):
        for module in self._modules.values():
            x = module(x, **kwargs)
        return x


class ParametricConcurrent(nn.Sequential):
    """
    A container for concatenation of modules with parameters.

    Parameters:
    ----------
    axis : int, default 1
        The axis on which to concatenate the outputs.
    """

    def __init__(self, axis=1):
        super(ParametricConcurrent, self).__init__()
        self.axis = axis

    def forward(self, x, **kwargs):
        out = []
        for module in self._modules.values():
            out.append(module(x, **kwargs))
        out = torch.cat(tuple(out), dim=self.axis)
        return out


class Hourglass(nn.Module):
    """
    A hourglass block.

    Parameters:
    ----------
    down_seq : nn.Sequential
        Down modules as sequential.
    up_seq : nn.Sequential
        Up modules as sequential.
    skip_seq : nn.Sequential
        Skip connection modules as sequential.
    merge_type : str, default 'add'
        Type of concatenation of up and skip outputs.
    return_first_skip : bool, default False
        Whether return the first skip connection output. Used in ResAttNet.
    """

    def __init__(self, down_seq, up_seq, skip_seq, merge_type='add',
        return_first_skip=False):
        super(Hourglass, self).__init__()
        self.depth = len(down_seq)
        assert merge_type in ['add']
        assert len(up_seq) == self.depth
        assert len(skip_seq) in (self.depth, self.depth + 1)
        self.merge_type = merge_type
        self.return_first_skip = return_first_skip
        self.extra_skip = len(skip_seq) == self.depth + 1
        self.down_seq = down_seq
        self.up_seq = up_seq
        self.skip_seq = skip_seq

    def forward(self, x, **kwargs):
        y = None
        down_outs = [x]
        for down_module in self.down_seq._modules.values():
            x = down_module(x)
            down_outs.append(x)
        for i in range(len(down_outs)):
            if i != 0:
                y = down_outs[self.depth - i]
                skip_module = self.skip_seq[self.depth - i]
                y = skip_module(y)
                if y is not None and self.merge_type == 'add':
                    x = x + y
            if i != len(down_outs) - 1:
                if i == 0 and self.extra_skip:
                    skip_module = self.skip_seq[self.depth]
                    x = skip_module(x)
                up_module = self.up_seq[self.depth - 1 - i]
                x = up_module(x)
        if self.return_first_skip:
            return x, y
        else:
            return x


class SesquialteralHourglass(nn.Module):
    """
    A sesquialteral hourglass block.

    Parameters:
    ----------
    down1_seq : nn.Sequential
        The first down modules as sequential.
    skip1_seq : nn.Sequential
        The first skip connection modules as sequential.
    up_seq : nn.Sequential
        Up modules as sequential.
    skip2_seq : nn.Sequential
        The second skip connection modules as sequential.
    down2_seq : nn.Sequential
        The second down modules as sequential.
    merge_type : str, default 'cat'
        Type of concatenation of up and skip outputs.
    """

    def __init__(self, down1_seq, skip1_seq, up_seq, skip2_seq, down2_seq,
        merge_type='cat'):
        super(SesquialteralHourglass, self).__init__()
        assert len(down1_seq) == len(up_seq)
        assert len(down1_seq) == len(down2_seq)
        assert len(skip1_seq) == len(skip2_seq)
        assert len(down1_seq) == len(skip1_seq) - 1
        assert merge_type in ['cat', 'add']
        self.merge_type = merge_type
        self.depth = len(down1_seq)
        self.down1_seq = down1_seq
        self.skip1_seq = skip1_seq
        self.up_seq = up_seq
        self.skip2_seq = skip2_seq
        self.down2_seq = down2_seq

    def _merge(self, x, y):
        if y is not None:
            if self.merge_type == 'cat':
                x = torch.cat((x, y), dim=1)
            elif self.merge_type == 'add':
                x = x + y
        return x

    def forward(self, x, **kwargs):
        y = self.skip1_seq[0](x)
        skip1_outs = [y]
        for i in range(self.depth):
            x = self.down1_seq[i](x)
            y = self.skip1_seq[i + 1](x)
            skip1_outs.append(y)
        x = skip1_outs[self.depth]
        y = self.skip2_seq[0](x)
        skip2_outs = [y]
        for i in range(self.depth):
            x = self.up_seq[i](x)
            y = skip1_outs[self.depth - 1 - i]
            x = self._merge(x, y)
            y = self.skip2_seq[i + 1](x)
            skip2_outs.append(y)
        x = self.skip2_seq[self.depth](x)
        for i in range(self.depth):
            x = self.down2_seq[i](x)
            y = skip2_outs[self.depth - 1 - i]
            x = self._merge(x, y)
        return x


class MultiOutputSequential(nn.Sequential):
    """
    A sequential container with multiple outputs.
    Modules will be executed in the order they are added.

    Parameters:
    ----------
    multi_output : bool, default True
        Whether to return multiple output.
    dual_output : bool, default False
        Whether to return dual output.
    return_last : bool, default True
        Whether to forcibly return last value.
    """

    def __init__(self, multi_output=True, dual_output=False, return_last=True):
        super(MultiOutputSequential, self).__init__()
        self.multi_output = multi_output
        self.dual_output = dual_output
        self.return_last = return_last

    def forward(self, x):
        outs = []
        for module in self._modules.values():
            x = module(x)
            if hasattr(module, 'do_output') and module.do_output:
                outs.append(x)
            elif hasattr(module, 'do_output2') and module.do_output2:
                assert type(x) == tuple
                outs.extend(x[1])
                x = x[0]
        if self.multi_output:
            return [x] + outs if self.return_last else outs
        elif self.dual_output:
            return x, outs
        else:
            return x


class ParallelConcurent(nn.Sequential):
    """
    A sequential container with multiple inputs and multiple outputs.
    Modules will be executed in the order they are added.
    """

    def __init__(self):
        super(ParallelConcurent, self).__init__()

    def forward(self, x):
        out = []
        for module, xi in zip(self._modules.values(), x):
            out.append(module(xi))
        return out


class Flatten(nn.Module):
    """
    Simple flatten module.
    """

    def forward(self, x):
        return x.view(x.size(0), -1)


class HeatmapMaxDetBlock(nn.Module):
    """
    Heatmap maximum detector block (for human pose estimation task).
    """

    def __init__(self):
        super(HeatmapMaxDetBlock, self).__init__()

    def forward(self, x):
        heatmap = x
        vector_dim = 2
        batch = heatmap.shape[0]
        channels = heatmap.shape[1]
        in_size = x.shape[2:]
        heatmap_vector = heatmap.view(batch, channels, -1)
        scores, indices = heatmap_vector.max(dim=vector_dim, keepdims=True)
        scores_mask = (scores > 0.0).float()
        pts_x = indices % in_size[1] * scores_mask
        pts_y = indices // in_size[1] * scores_mask
        pts = torch.cat((pts_x, pts_y, scores), dim=vector_dim)
        for b in range(batch):
            for k in range(channels):
                hm = heatmap[(b), (k), :, :]
                px = int(pts[b, k, 0])
                py = int(pts[b, k, 1])
                if 0 < px < in_size[1] - 1 and 0 < py < in_size[0] - 1:
                    pts[b, k, 0] += (hm[py, px + 1] - hm[py, px - 1]).sign(
                        ) * 0.25
                    pts[b, k, 1] += (hm[py + 1, px] - hm[py - 1, px]).sign(
                        ) * 0.25
        return pts

    @staticmethod
    def calc_flops(x):
        assert x.shape[0] == 1
        num_flops = x.numel() + 26 * x.shape[1]
        num_macs = 0
        return num_flops, num_macs


class CondenseSimpleConv(nn.Module):
    """
    CondenseNet specific simple convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    groups : int
        Number of groups.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, groups):
        super(CondenseSimpleConv, self).__init__()
        self.bn = nn.BatchNorm2d(num_features=in_channels)
        self.activ = nn.ReLU(inplace=True)
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, groups=groups, bias=False)

    def forward(self, x):
        x = self.bn(x)
        x = self.activ(x)
        x = self.conv(x)
        return x


class CondenseComplexConv(nn.Module):
    """
    CondenseNet specific complex convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    groups : int
        Number of groups.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, groups):
        super(CondenseComplexConv, self).__init__()
        self.bn = nn.BatchNorm2d(num_features=in_channels)
        self.activ = nn.ReLU(inplace=True)
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, groups=groups, bias=False)
        self.c_shuffle = ChannelShuffle(channels=out_channels, groups=groups)
        self.register_buffer('index', torch.LongTensor(in_channels))
        self.index.fill_(0)

    def forward(self, x):
        x = torch.index_select(x, dim=1, index=Variable(self.index))
        x = self.bn(x)
        x = self.activ(x)
        x = self.conv(x)
        x = self.c_shuffle(x)
        return x


def condense_simple_conv3x3(in_channels, out_channels, groups):
    """
    3x3 version of the CondenseNet specific simple convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    groups : int
        Number of groups.
    """
    return CondenseSimpleConv(in_channels=in_channels, out_channels=
        out_channels, kernel_size=3, stride=1, padding=1, groups=groups)


def condense_complex_conv1x1(in_channels, out_channels, groups):
    """
    1x1 version of the CondenseNet specific complex convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    groups : int
        Number of groups.
    """
    return CondenseComplexConv(in_channels=in_channels, out_channels=
        out_channels, kernel_size=1, stride=1, padding=0, groups=groups)


class CondenseUnit(nn.Module):
    """
    CondenseNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    groups : int
        Number of groups.
    """

    def __init__(self, in_channels, out_channels, groups):
        super(CondenseUnit, self).__init__()
        bottleneck_size = 4
        inc_channels = out_channels - in_channels
        mid_channels = inc_channels * bottleneck_size
        self.conv1 = condense_complex_conv1x1(in_channels=in_channels,
            out_channels=mid_channels, groups=groups)
        self.conv2 = condense_simple_conv3x3(in_channels=mid_channels,
            out_channels=inc_channels, groups=groups)

    def forward(self, x):
        identity = x
        x = self.conv1(x)
        x = self.conv2(x)
        x = torch.cat((identity, x), dim=1)
        return x


class TransitionBlock(nn.Module):
    """
    CondenseNet's auxiliary block, which can be treated as the initial part of the DenseNet unit, triggered only in the
    first unit of each stage.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self):
        super(TransitionBlock, self).__init__()
        self.pool = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)

    def forward(self, x):
        x = self.pool(x)
        return x


class CondenseInitBlock(nn.Module):
    """
    CondenseNet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(CondenseInitBlock, self).__init__()
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=3, stride=2, padding=1, bias=False)

    def forward(self, x):
        x = self.conv(x)
        return x


class PostActivation(nn.Module):
    """
    CondenseNet final block, which performs the same function of postactivation as in PreResNet.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    """

    def __init__(self, in_channels):
        super(PostActivation, self).__init__()
        self.bn = nn.BatchNorm2d(num_features=in_channels)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.bn(x)
        x = self.activ(x)
        return x


class CondenseLinear(nn.Module):
    """
    CondenseNet specific linear block.

    Parameters:
    ----------
    in_features : int
        Number of input channels.
    out_features : int
        Number of output channels.
    drop_rate : float
        Fraction of input channels for drop.
    """

    def __init__(self, in_features, out_features, drop_rate=0.5):
        super(CondenseLinear, self).__init__()
        drop_in_features = int(in_features * drop_rate)
        self.linear = nn.Linear(in_features=drop_in_features, out_features=
            out_features)
        self.register_buffer('index', torch.LongTensor(drop_in_features))
        self.index.fill_(0)

    def forward(self, x):
        x = torch.index_select(x, dim=1, index=Variable(self.index))
        x = self.linear(x)
        return x


class CondenseNet(nn.Module):
    """
    CondenseNet model (converted) from 'CondenseNet: An Efficient DenseNet using Learned Group Convolutions,'
    https://arxiv.org/abs/1711.09224.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    groups : int
        Number of groups in convolution layers.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, groups, in_channels=3,
        in_size=(224, 224), num_classes=1000):
        super(CondenseNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', CondenseInitBlock(
            in_channels=in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            if i != 0:
                stage.add_module('trans{}'.format(i + 1), TransitionBlock())
            for j, out_channels in enumerate(channels_per_stage):
                stage.add_module('unit{}'.format(j + 1), CondenseUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    groups=groups))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('post_activ', PostActivation(in_channels=
            in_channels))
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = CondenseLinear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)
            elif isinstance(module, nn.BatchNorm2d):
                init.constant_(module.weight, 1)
                init.constant_(module.bias, 0)
            elif isinstance(module, nn.Linear):
                init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


def dark_convYxY(in_channels, out_channels, alpha, pointwise):
    """
    DarkNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    alpha : float
        Slope coefficient for Leaky ReLU activation.
    pointwise : bool
        Whether use 1x1 (pointwise) convolution or 3x3 convolution.
    """
    if pointwise:
        return conv1x1_block(in_channels=in_channels, out_channels=
            out_channels, activation=nn.LeakyReLU(negative_slope=alpha,
            inplace=True))
    else:
        return conv3x3_block(in_channels=in_channels, out_channels=
            out_channels, activation=nn.LeakyReLU(negative_slope=alpha,
            inplace=True))


class DarkNet(nn.Module):
    """
    DarkNet model from 'Darknet: Open source neural networks in c,' https://github.com/pjreddie/darknet.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    odd_pointwise : bool
        Whether pointwise convolution layer is used for each odd unit.
    avg_pool_size : int
        Window size of the final average pooling.
    cls_activ : bool
        Whether classification convolution layer uses an activation.
    alpha : float, default 0.1
        Slope coefficient for Leaky ReLU activation.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, odd_pointwise, avg_pool_size, cls_activ,
        alpha=0.1, in_channels=3, in_size=(224, 224), num_classes=1000):
        super(DarkNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stage.add_module('unit{}'.format(j + 1), dark_convYxY(
                    in_channels=in_channels, out_channels=out_channels,
                    alpha=alpha, pointwise=len(channels_per_stage) > 1 and 
                    not ((j + 1) % 2 == 1) ^ odd_pointwise))
                in_channels = out_channels
            if i != len(channels) - 1:
                stage.add_module('pool{}'.format(i + 1), nn.MaxPool2d(
                    kernel_size=2, stride=2))
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.output = nn.Sequential()
        self.output.add_module('final_conv', nn.Conv2d(in_channels=
            in_channels, out_channels=num_classes, kernel_size=1))
        if cls_activ:
            self.output.add_module('final_activ', nn.LeakyReLU(
                negative_slope=alpha, inplace=True))
        self.output.add_module('final_pool', nn.AvgPool2d(kernel_size=
            avg_pool_size, stride=1))
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                if 'final_conv' in name:
                    init.normal_(module.weight, mean=0.0, std=0.01)
                else:
                    init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = self.output(x)
        x = x.view(x.size(0), -1)
        return x


class DarkUnit(nn.Module):
    """
    DarkNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    alpha : float
        Slope coefficient for Leaky ReLU activation.
    """

    def __init__(self, in_channels, out_channels, alpha):
        super(DarkUnit, self).__init__()
        assert out_channels % 2 == 0
        mid_channels = out_channels // 2
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            mid_channels, activation=nn.LeakyReLU(negative_slope=alpha,
            inplace=True))
        self.conv2 = conv3x3_block(in_channels=mid_channels, out_channels=
            out_channels, activation=nn.LeakyReLU(negative_slope=alpha,
            inplace=True))

    def forward(self, x):
        identity = x
        x = self.conv1(x)
        x = self.conv2(x)
        return x + identity


class DarkNet53(nn.Module):
    """
    DarkNet-53 model from 'YOLOv3: An Incremental Improvement,' https://arxiv.org/abs/1804.02767.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    alpha : float, default 0.1
        Slope coefficient for Leaky ReLU activation.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, alpha=0.1,
        in_channels=3, in_size=(224, 224), num_classes=1000):
        super(DarkNet53, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', conv3x3_block(in_channels=
            in_channels, out_channels=init_block_channels, activation=nn.
            LeakyReLU(negative_slope=alpha, inplace=True)))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                if j == 0:
                    stage.add_module('unit{}'.format(j + 1), conv3x3_block(
                        in_channels=in_channels, out_channels=out_channels,
                        stride=2, activation=nn.LeakyReLU(negative_slope=
                        alpha, inplace=True)))
                else:
                    stage.add_module('unit{}'.format(j + 1), DarkUnit(
                        in_channels=in_channels, out_channels=out_channels,
                        alpha=alpha))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class DwsConv(nn.Module):
    """
    Standard dilated depthwise separable convolution block with.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int
        Dilation value for convolution layer.
    bias : bool, default False
        Whether the layers use a bias vector.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, dilation, bias=False):
        super(DwsConv, self).__init__()
        self.dw_conv = nn.Conv2d(in_channels=in_channels, out_channels=
            in_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, dilation=dilation, groups=in_channels, bias=bias)
        self.pw_conv = conv1x1(in_channels=in_channels, out_channels=
            out_channels, bias=bias)

    def forward(self, x):
        x = self.dw_conv(x)
        x = self.pw_conv(x)
        return x


class DartsConv(nn.Module):
    """
    DARTS specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    activate : bool, default True
        Whether activate the convolution block.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, activate=True):
        super(DartsConv, self).__init__()
        self.activate = activate
        if self.activate:
            self.activ = nn.ReLU(inplace=False)
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, bias=False)
        self.bn = nn.BatchNorm2d(num_features=out_channels)

    def forward(self, x):
        if self.activate:
            x = self.activ(x)
        x = self.conv(x)
        x = self.bn(x)
        return x


class DartsDwsConv(nn.Module):
    """
    DARTS specific dilated convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int
        Dilation value for convolution layer.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, dilation):
        super(DartsDwsConv, self).__init__()
        self.activ = nn.ReLU(inplace=False)
        self.conv = DwsConv(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, dilation=dilation, bias=False)
        self.bn = nn.BatchNorm2d(num_features=out_channels)

    def forward(self, x):
        x = self.activ(x)
        x = self.conv(x)
        x = self.bn(x)
        return x


class DartsDwsBranch(nn.Module):
    """
    DARTS specific block with depthwise separable convolution layers.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride, padding
        ):
        super(DartsDwsBranch, self).__init__()
        mid_channels = in_channels
        self.conv1 = DartsDwsConv(in_channels=in_channels, out_channels=
            mid_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, dilation=1)
        self.conv2 = DartsDwsConv(in_channels=mid_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=1, padding=
            padding, dilation=1)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class DartsReduceBranch(nn.Module):
    """
    DARTS specific factorized reduce block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 2
        Strides of the convolution.
    """

    def __init__(self, in_channels, out_channels, stride=2):
        super(DartsReduceBranch, self).__init__()
        assert out_channels % 2 == 0
        mid_channels = out_channels // 2
        self.activ = nn.ReLU(inplace=False)
        self.conv1 = conv1x1(in_channels=in_channels, out_channels=
            mid_channels, stride=stride)
        self.conv2 = conv1x1(in_channels=in_channels, out_channels=
            mid_channels, stride=stride)
        self.bn = nn.BatchNorm2d(num_features=out_channels)

    def forward(self, x):
        x = self.activ(x)
        x1 = self.conv1(x)
        x = x[:, :, 1:, 1:].contiguous()
        x2 = self.conv2(x)
        x = torch.cat((x1, x2), dim=1)
        x = self.bn(x)
        return x


def darts_conv3x3_s2(in_channels, out_channels, activate=True):
    """
    3x3 version of the DARTS specific convolution block with stride 2.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    activate : bool, default True
        Whether activate the convolution block.
    """
    return DartsConv(in_channels=in_channels, out_channels=out_channels,
        kernel_size=3, stride=2, padding=1, activate=activate)


class Stem1Unit(nn.Module):
    """
    DARTS Stem1 unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(Stem1Unit, self).__init__()
        mid_channels = out_channels // 2
        self.conv1 = darts_conv3x3_s2(in_channels=in_channels, out_channels
            =mid_channels, activate=False)
        self.conv2 = darts_conv3x3_s2(in_channels=mid_channels,
            out_channels=out_channels, activate=True)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


def darts_maxpool3x3(channels, stride):
    """
    DARTS specific 3x3 Max pooling layer.

    Parameters:
    ----------
    channels : int
        Number of input/output channels. Unused parameter.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    """
    assert channels > 0
    return nn.MaxPool2d(kernel_size=3, stride=stride, padding=1)


def darts_dws_conv3x3(channels, stride):
    """
    3x3 version of DARTS specific dilated convolution block.

    Parameters:
    ----------
    channels : int
        Number of input/output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    """
    return DartsDwsConv(in_channels=channels, out_channels=channels,
        kernel_size=3, stride=stride, padding=2, dilation=2)


def darts_dws_branch3x3(channels, stride):
    """
    3x3 version of DARTS specific dilated convolution branch.

    Parameters:
    ----------
    channels : int
        Number of input/output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    """
    return DartsDwsBranch(in_channels=channels, out_channels=channels,
        kernel_size=3, stride=stride, padding=1)


def darts_skip_connection(channels, stride):
    """
    DARTS specific skip connection layer.

    Parameters:
    ----------
    channels : int
        Number of input/output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    """
    assert channels > 0
    if stride == 1:
        return Identity()
    else:
        assert stride == 2
        return DartsReduceBranch(in_channels=channels, out_channels=
            channels, stride=stride)


GENOTYPE_OPS = {'max_pool_3x3': darts_maxpool3x3, 'skip_connect':
    darts_skip_connection, 'dil_conv_3x3': darts_dws_conv3x3,
    'sep_conv_3x3': darts_dws_branch3x3}


class DartsMainBlock(nn.Module):
    """
    DARTS main block, described by genotype.

    Parameters:
    ----------
    genotype : list of tuples (str, int)
        List of genotype elements (operations and linked indices).
    channels : int
        Number of input/output channels.
    reduction : bool
        Whether use reduction.
    """

    def __init__(self, genotype, channels, reduction):
        super(DartsMainBlock, self).__init__()
        self.concat = [2, 3, 4, 5]
        op_names, indices = zip(*genotype)
        self.indices = indices
        self.steps = len(op_names) // 2
        self.ops = nn.ModuleList()
        for name, index in zip(op_names, indices):
            stride = 2 if reduction and index < 2 else 1
            op = GENOTYPE_OPS[name](channels, stride)
            self.ops += [op]

    def forward(self, x, x_prev):
        s0 = x_prev
        s1 = x
        states = [s0, s1]
        for i in range(self.steps):
            j1 = 2 * i
            j2 = 2 * i + 1
            op1 = self.ops[j1]
            op2 = self.ops[j2]
            y1 = states[self.indices[j1]]
            y2 = states[self.indices[j2]]
            y1 = op1(y1)
            y2 = op2(y2)
            s = y1 + y2
            states += [s]
        x_out = torch.cat([states[i] for i in self.concat], dim=1)
        return x_out


def darts_conv1x1(in_channels, out_channels, activate=True):
    """
    1x1 version of the DARTS specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    activate : bool, default True
        Whether activate the convolution block.
    """
    return DartsConv(in_channels=in_channels, out_channels=out_channels,
        kernel_size=1, stride=1, padding=0, activate=activate)


class DartsUnit(nn.Module):
    """
    DARTS unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    prev_in_channels : int
        Number of input channels in previous input.
    out_channels : int
        Number of output channels.
    genotype : list of tuples (str, int)
        List of genotype elements (operations and linked indices).
    reduction : bool
        Whether use reduction.
    """

    def __init__(self, in_channels, prev_in_channels, out_channels,
        genotype, reduction, prev_reduction):
        super(DartsUnit, self).__init__()
        mid_channels = out_channels // 4
        if prev_reduction:
            self.preprocess_prev = DartsReduceBranch(in_channels=
                prev_in_channels, out_channels=mid_channels)
        else:
            self.preprocess_prev = darts_conv1x1(in_channels=
                prev_in_channels, out_channels=mid_channels)
        self.preprocess = darts_conv1x1(in_channels=in_channels,
            out_channels=mid_channels)
        self.body = DartsMainBlock(genotype=genotype, channels=mid_channels,
            reduction=reduction)

    def forward(self, x, x_prev):
        x = self.preprocess(x)
        x_prev = self.preprocess_prev(x_prev)
        x_out = self.body(x, x_prev)
        return x_out


class NasDualPathScheme(object):
    """
    NASNet specific scheme of dual path response for a module in a DualPathSequential module.

    Parameters:
    ----------
    can_skip_input : bool
        Whether can skip input for some modules.
    """

    def __init__(self, can_skip_input):
        super(NasDualPathScheme, self).__init__()
        self.can_skip_input = can_skip_input
    """
    Scheme function.

    Parameters:
    ----------
    module : nn.Module
        A module.
    x : Tensor
        Current processed tensor.
    x_prev : Tensor
        Previous processed tensor.

    Returns
    -------
    x_next : Tensor
        Next processed tensor.
    x : Tensor
        Current processed tensor.
    """

    def __call__(self, module, x, x_prev):
        x_next = module(x, x_prev)
        if type(x_next) == tuple:
            x_next, x = x_next
        if self.can_skip_input and hasattr(module, 'skip_input'
            ) and module.skip_input:
            x = x_prev
        return x_next, x


def nasnet_dual_path_scheme_ordinal(module, x, _):
    """
    NASNet specific scheme of dual path response for an ordinal module with dual inputs/outputs in a DualPathSequential
    module.

    Parameters:
    ----------
    module : nn.Module
        A module.
    x : Tensor
        Current processed tensor.

    Returns
    -------
    x_next : Tensor
        Next processed tensor.
    x : Tensor
        Current processed tensor.
    """
    return module(x), x


def nasnet_dual_path_sequential(return_two=True, first_ordinals=0,
    last_ordinals=0, can_skip_input=False):
    """
    NASNet specific dual path sequential container.

    Parameters:
    ----------
    return_two : bool, default True
        Whether to return two output after execution.
    first_ordinals : int, default 0
        Number of the first modules with single input/output.
    last_ordinals : int, default 0
        Number of the final modules with single input/output.
    dual_path_scheme : function
        Scheme of dual path response for a module.
    dual_path_scheme_ordinal : function
        Scheme of dual path response for an ordinal module.
    can_skip_input : bool, default False
        Whether can skip input for some modules.
    """
    return DualPathSequential(return_two=return_two, first_ordinals=
        first_ordinals, last_ordinals=last_ordinals, dual_path_scheme=
        NasDualPathScheme(can_skip_input=can_skip_input),
        dual_path_scheme_ordinal=nasnet_dual_path_scheme_ordinal)


def stem2_unit(in_channels, out_channels):
    """
    DARTS Stem2 unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """
    return darts_conv3x3_s2(in_channels=in_channels, out_channels=
        out_channels, activate=True)


class DARTS(nn.Module):
    """
    DARTS model from 'DARTS: Differentiable Architecture Search,' https://arxiv.org/abs/1806.09055.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    stem_blocks_channels : int
        Number of output channels for the Stem units.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, stem_blocks_channels, normal_genotype,
        reduce_genotype, in_channels=3, in_size=(224, 224), num_classes=1000):
        super(DARTS, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nasnet_dual_path_sequential(return_two=False,
            first_ordinals=2, last_ordinals=1)
        self.features.add_module('stem1_unit', Stem1Unit(in_channels=
            in_channels, out_channels=stem_blocks_channels))
        in_channels = stem_blocks_channels
        self.features.add_module('stem2_unit', stem2_unit(in_channels=
            in_channels, out_channels=stem_blocks_channels))
        prev_in_channels = in_channels
        in_channels = stem_blocks_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nasnet_dual_path_sequential()
            for j, out_channels in enumerate(channels_per_stage):
                reduction = i != 0 and j == 0
                prev_reduction = i == 0 and j == 0 or i != 0 and j == 1
                genotype = reduce_genotype if reduction else normal_genotype
                stage.add_module('unit{}'.format(j + 1), DartsUnit(
                    in_channels=in_channels, prev_in_channels=
                    prev_in_channels, out_channels=out_channels, genotype=
                    genotype, reduction=reduction, prev_reduction=
                    prev_reduction))
                prev_in_channels = in_channels
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class DeepLabv3FinalBlock(nn.Module):
    """
    DeepLabv3 final block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    bottleneck_factor : int, default 4
        Bottleneck factor.
    """

    def __init__(self, in_channels, out_channels, bottleneck_factor=4):
        super(DeepLabv3FinalBlock, self).__init__()
        assert in_channels % bottleneck_factor == 0
        mid_channels = in_channels // bottleneck_factor
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            mid_channels)
        self.dropout = nn.Dropout(p=0.1, inplace=False)
        self.conv2 = conv1x1(in_channels=mid_channels, out_channels=
            out_channels, bias=True)

    def forward(self, x, out_size):
        x = self.conv1(x)
        x = self.dropout(x)
        x = self.conv2(x)
        x = F.interpolate(x, size=out_size, mode='bilinear', align_corners=True
            )
        return x


class ASPPAvgBranch(nn.Module):
    """
    ASPP branch with average pooling.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    upscale_out_size : tuple of 2 int
        Spatial size of output image for the bilinear upsampling operation.
    """

    def __init__(self, in_channels, out_channels, upscale_out_size):
        super(ASPPAvgBranch, self).__init__()
        self.upscale_out_size = upscale_out_size
        self.pool = nn.AdaptiveAvgPool2d(1)
        self.conv = conv1x1_block(in_channels=in_channels, out_channels=
            out_channels)

    def forward(self, x):
        in_size = (self.upscale_out_size if self.upscale_out_size is not
            None else x.shape[2:])
        x = self.pool(x)
        x = self.conv(x)
        x = F.interpolate(x, size=in_size, mode='bilinear', align_corners=True)
        return x


class AtrousSpatialPyramidPooling(nn.Module):
    """
    Atrous Spatial Pyramid Pooling (ASPP) module.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    upscale_out_size : tuple of 2 int
        Spatial size of the input tensor for the bilinear upsampling operation.
    """

    def __init__(self, in_channels, upscale_out_size):
        super(AtrousSpatialPyramidPooling, self).__init__()
        atrous_rates = [12, 24, 36]
        assert in_channels % 8 == 0
        mid_channels = in_channels // 8
        project_in_channels = 5 * mid_channels
        self.branches = Concurrent()
        self.branches.add_module('branch1', conv1x1_block(in_channels=
            in_channels, out_channels=mid_channels))
        for i, atrous_rate in enumerate(atrous_rates):
            self.branches.add_module('branch{}'.format(i + 2),
                conv3x3_block(in_channels=in_channels, out_channels=
                mid_channels, padding=atrous_rate, dilation=atrous_rate))
        self.branches.add_module('branch5', ASPPAvgBranch(in_channels=
            in_channels, out_channels=mid_channels, upscale_out_size=
            upscale_out_size))
        self.conv = conv1x1_block(in_channels=project_in_channels,
            out_channels=mid_channels)
        self.dropout = nn.Dropout(p=0.5, inplace=False)

    def forward(self, x):
        x = self.branches(x)
        x = self.conv(x)
        x = self.dropout(x)
        return x


class DeepLabv3(nn.Module):
    """
    DeepLabv3 model from 'Rethinking Atrous Convolution for Semantic Image Segmentation,'
    https://arxiv.org/abs/1706.05587.

    Parameters:
    ----------
    backbone : nn.Sequential
        Feature extractor.
    backbone_out_channels : int, default 2048
        Number of output channels form feature extractor.
    aux : bool, default False
        Whether to output an auxiliary result.
    fixed_size : bool, default True
        Whether to expect fixed spatial size of input image.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (480, 480)
        Spatial size of the expected input image.
    num_classes : int, default 21
        Number of segmentation classes.
    """

    def __init__(self, backbone, backbone_out_channels=2048, aux=False,
        fixed_size=True, in_channels=3, in_size=(480, 480), num_classes=21):
        super(DeepLabv3, self).__init__()
        assert in_channels > 0
        self.in_size = in_size
        self.num_classes = num_classes
        self.aux = aux
        self.fixed_size = fixed_size
        self.backbone = backbone
        pool_out_size = (self.in_size[0] // 8, self.in_size[1] // 8
            ) if fixed_size else None
        self.pool = AtrousSpatialPyramidPooling(in_channels=
            backbone_out_channels, upscale_out_size=pool_out_size)
        pool_out_channels = backbone_out_channels // 8
        self.final_block = DeepLabv3FinalBlock(in_channels=
            pool_out_channels, out_channels=num_classes, bottleneck_factor=1)
        if self.aux:
            aux_out_channels = backbone_out_channels // 2
            self.aux_block = DeepLabv3FinalBlock(in_channels=
                aux_out_channels, out_channels=num_classes, bottleneck_factor=4
                )
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        in_size = self.in_size if self.fixed_size else x.shape[2:]
        x, y = self.backbone(x)
        x = self.pool(x)
        x = self.final_block(x, in_size)
        if self.aux:
            y = self.aux_block(y, in_size)
            return x, y
        else:
            return x


def pre_conv3x3_block(in_channels, out_channels, stride=1, padding=1,
    dilation=1, bias=False, use_bn=True, return_preact=False, activate=True):
    """
    3x3 version of the pre-activated convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 1
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    bias : bool, default False
        Whether the layer uses a bias vector.
    use_bn : bool, default True
        Whether to use BatchNorm layer.
    return_preact : bool, default False
        Whether return pre-activation.
    activate : bool, default True
        Whether activate the convolution block.
    """
    return PreConvBlock(in_channels=in_channels, out_channels=out_channels,
        kernel_size=3, stride=stride, padding=padding, dilation=dilation,
        bias=bias, use_bn=use_bn, return_preact=return_preact, activate=
        activate)


class DenseUnit(nn.Module):
    """
    DenseNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    dropout_rate : float
        Parameter of Dropout layer. Faction of the input units to drop.
    """

    def __init__(self, in_channels, out_channels, dropout_rate):
        super(DenseUnit, self).__init__()
        self.use_dropout = dropout_rate != 0.0
        bn_size = 4
        inc_channels = out_channels - in_channels
        mid_channels = inc_channels * bn_size
        self.conv1 = pre_conv1x1_block(in_channels=in_channels,
            out_channels=mid_channels)
        self.conv2 = pre_conv3x3_block(in_channels=mid_channels,
            out_channels=inc_channels)
        if self.use_dropout:
            self.dropout = nn.Dropout(p=dropout_rate)

    def forward(self, x):
        identity = x
        x = self.conv1(x)
        x = self.conv2(x)
        if self.use_dropout:
            x = self.dropout(x)
        x = torch.cat((identity, x), dim=1)
        return x


class TransitionBlock(nn.Module):
    """
    DenseNet's auxiliary block, which can be treated as the initial part of the DenseNet unit, triggered only in the
    first unit of each stage.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(TransitionBlock, self).__init__()
        self.conv = pre_conv1x1_block(in_channels=in_channels, out_channels
            =out_channels)
        self.pool = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)

    def forward(self, x):
        x = self.conv(x)
        x = self.pool(x)
        return x


class DenseSimpleUnit(nn.Module):
    """
    DenseNet simple unit for CIFAR.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    dropout_rate : float
        Parameter of Dropout layer. Faction of the input units to drop.
    """

    def __init__(self, in_channels, out_channels, dropout_rate):
        super(DenseSimpleUnit, self).__init__()
        self.use_dropout = dropout_rate != 0.0
        inc_channels = out_channels - in_channels
        self.conv = pre_conv3x3_block(in_channels=in_channels, out_channels
            =inc_channels)
        if self.use_dropout:
            self.dropout = nn.Dropout(p=dropout_rate)

    def forward(self, x):
        identity = x
        x = self.conv(x)
        if self.use_dropout:
            x = self.dropout(x)
        x = torch.cat((identity, x), dim=1)
        return x


class FirstLSTMAmp(nn.Module):
    """
    First LSTM amplifier branch.

    Parameters:
    ----------
    in_features : int
        Number of input channels.
    out_features : int
        Number of output channels.
    """

    def __init__(self, in_features, out_features):
        super(FirstLSTMAmp, self).__init__()
        mid_features = in_features // 4
        self.fc1 = nn.Linear(in_features=in_features, out_features=mid_features
            )
        self.activ = nn.ReLU(inplace=True)
        self.fc2 = nn.Linear(in_features=mid_features, out_features=
            out_features)

    def forward(self, x):
        x = self.fc1(x)
        x = self.activ(x)
        x = self.fc2(x)
        return x


class DIALSTMCell(nn.Module):
    """
    DIA-LSTM cell.

    Parameters:
    ----------
    in_x_features : int
        Number of x input channels.
    in_h_features : int
        Number of h input channels.
    num_layers : int
        Number of amplifiers.
    dropout_rate : float, default 0.1
        Parameter of Dropout layer. Faction of the input units to drop.
    """

    def __init__(self, in_x_features, in_h_features, num_layers,
        dropout_rate=0.1):
        super(DIALSTMCell, self).__init__()
        self.num_layers = num_layers
        out_features = 4 * in_h_features
        self.x_amps = nn.Sequential()
        self.h_amps = nn.Sequential()
        for i in range(num_layers):
            amp_class = FirstLSTMAmp if i == 0 else nn.Linear
            self.x_amps.add_module('amp{}'.format(i + 1), amp_class(
                in_features=in_x_features, out_features=out_features))
            self.h_amps.add_module('amp{}'.format(i + 1), amp_class(
                in_features=in_h_features, out_features=out_features))
            in_x_features = in_h_features
        self.dropout = nn.Dropout(p=dropout_rate)

    def forward(self, x, h, c):
        hy = []
        cy = []
        for i in range(self.num_layers):
            hx_i = h[i]
            cx_i = c[i]
            gates = self.x_amps[i](x) + self.h_amps[i](hx_i)
            i_gate, f_gate, c_gate, o_gate = gates.chunk(chunks=4, dim=1)
            i_gate = torch.sigmoid(i_gate)
            f_gate = torch.sigmoid(f_gate)
            c_gate = torch.tanh(c_gate)
            o_gate = torch.sigmoid(o_gate)
            cy_i = f_gate * cx_i + i_gate * c_gate
            hy_i = o_gate * torch.sigmoid(cy_i)
            cy.append(cy_i)
            hy.append(hy_i)
            x = self.dropout(hy_i)
        return hy, cy


class DIAAttention(nn.Module):
    """
    DIA-Net attention module.

    Parameters:
    ----------
    in_x_features : int
        Number of x input channels.
    in_h_features : int
        Number of h input channels.
    num_layers : int, default 1
        Number of amplifiers.
    """

    def __init__(self, in_x_features, in_h_features, num_layers=1):
        super(DIAAttention, self).__init__()
        self.num_layers = num_layers
        self.pool = nn.AdaptiveAvgPool2d(output_size=1)
        self.lstm = DIALSTMCell(in_x_features=in_x_features, in_h_features=
            in_h_features, num_layers=num_layers)

    def forward(self, x, hc=None):
        w = self.pool(x)
        w = w.view(w.size(0), -1)
        if hc is None:
            h = [torch.zeros_like(w)] * self.num_layers
            c = [torch.zeros_like(w)] * self.num_layers
        else:
            h, c = hc
        h, c = self.lstm(w, h, c)
        w = h[-1].unsqueeze(dim=-1).unsqueeze(dim=-1)
        x = x * w
        return x, (h, c)


class DIAResUnit(nn.Module):
    """
    DIA-ResNet unit with residual connection.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 1
        Padding value for the second convolution layer in bottleneck.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for the second convolution layer in bottleneck.
    bottleneck : bool, default True
        Whether to use a bottleneck or simple block in units.
    conv1_stride : bool, default False
        Whether to use stride in the first or the second convolution layer of the block.
    attention : nn.Module, default None
        Attention module.
    """

    def __init__(self, in_channels, out_channels, stride, padding=1,
        dilation=1, bottleneck=True, conv1_stride=False, attention=None):
        super(DIAResUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        if bottleneck:
            self.body = ResBottleneck(in_channels=in_channels, out_channels
                =out_channels, stride=stride, padding=padding, dilation=
                dilation, conv1_stride=conv1_stride)
        else:
            self.body = ResBlock(in_channels=in_channels, out_channels=
                out_channels, stride=stride)
        if self.resize_identity:
            self.identity_conv = conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride, activation=None)
        self.activ = nn.ReLU(inplace=True)
        self.attention = attention

    def forward(self, x, hc=None):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        x, hc = self.attention(x, hc)
        x = x + identity
        x = self.activ(x)
        return x, hc


class CIFARDIAResNet(nn.Module):
    """
    DIA-ResNet model for CIFAR from 'DIANet: Dense-and-Implicit Attention Network,' https://arxiv.org/abs/1905.10671.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (32, 32)
        Spatial size of the expected input image.
    num_classes : int, default 10
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, bottleneck,
        in_channels=3, in_size=(32, 32), num_classes=10):
        super(CIFARDIAResNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', conv3x3_block(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = DualPathSequential(return_two=False)
            attention = DIAAttention(in_x_features=channels_per_stage[0],
                in_h_features=channels_per_stage[0])
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), DIAResUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, bottleneck=bottleneck, conv1_stride=
                    False, attention=attention))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=8,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class DiracConv(nn.Module):
    """
    DiracNetV2 specific convolution block with pre-activation.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride, padding
        ):
        super(DiracConv, self).__init__()
        self.activ = nn.ReLU(inplace=True)
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, bias=True)

    def forward(self, x):
        x = self.activ(x)
        x = self.conv(x)
        return x


class DiracInitBlock(nn.Module):
    """
    DiracNetV2 specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(DiracInitBlock, self).__init__()
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=7, stride=2, padding=3, bias=True)
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

    def forward(self, x):
        x = self.conv(x)
        x = self.pool(x)
        return x


def dirac_conv3x3(in_channels, out_channels):
    """
    3x3 version of the DiracNetV2 specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """
    return DiracConv(in_channels=in_channels, out_channels=out_channels,
        kernel_size=3, stride=1, padding=1)


class DiracNetV2(nn.Module):
    """
    DiracNetV2 model from 'DiracNets: Training Very Deep Neural Networks Without Skip-Connections,'
    https://arxiv.org/abs/1706.00388.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, in_channels=3,
        in_size=(224, 224), num_classes=1000):
        super(DiracNetV2, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', DiracInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stage.add_module('unit{}'.format(j + 1), dirac_conv3x3(
                    in_channels=in_channels, out_channels=out_channels))
                in_channels = out_channels
            if i != len(channels) - 1:
                stage.add_module('pool{}'.format(i + 1), nn.MaxPool2d(
                    kernel_size=2, stride=2, padding=0))
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_activ', nn.ReLU(inplace=True))
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class DLARoot(nn.Module):
    """
    DLA root block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    residual : bool
        Whether use residual connection.
    """

    def __init__(self, in_channels, out_channels, residual):
        super(DLARoot, self).__init__()
        self.residual = residual
        self.conv = conv1x1_block(in_channels=in_channels, out_channels=
            out_channels, activation=None)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x2, x1, extra):
        last_branch = x2
        x = torch.cat((x2, x1) + tuple(extra), dim=1)
        x = self.conv(x)
        if self.residual:
            x += last_branch
        x = self.activ(x)
        return x


class DLAInitBlock(nn.Module):
    """
    DLA specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(DLAInitBlock, self).__init__()
        mid_channels = out_channels // 2
        self.conv1 = conv7x7_block(in_channels=in_channels, out_channels=
            mid_channels)
        self.conv2 = conv3x3_block(in_channels=mid_channels, out_channels=
            mid_channels)
        self.conv3 = conv3x3_block(in_channels=mid_channels, out_channels=
            out_channels, stride=2)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class GlobalAvgMaxPool2D(nn.Module):
    """
    Global average+max pooling operation for spatial data.

    Parameters:
    ----------
    output_size : int, default 1
        The target output size.
    """

    def __init__(self, output_size=1):
        super(GlobalAvgMaxPool2D, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(output_size=output_size)
        self.max_pool = nn.AdaptiveMaxPool2d(output_size=output_size)

    def forward(self, x):
        x_avg = self.avg_pool(x)
        x_max = self.max_pool(x)
        x = 0.5 * (x_avg + x_max)
        return x


def dpn_batch_norm(channels):
    """
    DPN specific Batch normalization layer.

    Parameters:
    ----------
    channels : int
        Number of channels in input data.
    """
    return nn.BatchNorm2d(num_features=channels, eps=0.001)


class PreActivation(nn.Module):
    """
    DPN specific block, which performs the preactivation like in RreResNet.

    Parameters:
    ----------
    channels : int
        Number of channels.
    """

    def __init__(self, channels):
        super(PreActivation, self).__init__()
        self.bn = dpn_batch_norm(channels=channels)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.bn(x)
        x = self.activ(x)
        return x


class DPNConv(nn.Module):
    """
    DPN specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    groups : int
        Number of groups.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, groups):
        super(DPNConv, self).__init__()
        self.bn = dpn_batch_norm(channels=in_channels)
        self.activ = nn.ReLU(inplace=True)
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, groups=groups, bias=False)

    def forward(self, x):
        x = self.bn(x)
        x = self.activ(x)
        x = self.conv(x)
        return x


def dpn_conv3x3(in_channels, out_channels, stride, groups):
    """
    3x3 version of the DPN specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    groups : int
        Number of groups.
    """
    return DPNConv(in_channels=in_channels, out_channels=out_channels,
        kernel_size=3, stride=stride, padding=1, groups=groups)


def dpn_conv1x1(in_channels, out_channels, stride=1):
    """
    1x1 version of the DPN specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    """
    return DPNConv(in_channels=in_channels, out_channels=out_channels,
        kernel_size=1, stride=stride, padding=0, groups=1)


class DPNUnit(nn.Module):
    """
    DPN unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    mid_channels : int
        Number of intermediate channels.
    bw : int
        Number of residual channels.
    inc : int
        Incrementing step for channels.
    groups : int
        Number of groups in the units.
    has_proj : bool
        Whether to use projection.
    key_stride : int
        Key strides of the convolutions.
    b_case : bool, default False
        Whether to use B-case model.
    """

    def __init__(self, in_channels, mid_channels, bw, inc, groups, has_proj,
        key_stride, b_case=False):
        super(DPNUnit, self).__init__()
        self.bw = bw
        self.has_proj = has_proj
        self.b_case = b_case
        if self.has_proj:
            self.conv_proj = dpn_conv1x1(in_channels=in_channels,
                out_channels=bw + 2 * inc, stride=key_stride)
        self.conv1 = dpn_conv1x1(in_channels=in_channels, out_channels=
            mid_channels)
        self.conv2 = dpn_conv3x3(in_channels=mid_channels, out_channels=
            mid_channels, stride=key_stride, groups=groups)
        if b_case:
            self.preactiv = PreActivation(channels=mid_channels)
            self.conv3a = conv1x1(in_channels=mid_channels, out_channels=bw)
            self.conv3b = conv1x1(in_channels=mid_channels, out_channels=inc)
        else:
            self.conv3 = dpn_conv1x1(in_channels=mid_channels, out_channels
                =bw + inc)

    def forward(self, x1, x2=None):
        x_in = torch.cat((x1, x2), dim=1) if x2 is not None else x1
        if self.has_proj:
            x_s = self.conv_proj(x_in)
            x_s1 = x_s[:, :self.bw, :, :]
            x_s2 = x_s[:, self.bw:, :, :]
        else:
            assert x2 is not None
            x_s1 = x1
            x_s2 = x2
        x_in = self.conv1(x_in)
        x_in = self.conv2(x_in)
        if self.b_case:
            x_in = self.preactiv(x_in)
            y1 = self.conv3a(x_in)
            y2 = self.conv3b(x_in)
        else:
            x_in = self.conv3(x_in)
            y1 = x_in[:, :self.bw, :, :]
            y2 = x_in[:, self.bw:, :, :]
        residual = x_s1 + y1
        dense = torch.cat((x_s2, y2), dim=1)
        return residual, dense


class DPNInitBlock(nn.Module):
    """
    DPN specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    """

    def __init__(self, in_channels, out_channels, kernel_size, padding):
        super(DPNInitBlock, self).__init__()
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=2, padding=
            padding, bias=False)
        self.bn = dpn_batch_norm(channels=out_channels)
        self.activ = nn.ReLU(inplace=True)
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        x = self.activ(x)
        x = self.pool(x)
        return x


class DPNFinalBlock(nn.Module):
    """
    DPN final block, which performs the preactivation with cutting.

    Parameters:
    ----------
    channels : int
        Number of channels.
    """

    def __init__(self, channels):
        super(DPNFinalBlock, self).__init__()
        self.activ = PreActivation(channels=channels)

    def forward(self, x1, x2):
        assert x2 is not None
        x = torch.cat((x1, x2), dim=1)
        x = self.activ(x)
        return x, None


class DPN(nn.Module):
    """
    DPN model from 'Dual Path Networks,' https://arxiv.org/abs/1707.01629.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    init_block_kernel_size : int or tuple/list of 2 int
        Convolution window size for the initial unit.
    init_block_padding : int or tuple/list of 2 int
        Padding value for convolution layer in the initial unit.
    rs : list f int
        Number of intermediate channels for each unit.
    bws : list f int
        Number of residual channels for each unit.
    incs : list f int
        Incrementing step for channels for each unit.
    groups : int
        Number of groups in the units.
    b_case : bool
        Whether to use B-case model.
    for_training : bool
        Whether to use model for training.
    test_time_pool : bool
        Whether to use the avg-max pooling in the inference mode.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels,
        init_block_kernel_size, init_block_padding, rs, bws, incs, groups,
        b_case, for_training, test_time_pool, in_channels=3, in_size=(224, 
        224), num_classes=1000):
        super(DPN, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = DualPathSequential(return_two=False, first_ordinals
            =1, last_ordinals=0)
        self.features.add_module('init_block', DPNInitBlock(in_channels=
            in_channels, out_channels=init_block_channels, kernel_size=
            init_block_kernel_size, padding=init_block_padding))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = DualPathSequential()
            r = rs[i]
            bw = bws[i]
            inc = incs[i]
            for j, out_channels in enumerate(channels_per_stage):
                has_proj = j == 0
                key_stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), DPNUnit(
                    in_channels=in_channels, mid_channels=r, bw=bw, inc=inc,
                    groups=groups, has_proj=has_proj, key_stride=key_stride,
                    b_case=b_case))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_block', DPNFinalBlock(channels=
            in_channels))
        self.output = nn.Sequential()
        if for_training or not test_time_pool:
            self.output.add_module('final_pool', nn.AdaptiveAvgPool2d(
                output_size=1))
            self.output.add_module('classifier', conv1x1(in_channels=
                in_channels, out_channels=num_classes, bias=True))
        else:
            self.output.add_module('avg_pool', nn.AvgPool2d(kernel_size=7,
                stride=1))
            self.output.add_module('classifier', conv1x1(in_channels=
                in_channels, out_channels=num_classes, bias=True))
            self.output.add_module('avgmax_pool', GlobalAvgMaxPool2D())
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = self.output(x)
        x = x.view(x.size(0), -1)
        return x


class DRNConv(nn.Module):
    """
    DRN specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int
        Dilation value for convolution layer.
    activate : bool
        Whether activate the convolution block.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, dilation, activate):
        super(DRNConv, self).__init__()
        self.activate = activate
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, dilation=dilation, bias=False)
        self.bn = nn.BatchNorm2d(num_features=out_channels)
        if self.activate:
            self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        if self.activate:
            x = self.activ(x)
        return x


def drn_conv3x3(in_channels, out_channels, stride, dilation, activate):
    """
    3x3 version of the DRN specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    dilation : int or tuple/list of 2 int
        Padding/dilation value for convolution layer.
    activate : bool
        Whether activate the convolution block.
    """
    return DRNConv(in_channels=in_channels, out_channels=out_channels,
        kernel_size=3, stride=stride, padding=dilation, dilation=dilation,
        activate=activate)


class DRNBlock(nn.Module):
    """
    Simple DRN block for residual path in DRN unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    dilation : int or tuple/list of 2 int
        Padding/dilation value for convolution layers.
    """

    def __init__(self, in_channels, out_channels, stride, dilation):
        super(DRNBlock, self).__init__()
        self.conv1 = drn_conv3x3(in_channels=in_channels, out_channels=
            out_channels, stride=stride, dilation=dilation, activate=True)
        self.conv2 = drn_conv3x3(in_channels=out_channels, out_channels=
            out_channels, stride=1, dilation=dilation, activate=False)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


def drn_conv1x1(in_channels, out_channels, stride, activate):
    """
    1x1 version of the DRN specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    activate : bool
        Whether activate the convolution block.
    """
    return DRNConv(in_channels=in_channels, out_channels=out_channels,
        kernel_size=1, stride=stride, padding=0, dilation=1, activate=activate)


class DRNBottleneck(nn.Module):
    """
    DRN bottleneck block for residual path in DRN unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    dilation : int or tuple/list of 2 int
        Padding/dilation value for 3x3 convolution layer.
    """

    def __init__(self, in_channels, out_channels, stride, dilation):
        super(DRNBottleneck, self).__init__()
        mid_channels = out_channels // 4
        self.conv1 = drn_conv1x1(in_channels=in_channels, out_channels=
            mid_channels, stride=1, activate=True)
        self.conv2 = drn_conv3x3(in_channels=mid_channels, out_channels=
            mid_channels, stride=stride, dilation=dilation, activate=True)
        self.conv3 = drn_conv1x1(in_channels=mid_channels, out_channels=
            out_channels, stride=1, activate=False)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class DRNUnit(nn.Module):
    """
    DRN unit with residual connection.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    dilation : int or tuple/list of 2 int
        Padding/dilation value for 3x3 convolution layers.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    simplified : bool
        Whether to use a simple or simplified block in units.
    residual : bool
        Whether do residual calculations.
    """

    def __init__(self, in_channels, out_channels, stride, dilation,
        bottleneck, simplified, residual):
        super(DRNUnit, self).__init__()
        assert residual or not bottleneck
        assert not (bottleneck and simplified)
        assert not (residual and simplified)
        self.residual = residual
        self.resize_identity = (in_channels != out_channels or stride != 1
            ) and self.residual and not simplified
        if bottleneck:
            self.body = DRNBottleneck(in_channels=in_channels, out_channels
                =out_channels, stride=stride, dilation=dilation)
        elif simplified:
            self.body = drn_conv3x3(in_channels=in_channels, out_channels=
                out_channels, stride=stride, dilation=dilation, activate=False)
        else:
            self.body = DRNBlock(in_channels=in_channels, out_channels=
                out_channels, stride=stride, dilation=dilation)
        if self.resize_identity:
            self.identity_conv = drn_conv1x1(in_channels=in_channels,
                out_channels=out_channels, stride=stride, activate=False)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        if self.residual:
            x = x + identity
        x = self.activ(x)
        return x


def drn_init_block(in_channels, out_channels):
    """
    DRN specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """
    return DRNConv(in_channels=in_channels, out_channels=out_channels,
        kernel_size=7, stride=1, padding=3, dilation=1, activate=True)


class DRN(nn.Module):
    """
    DRN-C&D model from 'Dilated Residual Networks,' https://arxiv.org/abs/1705.09914.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    dilations : list of list of int
        Dilation values for 3x3 convolution layers for each unit.
    bottlenecks : list of list of int
        Whether to use a bottleneck or simple block in each unit.
    simplifieds : list of list of int
        Whether to use a simple or simplified block in each unit.
    residuals : list of list of int
        Whether to use residual block in each unit.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, dilations,
        bottlenecks, simplifieds, residuals, in_channels=3, in_size=(224, 
        224), num_classes=1000):
        super(DRN, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', drn_init_block(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), DRNUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, dilation=dilations[i][j], bottleneck=
                    bottlenecks[i][j] == 1, simplified=simplifieds[i][j] ==
                    1, residual=residuals[i][j] == 1))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=28,
            stride=1))
        self.output = nn.Conv2d(in_channels=in_channels, out_channels=
            num_classes, kernel_size=1)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = self.output(x)
        x = x.view(x.size(0), -1)
        return x


def dwconv3x3_block(in_channels, out_channels, strides=1, padding=1,
    dilation=1, use_bias=False, bn_eps=1e-05, activation='relu',
    data_format='channels_last', **kwargs):
    """
    3x3 depthwise version of the standard convolution block (SINet version).

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    strides : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 1
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    use_bias : bool, default False
        Whether the layer uses a bias vector.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    activation : function or str or None, default 'relu'
        Activation function or name of activation function.
    data_format : str, default 'channels_last'
        The ordering of the dimensions in tensors.
    """
    return dwconv_block(in_channels=in_channels, out_channels=out_channels,
        kernel_size=3, strides=strides, padding=padding, dilation=dilation,
        use_bias=use_bias, bn_eps=bn_eps, activation=activation,
        data_format=data_format, **kwargs)


def calc_tf_padding(x, kernel_size, stride=1, dilation=1):
    """
    Calculate TF-same like padding size.

    Parameters:
    ----------
    x : tensor
        Input tensor.
    kernel_size : int
        Convolution window size.
    stride : int, default 1
        Strides of the convolution.
    dilation : int, default 1
        Dilation value for convolution layer.

    Returns
    -------
    tuple of 4 int
        The size of the padding.
    """
    height, width = x.size()[2:]
    oh = math.ceil(height / stride)
    ow = math.ceil(width / stride)
    pad_h = max((oh - 1) * stride + (kernel_size - 1) * dilation + 1 -
        height, 0)
    pad_w = max((ow - 1) * stride + (kernel_size - 1) * dilation + 1 - width, 0
        )
    return pad_h // 2, pad_h - pad_h // 2, pad_w // 2, pad_w - pad_w // 2


class EffiDwsConvUnit(nn.Module):
    """
    EfficientNet specific depthwise separable convolution block/unit with BatchNorms and activations at each convolution
    layers.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the second convolution layer.
    bn_eps : float
        Small float added to variance in Batch norm.
    activation : str
        Name of activation function.
    tf_mode : bool
        Whether to use TF-like mode.
    """

    def __init__(self, in_channels, out_channels, stride, bn_eps,
        activation, tf_mode):
        super(EffiDwsConvUnit, self).__init__()
        self.tf_mode = tf_mode
        self.residual = in_channels == out_channels and stride == 1
        self.dw_conv = dwconv3x3_block(in_channels=in_channels,
            out_channels=in_channels, padding=0 if tf_mode else 1, bn_eps=
            bn_eps, activation=activation)
        self.se = SEBlock(channels=in_channels, reduction=4, mid_activation
            =activation)
        self.pw_conv = conv1x1_block(in_channels=in_channels, out_channels=
            out_channels, bn_eps=bn_eps, activation=None)

    def forward(self, x):
        if self.residual:
            identity = x
        if self.tf_mode:
            x = F.pad(x, pad=calc_tf_padding(x, kernel_size=3))
        x = self.dw_conv(x)
        x = self.se(x)
        x = self.pw_conv(x)
        if self.residual:
            x = x + identity
        return x


def dwconv5x5_block(in_channels, out_channels, stride=1, padding=2,
    dilation=1, bias=False, bn_eps=1e-05, activation=lambda : nn.ReLU(
    inplace=True)):
    """
    5x5 depthwise version of the standard convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    padding : int, or tuple/list of 2 int, or tuple/list of 4 int, default 2
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    bias : bool, default False
        Whether the layer uses a bias vector.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function or name of activation function.
    """
    return dwconv_block(in_channels=in_channels, out_channels=out_channels,
        kernel_size=5, stride=stride, padding=padding, dilation=dilation,
        bias=bias, bn_eps=bn_eps, activation=activation)


class EffiInvResUnit(nn.Module):
    """
    EfficientNet inverted residual unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the second convolution layer.
    exp_factor : int
        Factor for expansion of channels.
    se_factor : int
        SE reduction factor for each unit.
    bn_eps : float
        Small float added to variance in Batch norm.
    activation : str
        Name of activation function.
    tf_mode : bool
        Whether to use TF-like mode.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        exp_factor, se_factor, bn_eps, activation, tf_mode):
        super(EffiInvResUnit, self).__init__()
        self.kernel_size = kernel_size
        self.stride = stride
        self.tf_mode = tf_mode
        self.residual = in_channels == out_channels and stride == 1
        self.use_se = se_factor > 0
        mid_channels = in_channels * exp_factor
        dwconv_block_fn = (dwconv3x3_block if kernel_size == 3 else 
            dwconv5x5_block if kernel_size == 5 else None)
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            mid_channels, bn_eps=bn_eps, activation=activation)
        self.conv2 = dwconv_block_fn(in_channels=mid_channels, out_channels
            =mid_channels, stride=stride, padding=0 if tf_mode else 
            kernel_size // 2, bn_eps=bn_eps, activation=activation)
        if self.use_se:
            self.se = SEBlock(channels=mid_channels, reduction=exp_factor *
                se_factor, mid_activation=activation)
        self.conv3 = conv1x1_block(in_channels=mid_channels, out_channels=
            out_channels, bn_eps=bn_eps, activation=None)

    def forward(self, x):
        if self.residual:
            identity = x
        x = self.conv1(x)
        if self.tf_mode:
            x = F.pad(x, pad=calc_tf_padding(x, kernel_size=self.
                kernel_size, stride=self.stride))
        x = self.conv2(x)
        if self.use_se:
            x = self.se(x)
        x = self.conv3(x)
        if self.residual:
            x = x + identity
        return x


class EffiInitBlock(nn.Module):
    """
    EfficientNet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    bn_eps : float
        Small float added to variance in Batch norm.
    activation : str
        Name of activation function.
    tf_mode : bool
        Whether to use TF-like mode.
    """

    def __init__(self, in_channels, out_channels, bn_eps, activation, tf_mode):
        super(EffiInitBlock, self).__init__()
        self.tf_mode = tf_mode
        self.conv = conv3x3_block(in_channels=in_channels, out_channels=
            out_channels, stride=2, padding=0 if tf_mode else 1, bn_eps=
            bn_eps, activation=activation)

    def forward(self, x):
        if self.tf_mode:
            x = F.pad(x, pad=calc_tf_padding(x, kernel_size=3, stride=2))
        x = self.conv(x)
        return x


class EfficientNet(nn.Module):
    """
    EfficientNet model from 'EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,'
    https://arxiv.org/abs/1905.11946.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for initial unit.
    final_block_channels : int
        Number of output channels for the final block of the feature extractor.
    kernel_sizes : list of list of int
        Number of kernel sizes for each unit.
    strides_per_stage : list int
        Stride value for the first unit of each stage.
    expansion_factors : list of list of int
        Number of expansion factors for each unit.
    dropout_rate : float, default 0.2
        Fraction of the input units to drop. Must be a number between 0 and 1.
    tf_mode : bool, default False
        Whether to use TF-like mode.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, final_block_channels,
        kernel_sizes, strides_per_stage, expansion_factors, dropout_rate=
        0.2, tf_mode=False, bn_eps=1e-05, in_channels=3, in_size=(224, 224),
        num_classes=1000):
        super(EfficientNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        activation = 'swish'
        self.features = nn.Sequential()
        self.features.add_module('init_block', EffiInitBlock(in_channels=
            in_channels, out_channels=init_block_channels, bn_eps=bn_eps,
            activation=activation, tf_mode=tf_mode))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            kernel_sizes_per_stage = kernel_sizes[i]
            expansion_factors_per_stage = expansion_factors[i]
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                kernel_size = kernel_sizes_per_stage[j]
                expansion_factor = expansion_factors_per_stage[j]
                stride = strides_per_stage[i] if j == 0 else 1
                if i == 0:
                    stage.add_module('unit{}'.format(j + 1),
                        EffiDwsConvUnit(in_channels=in_channels,
                        out_channels=out_channels, stride=stride, bn_eps=
                        bn_eps, activation=activation, tf_mode=tf_mode))
                else:
                    stage.add_module('unit{}'.format(j + 1), EffiInvResUnit
                        (in_channels=in_channels, out_channels=out_channels,
                        kernel_size=kernel_size, stride=stride, exp_factor=
                        expansion_factor, se_factor=4, bn_eps=bn_eps,
                        activation=activation, tf_mode=tf_mode))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_block', conv1x1_block(in_channels=
            in_channels, out_channels=final_block_channels, bn_eps=bn_eps,
            activation=activation))
        in_channels = final_block_channels
        self.features.add_module('final_pool', nn.AdaptiveAvgPool2d(
            output_size=1))
        self.output = nn.Sequential()
        if dropout_rate > 0.0:
            self.output.add_module('dropout', nn.Dropout(p=dropout_rate))
        self.output.add_module('fc', nn.Linear(in_features=in_channels,
            out_features=num_classes))
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class EffiEdgeResUnit(nn.Module):
    """
    EfficientNet-Edge edge residual unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the second convolution layer.
    exp_factor : int
        Factor for expansion of channels.
    se_factor : int
        SE reduction factor for each unit.
    mid_from_in : bool
        Whether to use input channel count for middle channel count calculation.
    use_skip : bool
        Whether to use skip connection.
    bn_eps : float
        Small float added to variance in Batch norm.
    activation : str
        Name of activation function.
    """

    def __init__(self, in_channels, out_channels, stride, exp_factor,
        se_factor, mid_from_in, use_skip, bn_eps, activation):
        super(EffiEdgeResUnit, self).__init__()
        self.residual = (in_channels == out_channels and stride == 1 and
            use_skip)
        self.use_se = se_factor > 0
        mid_channels = (in_channels * exp_factor if mid_from_in else 
            out_channels * exp_factor)
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            mid_channels, bn_eps=bn_eps, activation=activation)
        if self.use_se:
            self.se = SEBlock(channels=mid_channels, reduction=exp_factor *
                se_factor, mid_activation=activation)
        self.conv2 = conv1x1_block(in_channels=mid_channels, out_channels=
            out_channels, stride=stride, bn_eps=bn_eps, activation=None)

    def forward(self, x):
        if self.residual:
            identity = x
        x = self.conv1(x)
        if self.use_se:
            x = self.se(x)
        x = self.conv2(x)
        if self.residual:
            x = x + identity
        return x


class EfficientNetEdge(nn.Module):
    """
    EfficientNet-Edge model from 'EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,'
    https://arxiv.org/abs/1905.11946.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for initial unit.
    final_block_channels : int
        Number of output channels for the final block of the feature extractor.
    kernel_sizes : list of list of int
        Number of kernel sizes for each unit.
    strides_per_stage : list int
        Stride value for the first unit of each stage.
    expansion_factors : list of list of int
        Number of expansion factors for each unit.
    dropout_rate : float, default 0.2
        Fraction of the input units to drop. Must be a number between 0 and 1.
    tf_mode : bool, default False
        Whether to use TF-like mode.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, final_block_channels,
        kernel_sizes, strides_per_stage, expansion_factors, dropout_rate=
        0.2, tf_mode=False, bn_eps=1e-05, in_channels=3, in_size=(224, 224),
        num_classes=1000):
        super(EfficientNetEdge, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        activation = 'relu'
        self.features = nn.Sequential()
        self.features.add_module('init_block', EffiInitBlock(in_channels=
            in_channels, out_channels=init_block_channels, bn_eps=bn_eps,
            activation=activation, tf_mode=tf_mode))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            kernel_sizes_per_stage = kernel_sizes[i]
            expansion_factors_per_stage = expansion_factors[i]
            mid_from_in = i != 0
            use_skip = i != 0
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                kernel_size = kernel_sizes_per_stage[j]
                expansion_factor = expansion_factors_per_stage[j]
                stride = strides_per_stage[i] if j == 0 else 1
                if i < 3:
                    stage.add_module('unit{}'.format(j + 1),
                        EffiEdgeResUnit(in_channels=in_channels,
                        out_channels=out_channels, stride=stride,
                        exp_factor=expansion_factor, se_factor=0,
                        mid_from_in=mid_from_in, use_skip=use_skip, bn_eps=
                        bn_eps, activation=activation))
                else:
                    stage.add_module('unit{}'.format(j + 1), EffiInvResUnit
                        (in_channels=in_channels, out_channels=out_channels,
                        kernel_size=kernel_size, stride=stride, exp_factor=
                        expansion_factor, se_factor=0, bn_eps=bn_eps,
                        activation=activation, tf_mode=tf_mode))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_block', conv1x1_block(in_channels=
            in_channels, out_channels=final_block_channels, bn_eps=bn_eps,
            activation=activation))
        in_channels = final_block_channels
        self.features.add_module('final_pool', nn.AdaptiveAvgPool2d(
            output_size=1))
        self.output = nn.Sequential()
        if dropout_rate > 0.0:
            self.output.add_module('dropout', nn.Dropout(p=dropout_rate))
        self.output.add_module('fc', nn.Linear(in_features=in_channels,
            out_features=num_classes))
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class PreActivation(nn.Module):
    """
    PreResNet like pure pre-activation block without convolution layer.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    """

    def __init__(self, in_channels):
        super(PreActivation, self).__init__()
        self.bn = nn.BatchNorm2d(num_features=in_channels)
        self.activ = nn.PReLU(num_parameters=in_channels)

    def forward(self, x):
        x = self.bn(x)
        x = self.activ(x)
        return x


class ShortcutBlock(nn.Module):
    """
    ESPNetv2 shortcut block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(ShortcutBlock, self).__init__()
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            in_channels, activation=lambda : nn.PReLU(in_channels))
        self.conv2 = conv1x1_block(in_channels=in_channels, out_channels=
            out_channels, activation=None)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class HierarchicalConcurrent(nn.Sequential):
    """
    A container for hierarchical concatenation of modules on the base of the sequential container.

    Parameters:
    ----------
    axis : int, default 1
        The axis on which to concatenate the outputs.
    """

    def __init__(self, axis=1):
        super(HierarchicalConcurrent, self).__init__()
        self.axis = axis

    def forward(self, x):
        out = []
        y_prev = None
        for module in self._modules.values():
            y = module(x)
            if y_prev is not None:
                y += y_prev
            out.append(y)
            y_prev = y
        out = torch.cat(tuple(out), dim=self.axis)
        return out


def conv3x3(in_planes, out_planes, stride=1):
    """3x3 convolution with padding"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
        padding=1, bias=False)


class ESPBlock(nn.Module):
    """
    ESPNetv2 block (so-called EESP block).

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the branch convolution layers.
    dilations : list of int
        Dilation values for branches.
    """

    def __init__(self, in_channels, out_channels, stride, dilations):
        super(ESPBlock, self).__init__()
        num_branches = len(dilations)
        assert out_channels % num_branches == 0
        self.downsample = stride != 1
        mid_channels = out_channels // num_branches
        self.reduce_conv = conv1x1_block(in_channels=in_channels,
            out_channels=mid_channels, groups=num_branches, activation=lambda :
            nn.PReLU(mid_channels))
        self.branches = HierarchicalConcurrent()
        for i in range(num_branches):
            self.branches.add_module('branch{}'.format(i + 1), conv3x3(
                in_channels=mid_channels, out_channels=mid_channels, stride
                =stride, padding=dilations[i], dilation=dilations[i],
                groups=mid_channels))
        self.merge_conv = conv1x1_block(in_channels=out_channels,
            out_channels=out_channels, groups=num_branches, activation=None)
        self.preactiv = PreActivation(in_channels=out_channels)
        if not self.downsample:
            self.activ = nn.PReLU(out_channels)

    def forward(self, x, x0):
        y = self.reduce_conv(x)
        y = self.branches(y)
        y = self.preactiv(y)
        y = self.merge_conv(y)
        if not self.downsample:
            y = y + x
            y = self.activ(y)
        return y, x0


class DownsampleBlock(nn.Module):
    """
    ESPNetv2 downsample block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    x0_channels : int
        Number of input channels for shortcut.
    dilations : list of int
        Dilation values for branches in EESP block.
    """

    def __init__(self, in_channels, out_channels, x0_channels, dilations):
        super(DownsampleBlock, self).__init__()
        inc_channels = out_channels - in_channels
        self.pool = nn.AvgPool2d(kernel_size=3, stride=2, padding=1)
        self.eesp = ESPBlock(in_channels=in_channels, out_channels=
            inc_channels, stride=2, dilations=dilations)
        self.shortcut_block = ShortcutBlock(in_channels=x0_channels,
            out_channels=out_channels)
        self.activ = nn.PReLU(out_channels)

    def forward(self, x, x0):
        y1 = self.pool(x)
        y2, _ = self.eesp(x, None)
        x = torch.cat((y1, y2), dim=1)
        x0 = self.pool(x0)
        y3 = self.shortcut_block(x0)
        x = x + y3
        x = self.activ(x)
        return x, x0


class ESPInitBlock(nn.Module):
    """
    ESPNetv2 initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(ESPInitBlock, self).__init__()
        self.conv = conv3x3_block(in_channels=in_channels, out_channels=
            out_channels, stride=2, activation=lambda : nn.PReLU(out_channels))
        self.pool = nn.AvgPool2d(kernel_size=3, stride=2, padding=1)

    def forward(self, x, x0):
        x = self.conv(x)
        x0 = self.pool(x0)
        return x, x0


class ESPFinalBlock(nn.Module):
    """
    ESPNetv2 final block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    final_groups : int
        Number of groups in the last convolution layer.
    """

    def __init__(self, in_channels, out_channels, final_groups):
        super(ESPFinalBlock, self).__init__()
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            in_channels, groups=in_channels, activation=lambda : nn.PReLU(
            in_channels))
        self.conv2 = conv1x1_block(in_channels=in_channels, out_channels=
            out_channels, groups=final_groups, activation=lambda : nn.PReLU
            (out_channels))

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class ESPNetv2(nn.Module):
    """
    ESPNetv2 model from 'ESPNetv2: A Light-weight, Power Efficient, and General Purpose Convolutional Neural Network,'
    https://arxiv.org/abs/1811.11431.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    final_block_channels : int
        Number of output channels for the final unit.
    final_block_groups : int
        Number of groups for the final unit.
    dilations : list of list of list of int
        Dilation values for branches in each unit.
    dropout_rate : float, default 0.2
        Parameter of Dropout layer. Faction of the input units to drop.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, final_block_channels,
        final_block_groups, dilations, dropout_rate=0.2, in_channels=3,
        in_size=(224, 224), num_classes=1000):
        super(ESPNetv2, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        x0_channels = in_channels
        self.features = DualPathSequential(return_two=False, first_ordinals
            =0, last_ordinals=2)
        self.features.add_module('init_block', ESPInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = DualPathSequential()
            for j, out_channels in enumerate(channels_per_stage):
                if j == 0:
                    unit = DownsampleBlock(in_channels=in_channels,
                        out_channels=out_channels, x0_channels=x0_channels,
                        dilations=dilations[i][j])
                else:
                    unit = ESPBlock(in_channels=in_channels, out_channels=
                        out_channels, stride=1, dilations=dilations[i][j])
                stage.add_module('unit{}'.format(j + 1), unit)
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_block', ESPFinalBlock(in_channels=
            in_channels, out_channels=final_block_channels, final_groups=
            final_block_groups))
        in_channels = final_block_channels
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Sequential()
        self.output.add_module('dropout', nn.Dropout(p=dropout_rate))
        self.output.add_module('fc', nn.Linear(in_features=in_channels,
            out_features=num_classes))
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x, x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class FastSEResUnit(nn.Module):
    """
    Fast-SE-ResNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    conv1_stride : bool
        Whether to use stride in the first or the second convolution layer of the block.
    use_se : bool
        Whether to use SE-module.
    """

    def __init__(self, in_channels, out_channels, stride, bottleneck,
        conv1_stride, use_se):
        super(FastSEResUnit, self).__init__()
        self.use_se = use_se
        self.resize_identity = in_channels != out_channels or stride != 1
        if bottleneck:
            self.body = ResBottleneck(in_channels=in_channels, out_channels
                =out_channels, stride=stride, conv1_stride=conv1_stride)
        else:
            self.body = ResBlock(in_channels=in_channels, out_channels=
                out_channels, stride=stride)
        if self.use_se:
            self.se = SEBlock(channels=out_channels, reduction=1, use_conv=
                False)
        if self.resize_identity:
            self.identity_conv = conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride, activation=None)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        if self.use_se:
            x = self.se(x)
        x = x + identity
        x = self.activ(x)
        return x


class FastSEResNet(nn.Module):
    """
    Fast-SE-ResNet model from 'Squeeze-and-Excitation Networks,' https://arxiv.org/abs/1709.01507.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    conv1_stride : bool
        Whether to use stride in the first or the second convolution layer in units.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, bottleneck,
        conv1_stride, in_channels=3, in_size=(224, 224), num_classes=1000):
        super(FastSEResNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', ResInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                use_se = j == 0
                stage.add_module('unit{}'.format(j + 1), FastSEResUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, bottleneck=bottleneck, conv1_stride=
                    conv1_stride, use_se=use_se))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class FBNetUnit(nn.Module):
    """
    FBNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the second convolution layer.
    bn_eps : float
        Small float added to variance in Batch norm.
    use_kernel3 : bool
        Whether to use 3x3 (instead of 5x5) kernel.
    exp_factor : int
        Expansion factor for each unit.
    activation : str, default 'relu'
        Activation function or name of activation function.
    """

    def __init__(self, in_channels, out_channels, stride, bn_eps,
        use_kernel3, exp_factor, activation='relu'):
        super(FBNetUnit, self).__init__()
        assert exp_factor >= 1
        self.residual = in_channels == out_channels and stride == 1
        self.use_exp_conv = True
        mid_channels = exp_factor * in_channels
        if self.use_exp_conv:
            self.exp_conv = conv1x1_block(in_channels=in_channels,
                out_channels=mid_channels, bn_eps=bn_eps, activation=activation
                )
        if use_kernel3:
            self.conv1 = dwconv3x3_block(in_channels=mid_channels,
                out_channels=mid_channels, stride=stride, bn_eps=bn_eps,
                activation=activation)
        else:
            self.conv1 = dwconv5x5_block(in_channels=mid_channels,
                out_channels=mid_channels, stride=stride, bn_eps=bn_eps,
                activation=activation)
        self.conv2 = conv1x1_block(in_channels=mid_channels, out_channels=
            out_channels, bn_eps=bn_eps, activation=None)

    def forward(self, x):
        if self.residual:
            identity = x
        if self.use_exp_conv:
            x = self.exp_conv(x)
        x = self.conv1(x)
        x = self.conv2(x)
        if self.residual:
            x = x + identity
        return x


class FBNetInitBlock(nn.Module):
    """
    FBNet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    bn_eps : float
        Small float added to variance in Batch norm.
    """

    def __init__(self, in_channels, out_channels, bn_eps):
        super(FBNetInitBlock, self).__init__()
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            out_channels, stride=2, bn_eps=bn_eps)
        self.conv2 = FBNetUnit(in_channels=out_channels, out_channels=
            out_channels, stride=1, bn_eps=bn_eps, use_kernel3=True,
            exp_factor=1)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class FBNet(nn.Module):
    """
    FBNet model from 'FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search,'
    https://arxiv.org/abs/1812.03443.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    final_block_channels : int
        Number of output channels for the final block of the feature extractor.
    kernels3 : list of list of int/bool
        Using 3x3 (instead of 5x5) kernel for each unit.
    exp_factors : list of list of int
        Expansion factor for each unit.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, final_block_channels,
        kernels3, exp_factors, bn_eps=1e-05, in_channels=3, in_size=(224, 
        224), num_classes=1000):
        super(FBNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', FBNetInitBlock(in_channels=
            in_channels, out_channels=init_block_channels, bn_eps=bn_eps))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 else 1
                use_kernel3 = kernels3[i][j] == 1
                exp_factor = exp_factors[i][j]
                stage.add_module('unit{}'.format(j + 1), FBNetUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, bn_eps=bn_eps, use_kernel3=use_kernel3,
                    exp_factor=exp_factor))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_block', conv1x1_block(in_channels=
            in_channels, out_channels=final_block_channels, bn_eps=bn_eps))
        in_channels = final_block_channels
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class FCNFinalBlock(nn.Module):
    """
    FCN-8s(d) final block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    bottleneck_factor : int, default 4
        Bottleneck factor.
    """

    def __init__(self, in_channels, out_channels, bottleneck_factor=4):
        super(FCNFinalBlock, self).__init__()
        assert in_channels % bottleneck_factor == 0
        mid_channels = in_channels // bottleneck_factor
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            mid_channels)
        self.dropout = nn.Dropout(p=0.1, inplace=False)
        self.conv2 = conv1x1(in_channels=mid_channels, out_channels=
            out_channels, bias=True)

    def forward(self, x, out_size):
        x = self.conv1(x)
        x = self.dropout(x)
        x = self.conv2(x)
        x = F.interpolate(x, size=out_size, mode='bilinear', align_corners=True
            )
        return x


class FCN8sd(nn.Module):
    """
    FCN-8s(d) model from 'Fully Convolutional Networks for Semantic Segmentation,' https://arxiv.org/abs/1411.4038.
    It is an experimental model mixed FCN-8s and PSPNet.

    Parameters:
    ----------
    backbone : nn.Sequential
        Feature extractor.
    backbone_out_channels : int, default 2048
        Number of output channels form feature extractor.
    aux : bool, default False
        Whether to output an auxiliary result.
    fixed_size : bool, default True
        Whether to expect fixed spatial size of input image.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (480, 480)
        Spatial size of the expected input image.
    num_classes : int, default 21
        Number of segmentation classes.
    """

    def __init__(self, backbone, backbone_out_channels=2048, aux=False,
        fixed_size=True, in_channels=3, in_size=(480, 480), num_classes=21):
        super(FCN8sd, self).__init__()
        assert in_channels > 0
        self.in_size = in_size
        self.num_classes = num_classes
        self.aux = aux
        self.fixed_size = fixed_size
        self.backbone = backbone
        pool_out_channels = backbone_out_channels
        self.final_block = FCNFinalBlock(in_channels=pool_out_channels,
            out_channels=num_classes)
        if self.aux:
            aux_out_channels = backbone_out_channels // 2
            self.aux_block = FCNFinalBlock(in_channels=aux_out_channels,
                out_channels=num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        in_size = self.in_size if self.fixed_size else x.shape[2:]
        x, y = self.backbone(x)
        x = self.final_block(x, in_size)
        if self.aux:
            y = self.aux_block(y, in_size)
            return x, y
        else:
            return x


def channel_squeeze(x, groups):
    """
    Channel squeeze operation.

    Parameters:
    ----------
    x : Tensor
        Input tensor.
    groups : int
        Number of groups.

    Returns
    -------
    Tensor
        Resulted tensor.
    """
    batch, channels, height, width = x.size()
    channels_per_group = channels // groups
    x = x.view(batch, channels_per_group, groups, height, width).sum(dim=2)
    return x


class ChannelSqueeze(nn.Module):
    """
    Channel squeeze layer. This is a wrapper over the same operation. It is designed to save the number of groups.

    Parameters:
    ----------
    channels : int
        Number of channels.
    groups : int
        Number of groups.
    """

    def __init__(self, channels, groups):
        super(ChannelSqueeze, self).__init__()
        if channels % groups != 0:
            raise ValueError('channels must be divisible by groups')
        self.groups = groups

    def forward(self, x):
        return channel_squeeze(x, self.groups)


class PreSEAttBlock(nn.Module):
    """
    FishNet specific Squeeze-and-Excitation attention block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    reduction : int, default 16
        Squeeze reduction value.
    """

    def __init__(self, in_channels, out_channels, reduction=16):
        super(PreSEAttBlock, self).__init__()
        mid_cannels = out_channels // reduction
        self.bn = nn.BatchNorm2d(num_features=in_channels)
        self.relu = nn.ReLU(inplace=True)
        self.pool = nn.AdaptiveAvgPool2d(output_size=1)
        self.conv1 = conv1x1(in_channels=in_channels, out_channels=
            mid_cannels, bias=True)
        self.conv2 = conv1x1(in_channels=mid_cannels, out_channels=
            out_channels, bias=True)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.bn(x)
        x = self.relu(x)
        x = self.pool(x)
        x = self.conv1(x)
        x = self.relu(x)
        x = self.conv2(x)
        x = self.sigmoid(x)
        return x


class FishBottleneck(nn.Module):
    """
    FishNet bottleneck block for residual unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    dilation : int or tuple/list of 2 int
        Dilation value for convolution layer.
    """

    def __init__(self, in_channels, out_channels, stride, dilation):
        super(FishBottleneck, self).__init__()
        mid_channels = out_channels // 4
        self.conv1 = pre_conv1x1_block(in_channels=in_channels,
            out_channels=mid_channels)
        self.conv2 = pre_conv3x3_block(in_channels=mid_channels,
            out_channels=mid_channels, stride=stride, padding=dilation,
            dilation=dilation)
        self.conv3 = pre_conv1x1_block(in_channels=mid_channels,
            out_channels=out_channels)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class FishBlock(nn.Module):
    """
    FishNet block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    squeeze : bool, default False
        Whether to use a channel squeeze operation.
    """

    def __init__(self, in_channels, out_channels, stride=1, dilation=1,
        squeeze=False):
        super(FishBlock, self).__init__()
        self.squeeze = squeeze
        self.resize_identity = in_channels != out_channels or stride != 1
        self.body = FishBottleneck(in_channels=in_channels, out_channels=
            out_channels, stride=stride, dilation=dilation)
        if self.squeeze:
            assert in_channels // 2 == out_channels
            self.c_squeeze = ChannelSqueeze(channels=in_channels, groups=2)
        elif self.resize_identity:
            self.identity_conv = pre_conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride)

    def forward(self, x):
        if self.squeeze:
            identity = self.c_squeeze(x)
        elif self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        x = x + identity
        return x


class DownUnit(nn.Module):
    """
    FishNet down unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels_list : list of int
        Number of output channels for each block.
    """

    def __init__(self, in_channels, out_channels_list):
        super(DownUnit, self).__init__()
        self.blocks = nn.Sequential()
        for i, out_channels in enumerate(out_channels_list):
            self.blocks.add_module('block{}'.format(i + 1), FishBlock(
                in_channels=in_channels, out_channels=out_channels))
            in_channels = out_channels
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)

    def forward(self, x):
        x = self.blocks(x)
        x = self.pool(x)
        return x


class UpUnit(nn.Module):
    """
    FishNet up unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels_list : list of int
        Number of output channels for each block.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    """

    def __init__(self, in_channels, out_channels_list, dilation=1):
        super(UpUnit, self).__init__()
        self.blocks = nn.Sequential()
        for i, out_channels in enumerate(out_channels_list):
            squeeze = dilation > 1 and i == 0
            self.blocks.add_module('block{}'.format(i + 1), FishBlock(
                in_channels=in_channels, out_channels=out_channels,
                dilation=dilation, squeeze=squeeze))
            in_channels = out_channels
        self.upsample = InterpolationBlock(scale_factor=2, mode='nearest',
            align_corners=None)

    def forward(self, x):
        x = self.blocks(x)
        x = self.upsample(x)
        return x


class SkipUnit(nn.Module):
    """
    FishNet skip connection unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels_list : list of int
        Number of output channels for each block.
    """

    def __init__(self, in_channels, out_channels_list):
        super(SkipUnit, self).__init__()
        self.blocks = nn.Sequential()
        for i, out_channels in enumerate(out_channels_list):
            self.blocks.add_module('block{}'.format(i + 1), FishBlock(
                in_channels=in_channels, out_channels=out_channels))
            in_channels = out_channels

    def forward(self, x):
        x = self.blocks(x)
        return x


class SkipAttUnit(nn.Module):
    """
    FishNet skip connection unit with attention block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels_list : list of int
        Number of output channels for each block.
    """

    def __init__(self, in_channels, out_channels_list):
        super(SkipAttUnit, self).__init__()
        mid_channels1 = in_channels // 2
        mid_channels2 = 2 * in_channels
        self.conv1 = pre_conv1x1_block(in_channels=in_channels,
            out_channels=mid_channels1)
        self.conv2 = pre_conv1x1_block(in_channels=mid_channels1,
            out_channels=mid_channels2, bias=True)
        in_channels = mid_channels2
        self.se = PreSEAttBlock(in_channels=mid_channels2, out_channels=
            out_channels_list[-1])
        self.blocks = nn.Sequential()
        for i, out_channels in enumerate(out_channels_list):
            self.blocks.add_module('block{}'.format(i + 1), FishBlock(
                in_channels=in_channels, out_channels=out_channels))
            in_channels = out_channels

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        w = self.se(x)
        x = self.blocks(x)
        x = x * w + w
        return x


class FishFinalBlock(nn.Module):
    """
    FishNet final block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    """

    def __init__(self, in_channels):
        super(FishFinalBlock, self).__init__()
        mid_channels = in_channels // 2
        self.conv1 = pre_conv1x1_block(in_channels=in_channels,
            out_channels=mid_channels)
        self.preactiv = PreResActivation(in_channels=mid_channels)

    def forward(self, x):
        x = self.conv1(x)
        x = self.preactiv(x)
        return x


class DropConvBlock(nn.Module):
    """
    Convolution block with Batch normalization, ReLU activation, and Dropout layer.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    bias : bool, default False
        Whether the layer uses a bias vector.
    dropout_rate : float, default 0.0
        Parameter of Dropout layer. Faction of the input units to drop.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, bias=False, dropout_prob=0.0):
        super(DropConvBlock, self).__init__()
        self.use_dropout = dropout_prob != 0.0
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, bias=bias)
        self.bn = nn.BatchNorm2d(num_features=out_channels)
        self.activ = nn.ReLU(inplace=True)
        if self.use_dropout:
            self.dropout = nn.Dropout2d(p=dropout_prob)

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        x = self.activ(x)
        if self.use_dropout:
            x = self.dropout(x)
        return x


def drop_conv3x3_block(in_channels, out_channels, stride=1, padding=1, bias
    =False, dropout_prob=0.0):
    """
    3x3 version of the convolution block with dropout.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 1
        Padding value for convolution layer.
    bias : bool, default False
        Whether the layer uses a bias vector.
    dropout_rate : float, default 0.0
        Parameter of Dropout layer. Faction of the input units to drop.
    """
    return DropConvBlock(in_channels=in_channels, out_channels=out_channels,
        kernel_size=3, stride=stride, padding=padding, bias=bias,
        dropout_prob=dropout_prob)


class FractalBlock(nn.Module):
    """
    FractalNet block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    num_columns : int
        Number of columns in each block.
    loc_drop_prob : float
        Local drop path probability.
    dropout_prob : float
        Probability of dropout.
    """

    def __init__(self, in_channels, out_channels, num_columns,
        loc_drop_prob, dropout_prob):
        super(FractalBlock, self).__init__()
        assert num_columns >= 1
        self.num_columns = num_columns
        self.loc_drop_prob = loc_drop_prob
        self.blocks = nn.Sequential()
        depth = 2 ** (num_columns - 1)
        for i in range(depth):
            level_block_i = nn.Sequential()
            for j in range(self.num_columns):
                column_step_j = 2 ** j
                if (i + 1) % column_step_j == 0:
                    in_channels_ij = (in_channels if i + 1 == column_step_j
                         else out_channels)
                    level_block_i.add_module('subblock{}'.format(j + 1),
                        drop_conv3x3_block(in_channels=in_channels_ij,
                        out_channels=out_channels, dropout_prob=dropout_prob))
            self.blocks.add_module('block{}'.format(i + 1), level_block_i)

    @staticmethod
    def calc_drop_mask(batch_size, glob_num_columns, curr_num_columns,
        max_num_columns, loc_drop_prob):
        """
        Calculate drop path mask.

        Parameters:
        ----------
        batch_size : int
            Size of batch.
        glob_num_columns : int
            Number of columns in global drop path mask.
        curr_num_columns : int
            Number of active columns in the current level of block.
        max_num_columns : int
            Number of columns for all network.
        loc_drop_prob : float
            Local drop path probability.

        Returns
        -------
        Tensor
            Resulted mask.
        """
        glob_batch_size = glob_num_columns.shape[0]
        glob_drop_mask = np.zeros((curr_num_columns, glob_batch_size),
            dtype=np.float32)
        glob_drop_num_columns = glob_num_columns - (max_num_columns -
            curr_num_columns)
        glob_drop_indices = np.where(glob_drop_num_columns >= 0)[0]
        glob_drop_mask[glob_drop_num_columns[glob_drop_indices],
            glob_drop_indices] = 1.0
        loc_batch_size = batch_size - glob_batch_size
        loc_drop_mask = np.random.binomial(n=1, p=1.0 - loc_drop_prob, size
            =(curr_num_columns, loc_batch_size)).astype(np.float32)
        alive_count = loc_drop_mask.sum(axis=0)
        dead_indices = np.where(alive_count == 0.0)[0]
        loc_drop_mask[np.random.randint(0, curr_num_columns, size=
            dead_indices.shape), dead_indices] = 1.0
        drop_mask = np.concatenate((glob_drop_mask, loc_drop_mask), axis=1)
        return torch.from_numpy(drop_mask)

    @staticmethod
    def join_outs(raw_outs, glob_num_columns, num_columns, loc_drop_prob,
        training):
        """
        Join outputs for current level of block.

        Parameters:
        ----------
        raw_outs : list of Tensor
            Current outputs from active columns.
        glob_num_columns : int
            Number of columns in global drop path mask.
        num_columns : int
            Number of columns for all network.
        loc_drop_prob : float
            Local drop path probability.
        training : bool
            Whether training mode for network.

        Returns
        -------
        Tensor
            Joined output.
        """
        curr_num_columns = len(raw_outs)
        out = torch.stack(raw_outs, dim=0)
        assert out.size(0) == curr_num_columns
        if training:
            batch_size = out.size(1)
            batch_mask = FractalBlock.calc_drop_mask(batch_size=batch_size,
                glob_num_columns=glob_num_columns, curr_num_columns=
                curr_num_columns, max_num_columns=num_columns,
                loc_drop_prob=loc_drop_prob)
            batch_mask = batch_mask.to(out.device)
            assert batch_mask.size(0) == curr_num_columns
            assert batch_mask.size(1) == batch_size
            batch_mask = batch_mask.unsqueeze(2).unsqueeze(3).unsqueeze(4)
            masked_out = out * batch_mask
            num_alive = batch_mask.sum(dim=0)
            num_alive[num_alive == 0.0] = 1.0
            out = masked_out.sum(dim=0) / num_alive
        else:
            out = out.mean(dim=0)
        return out

    def forward(self, x, glob_num_columns):
        outs = [x] * self.num_columns
        for level_block_i in self.blocks._modules.values():
            outs_i = []
            for j, block_ij in enumerate(level_block_i._modules.values()):
                input_i = outs[j]
                outs_i.append(block_ij(input_i))
            joined_out = FractalBlock.join_outs(raw_outs=outs_i[::-1],
                glob_num_columns=glob_num_columns, num_columns=self.
                num_columns, loc_drop_prob=self.loc_drop_prob, training=
                self.training)
            len_level_block_i = len(level_block_i._modules.values())
            for j in range(len_level_block_i):
                outs[j] = joined_out
        return outs[0]


class FractalUnit(nn.Module):
    """
    FractalNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    num_columns : int
        Number of columns in each block.
    loc_drop_prob : float
        Local drop path probability.
    dropout_prob : float
        Probability of dropout.
    """

    def __init__(self, in_channels, out_channels, num_columns,
        loc_drop_prob, dropout_prob):
        super(FractalUnit, self).__init__()
        self.block = FractalBlock(in_channels=in_channels, out_channels=
            out_channels, num_columns=num_columns, loc_drop_prob=
            loc_drop_prob, dropout_prob=dropout_prob)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)

    def forward(self, x, glob_num_columns):
        x = self.block(x, glob_num_columns=glob_num_columns)
        x = self.pool(x)
        return x


class CIFARFractalNet(nn.Module):
    """
    FractalNet model for CIFAR from 'FractalNet: Ultra-Deep Neural Networks without Residuals,'
    https://arxiv.org/abs/1605.07648.

    Parameters:
    ----------
    channels : list of int
        Number of output channels for each unit.
    num_columns : int
        Number of columns in each block.
    dropout_probs : list of float
        Probability of dropout in each block.
    loc_drop_prob : float
        Local drop path probability.
    glob_drop_ratio : float
        Global drop part fraction.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (32, 32)
        Spatial size of the expected input image.
    num_classes : int, default 10
        Number of classification classes.
    """

    def __init__(self, channels, num_columns, dropout_probs, loc_drop_prob,
        glob_drop_ratio, in_channels=3, in_size=(32, 32), num_classes=10):
        super(CIFARFractalNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.glob_drop_ratio = glob_drop_ratio
        self.num_columns = num_columns
        self.features = ParametricSequential()
        for i, out_channels in enumerate(channels):
            dropout_prob = dropout_probs[i]
            self.features.add_module('unit{}'.format(i + 1), FractalUnit(
                in_channels=in_channels, out_channels=out_channels,
                num_columns=num_columns, loc_drop_prob=loc_drop_prob,
                dropout_prob=dropout_prob))
            in_channels = out_channels
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        glob_batch_size = int(x.size(0) * self.glob_drop_ratio)
        glob_num_columns = np.random.randint(0, self.num_columns, size=(
            glob_batch_size,))
        x = self.features(x, glob_num_columns=glob_num_columns)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class GhostHSigmoid(nn.Module):
    """
    Approximated sigmoid function, specific for GhostNet.
    """

    def forward(self, x):
        return torch.clamp(x, min=0.0, max=1.0)


class GhostConvBlock(nn.Module):
    """
    GhostNet specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function or name of activation function.
    """

    def __init__(self, in_channels, out_channels, activation=lambda : nn.
        ReLU(inplace=True)):
        super(GhostConvBlock, self).__init__()
        main_out_channels = math.ceil(0.5 * out_channels)
        cheap_out_channels = out_channels - main_out_channels
        self.main_conv = conv1x1_block(in_channels=in_channels,
            out_channels=main_out_channels, activation=activation)
        self.cheap_conv = dwconv3x3_block(in_channels=main_out_channels,
            out_channels=cheap_out_channels, activation=activation)

    def forward(self, x):
        x = self.main_conv(x)
        y = self.cheap_conv(x)
        return torch.cat((x, y), dim=1)


class GhostExpBlock(nn.Module):
    """
    GhostNet expansion block for residual path in GhostNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    use_kernel3 : bool
        Whether to use 3x3 (instead of 5x5) kernel.
    exp_factor : float
        Expansion factor.
    use_se : bool
        Whether to use SE-module.
    """

    def __init__(self, in_channels, out_channels, stride, use_kernel3,
        exp_factor, use_se):
        super(GhostExpBlock, self).__init__()
        self.use_dw_conv = stride != 1
        self.use_se = use_se
        mid_channels = int(math.ceil(exp_factor * in_channels))
        self.exp_conv = GhostConvBlock(in_channels=in_channels,
            out_channels=mid_channels)
        if self.use_dw_conv:
            dw_conv_class = dwconv3x3_block if use_kernel3 else dwconv5x5_block
            self.dw_conv = dw_conv_class(in_channels=mid_channels,
                out_channels=mid_channels, stride=stride, activation=None)
        if self.use_se:
            self.se = SEBlock(channels=mid_channels, reduction=4,
                out_activation=GhostHSigmoid())
        self.pw_conv = GhostConvBlock(in_channels=mid_channels,
            out_channels=out_channels, activation=None)

    def forward(self, x):
        x = self.exp_conv(x)
        if self.use_dw_conv:
            x = self.dw_conv(x)
        if self.use_se:
            x = self.se(x)
        x = self.pw_conv(x)
        return x


def dwsconv3x3_block(in_channels, out_channels, strides=1, padding=1,
    dilation=1, use_bias=False, dw_use_bn=True, pw_use_bn=True, bn_eps=
    1e-05, dw_activation='relu', pw_activation='relu', se_reduction=0,
    data_format='channels_last', **kwargs):
    """
    3x3 depthwise separable version of the standard convolution block (SINet version).

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    strides : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 1
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    use_bias : bool, default False
        Whether the layer uses a bias vector.
    dw_use_bn : bool, default True
        Whether to use BatchNorm layer (depthwise convolution block).
    pw_use_bn : bool, default True
        Whether to use BatchNorm layer (pointwise convolution block).
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    dw_activation : function or str or None, default 'relu'
        Activation function after the depthwise convolution block.
    pw_activation : function or str or None, default 'relu'
        Activation function after the pointwise convolution block.
    se_reduction : int, default 0
        Squeeze reduction value (0 means no-se).
    data_format : str, default 'channels_last'
        The ordering of the dimensions in tensors.
    """
    return DwsConvBlock(in_channels=in_channels, out_channels=out_channels,
        kernel_size=3, strides=strides, padding=padding, dilation=dilation,
        use_bias=use_bias, dw_use_bn=dw_use_bn, pw_use_bn=pw_use_bn, bn_eps
        =bn_eps, dw_activation=dw_activation, pw_activation=pw_activation,
        se_reduction=se_reduction, data_format=data_format, **kwargs)


class GhostUnit(nn.Module):
    """
    GhostNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the second convolution layer.
    use_kernel3 : bool
        Whether to use 3x3 (instead of 5x5) kernel.
    exp_factor : float
        Expansion factor.
    use_se : bool
        Whether to use SE-module.
    """

    def __init__(self, in_channels, out_channels, stride, use_kernel3,
        exp_factor, use_se):
        super(GhostUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        self.body = GhostExpBlock(in_channels=in_channels, out_channels=
            out_channels, stride=stride, use_kernel3=use_kernel3,
            exp_factor=exp_factor, use_se=use_se)
        if self.resize_identity:
            self.identity_conv = dwsconv3x3_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride, pw_activation=None)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        x = x + identity
        return x


class GhostClassifier(nn.Module):
    """
    GhostNet classifier.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    mid_channels : int
        Number of middle channels.
    """

    def __init__(self, in_channels, out_channels, mid_channels):
        super(GhostClassifier, self).__init__()
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            mid_channels)
        self.conv2 = conv1x1(in_channels=mid_channels, out_channels=
            out_channels, bias=True)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class GhostNet(nn.Module):
    """
    GhostNet model from 'GhostNet: More Features from Cheap Operations,' https://arxiv.org/abs/1911.11907.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    final_block_channels : int
        Number of output channels for the final block of the feature extractor.
    classifier_mid_channels : int
        Number of middle channels for classifier.
    kernels3 : list of list of int/bool
        Using 3x3 (instead of 5x5) kernel for each unit.
    exp_factors : list of list of int
        Expansion factor for each unit.
    use_se : list of list of int/bool
        Using SE-block flag for each unit.
    first_stride : bool
        Whether to use stride for the first stage.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, final_block_channels,
        classifier_mid_channels, kernels3, exp_factors, use_se,
        first_stride, in_channels=3, in_size=(224, 224), num_classes=1000):
        super(GhostNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', conv3x3_block(in_channels=
            in_channels, out_channels=init_block_channels, stride=2))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and (i != 0 or first_stride) else 1
                use_kernel3 = kernels3[i][j] == 1
                exp_factor = exp_factors[i][j]
                use_se_flag = use_se[i][j] == 1
                stage.add_module('unit{}'.format(j + 1), GhostUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, use_kernel3=use_kernel3, exp_factor=
                    exp_factor, use_se=use_se_flag))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_block', conv1x1_block(in_channels=
            in_channels, out_channels=final_block_channels))
        in_channels = final_block_channels
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = GhostClassifier(in_channels=in_channels, out_channels
            =num_classes, mid_channels=classifier_mid_channels)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                nn.init.kaiming_normal_(module.weight, mode='fan_out',
                    nonlinearity='relu')
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = self.output(x)
        x = x.view(x.size(0), -1)
        return x


class InvDwsConvBlock(nn.Module):
    """
    Inverse depthwise separable convolution block with BatchNorms and activations at each convolution layers.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    bias : bool, default False
        Whether the layer uses a bias vector.
    use_bn : bool, default True
        Whether to use BatchNorm layer.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    pw_activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function after the pointwise convolution block.
    dw_activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function after the depthwise convolution block.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, dilation=1, bias=False, use_bn=True, bn_eps=1e-05,
        pw_activation=lambda : nn.ReLU(inplace=True), dw_activation=lambda :
        nn.ReLU(inplace=True)):
        super(InvDwsConvBlock, self).__init__()
        self.pw_conv = conv1x1_block(in_channels=in_channels, out_channels=
            out_channels, bias=bias, use_bn=use_bn, bn_eps=bn_eps,
            activation=pw_activation)
        self.dw_conv = dwconv_block(in_channels=out_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, dilation=dilation, bias=bias, use_bn=use_bn, bn_eps=
            bn_eps, activation=dw_activation)

    def forward(self, x):
        x = self.pw_conv(x)
        x = self.dw_conv(x)
        return x


def invdwsconv3x3_block(in_channels, out_channels, stride=1, padding=1,
    dilation=1, bias=False, bn_eps=1e-05, pw_activation=lambda : nn.ReLU(
    inplace=True), dw_activation=lambda : nn.ReLU(inplace=True)):
    """
    3x3 inverse depthwise separable version of the standard convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 1
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    bias : bool, default False
        Whether the layer uses a bias vector.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    pw_activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function after the pointwise convolution block.
    dw_activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function after the depthwise convolution block.
    """
    return InvDwsConvBlock(in_channels=in_channels, out_channels=
        out_channels, kernel_size=3, stride=stride, padding=padding,
        dilation=dilation, bias=bias, bn_eps=bn_eps, pw_activation=
        pw_activation, dw_activation=dw_activation)


class HarDUnit(nn.Module):
    """
    HarDNet unit.

    Parameters:
    ----------
    in_channels_list : list of int
        Number of input channels for each block.
    out_channels_list : list of int
        Number of output channels for each block.
    links_list : list of list of int
        List of indices for each layer.
    use_deptwise : bool
        Whether to use depthwise downsampling.
    use_dropout : bool
        Whether to use dropout module.
    downsampling : bool
        Whether to downsample input.
    activation : str
        Name of activation function.
    """

    def __init__(self, in_channels_list, out_channels_list, links_list,
        use_deptwise, use_dropout, downsampling, activation):
        super(HarDUnit, self).__init__()
        self.links_list = links_list
        self.use_dropout = use_dropout
        self.downsampling = downsampling
        self.blocks = nn.Sequential()
        for i in range(len(links_list)):
            in_channels = in_channels_list[i]
            out_channels = out_channels_list[i]
            if use_deptwise:
                unit = invdwsconv3x3_block(in_channels=in_channels,
                    out_channels=out_channels, pw_activation=activation,
                    dw_activation=None)
            else:
                unit = conv3x3_block(in_channels=in_channels, out_channels=
                    out_channels)
            self.blocks.add_module('block{}'.format(i + 1), unit)
        if self.use_dropout:
            self.dropout = nn.Dropout(p=0.1)
        self.conv = conv1x1_block(in_channels=in_channels_list[-1],
            out_channels=out_channels_list[-1], activation=activation)
        if self.downsampling:
            if use_deptwise:
                self.downsample = dwconv3x3_block(in_channels=
                    out_channels_list[-1], out_channels=out_channels_list[-
                    1], stride=2, activation=None)
            else:
                self.downsample = nn.MaxPool2d(kernel_size=2, stride=2)

    def forward(self, x):
        layer_outs = [x]
        for links_i, layer_i in zip(self.links_list, self.blocks._modules.
            values()):
            layer_in = []
            for idx_ij in links_i:
                layer_in.append(layer_outs[idx_ij])
            if len(layer_in) > 1:
                x = torch.cat(layer_in, dim=1)
            else:
                x = layer_in[0]
            out = layer_i(x)
            layer_outs.append(out)
        outs = []
        for i, layer_out_i in enumerate(layer_outs):
            if i == len(layer_outs) - 1 or i % 2 == 1:
                outs.append(layer_out_i)
        x = torch.cat(outs, dim=1)
        if self.use_dropout:
            x = self.dropout(x)
        x = self.conv(x)
        if self.downsampling:
            x = self.downsample(x)
        return x


class HarDInitBlock(nn.Module):
    """
    HarDNet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    use_deptwise : bool
        Whether to use depthwise downsampling.
    activation : str
        Name of activation function.
    """

    def __init__(self, in_channels, out_channels, use_deptwise, activation):
        super(HarDInitBlock, self).__init__()
        mid_channels = out_channels // 2
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            mid_channels, stride=2, activation=activation)
        conv2_block_class = conv1x1_block if use_deptwise else conv3x3_block
        self.conv2 = conv2_block_class(in_channels=mid_channels,
            out_channels=out_channels, activation=activation)
        if use_deptwise:
            self.downsample = dwconv3x3_block(in_channels=out_channels,
                out_channels=out_channels, stride=2, activation=None)
        else:
            self.downsample = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.downsample(x)
        return x


class HarDNet(nn.Module):
    """
    HarDNet model from 'HarDNet: A Low Memory Traffic Network,' https://arxiv.org/abs/1909.00948.

    Parameters:
    ----------
    init_block_channels : int
        Number of output channels for the initial unit.
    unit_in_channels : list of list of list of int
        Number of input channels for each layer in each stage.
    unit_out_channels : list list of of list of int
        Number of output channels for each layer in each stage.
    unit_links : list of list of list of int
        List of indices for each layer in each stage.
    use_deptwise : bool
        Whether to use depthwise downsampling.
    use_last_dropout : bool
        Whether to use dropouts in the last unit.
    output_dropout_rate : float
        Parameter of Dropout layer before classifier. Faction of the input units to drop.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, init_block_channels, unit_in_channels,
        unit_out_channels, unit_links, use_deptwise, use_last_dropout,
        output_dropout_rate, in_channels=3, in_size=(224, 224), num_classes
        =1000):
        super(HarDNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        activation = 'relu6'
        self.features = nn.Sequential()
        self.features.add_module('init_block', HarDInitBlock(in_channels=
            in_channels, out_channels=init_block_channels, use_deptwise=
            use_deptwise, activation=activation))
        for i, (in_channels_list_i, out_channels_list_i) in enumerate(zip(
            unit_in_channels, unit_out_channels)):
            stage = nn.Sequential()
            for j, (in_channels_list_ij, out_channels_list_ij) in enumerate(zip
                (in_channels_list_i, out_channels_list_i)):
                use_dropout = j == len(in_channels_list_i) - 1 and i == len(
                    unit_in_channels) - 1 and use_last_dropout
                downsampling = j == len(in_channels_list_i) - 1 and i != len(
                    unit_in_channels) - 1
                stage.add_module('unit{}'.format(j + 1), HarDUnit(
                    in_channels_list=in_channels_list_ij, out_channels_list
                    =out_channels_list_ij, links_list=unit_links[i][j],
                    use_deptwise=use_deptwise, use_dropout=use_dropout,
                    downsampling=downsampling, activation=activation))
            self.features.add_module('stage{}'.format(i + 1), stage)
        in_channels = unit_out_channels[-1][-1][-1]
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Sequential()
        self.output.add_module('dropout', nn.Dropout(p=output_dropout_rate))
        self.output.add_module('fc', nn.Linear(in_features=in_channels,
            out_features=num_classes))
        self._init_params()

    def _init_params(self):
        for module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                nn.init.kaiming_uniform_(module.weight, mode='fan_out',
                    nonlinearity='relu')
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)
            elif isinstance(module, nn.BatchNorm2d):
                nn.init.constant_(module.weight, 1)
                nn.init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class UpSamplingBlock(nn.Module):
    """
    HFNet specific upsampling block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    scale_factor : int
        Multiplier for spatial size.
    """

    def __init__(self, in_channels, out_channels, scale_factor):
        super(UpSamplingBlock, self).__init__()
        self.conv = conv1x1_block(in_channels=in_channels, out_channels=
            out_channels, stride=1, activation=None)
        self.upsample = nn.Upsample(scale_factor=scale_factor, mode='nearest')

    def forward(self, x):
        x = self.conv(x)
        x = self.upsample(x)
        return x


class HRBlock(nn.Module):
    """
    HFNet block.

    Parameters:
    ----------
    in_channels_list : list of int
        Number of input channels.
    out_channels_list : list of int
        Number of output channels.
    num_branches : int
        Number of branches.
    num_subblocks : list of int
        Number of subblock.
    """

    def __init__(self, in_channels_list, out_channels_list, num_branches,
        num_subblocks):
        super(HRBlock, self).__init__()
        self.in_channels_list = in_channels_list
        self.num_branches = num_branches
        self.branches = nn.Sequential()
        for i in range(num_branches):
            layers = nn.Sequential()
            in_channels_i = self.in_channels_list[i]
            out_channels_i = out_channels_list[i]
            for j in range(num_subblocks[i]):
                layers.add_module('unit{}'.format(j + 1), ResUnit(
                    in_channels=in_channels_i, out_channels=out_channels_i,
                    stride=1, bottleneck=False))
                in_channels_i = out_channels_i
            self.in_channels_list[i] = out_channels_i
            self.branches.add_module('branch{}'.format(i + 1), layers)
        if num_branches > 1:
            self.fuse_layers = nn.Sequential()
            for i in range(num_branches):
                fuse_layer = nn.Sequential()
                for j in range(num_branches):
                    if j > i:
                        fuse_layer.add_module('block{}'.format(j + 1),
                            UpSamplingBlock(in_channels=in_channels_list[j],
                            out_channels=in_channels_list[i], scale_factor=
                            2 ** (j - i)))
                    elif j == i:
                        fuse_layer.add_module('block{}'.format(j + 1),
                            Identity())
                    else:
                        conv3x3_seq = nn.Sequential()
                        for k in range(i - j):
                            if k == i - j - 1:
                                conv3x3_seq.add_module('subblock{}'.format(
                                    k + 1), conv3x3_block(in_channels=
                                    in_channels_list[j], out_channels=
                                    in_channels_list[i], stride=2,
                                    activation=None))
                            else:
                                conv3x3_seq.add_module('subblock{}'.format(
                                    k + 1), conv3x3_block(in_channels=
                                    in_channels_list[j], out_channels=
                                    in_channels_list[j], stride=2))
                        fuse_layer.add_module('block{}'.format(j + 1),
                            conv3x3_seq)
                self.fuse_layers.add_module('layer{}'.format(i + 1), fuse_layer
                    )
            self.activ = nn.ReLU(True)

    def forward(self, x):
        for i in range(self.num_branches):
            x[i] = self.branches[i](x[i])
        if self.num_branches == 1:
            return x
        x_fuse = []
        for i in range(len(self.fuse_layers)):
            y = x[0] if i == 0 else self.fuse_layers[i][0](x[0])
            for j in range(1, self.num_branches):
                if i == j:
                    y = y + x[j]
                else:
                    y = y + self.fuse_layers[i][j](x[j])
            x_fuse.append(self.activ(y))
        return x_fuse


class HRStage(nn.Module):
    """
    HRNet stage block.

    Parameters:
    ----------
    in_channels_list : list of int
        Number of output channels from the previous layer.
    out_channels_list : list of int
        Number of output channels in the current layer.
    num_modules : int
        Number of modules.
    num_branches : int
        Number of branches.
    num_subblocks : list of int
        Number of subblocks.
    """

    def __init__(self, in_channels_list, out_channels_list, num_modules,
        num_branches, num_subblocks):
        super(HRStage, self).__init__()
        self.branches = num_branches
        self.in_channels_list = out_channels_list
        in_branches = len(in_channels_list)
        out_branches = len(out_channels_list)
        self.transition = nn.Sequential()
        for i in range(out_branches):
            if i < in_branches:
                if out_channels_list[i] != in_channels_list[i]:
                    self.transition.add_module('block{}'.format(i + 1),
                        conv3x3_block(in_channels=in_channels_list[i],
                        out_channels=out_channels_list[i], stride=1))
                else:
                    self.transition.add_module('block{}'.format(i + 1),
                        Identity())
            else:
                conv3x3_seq = nn.Sequential()
                for j in range(i + 1 - in_branches):
                    in_channels_i = in_channels_list[-1]
                    out_channels_i = out_channels_list[i
                        ] if j == i - in_branches else in_channels_i
                    conv3x3_seq.add_module('subblock{}'.format(j + 1),
                        conv3x3_block(in_channels=in_channels_i,
                        out_channels=out_channels_i, stride=2))
                self.transition.add_module('block{}'.format(i + 1), conv3x3_seq
                    )
        self.layers = nn.Sequential()
        for i in range(num_modules):
            self.layers.add_module('block{}'.format(i + 1), HRBlock(
                in_channels_list=self.in_channels_list, out_channels_list=
                out_channels_list, num_branches=num_branches, num_subblocks
                =num_subblocks))
            self.in_channels_list = self.layers[-1].in_channels_list

    def forward(self, x):
        x_list = []
        for j in range(self.branches):
            if not isinstance(self.transition[j], Identity):
                x_list.append(self.transition[j](x[-1] if type(x) is list else
                    x))
            else:
                x_list_j = x[j] if type(x) is list else x
                x_list.append(x_list_j)
        y_list = self.layers(x_list)
        return y_list


class HRInitBlock(nn.Module):
    """
    HRNet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    mid_channels : int
        Number of middle channels.
    num_subblocks : int
        Number of subblocks.
    """

    def __init__(self, in_channels, out_channels, mid_channels, num_subblocks):
        super(HRInitBlock, self).__init__()
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            mid_channels, stride=2)
        self.conv2 = conv3x3_block(in_channels=mid_channels, out_channels=
            mid_channels, stride=2)
        in_channels = mid_channels
        self.subblocks = nn.Sequential()
        for i in range(num_subblocks):
            self.subblocks.add_module('block{}'.format(i + 1), ResUnit(
                in_channels=in_channels, out_channels=out_channels, stride=
                1, bottleneck=True))
            in_channels = out_channels

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.subblocks(x)
        return x


class HRFinalBlock(nn.Module):
    """
    HRNet specific final block.

    Parameters:
    ----------
    in_channels_list : list of int
        Number of input channels per stage.
    out_channels_list : list of int
        Number of output channels per stage.
    """

    def __init__(self, in_channels_list, out_channels_list):
        super(HRFinalBlock, self).__init__()
        self.inc_blocks = nn.Sequential()
        for i, in_channels_i in enumerate(in_channels_list):
            self.inc_blocks.add_module('block{}'.format(i + 1), ResUnit(
                in_channels=in_channels_i, out_channels=out_channels_list[i
                ], stride=1, bottleneck=True))
        self.down_blocks = nn.Sequential()
        for i in range(len(in_channels_list) - 1):
            self.down_blocks.add_module('block{}'.format(i + 1),
                conv3x3_block(in_channels=out_channels_list[i],
                out_channels=out_channels_list[i + 1], stride=2, bias=True))
        self.final_layer = conv1x1_block(in_channels=1024, out_channels=
            2048, stride=1, bias=True)

    def forward(self, x):
        y = self.inc_blocks[0](x[0])
        for i in range(len(self.down_blocks)):
            y = self.inc_blocks[i + 1](x[i + 1]) + self.down_blocks[i](y)
        y = self.final_layer(y)
        return y


class HRNet(nn.Module):
    """
    HRNet model from 'Deep High-Resolution Representation Learning for Visual Recognition,'
    https://arxiv.org/abs/1908.07919.

    Parameters:
    ----------
    channels : list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    init_num_subblocks : int
        Number of subblocks in the initial unit.
    num_modules : int
        Number of modules per stage.
    num_subblocks : list of int
        Number of subblocks per stage.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, init_num_subblocks,
        num_modules, num_subblocks, in_channels=3, in_size=(224, 224),
        num_classes=1000):
        super(HRNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.branches = [2, 3, 4]
        self.features = nn.Sequential()
        self.features.add_module('init_block', HRInitBlock(in_channels=
            in_channels, out_channels=init_block_channels, mid_channels=64,
            num_subblocks=init_num_subblocks))
        in_channels_list = [init_block_channels]
        for i in range(len(self.branches)):
            self.features.add_module('stage{}'.format(i + 1), HRStage(
                in_channels_list=in_channels_list, out_channels_list=
                channels[i], num_modules=num_modules[i], num_branches=self.
                branches[i], num_subblocks=num_subblocks[i]))
            in_channels_list = self.features[-1].in_channels_list
        self.features.add_module('final_block', HRFinalBlock(
            in_channels_list=in_channels_list, out_channels_list=[128, 256,
            512, 1024]))
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=2048, out_features=num_classes)
        self._init_params()

    def _init_params(self):
        for module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                nn.init.kaiming_uniform_(module.weight, mode='fan_out',
                    nonlinearity='relu')
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)
            elif isinstance(module, nn.BatchNorm2d):
                nn.init.constant_(module.weight, 1)
                nn.init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class IBNbConvBlock(nn.Module):
    """
    IBN(b)-ResNet specific convolution block with Instance normalization and ReLU activation.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    activate : bool, default True
        Whether activate the convolution block.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, dilation=1, groups=1, bias=False, activate=True):
        super(IBNbConvBlock, self).__init__()
        self.activate = activate
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, dilation=dilation, groups=groups, bias=bias)
        self.inst_norm = nn.InstanceNorm2d(num_features=out_channels,
            affine=True)
        if self.activate:
            self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.conv(x)
        x = self.inst_norm(x)
        if self.activate:
            x = self.activ(x)
        return x


class IBNbResUnit(nn.Module):
    """
    IBN(b)-ResNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    use_inst_norm : bool
        Whether to use instance normalization.
    """

    def __init__(self, in_channels, out_channels, stride, use_inst_norm):
        super(IBNbResUnit, self).__init__()
        self.use_inst_norm = use_inst_norm
        self.resize_identity = in_channels != out_channels or stride != 1
        self.body = ResBottleneck(in_channels=in_channels, out_channels=
            out_channels, stride=stride, conv1_stride=False)
        if self.resize_identity:
            self.identity_conv = conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride, activation=None)
        if self.use_inst_norm:
            self.inst_norm = nn.InstanceNorm2d(num_features=out_channels,
                affine=True)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        x = x + identity
        if self.use_inst_norm:
            x = self.inst_norm(x)
        x = self.activ(x)
        return x


def ibnb_conv7x7_block(in_channels, out_channels, stride=1, padding=3, bias
    =False, activate=True):
    """
    7x7 version of the IBN(b)-ResNet specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 3
        Padding value for convolution layer.
    bias : bool, default False
        Whether the layer uses a bias vector.
    activate : bool, default True
        Whether activate the convolution block.
    """
    return IBNbConvBlock(in_channels=in_channels, out_channels=out_channels,
        kernel_size=7, stride=stride, padding=padding, bias=bias, activate=
        activate)


class IBNbResInitBlock(nn.Module):
    """
    IBN(b)-ResNet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(IBNbResInitBlock, self).__init__()
        self.conv = ibnb_conv7x7_block(in_channels=in_channels,
            out_channels=out_channels, stride=2)
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

    def forward(self, x):
        x = self.conv(x)
        x = self.pool(x)
        return x


class IBNbResNet(nn.Module):
    """
    IBN(b)-ResNet model from 'Two at Once: Enhancing Learning and Generalization Capacities via IBN-Net,'
    https://arxiv.org/abs/1807.09441.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, in_channels=3,
        in_size=(224, 224), num_classes=1000):
        super(IBNbResNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', IBNbResInitBlock(in_channels
            =in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                use_inst_norm = i < 2 and j == len(channels_per_stage) - 1
                stage.add_module('unit{}'.format(j + 1), IBNbResUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, use_inst_norm=use_inst_norm))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class IBNPreConvBlock(nn.Module):
    """
    IBN-Net specific convolution block with BN/IBN normalization and ReLU pre-activation.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    use_ibn : bool, default False
        Whether use Instance-Batch Normalization.
    return_preact : bool, default False
        Whether return pre-activation. It's used by PreResNet.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, use_ibn=False, return_preact=False):
        super(IBNPreConvBlock, self).__init__()
        self.use_ibn = use_ibn
        self.return_preact = return_preact
        if self.use_ibn:
            self.ibn = IBN(channels=in_channels, first_fraction=0.6,
                inst_first=False)
        else:
            self.bn = nn.BatchNorm2d(num_features=in_channels)
        self.activ = nn.ReLU(inplace=True)
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, bias=False)

    def forward(self, x):
        if self.use_ibn:
            x = self.ibn(x)
        else:
            x = self.bn(x)
        x = self.activ(x)
        if self.return_preact:
            x_pre_activ = x
        x = self.conv(x)
        if self.return_preact:
            return x, x_pre_activ
        else:
            return x


def ibn_pre_conv1x1_block(in_channels, out_channels, stride=1, use_ibn=
    False, return_preact=False):
    """
    1x1 version of the IBN-Net specific pre-activated convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    use_ibn : bool, default False
        Whether use Instance-Batch Normalization.
    return_preact : bool, default False
        Whether return pre-activation.
    """
    return IBNPreConvBlock(in_channels=in_channels, out_channels=
        out_channels, kernel_size=1, stride=stride, padding=0, use_ibn=
        use_ibn, return_preact=return_preact)


class IBNDenseUnit(nn.Module):
    """
    IBN-DenseNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    dropout_rate : float
        Parameter of Dropout layer. Faction of the input units to drop.
    conv1_ibn : bool
        Whether to use IBN normalization in the first convolution layer of the block.
    """

    def __init__(self, in_channels, out_channels, dropout_rate, conv1_ibn):
        super(IBNDenseUnit, self).__init__()
        self.use_dropout = dropout_rate != 0.0
        bn_size = 4
        inc_channels = out_channels - in_channels
        mid_channels = inc_channels * bn_size
        self.conv1 = ibn_pre_conv1x1_block(in_channels=in_channels,
            out_channels=mid_channels, use_ibn=conv1_ibn)
        self.conv2 = pre_conv3x3_block(in_channels=mid_channels,
            out_channels=inc_channels)
        if self.use_dropout:
            self.dropout = nn.Dropout(p=dropout_rate)

    def forward(self, x):
        identity = x
        x = self.conv1(x)
        x = self.conv2(x)
        if self.use_dropout:
            x = self.dropout(x)
        x = torch.cat((identity, x), dim=1)
        return x


class IBNDenseNet(nn.Module):
    """
    IBN-DenseNet model from 'Two at Once: Enhancing Learning and Generalization Capacities via IBN-Net,'
    https://arxiv.org/abs/1807.09441.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    dropout_rate : float, default 0.0
        Parameter of Dropout layer. Faction of the input units to drop.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, dropout_rate=0.0,
        in_channels=3, in_size=(224, 224), num_classes=1000):
        super(IBNDenseNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', PreResInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            if i != 0:
                stage.add_module('trans{}'.format(i + 1), TransitionBlock(
                    in_channels=in_channels, out_channels=in_channels // 2))
                in_channels = in_channels // 2
            for j, out_channels in enumerate(channels_per_stage):
                conv1_ibn = i < 3 and j % 3 == 0
                stage.add_module('unit{}'.format(j + 1), IBNDenseUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    dropout_rate=dropout_rate, conv1_ibn=conv1_ibn))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('post_activ', PreResActivation(in_channels
            =in_channels))
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class IBNConvBlock(nn.Module):
    """
    IBN-Net specific convolution block with BN/IBN normalization and ReLU activation.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    use_ibn : bool, default False
        Whether use Instance-Batch Normalization.
    activate : bool, default True
        Whether activate the convolution block.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, dilation=1, groups=1, bias=False, use_ibn=False, activate=True
        ):
        super(IBNConvBlock, self).__init__()
        self.activate = activate
        self.use_ibn = use_ibn
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, dilation=dilation, groups=groups, bias=bias)
        if self.use_ibn:
            self.ibn = IBN(channels=out_channels)
        else:
            self.bn = nn.BatchNorm2d(num_features=out_channels)
        if self.activate:
            self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.conv(x)
        if self.use_ibn:
            x = self.ibn(x)
        else:
            x = self.bn(x)
        if self.activate:
            x = self.activ(x)
        return x


def ibn_conv1x1_block(in_channels, out_channels, stride=1, groups=1, bias=
    False, use_ibn=False, activate=True):
    """
    1x1 version of the IBN-Net specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    use_ibn : bool, default False
        Whether use Instance-Batch Normalization.
    activate : bool, default True
        Whether activate the convolution block.
    """
    return IBNConvBlock(in_channels=in_channels, out_channels=out_channels,
        kernel_size=1, stride=stride, padding=0, groups=groups, bias=bias,
        use_ibn=use_ibn, activate=activate)


class IBNResBottleneck(nn.Module):
    """
    IBN-ResNet bottleneck block for residual path in IBN-ResNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    conv1_ibn : bool
        Whether to use IBN normalization in the first convolution layer of the block.
    """

    def __init__(self, in_channels, out_channels, stride, conv1_ibn):
        super(IBNResBottleneck, self).__init__()
        mid_channels = out_channels // 4
        self.conv1 = ibn_conv1x1_block(in_channels=in_channels,
            out_channels=mid_channels, use_ibn=conv1_ibn)
        self.conv2 = conv3x3_block(in_channels=mid_channels, out_channels=
            mid_channels, stride=stride)
        self.conv3 = conv1x1_block(in_channels=mid_channels, out_channels=
            out_channels, activation=None)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class IBNResUnit(nn.Module):
    """
    IBN-ResNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    conv1_ibn : bool
        Whether to use IBN normalization in the first convolution layer of the block.
    """

    def __init__(self, in_channels, out_channels, stride, conv1_ibn):
        super(IBNResUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        self.body = IBNResBottleneck(in_channels=in_channels, out_channels=
            out_channels, stride=stride, conv1_ibn=conv1_ibn)
        if self.resize_identity:
            self.identity_conv = conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride, activation=None)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        x = x + identity
        x = self.activ(x)
        return x


class IBNResNet(nn.Module):
    """
    IBN-ResNet model from 'Two at Once: Enhancing Learning and Generalization Capacities via IBN-Net,'
    https://arxiv.org/abs/1807.09441.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, in_channels=3,
        in_size=(224, 224), num_classes=1000):
        super(IBNResNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', ResInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                conv1_ibn = out_channels < 2048
                stage.add_module('unit{}'.format(j + 1), IBNResUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, conv1_ibn=conv1_ibn))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class IBNResNeXtBottleneck(nn.Module):
    """
    IBN-ResNeXt bottleneck block for residual path in IBN-ResNeXt unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    cardinality: int
        Number of groups.
    bottleneck_width: int
        Width of bottleneck block.
    conv1_ibn : bool
        Whether to use IBN normalization in the first convolution layer of the block.
    """

    def __init__(self, in_channels, out_channels, stride, cardinality,
        bottleneck_width, conv1_ibn):
        super(IBNResNeXtBottleneck, self).__init__()
        mid_channels = out_channels // 4
        D = int(math.floor(mid_channels * (bottleneck_width / 64.0)))
        group_width = cardinality * D
        self.conv1 = ibn_conv1x1_block(in_channels=in_channels,
            out_channels=group_width, use_ibn=conv1_ibn)
        self.conv2 = conv3x3_block(in_channels=group_width, out_channels=
            group_width, stride=stride, groups=cardinality)
        self.conv3 = conv1x1_block(in_channels=group_width, out_channels=
            out_channels, activation=None)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class IBNResNeXtUnit(nn.Module):
    """
    IBN-ResNeXt unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    cardinality: int
        Number of groups.
    bottleneck_width: int
        Width of bottleneck block.
    conv1_ibn : bool
        Whether to use IBN normalization in the first convolution layer of the block.
    """

    def __init__(self, in_channels, out_channels, stride, cardinality,
        bottleneck_width, conv1_ibn):
        super(IBNResNeXtUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        self.body = IBNResNeXtBottleneck(in_channels=in_channels,
            out_channels=out_channels, stride=stride, cardinality=
            cardinality, bottleneck_width=bottleneck_width, conv1_ibn=conv1_ibn
            )
        if self.resize_identity:
            self.identity_conv = conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride, activation=None)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        x = x + identity
        x = self.activ(x)
        return x


class IBNResNeXt(nn.Module):
    """
    IBN-ResNeXt model from 'Two at Once: Enhancing Learning and Generalization Capacities via IBN-Net,'
    https://arxiv.org/abs/1807.09441.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    cardinality: int
        Number of groups.
    bottleneck_width: int
        Width of bottleneck block.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, cardinality,
        bottleneck_width, in_channels=3, in_size=(224, 224), num_classes=1000):
        super(IBNResNeXt, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', ResInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                conv1_ibn = out_channels < 2048
                stage.add_module('unit{}'.format(j + 1), IBNResNeXtUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, cardinality=cardinality,
                    bottleneck_width=bottleneck_width, conv1_ibn=conv1_ibn))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class IbpResBottleneck(nn.Module):
    """
    Bottleneck block for residual path in the residual unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    bias : bool, default False
        Whether the layer uses a bias vector.
    bottleneck_factor : int, default 2
        Bottleneck factor.
    activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function or name of activation function.
    """

    def __init__(self, in_channels, out_channels, stride, bias=False,
        bottleneck_factor=2, activation=lambda : nn.ReLU(inplace=True)):
        super(IbpResBottleneck, self).__init__()
        mid_channels = out_channels // bottleneck_factor
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            mid_channels, bias=bias, activation=activation)
        self.conv2 = conv3x3_block(in_channels=mid_channels, out_channels=
            mid_channels, stride=stride, bias=bias, activation=activation)
        self.conv3 = conv1x1_block(in_channels=mid_channels, out_channels=
            out_channels, bias=bias, activation=None)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class IbpResUnit(nn.Module):
    """
    ResNet-like residual unit with residual connection.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    bias : bool, default False
        Whether the layer uses a bias vector.
    bottleneck_factor : int, default 2
        Bottleneck factor.
    activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function or name of activation function.
    """

    def __init__(self, in_channels, out_channels, stride=1, bias=False,
        bottleneck_factor=2, activation=lambda : nn.ReLU(inplace=True)):
        super(IbpResUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        self.body = IbpResBottleneck(in_channels=in_channels, out_channels=
            out_channels, stride=stride, bias=bias, bottleneck_factor=
            bottleneck_factor, activation=activation)
        if self.resize_identity:
            self.identity_conv = conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride, bias=bias,
                activation=None)
        self.activ = get_activation_layer(activation)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        x = x + identity
        x = self.activ(x)
        return x


class IbpBackbone(nn.Module):
    """
    IBPPose backbone.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    activation : function or str or None
        Activation function or name of activation function.
    """

    def __init__(self, in_channels, out_channels, activation):
        super(IbpBackbone, self).__init__()
        dilations = 3, 3, 4, 4, 5, 5
        mid1_channels = out_channels // 4
        mid2_channels = out_channels // 2
        self.conv1 = conv7x7_block(in_channels=in_channels, out_channels=
            mid1_channels, stride=2, activation=activation)
        self.res1 = IbpResUnit(in_channels=mid1_channels, out_channels=
            mid2_channels, activation=activation)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.res2 = IbpResUnit(in_channels=mid2_channels, out_channels=
            mid2_channels, activation=activation)
        self.dilation_branch = nn.Sequential()
        for i, dilation in enumerate(dilations):
            self.dilation_branch.add_module('block{}'.format(i + 1),
                conv3x3_block(in_channels=mid2_channels, out_channels=
                mid2_channels, padding=dilation, dilation=dilation,
                activation=activation))

    def forward(self, x):
        x = self.conv1(x)
        x = self.res1(x)
        x = self.pool(x)
        x = self.res2(x)
        y = self.dilation_branch(x)
        x = torch.cat((x, y), dim=1)
        return x


class IbpDownBlock(nn.Module):
    """
    IBPPose down block for the hourglass.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    activation : function or str or None
        Activation function or name of activation function.
    """

    def __init__(self, in_channels, out_channels, activation):
        super(IbpDownBlock, self).__init__()
        self.down = nn.MaxPool2d(kernel_size=2, stride=2)
        self.res = IbpResUnit(in_channels=in_channels, out_channels=
            out_channels, activation=activation)

    def forward(self, x):
        x = self.down(x)
        x = self.res(x)
        return x


class IbpUpBlock(nn.Module):
    """
    IBPPose up block for the hourglass.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    use_bn : bool
        Whether to use BatchNorm layer.
    activation : function or str or None
        Activation function or name of activation function.
    """

    def __init__(self, in_channels, out_channels, use_bn, activation):
        super(IbpUpBlock, self).__init__()
        self.res = IbpResUnit(in_channels=in_channels, out_channels=
            out_channels, activation=activation)
        self.up = InterpolationBlock(scale_factor=2, mode='nearest',
            align_corners=None)
        self.conv = conv3x3_block(in_channels=out_channels, out_channels=
            out_channels, bias=not use_bn, use_bn=use_bn, activation=activation
            )

    def forward(self, x):
        x = self.res(x)
        x = self.up(x)
        x = self.conv(x)
        return x


class MergeBlock(nn.Module):
    """
    IBPPose merge block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    use_bn : bool
        Whether to use BatchNorm layer.
    """

    def __init__(self, in_channels, out_channels, use_bn):
        super(MergeBlock, self).__init__()
        self.conv = conv1x1_block(in_channels=in_channels, out_channels=
            out_channels, bias=not use_bn, use_bn=use_bn, activation=None)

    def forward(self, x):
        return self.conv(x)


class IbpPreBlock(nn.Module):
    """
    IBPPose preliminary decoder block.

    Parameters:
    ----------
    out_channels : int
        Number of output channels.
    use_bn : bool
        Whether to use BatchNorm layer.
    activation : function or str or None
        Activation function or name of activation function.
    """

    def __init__(self, out_channels, use_bn, activation):
        super(IbpPreBlock, self).__init__()
        self.conv1 = conv3x3_block(in_channels=out_channels, out_channels=
            out_channels, bias=not use_bn, use_bn=use_bn, activation=activation
            )
        self.conv2 = conv3x3_block(in_channels=out_channels, out_channels=
            out_channels, bias=not use_bn, use_bn=use_bn, activation=activation
            )
        self.se = SEBlock(channels=out_channels, use_conv=False,
            mid_activation=activation)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.se(x)
        return x


class IbpPass(nn.Module):
    """
    IBPPose single pass decoder block.

    Parameters:
    ----------
    channels : int
        Number of input/output channels.
    mid_channels : int
        Number of middle channels.
    depth : int
        Depth of hourglass.
    growth_rate : int
        Addition for number of channel for each level.
    use_bn : bool
        Whether to use BatchNorm layer.
    activation : function or str or None
        Activation function or name of activation function.
    """

    def __init__(self, channels, mid_channels, depth, growth_rate, merge,
        use_bn, activation):
        super(IbpPass, self).__init__()
        self.merge = merge
        down_seq = nn.Sequential()
        up_seq = nn.Sequential()
        skip_seq = nn.Sequential()
        top_channels = channels
        bottom_channels = channels
        for i in range(depth + 1):
            skip_seq.add_module('skip{}'.format(i + 1), IbpResUnit(
                in_channels=top_channels, out_channels=top_channels,
                activation=activation))
            bottom_channels += growth_rate
            if i < depth:
                down_seq.add_module('down{}'.format(i + 1), IbpDownBlock(
                    in_channels=top_channels, out_channels=bottom_channels,
                    activation=activation))
                up_seq.add_module('up{}'.format(i + 1), IbpUpBlock(
                    in_channels=bottom_channels, out_channels=top_channels,
                    use_bn=use_bn, activation=activation))
            top_channels = bottom_channels
        self.hg = Hourglass(down_seq=down_seq, up_seq=up_seq, skip_seq=
            skip_seq, return_first_skip=False)
        self.pre_block = IbpPreBlock(out_channels=channels, use_bn=use_bn,
            activation=activation)
        self.post_block = conv1x1_block(in_channels=channels, out_channels=
            mid_channels, bias=True, use_bn=False, activation=None)
        if self.merge:
            self.pre_merge_block = MergeBlock(in_channels=channels,
                out_channels=channels, use_bn=use_bn)
            self.post_merge_block = MergeBlock(in_channels=mid_channels,
                out_channels=channels, use_bn=use_bn)

    def forward(self, x, x_prev):
        x = self.hg(x)
        if x_prev is not None:
            x = x + x_prev
        y = self.pre_block(x)
        z = self.post_block(y)
        if self.merge:
            z = self.post_merge_block(z) + self.pre_merge_block(y)
        return z


class IbpPose(nn.Module):
    """
    IBPPose model from 'Simple Pose: Rethinking and Improving a Bottom-up Approach for Multi-Person Pose Estimation,'
    https://arxiv.org/abs/1911.10529.

    Parameters:
    ----------
    passes : int
        Number of passes.
    backbone_out_channels : int
        Number of output channels for the backbone.
    outs_channels : int
        Number of output channels for the backbone.
    depth : int
        Depth of hourglass.
    growth_rate : int
        Addition for number of channel for each level.
    use_bn : bool
        Whether to use BatchNorm layer.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (256, 256)
        Spatial size of the expected input image.
    """

    def __init__(self, passes, backbone_out_channels, outs_channels, depth,
        growth_rate, use_bn, in_channels=3, in_size=(256, 256)):
        super(IbpPose, self).__init__()
        self.in_size = in_size
        activation = lambda : nn.LeakyReLU(inplace=True)
        self.backbone = IbpBackbone(in_channels=in_channels, out_channels=
            backbone_out_channels, activation=activation)
        self.decoder = nn.Sequential()
        for i in range(passes):
            merge = i != passes - 1
            self.decoder.add_module('pass{}'.format(i + 1), IbpPass(
                channels=backbone_out_channels, mid_channels=outs_channels,
                depth=depth, growth_rate=growth_rate, merge=merge, use_bn=
                use_bn, activation=activation))
        self._initialize_weights()

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                m.weight.data.normal_(0, 0.001)
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()
            elif isinstance(m, nn.Linear):
                torch.nn.init.normal_(m.weight.data, 0, 0.01)
                m.bias.data.zero_()

    def forward(self, x):
        x = self.backbone(x)
        x_prev = None
        for module in self.decoder._modules.values():
            if x_prev is not None:
                x = x + x_prev
            x_prev = module(x, x_prev)
        return x_prev


class ICInitBlock(nn.Module):
    """
    ICNet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(ICInitBlock, self).__init__()
        mid_channels = out_channels // 2
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            mid_channels, stride=2)
        self.conv2 = conv3x3_block(in_channels=mid_channels, out_channels=
            mid_channels, stride=2)
        self.conv3 = conv3x3_block(in_channels=mid_channels, out_channels=
            out_channels, stride=2)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class PSPBlock(nn.Module):
    """
    ICNet specific PSPNet reduced head block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    upscale_out_size : tuple of 2 int
        Spatial size of the input tensor for the bilinear upsampling operation.
    bottleneck_factor : int
        Bottleneck factor.
    """

    def __init__(self, in_channels, upscale_out_size, bottleneck_factor):
        super(PSPBlock, self).__init__()
        assert in_channels % bottleneck_factor == 0
        mid_channels = in_channels // bottleneck_factor
        self.pool = PyramidPooling(in_channels=in_channels,
            upscale_out_size=upscale_out_size)
        self.conv = conv3x3_block(in_channels=4096, out_channels=mid_channels)
        self.dropout = nn.Dropout(p=0.1, inplace=False)

    def forward(self, x):
        x = self.pool(x)
        x = self.conv(x)
        x = self.dropout(x)
        return x


class CFFBlock(nn.Module):
    """
    Cascade Feature Fusion block.

    Parameters:
    ----------
    in_channels_low : int
        Number of input channels (low input).
    in_channels_high : int
        Number of input channels (low high).
    out_channels : int
        Number of output channels.
    num_classes : int
        Number of classification classes.
    """

    def __init__(self, in_channels_low, in_channels_high, out_channels,
        num_classes):
        super(CFFBlock, self).__init__()
        self.up = InterpolationBlock(scale_factor=2)
        self.conv_low = conv3x3_block(in_channels=in_channels_low,
            out_channels=out_channels, padding=2, dilation=2, activation=None)
        self.conv_hign = conv1x1_block(in_channels=in_channels_high,
            out_channels=out_channels, activation=None)
        self.activ = nn.ReLU(inplace=True)
        self.conv_cls = conv1x1(in_channels=out_channels, out_channels=
            num_classes)

    def forward(self, xl, xh):
        xl = self.up(xl)
        xl = self.conv_low(xl)
        xh = self.conv_hign(xh)
        x = xl + xh
        x = self.activ(x)
        x_cls = self.conv_cls(xl)
        return x, x_cls


class ICHeadBlock(nn.Module):
    """
    ICNet head block.

    Parameters:
    ----------
    num_classes : int
        Number of classification classes.
    """

    def __init__(self, num_classes):
        super(ICHeadBlock, self).__init__()
        self.cff_12 = CFFBlock(in_channels_low=128, in_channels_high=64,
            out_channels=128, num_classes=num_classes)
        self.cff_24 = CFFBlock(in_channels_low=256, in_channels_high=256,
            out_channels=128, num_classes=num_classes)
        self.up_x2 = InterpolationBlock(scale_factor=2)
        self.up_x8 = InterpolationBlock(scale_factor=4)
        self.conv_cls = conv1x1(in_channels=128, out_channels=num_classes)

    def forward(self, x1, x2, x4):
        outputs = []
        x_cff_24, x_24_cls = self.cff_24(x4, x2)
        outputs.append(x_24_cls)
        x_cff_12, x_12_cls = self.cff_12(x_cff_24, x1)
        outputs.append(x_12_cls)
        up_x2 = self.up_x2(x_cff_12)
        up_x2 = self.conv_cls(up_x2)
        outputs.append(up_x2)
        up_x8 = self.up_x8(up_x2)
        outputs.append(up_x8)
        outputs.reverse()
        return tuple(outputs)


class ICNet(nn.Module):
    """
    ICNet model from 'ICNet for Real-Time Semantic Segmentation on High-Resolution Images,'
    https://arxiv.org/abs/1704.08545.

    Parameters:
    ----------
    backbones : tuple of nn.Sequential
        Feature extractors.
    backbones_out_channels : tuple of int
        Number of output channels form each feature extractor.
    num_classes : tuple of int
        Number of output channels for each branch.
    aux : bool, default False
        Whether to output an auxiliary result.
    fixed_size : bool, default True
        Whether to expect fixed spatial size of input image.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (480, 480)
        Spatial size of the expected input image.
    num_classes : int, default 21
        Number of segmentation classes.
    """

    def __init__(self, backbones, backbones_out_channels, channels, aux=
        False, fixed_size=True, in_channels=3, in_size=(480, 480),
        num_classes=21):
        super(ICNet, self).__init__()
        assert in_channels > 0
        assert in_size[0] % 8 == 0 and in_size[1] % 8 == 0
        self.in_size = in_size
        self.num_classes = num_classes
        self.aux = aux
        self.fixed_size = fixed_size
        psp_pool_out_size = (self.in_size[0] // 32, self.in_size[1] // 32
            ) if fixed_size else None
        psp_head_out_channels = 512
        self.branch1 = ICInitBlock(in_channels=in_channels, out_channels=
            channels[0])
        self.branch2 = MultiOutputSequential()
        self.branch2.add_module('down1', InterpolationBlock(scale_factor=0.5))
        backbones[0].do_output = True
        self.branch2.add_module('backbones1', backbones[0])
        self.branch2.add_module('down2', InterpolationBlock(scale_factor=0.5))
        self.branch2.add_module('backbones2', backbones[1])
        self.branch2.add_module('psp', PSPBlock(in_channels=
            backbones_out_channels[1], upscale_out_size=psp_pool_out_size,
            bottleneck_factor=4))
        self.branch2.add_module('final_block', conv1x1_block(in_channels=
            psp_head_out_channels, out_channels=channels[2]))
        self.conv_y2 = conv1x1_block(in_channels=backbones_out_channels[0],
            out_channels=channels[1])
        self.final_block = ICHeadBlock(num_classes=num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                nn.init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)

    def forward(self, x):
        y1 = self.branch1(x)
        y3, y2 = self.branch2(x)
        y2 = self.conv_y2(y2)
        x = self.final_block(y1, y2, y3)
        if self.aux:
            return x
        else:
            return x[0]


class InvResUnit(nn.Module):
    """
    So-called 'Inverted Residual Unit' layer.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the second convolution layer.
    expansion : bool
        Whether do expansion of channels.
    """

    def __init__(self, in_channels, out_channels, stride, expansion):
        super(InvResUnit, self).__init__()
        self.residual = in_channels == out_channels and stride == 1
        mid_channels = in_channels * 6 if expansion else in_channels
        groups = 2
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            mid_channels, groups=groups, activation=None)
        self.c_shuffle = ChannelShuffle(channels=mid_channels, groups=groups)
        self.conv2 = dwconv3x3_block(in_channels=mid_channels, out_channels
            =mid_channels, stride=stride, activation='relu6')
        self.conv3 = conv1x1_block(in_channels=mid_channels, out_channels=
            out_channels, groups=groups, activation=None)

    def forward(self, x):
        if self.residual:
            identity = x
        x = self.conv1(x)
        x = self.c_shuffle(x)
        x = self.conv2(x)
        x = self.conv3(x)
        if self.residual:
            x = x + identity
        return x


class IGCV3(nn.Module):
    """
    IGCV3 model from 'IGCV3: Interleaved Low-Rank Group Convolutions for Efficient Deep Neural Networks,'
    https://arxiv.org/abs/1806.00178.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    final_block_channels : int
        Number of output channels for the final block of the feature extractor.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, final_block_channels,
        in_channels=3, in_size=(224, 224), num_classes=1000):
        super(IGCV3, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', conv3x3_block(in_channels=
            in_channels, out_channels=init_block_channels, stride=2,
            activation='relu6'))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                expansion = i != 0 or j != 0
                stage.add_module('unit{}'.format(j + 1), InvResUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, expansion=expansion))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_block', conv1x1_block(in_channels=
            in_channels, out_channels=final_block_channels, activation='relu6')
            )
        in_channels = final_block_channels
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class InceptConv(nn.Module):
    """
    InceptionResNetV2 specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride, padding
        ):
        super(InceptConv, self).__init__()
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, bias=False)
        self.bn = nn.BatchNorm2d(num_features=out_channels, eps=0.001,
            momentum=0.1)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        x = self.activ(x)
        return x


class MaxPoolBranch(nn.Module):
    """
    InceptionResNetV2 specific max pooling branch block.
    """

    def __init__(self):
        super(MaxPoolBranch, self).__init__()
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)

    def forward(self, x):
        x = self.pool(x)
        return x


def incept_conv1x1(in_channels, out_channels):
    """
    1x1 version of the InceptionV4 specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """
    return InceptConv(in_channels=in_channels, out_channels=out_channels,
        kernel_size=1, stride=1, padding=0)


class AvgPoolBranch(nn.Module):
    """
    InceptionResNetV2 specific average pooling branch block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(AvgPoolBranch, self).__init__()
        self.pool = nn.AvgPool2d(kernel_size=3, stride=1, padding=1,
            count_include_pad=False)
        self.conv = incept_conv1x1(in_channels=in_channels, out_channels=
            out_channels)

    def forward(self, x):
        x = self.pool(x)
        x = self.conv(x)
        return x


class Conv1x1Branch(nn.Module):
    """
    InceptionResNetV2 specific convolutional 1x1 branch block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(Conv1x1Branch, self).__init__()
        self.conv = incept_conv1x1(in_channels=in_channels, out_channels=
            out_channels)

    def forward(self, x):
        x = self.conv(x)
        return x


class ConvSeqBranch(nn.Module):
    """
    InceptionResNetV2 specific convolutional sequence branch block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels_list : list of tuple of int
        List of numbers of output channels.
    kernel_size_list : list of tuple of int or tuple of tuple/list of 2 int
        List of convolution window sizes.
    strides_list : list of tuple of int or tuple of tuple/list of 2 int
        List of strides of the convolution.
    padding_list : list of tuple of int or tuple of tuple/list of 2 int
        List of padding values for convolution layers.
    """

    def __init__(self, in_channels, out_channels_list, kernel_size_list,
        strides_list, padding_list):
        super(ConvSeqBranch, self).__init__()
        assert len(out_channels_list) == len(kernel_size_list)
        assert len(out_channels_list) == len(strides_list)
        assert len(out_channels_list) == len(padding_list)
        self.conv_list = nn.Sequential()
        for i, (out_channels, kernel_size, strides, padding) in enumerate(zip
            (out_channels_list, kernel_size_list, strides_list, padding_list)):
            self.conv_list.add_module('conv{}'.format(i + 1), InceptConv(
                in_channels=in_channels, out_channels=out_channels,
                kernel_size=kernel_size, stride=strides, padding=padding))
            in_channels = out_channels

    def forward(self, x):
        x = self.conv_list(x)
        return x


class InceptionAUnit(nn.Module):
    """
    InceptionResNetV2 type Inception-A unit.
    """

    def __init__(self):
        super(InceptionAUnit, self).__init__()
        self.scale = 0.17
        in_channels = 320
        self.branches = Concurrent()
        self.branches.add_module('branch1', Conv1x1Branch(in_channels=
            in_channels, out_channels=32))
        self.branches.add_module('branch2', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(32, 32), kernel_size_list=(1, 3
            ), strides_list=(1, 1), padding_list=(0, 1)))
        self.branches.add_module('branch3', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(32, 48, 64), kernel_size_list=(
            1, 3, 3), strides_list=(1, 1, 1), padding_list=(0, 1, 1)))
        self.conv = conv1x1(in_channels=128, out_channels=in_channels, bias
            =True)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        identity = x
        x = self.branches(x)
        x = self.conv(x)
        x = self.scale * x + identity
        x = self.activ(x)
        return x


class ReductionAUnit(nn.Module):
    """
    InceptionResNetV2 type Reduction-A unit.
    """

    def __init__(self):
        super(ReductionAUnit, self).__init__()
        in_channels = 320
        self.branches = Concurrent()
        self.branches.add_module('branch1', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(384,), kernel_size_list=(3,),
            strides_list=(2,), padding_list=(0,)))
        self.branches.add_module('branch2', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(256, 256, 384),
            kernel_size_list=(1, 3, 3), strides_list=(1, 1, 2),
            padding_list=(0, 1, 0)))
        self.branches.add_module('branch3', MaxPoolBranch())

    def forward(self, x):
        x = self.branches(x)
        return x


class InceptionBUnit(nn.Module):
    """
    InceptionResNetV2 type Inception-B unit.
    """

    def __init__(self):
        super(InceptionBUnit, self).__init__()
        self.scale = 0.1
        in_channels = 1088
        self.branches = Concurrent()
        self.branches.add_module('branch1', Conv1x1Branch(in_channels=
            in_channels, out_channels=192))
        self.branches.add_module('branch2', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(128, 160, 192),
            kernel_size_list=(1, (1, 7), (7, 1)), strides_list=(1, 1, 1),
            padding_list=(0, (0, 3), (3, 0))))
        self.conv = conv1x1(in_channels=384, out_channels=in_channels, bias
            =True)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        identity = x
        x = self.branches(x)
        x = self.conv(x)
        x = self.scale * x + identity
        x = self.activ(x)
        return x


class ReductionBUnit(nn.Module):
    """
    InceptionResNetV2 type Reduction-B unit.
    """

    def __init__(self):
        super(ReductionBUnit, self).__init__()
        in_channels = 1088
        self.branches = Concurrent()
        self.branches.add_module('branch1', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(256, 384), kernel_size_list=(1,
            3), strides_list=(1, 2), padding_list=(0, 0)))
        self.branches.add_module('branch2', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(256, 288), kernel_size_list=(1,
            3), strides_list=(1, 2), padding_list=(0, 0)))
        self.branches.add_module('branch3', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(256, 288, 320),
            kernel_size_list=(1, 3, 3), strides_list=(1, 1, 2),
            padding_list=(0, 1, 0)))
        self.branches.add_module('branch4', MaxPoolBranch())

    def forward(self, x):
        x = self.branches(x)
        return x


class InceptionCUnit(nn.Module):
    """
    InceptionResNetV2 type Inception-C unit.

    Parameters:
    ----------
    scale : float, default 1.0
        Scale value for residual branch.
    activate : bool, default True
        Whether activate the convolution block.
    """

    def __init__(self, scale=0.2, activate=True):
        super(InceptionCUnit, self).__init__()
        self.activate = activate
        self.scale = scale
        in_channels = 2080
        self.branches = Concurrent()
        self.branches.add_module('branch1', Conv1x1Branch(in_channels=
            in_channels, out_channels=192))
        self.branches.add_module('branch2', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(192, 224, 256),
            kernel_size_list=(1, (1, 3), (3, 1)), strides_list=(1, 1, 1),
            padding_list=(0, (0, 1), (1, 0))))
        self.conv = conv1x1(in_channels=448, out_channels=in_channels, bias
            =True)
        if self.activate:
            self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        identity = x
        x = self.branches(x)
        x = self.conv(x)
        x = self.scale * x + identity
        if self.activate:
            x = self.activ(x)
        return x


class InceptBlock5b(nn.Module):
    """
    InceptionResNetV2 type Mixed-5b block.
    """

    def __init__(self):
        super(InceptBlock5b, self).__init__()
        in_channels = 192
        self.branches = Concurrent()
        self.branches.add_module('branch1', Conv1x1Branch(in_channels=
            in_channels, out_channels=96))
        self.branches.add_module('branch2', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(48, 64), kernel_size_list=(1, 5
            ), strides_list=(1, 1), padding_list=(0, 2)))
        self.branches.add_module('branch3', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(64, 96, 96), kernel_size_list=(
            1, 3, 3), strides_list=(1, 1, 1), padding_list=(0, 1, 1)))
        self.branches.add_module('branch4', AvgPoolBranch(in_channels=
            in_channels, out_channels=64))

    def forward(self, x):
        x = self.branches(x)
        return x


class InceptInitBlock(nn.Module):
    """
    InceptionResNetV2 specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    """

    def __init__(self, in_channels):
        super(InceptInitBlock, self).__init__()
        self.conv1 = InceptConv(in_channels=in_channels, out_channels=32,
            kernel_size=3, stride=2, padding=0)
        self.conv2 = InceptConv(in_channels=32, out_channels=32,
            kernel_size=3, stride=1, padding=0)
        self.conv3 = InceptConv(in_channels=32, out_channels=64,
            kernel_size=3, stride=1, padding=1)
        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)
        self.conv4 = InceptConv(in_channels=64, out_channels=80,
            kernel_size=1, stride=1, padding=0)
        self.conv5 = InceptConv(in_channels=80, out_channels=192,
            kernel_size=3, stride=1, padding=0)
        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)
        self.block = InceptBlock5b()

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.pool1(x)
        x = self.conv4(x)
        x = self.conv5(x)
        x = self.pool2(x)
        x = self.block(x)
        return x


class InceptionResNetV2(nn.Module):
    """
    InceptionResNetV2 model from 'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning,'
    https://arxiv.org/abs/1602.07261.

    Parameters:
    ----------
    dropout_rate : float, default 0.0
        Fraction of the input units to drop. Must be a number between 0 and 1.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (299, 299)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, dropout_rate=0.0, in_channels=3, in_size=(299, 299),
        num_classes=1000):
        super(InceptionResNetV2, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        layers = [10, 21, 11]
        normal_units = [InceptionAUnit, InceptionBUnit, InceptionCUnit]
        reduction_units = [ReductionAUnit, ReductionBUnit]
        self.features = nn.Sequential()
        self.features.add_module('init_block', InceptInitBlock(in_channels=
            in_channels))
        for i, layers_per_stage in enumerate(layers):
            stage = nn.Sequential()
            for j in range(layers_per_stage):
                if j == 0 and i != 0:
                    unit = reduction_units[i - 1]
                else:
                    unit = normal_units[i]
                if i == len(layers) - 1 and j == layers_per_stage - 1:
                    stage.add_module('unit{}'.format(j + 1), unit(scale=1.0,
                        activate=False))
                else:
                    stage.add_module('unit{}'.format(j + 1), unit())
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_conv', incept_conv1x1(in_channels=
            2080, out_channels=1536))
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=8,
            stride=1))
        self.output = nn.Sequential()
        if dropout_rate > 0.0:
            self.output.add_module('dropout', nn.Dropout(p=dropout_rate))
        self.output.add_module('fc', nn.Linear(in_features=1536,
            out_features=num_classes))
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class InceptConv(nn.Module):
    """
    InceptionV3 specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride, padding
        ):
        super(InceptConv, self).__init__()
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, bias=False)
        self.bn = nn.BatchNorm2d(num_features=out_channels, eps=0.001)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        x = self.activ(x)
        return x


class MaxPoolBranch(nn.Module):
    """
    InceptionV3 specific max pooling branch block.
    """

    def __init__(self):
        super(MaxPoolBranch, self).__init__()
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)

    def forward(self, x):
        x = self.pool(x)
        return x


class AvgPoolBranch(nn.Module):
    """
    InceptionV3 specific average pooling branch block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(AvgPoolBranch, self).__init__()
        self.pool = nn.AvgPool2d(kernel_size=3, stride=1, padding=1)
        self.conv = incept_conv1x1(in_channels=in_channels, out_channels=
            out_channels)

    def forward(self, x):
        x = self.pool(x)
        x = self.conv(x)
        return x


class Conv1x1Branch(nn.Module):
    """
    InceptionV3 specific convolutional 1x1 branch block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(Conv1x1Branch, self).__init__()
        self.conv = incept_conv1x1(in_channels=in_channels, out_channels=
            out_channels)

    def forward(self, x):
        x = self.conv(x)
        return x


class ConvSeqBranch(nn.Module):
    """
    InceptionV3 specific convolutional sequence branch block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels_list : list of tuple of int
        List of numbers of output channels.
    kernel_size_list : list of tuple of int or tuple of tuple/list of 2 int
        List of convolution window sizes.
    strides_list : list of tuple of int or tuple of tuple/list of 2 int
        List of strides of the convolution.
    padding_list : list of tuple of int or tuple of tuple/list of 2 int
        List of padding values for convolution layers.
    """

    def __init__(self, in_channels, out_channels_list, kernel_size_list,
        strides_list, padding_list):
        super(ConvSeqBranch, self).__init__()
        assert len(out_channels_list) == len(kernel_size_list)
        assert len(out_channels_list) == len(strides_list)
        assert len(out_channels_list) == len(padding_list)
        self.conv_list = nn.Sequential()
        for i, (out_channels, kernel_size, strides, padding) in enumerate(zip
            (out_channels_list, kernel_size_list, strides_list, padding_list)):
            self.conv_list.add_module('conv{}'.format(i + 1), InceptConv(
                in_channels=in_channels, out_channels=out_channels,
                kernel_size=kernel_size, stride=strides, padding=padding))
            in_channels = out_channels

    def forward(self, x):
        x = self.conv_list(x)
        return x


class ConvSeq3x3Branch(nn.Module):
    """
    InceptionV3 specific convolutional sequence branch block with splitting by 3x3.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels_list : list of tuple of int
        List of numbers of output channels.
    kernel_size_list : list of tuple of int or tuple of tuple/list of 2 int
        List of convolution window sizes.
    strides_list : list of tuple of int or tuple of tuple/list of 2 int
        List of strides of the convolution.
    padding_list : list of tuple of int or tuple of tuple/list of 2 int
        List of padding values for convolution layers.
    """

    def __init__(self, in_channels, out_channels_list, kernel_size_list,
        strides_list, padding_list):
        super(ConvSeq3x3Branch, self).__init__()
        self.conv_list = nn.Sequential()
        for i, (out_channels, kernel_size, strides, padding) in enumerate(zip
            (out_channels_list, kernel_size_list, strides_list, padding_list)):
            self.conv_list.add_module('conv{}'.format(i + 1), InceptConv(
                in_channels=in_channels, out_channels=out_channels,
                kernel_size=kernel_size, stride=strides, padding=padding))
            in_channels = out_channels
        self.conv1x3 = InceptConv(in_channels=in_channels, out_channels=
            in_channels, kernel_size=(1, 3), stride=1, padding=(0, 1))
        self.conv3x1 = InceptConv(in_channels=in_channels, out_channels=
            in_channels, kernel_size=(3, 1), stride=1, padding=(1, 0))

    def forward(self, x):
        x = self.conv_list(x)
        y1 = self.conv1x3(x)
        y2 = self.conv3x1(x)
        x = torch.cat((y1, y2), dim=1)
        return x


class InceptionAUnit(nn.Module):
    """
    InceptionV3 type Inception-A unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(InceptionAUnit, self).__init__()
        assert out_channels > 224
        pool_out_channels = out_channels - 224
        self.branches = Concurrent()
        self.branches.add_module('branch1', Conv1x1Branch(in_channels=
            in_channels, out_channels=64))
        self.branches.add_module('branch2', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(48, 64), kernel_size_list=(1, 5
            ), strides_list=(1, 1), padding_list=(0, 2)))
        self.branches.add_module('branch3', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(64, 96, 96), kernel_size_list=(
            1, 3, 3), strides_list=(1, 1, 1), padding_list=(0, 1, 1)))
        self.branches.add_module('branch4', AvgPoolBranch(in_channels=
            in_channels, out_channels=pool_out_channels))

    def forward(self, x):
        x = self.branches(x)
        return x


class ReductionAUnit(nn.Module):
    """
    InceptionV3 type Reduction-A unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(ReductionAUnit, self).__init__()
        assert in_channels == 288
        assert out_channels == 768
        self.branches = Concurrent()
        self.branches.add_module('branch1', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(384,), kernel_size_list=(3,),
            strides_list=(2,), padding_list=(0,)))
        self.branches.add_module('branch2', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(64, 96, 96), kernel_size_list=(
            1, 3, 3), strides_list=(1, 1, 2), padding_list=(0, 1, 0)))
        self.branches.add_module('branch3', MaxPoolBranch())

    def forward(self, x):
        x = self.branches(x)
        return x


class InceptionBUnit(nn.Module):
    """
    InceptionV3 type Inception-B unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    mid_channels : int
        Number of output channels in the 7x7 branches.
    """

    def __init__(self, in_channels, out_channels, mid_channels):
        super(InceptionBUnit, self).__init__()
        assert in_channels == 768
        assert out_channels == 768
        self.branches = Concurrent()
        self.branches.add_module('branch1', Conv1x1Branch(in_channels=
            in_channels, out_channels=192))
        self.branches.add_module('branch2', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(mid_channels, mid_channels, 192
            ), kernel_size_list=(1, (1, 7), (7, 1)), strides_list=(1, 1, 1),
            padding_list=(0, (0, 3), (3, 0))))
        self.branches.add_module('branch3', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(mid_channels, mid_channels,
            mid_channels, mid_channels, 192), kernel_size_list=(1, (7, 1),
            (1, 7), (7, 1), (1, 7)), strides_list=(1, 1, 1, 1, 1),
            padding_list=(0, (3, 0), (0, 3), (3, 0), (0, 3))))
        self.branches.add_module('branch4', AvgPoolBranch(in_channels=
            in_channels, out_channels=192))

    def forward(self, x):
        x = self.branches(x)
        return x


class ReductionBUnit(nn.Module):
    """
    InceptionV3 type Reduction-B unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(ReductionBUnit, self).__init__()
        assert in_channels == 768
        assert out_channels == 1280
        self.branches = Concurrent()
        self.branches.add_module('branch1', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(192, 320), kernel_size_list=(1,
            3), strides_list=(1, 2), padding_list=(0, 0)))
        self.branches.add_module('branch2', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(192, 192, 192, 192),
            kernel_size_list=(1, (1, 7), (7, 1), 3), strides_list=(1, 1, 1,
            2), padding_list=(0, (0, 3), (3, 0), 0)))
        self.branches.add_module('branch3', MaxPoolBranch())

    def forward(self, x):
        x = self.branches(x)
        return x


class InceptionCUnit(nn.Module):
    """
    InceptionV3 type Inception-C unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(InceptionCUnit, self).__init__()
        assert out_channels == 2048
        self.branches = Concurrent()
        self.branches.add_module('branch1', Conv1x1Branch(in_channels=
            in_channels, out_channels=320))
        self.branches.add_module('branch2', ConvSeq3x3Branch(in_channels=
            in_channels, out_channels_list=(384,), kernel_size_list=(1,),
            strides_list=(1,), padding_list=(0,)))
        self.branches.add_module('branch3', ConvSeq3x3Branch(in_channels=
            in_channels, out_channels_list=(448, 384), kernel_size_list=(1,
            3), strides_list=(1, 1), padding_list=(0, 1)))
        self.branches.add_module('branch4', AvgPoolBranch(in_channels=
            in_channels, out_channels=192))

    def forward(self, x):
        x = self.branches(x)
        return x


class InceptInitBlock(nn.Module):
    """
    InceptionV3 specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(InceptInitBlock, self).__init__()
        assert out_channels == 192
        self.conv1 = InceptConv(in_channels=in_channels, out_channels=32,
            kernel_size=3, stride=2, padding=0)
        self.conv2 = InceptConv(in_channels=32, out_channels=32,
            kernel_size=3, stride=1, padding=0)
        self.conv3 = InceptConv(in_channels=32, out_channels=64,
            kernel_size=3, stride=1, padding=1)
        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)
        self.conv4 = InceptConv(in_channels=64, out_channels=80,
            kernel_size=1, stride=1, padding=0)
        self.conv5 = InceptConv(in_channels=80, out_channels=192,
            kernel_size=3, stride=1, padding=0)
        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.pool1(x)
        x = self.conv4(x)
        x = self.conv5(x)
        x = self.pool2(x)
        return x


class InceptionV3(nn.Module):
    """
    InceptionV3 model from 'Rethinking the Inception Architecture for Computer Vision,'
    https://arxiv.org/abs/1512.00567.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    b_mid_channels : list of int
        Number of middle channels for each Inception-B unit.
    dropout_rate : float, default 0.0
        Fraction of the input units to drop. Must be a number between 0 and 1.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (299, 299)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, b_mid_channels,
        dropout_rate=0.5, in_channels=3, in_size=(299, 299), num_classes=1000):
        super(InceptionV3, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        normal_units = [InceptionAUnit, InceptionBUnit, InceptionCUnit]
        reduction_units = [ReductionAUnit, ReductionBUnit]
        self.features = nn.Sequential()
        self.features.add_module('init_block', InceptInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                if j == 0 and i != 0:
                    unit = reduction_units[i - 1]
                else:
                    unit = normal_units[i]
                if unit == InceptionBUnit:
                    stage.add_module('unit{}'.format(j + 1), unit(
                        in_channels=in_channels, out_channels=out_channels,
                        mid_channels=b_mid_channels[j - 1]))
                else:
                    stage.add_module('unit{}'.format(j + 1), unit(
                        in_channels=in_channels, out_channels=out_channels))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=8,
            stride=1))
        self.output = nn.Sequential()
        self.output.add_module('dropout', nn.Dropout(p=dropout_rate))
        self.output.add_module('fc', nn.Linear(in_features=in_channels,
            out_features=num_classes))
        self._init_params()

    def _init_params(self):
        for module in self.modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class InceptConv(nn.Module):
    """
    InceptionV4 specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride, padding
        ):
        super(InceptConv, self).__init__()
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, bias=False)
        self.bn = nn.BatchNorm2d(num_features=out_channels, eps=0.001,
            momentum=0.1)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        x = self.activ(x)
        return x


class MaxPoolBranch(nn.Module):
    """
    InceptionV4 specific max pooling branch block.
    """

    def __init__(self):
        super(MaxPoolBranch, self).__init__()
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)

    def forward(self, x):
        x = self.pool(x)
        return x


class AvgPoolBranch(nn.Module):
    """
    InceptionV4 specific average pooling branch block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(AvgPoolBranch, self).__init__()
        self.pool = nn.AvgPool2d(kernel_size=3, stride=1, padding=1,
            count_include_pad=False)
        self.conv = incept_conv1x1(in_channels=in_channels, out_channels=
            out_channels)

    def forward(self, x):
        x = self.pool(x)
        x = self.conv(x)
        return x


class Conv1x1Branch(nn.Module):
    """
    InceptionV4 specific convolutional 1x1 branch block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(Conv1x1Branch, self).__init__()
        self.conv = incept_conv1x1(in_channels=in_channels, out_channels=
            out_channels)

    def forward(self, x):
        x = self.conv(x)
        return x


def incept_conv3x3(in_channels, out_channels, stride, padding=1):
    """
    3x3 version of the InceptionV4 specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 0
        Padding value for convolution layer.
    """
    return InceptConv(in_channels=in_channels, out_channels=out_channels,
        kernel_size=3, stride=stride, padding=padding)


class Conv3x3Branch(nn.Module):
    """
    InceptionV4 specific convolutional 3x3 branch block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(Conv3x3Branch, self).__init__()
        self.conv = incept_conv3x3(in_channels=in_channels, out_channels=
            out_channels, stride=2, padding=0)

    def forward(self, x):
        x = self.conv(x)
        return x


class ConvSeqBranch(nn.Module):
    """
    InceptionV4 specific convolutional sequence branch block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels_list : list of tuple of int
        List of numbers of output channels.
    kernel_size_list : list of tuple of int or tuple of tuple/list of 2 int
        List of convolution window sizes.
    strides_list : list of tuple of int or tuple of tuple/list of 2 int
        List of strides of the convolution.
    padding_list : list of tuple of int or tuple of tuple/list of 2 int
        List of padding values for convolution layers.
    """

    def __init__(self, in_channels, out_channels_list, kernel_size_list,
        strides_list, padding_list):
        super(ConvSeqBranch, self).__init__()
        assert len(out_channels_list) == len(kernel_size_list)
        assert len(out_channels_list) == len(strides_list)
        assert len(out_channels_list) == len(padding_list)
        self.conv_list = nn.Sequential()
        for i, (out_channels, kernel_size, strides, padding) in enumerate(zip
            (out_channels_list, kernel_size_list, strides_list, padding_list)):
            self.conv_list.add_module('conv{}'.format(i + 1), InceptConv(
                in_channels=in_channels, out_channels=out_channels,
                kernel_size=kernel_size, stride=strides, padding=padding))
            in_channels = out_channels

    def forward(self, x):
        x = self.conv_list(x)
        return x


class ConvSeq3x3Branch(nn.Module):
    """
    InceptionV4 specific convolutional sequence branch block with splitting by 3x3.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    mid_channels_list : list of tuple of int
        List of numbers of output channels for middle layers.
    kernel_size_list : list of tuple of int or tuple of tuple/list of 2 int
        List of convolution window sizes.
    strides_list : list of tuple of int or tuple of tuple/list of 2 int
        List of strides of the convolution.
    padding_list : list of tuple of int or tuple of tuple/list of 2 int
        List of padding values for convolution layers.
    """

    def __init__(self, in_channels, out_channels, mid_channels_list,
        kernel_size_list, strides_list, padding_list):
        super(ConvSeq3x3Branch, self).__init__()
        self.conv_list = nn.Sequential()
        for i, (mid_channels, kernel_size, strides, padding) in enumerate(zip
            (mid_channels_list, kernel_size_list, strides_list, padding_list)):
            self.conv_list.add_module('conv{}'.format(i + 1), InceptConv(
                in_channels=in_channels, out_channels=mid_channels,
                kernel_size=kernel_size, stride=strides, padding=padding))
            in_channels = mid_channels
        self.conv1x3 = InceptConv(in_channels=in_channels, out_channels=
            out_channels, kernel_size=(1, 3), stride=1, padding=(0, 1))
        self.conv3x1 = InceptConv(in_channels=in_channels, out_channels=
            out_channels, kernel_size=(3, 1), stride=1, padding=(1, 0))

    def forward(self, x):
        x = self.conv_list(x)
        y1 = self.conv1x3(x)
        y2 = self.conv3x1(x)
        x = torch.cat((y1, y2), dim=1)
        return x


class InceptionAUnit(nn.Module):
    """
    InceptionV4 type Inception-A unit.
    """

    def __init__(self):
        super(InceptionAUnit, self).__init__()
        in_channels = 384
        self.branches = Concurrent()
        self.branches.add_module('branch1', Conv1x1Branch(in_channels=
            in_channels, out_channels=96))
        self.branches.add_module('branch2', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(64, 96), kernel_size_list=(1, 3
            ), strides_list=(1, 1), padding_list=(0, 1)))
        self.branches.add_module('branch3', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(64, 96, 96), kernel_size_list=(
            1, 3, 3), strides_list=(1, 1, 1), padding_list=(0, 1, 1)))
        self.branches.add_module('branch4', AvgPoolBranch(in_channels=
            in_channels, out_channels=96))

    def forward(self, x):
        x = self.branches(x)
        return x


class ReductionAUnit(nn.Module):
    """
    InceptionV4 type Reduction-A unit.
    """

    def __init__(self):
        super(ReductionAUnit, self).__init__()
        in_channels = 384
        self.branches = Concurrent()
        self.branches.add_module('branch1', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(384,), kernel_size_list=(3,),
            strides_list=(2,), padding_list=(0,)))
        self.branches.add_module('branch2', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(192, 224, 256),
            kernel_size_list=(1, 3, 3), strides_list=(1, 1, 2),
            padding_list=(0, 1, 0)))
        self.branches.add_module('branch3', MaxPoolBranch())

    def forward(self, x):
        x = self.branches(x)
        return x


class InceptionBUnit(nn.Module):
    """
    InceptionV4 type Inception-B unit.
    """

    def __init__(self):
        super(InceptionBUnit, self).__init__()
        in_channels = 1024
        self.branches = Concurrent()
        self.branches.add_module('branch1', Conv1x1Branch(in_channels=
            in_channels, out_channels=384))
        self.branches.add_module('branch2', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(192, 224, 256),
            kernel_size_list=(1, (1, 7), (7, 1)), strides_list=(1, 1, 1),
            padding_list=(0, (0, 3), (3, 0))))
        self.branches.add_module('branch3', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(192, 192, 224, 224, 256),
            kernel_size_list=(1, (7, 1), (1, 7), (7, 1), (1, 7)),
            strides_list=(1, 1, 1, 1, 1), padding_list=(0, (3, 0), (0, 3),
            (3, 0), (0, 3))))
        self.branches.add_module('branch4', AvgPoolBranch(in_channels=
            in_channels, out_channels=128))

    def forward(self, x):
        x = self.branches(x)
        return x


class ReductionBUnit(nn.Module):
    """
    InceptionV4 type Reduction-B unit.
    """

    def __init__(self):
        super(ReductionBUnit, self).__init__()
        in_channels = 1024
        self.branches = Concurrent()
        self.branches.add_module('branch1', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(192, 192), kernel_size_list=(1,
            3), strides_list=(1, 2), padding_list=(0, 0)))
        self.branches.add_module('branch2', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(256, 256, 320, 320),
            kernel_size_list=(1, (1, 7), (7, 1), 3), strides_list=(1, 1, 1,
            2), padding_list=(0, (0, 3), (3, 0), 0)))
        self.branches.add_module('branch3', MaxPoolBranch())

    def forward(self, x):
        x = self.branches(x)
        return x


class InceptionCUnit(nn.Module):
    """
    InceptionV4 type Inception-C unit.
    """

    def __init__(self):
        super(InceptionCUnit, self).__init__()
        in_channels = 1536
        self.branches = Concurrent()
        self.branches.add_module('branch1', Conv1x1Branch(in_channels=
            in_channels, out_channels=256))
        self.branches.add_module('branch2', ConvSeq3x3Branch(in_channels=
            in_channels, out_channels=256, mid_channels_list=(384,),
            kernel_size_list=(1,), strides_list=(1,), padding_list=(0,)))
        self.branches.add_module('branch3', ConvSeq3x3Branch(in_channels=
            in_channels, out_channels=256, mid_channels_list=(384, 448, 512
            ), kernel_size_list=(1, (3, 1), (1, 3)), strides_list=(1, 1, 1),
            padding_list=(0, (1, 0), (0, 1))))
        self.branches.add_module('branch4', AvgPoolBranch(in_channels=
            in_channels, out_channels=256))

    def forward(self, x):
        x = self.branches(x)
        return x


class InceptBlock3a(nn.Module):
    """
    InceptionV4 type Mixed-3a block.
    """

    def __init__(self):
        super(InceptBlock3a, self).__init__()
        self.branches = Concurrent()
        self.branches.add_module('branch1', MaxPoolBranch())
        self.branches.add_module('branch2', Conv3x3Branch(in_channels=64,
            out_channels=96))

    def forward(self, x):
        x = self.branches(x)
        return x


class InceptBlock4a(nn.Module):
    """
    InceptionV4 type Mixed-4a block.
    """

    def __init__(self):
        super(InceptBlock4a, self).__init__()
        self.branches = Concurrent()
        self.branches.add_module('branch1', ConvSeqBranch(in_channels=160,
            out_channels_list=(64, 96), kernel_size_list=(1, 3),
            strides_list=(1, 1), padding_list=(0, 0)))
        self.branches.add_module('branch2', ConvSeqBranch(in_channels=160,
            out_channels_list=(64, 64, 64, 96), kernel_size_list=(1, (1, 7),
            (7, 1), 3), strides_list=(1, 1, 1, 1), padding_list=(0, (0, 3),
            (3, 0), 0)))

    def forward(self, x):
        x = self.branches(x)
        return x


class InceptBlock5a(nn.Module):
    """
    InceptionV4 type Mixed-5a block.
    """

    def __init__(self):
        super(InceptBlock5a, self).__init__()
        self.branches = Concurrent()
        self.branches.add_module('branch1', Conv3x3Branch(in_channels=192,
            out_channels=192))
        self.branches.add_module('branch2', MaxPoolBranch())

    def forward(self, x):
        x = self.branches(x)
        return x


class InceptInitBlock(nn.Module):
    """
    InceptionV4 specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    """

    def __init__(self, in_channels):
        super(InceptInitBlock, self).__init__()
        self.conv1 = InceptConv(in_channels=in_channels, out_channels=32,
            kernel_size=3, stride=2, padding=0)
        self.conv2 = InceptConv(in_channels=32, out_channels=32,
            kernel_size=3, stride=1, padding=0)
        self.conv3 = InceptConv(in_channels=32, out_channels=64,
            kernel_size=3, stride=1, padding=1)
        self.block1 = InceptBlock3a()
        self.block2 = InceptBlock4a()
        self.block3 = InceptBlock5a()

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.block1(x)
        x = self.block2(x)
        x = self.block3(x)
        return x


class InceptionV4(nn.Module):
    """
    InceptionV4 model from 'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning,'
    https://arxiv.org/abs/1602.07261.

    Parameters:
    ----------
    dropout_rate : float, default 0.0
        Fraction of the input units to drop. Must be a number between 0 and 1.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (299, 299)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, dropout_rate=0.0, in_channels=3, in_size=(299, 299),
        num_classes=1000):
        super(InceptionV4, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        layers = [4, 8, 4]
        normal_units = [InceptionAUnit, InceptionBUnit, InceptionCUnit]
        reduction_units = [ReductionAUnit, ReductionBUnit]
        self.features = nn.Sequential()
        self.features.add_module('init_block', InceptInitBlock(in_channels=
            in_channels))
        for i, layers_per_stage in enumerate(layers):
            stage = nn.Sequential()
            for j in range(layers_per_stage):
                if j == 0 and i != 0:
                    unit = reduction_units[i - 1]
                else:
                    unit = normal_units[i]
                stage.add_module('unit{}'.format(j + 1), unit())
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=8,
            stride=1))
        self.output = nn.Sequential()
        if dropout_rate > 0.0:
            self.output.add_module('dropout', nn.Dropout(p=dropout_rate))
        self.output.add_module('fc', nn.Linear(in_features=1536,
            out_features=num_classes))
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class IRevDownscale(nn.Module):
    """
    i-RevNet specific downscale (so-called psi-block).

    Parameters:
    ----------
    scale : int
        Scale (downscale) value.
    """

    def __init__(self, scale):
        super(IRevDownscale, self).__init__()
        self.scale = scale

    def forward(self, x):
        batch, x_channels, x_height, x_width = x.size()
        y_channels = x_channels * self.scale * self.scale
        assert x_height % self.scale == 0
        y_height = x_height // self.scale
        y = x.permute(0, 2, 3, 1)
        d2_split_seq = y.split(split_size=self.scale, dim=2)
        d2_split_seq = [t.contiguous().view(batch, y_height, y_channels) for
            t in d2_split_seq]
        y = torch.stack(d2_split_seq, dim=1)
        y = y.permute(0, 3, 2, 1)
        return y.contiguous()

    def inverse(self, y):
        scale_sqr = self.scale * self.scale
        batch, y_channels, y_height, y_width = y.size()
        assert y_channels % scale_sqr == 0
        x_channels = y_channels // scale_sqr
        x_height = y_height * self.scale
        x_width = y_width * self.scale
        x = y.permute(0, 2, 3, 1)
        x = x.contiguous().view(batch, y_height, y_width, scale_sqr, x_channels
            )
        d3_split_seq = x.split(split_size=self.scale, dim=3)
        d3_split_seq = [t.contiguous().view(batch, y_height, x_width,
            x_channels) for t in d3_split_seq]
        x = torch.stack(d3_split_seq, dim=0)
        x = x.transpose(0, 1).permute(0, 2, 1, 3, 4).contiguous().view(batch,
            x_height, x_width, x_channels)
        x = x.permute(0, 3, 1, 2)
        return x.contiguous()


class IRevInjectivePad(nn.Module):
    """
    i-RevNet channel zero padding block.

    Parameters:
    ----------
    padding : int
        Size of the padding.
    """

    def __init__(self, padding):
        super(IRevInjectivePad, self).__init__()
        self.padding = padding
        self.pad = nn.ZeroPad2d(padding=(0, 0, 0, padding))

    def forward(self, x):
        x = x.permute(0, 2, 1, 3)
        x = self.pad(x)
        return x.permute(0, 2, 1, 3)

    def inverse(self, x):
        return x[:, :x.size(1) - self.padding, :, :]


class IRevSplitBlock(nn.Module):
    """
    iRevNet split block.
    """

    def __init__(self):
        super(IRevSplitBlock, self).__init__()

    def forward(self, x, _):
        x1, x2 = torch.chunk(x, chunks=2, dim=1)
        return x1, x2

    def inverse(self, x1, x2):
        x = torch.cat((x1, x2), dim=1)
        return x, None


class IRevMergeBlock(nn.Module):
    """
    iRevNet merge block.
    """

    def __init__(self):
        super(IRevMergeBlock, self).__init__()

    def forward(self, x1, x2):
        x = torch.cat((x1, x2), dim=1)
        return x, x

    def inverse(self, x, _):
        x1, x2 = torch.chunk(x, chunks=2, dim=1)
        return x1, x2


class IRevBottleneck(nn.Module):
    """
    iRevNet bottleneck block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the branch convolution layers.
    preactivate : bool
        Whether use pre-activation for the first convolution block.
    """

    def __init__(self, in_channels, out_channels, stride, preactivate):
        super(IRevBottleneck, self).__init__()
        mid_channels = out_channels // 4
        if preactivate:
            self.conv1 = pre_conv3x3_block(in_channels=in_channels,
                out_channels=mid_channels, stride=stride)
        else:
            self.conv1 = conv3x3(in_channels=in_channels, out_channels=
                mid_channels, stride=stride)
        self.conv2 = pre_conv3x3_block(in_channels=mid_channels,
            out_channels=mid_channels)
        self.conv3 = pre_conv3x3_block(in_channels=mid_channels,
            out_channels=out_channels)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class IRevUnit(nn.Module):
    """
    iRevNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the branch convolution layers.
    preactivate : bool
        Whether use pre-activation for the first convolution block.
    """

    def __init__(self, in_channels, out_channels, stride, preactivate):
        super(IRevUnit, self).__init__()
        if not preactivate:
            in_channels = in_channels // 2
        padding = 2 * (out_channels - in_channels)
        self.do_padding = padding != 0 and stride == 1
        self.do_downscale = stride != 1
        if self.do_padding:
            self.pad = IRevInjectivePad(padding)
        self.bottleneck = IRevBottleneck(in_channels=in_channels,
            out_channels=out_channels, stride=stride, preactivate=preactivate)
        if self.do_downscale:
            self.psi = IRevDownscale(stride)

    def forward(self, x1, x2):
        if self.do_padding:
            x = torch.cat((x1, x2), dim=1)
            x = self.pad(x)
            x1, x2 = torch.chunk(x, chunks=2, dim=1)
        fx2 = self.bottleneck(x2)
        if self.do_downscale:
            x1 = self.psi(x1)
            x2 = self.psi(x2)
        y1 = fx2 + x1
        return x2, y1

    def inverse(self, x2, y1):
        if self.do_downscale:
            x2 = self.psi.inverse(x2)
        fx2 = -self.bottleneck(x2)
        x1 = fx2 + y1
        if self.do_downscale:
            x1 = self.psi.inverse(x1)
        if self.do_padding:
            x = torch.cat((x1, x2), dim=1)
            x = self.pad.inverse(x)
            x1, x2 = torch.chunk(x, chunks=2, dim=1)
        return x1, x2


class IRevPostActivation(nn.Module):
    """
    iRevNet specific post-activation block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    """

    def __init__(self, in_channels):
        super(IRevPostActivation, self).__init__()
        self.bn = nn.BatchNorm2d(num_features=in_channels, momentum=0.9)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.bn(x)
        x = self.activ(x)
        return x


class IRevDualPathSequential(DualPathSequential):
    """
    An invertible sequential container for modules with dual inputs/outputs.
    Modules will be executed in the order they are added.

    Parameters:
    ----------
    return_two : bool, default True
        Whether to return two output after execution.
    first_ordinals : int, default 0
        Number of the first modules with single input/output.
    last_ordinals : int, default 0
        Number of the final modules with single input/output.
    dual_path_scheme : function
        Scheme of dual path response for a module.
    dual_path_scheme_ordinal : function
        Scheme of dual path response for an ordinal module.
    last_noninvertible : int, default 0
        Number of the final modules skipped during inverse.
    """

    def __init__(self, return_two=True, first_ordinals=0, last_ordinals=0,
        dual_path_scheme=lambda module, x1, x2: module(x1, x2),
        dual_path_scheme_ordinal=lambda module, x1, x2: (module(x1), x2),
        last_noninvertible=0):
        super(IRevDualPathSequential, self).__init__(return_two=return_two,
            first_ordinals=first_ordinals, last_ordinals=last_ordinals,
            dual_path_scheme=dual_path_scheme, dual_path_scheme_ordinal=
            dual_path_scheme_ordinal)
        self.last_noninvertible = last_noninvertible

    def inverse(self, x1, x2=None):
        length = len(self._modules.values())
        for i, module in enumerate(reversed(self._modules.values())):
            if i < self.last_noninvertible:
                pass
            elif i < self.last_ordinals or i >= length - self.first_ordinals:
                x1, x2 = self.dual_path_scheme_ordinal(module.inverse, x1, x2)
            else:
                x1, x2 = self.dual_path_scheme(module.inverse, x1, x2)
        if self.return_two:
            return x1, x2
        else:
            return x1


class IRevNet(nn.Module):
    """
    i-RevNet model from 'i-RevNet: Deep Invertible Networks,' https://arxiv.org/abs/1802.07088.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    final_block_channels : int
        Number of output channels for the final unit.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, final_block_channels,
        in_channels=3, in_size=(224, 224), num_classes=1000):
        super(IRevNet, self).__init__()
        assert in_channels > 0
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = IRevDualPathSequential(first_ordinals=1,
            last_ordinals=2, last_noninvertible=2)
        self.features.add_module('init_block', IRevDownscale(scale=2))
        in_channels = init_block_channels
        self.features.add_module('init_split', IRevSplitBlock())
        for i, channels_per_stage in enumerate(channels):
            stage = IRevDualPathSequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 else 1
                preactivate = not (i == 0 and j == 0)
                stage.add_module('unit{}'.format(j + 1), IRevUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, preactivate=preactivate))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        in_channels = final_block_channels
        self.features.add_module('final_merge', IRevMergeBlock())
        self.features.add_module('final_postactiv', IRevPostActivation(
            in_channels=in_channels))
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x, return_out_bij=False):
        x, out_bij = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        if return_out_bij:
            return x, out_bij
        else:
            return x

    def inverse(self, out_bij):
        x, _ = self.features.inverse(out_bij)
        return x


class CovPool(torch.autograd.Function):
    """
    Covariance pooling function.
    """

    @staticmethod
    def forward(ctx, x):
        batch, channels, height, width = x.size()
        n = height * width
        xn = x.reshape(batch, channels, n)
        identity_bar = (1.0 / n * torch.eye(n, dtype=xn.dtype, device=xn.
            device)).unsqueeze(dim=0).repeat(batch, 1, 1)
        ones_bar = torch.full((batch, n, n), fill_value=-1.0 / n / n, dtype
            =xn.dtype, device=xn.device)
        i_bar = identity_bar + ones_bar
        sigma = xn.bmm(i_bar).bmm(xn.transpose(1, 2))
        ctx.save_for_backward(x, i_bar)
        return sigma

    @staticmethod
    def backward(ctx, grad_sigma):
        x, i_bar = ctx.saved_tensors
        batch, channels, height, width = x.size()
        n = height * width
        xn = x.reshape(batch, channels, n)
        grad_x = grad_sigma + grad_sigma.transpose(1, 2)
        grad_x = grad_x.bmm(xn).bmm(i_bar)
        grad_x = grad_x.reshape(batch, channels, height, width)
        return grad_x


class NewtonSchulzSqrt(torch.autograd.Function):
    """
    Newton-Schulz iterative matrix square root function.

    Parameters:
    ----------
    x : Tensor
        Input tensor (batch * cols * rows).
    n : int
        Number of iterations (n > 1).
    """

    @staticmethod
    def forward(ctx, x, n):
        assert n > 1
        batch, cols, rows = x.size()
        assert cols == rows
        m = cols
        identity = torch.eye(m, dtype=x.dtype, device=x.device).unsqueeze(dim=0
            ).repeat(batch, 1, 1)
        x_trace = (x * identity).sum(dim=(1, 2), keepdim=True)
        a = x / x_trace
        i3 = 3.0 * identity
        yi = torch.zeros(batch, n - 1, m, m, dtype=x.dtype, device=x.device)
        zi = torch.zeros(batch, n - 1, m, m, dtype=x.dtype, device=x.device)
        b2 = 0.5 * (i3 - a)
        yi[:, (0), :, :] = a.bmm(b2)
        zi[:, (0), :, :] = b2
        for i in range(1, n - 1):
            b2 = 0.5 * (i3 - zi[:, (i - 1), :, :].bmm(yi[:, (i - 1), :, :]))
            yi[:, (i), :, :] = yi[:, (i - 1), :, :].bmm(b2)
            zi[:, (i), :, :] = b2.bmm(zi[:, (i - 1), :, :])
        b2 = 0.5 * (i3 - zi[:, (n - 2), :, :].bmm(yi[:, (n - 2), :, :]))
        yn = yi[:, (n - 2), :, :].bmm(b2)
        x_trace_sqrt = torch.sqrt(x_trace)
        c = yn * x_trace_sqrt
        ctx.save_for_backward(x, x_trace, a, yi, zi, yn, x_trace_sqrt)
        ctx.n = n
        return c

    @staticmethod
    def backward(ctx, grad_c):
        x, x_trace, a, yi, zi, yn, x_trace_sqrt = ctx.saved_tensors
        n = ctx.n
        batch, m, _ = x.size()
        identity0 = torch.eye(m, dtype=x.dtype, device=x.device)
        identity = identity0.unsqueeze(dim=0).repeat(batch, 1, 1)
        i3 = 3.0 * identity
        grad_yn = grad_c * x_trace_sqrt
        b = i3 - yi[:, (n - 2), :, :].bmm(zi[:, (n - 2), :, :])
        grad_yi = 0.5 * (grad_yn.bmm(b) - zi[:, (n - 2), :, :].bmm(yi[:, (n -
            2), :, :]).bmm(grad_yn))
        grad_zi = -0.5 * yi[:, (n - 2), :, :].bmm(grad_yn).bmm(yi[:, (n - 2
            ), :, :])
        for i in range(n - 3, -1, -1):
            b = i3 - yi[:, (i), :, :].bmm(zi[:, (i), :, :])
            ziyi = zi[:, (i), :, :].bmm(yi[:, (i), :, :])
            grad_yi_m1 = 0.5 * (grad_yi.bmm(b) - zi[:, (i), :, :].bmm(
                grad_zi).bmm(zi[:, (i), :, :]) - ziyi.bmm(grad_yi))
            grad_zi_m1 = 0.5 * (b.bmm(grad_zi) - yi[:, (i), :, :].bmm(
                grad_yi).bmm(yi[:, (i), :, :]) - grad_zi.bmm(ziyi))
            grad_yi = grad_yi_m1
            grad_zi = grad_zi_m1
        grad_a = 0.5 * (grad_yi.bmm(i3 - a) - grad_zi - a.bmm(grad_yi))
        x_trace_sqr = x_trace * x_trace
        grad_atx_trace = (grad_a.transpose(1, 2).bmm(x) * identity).sum(dim
            =(1, 2), keepdim=True)
        grad_cty_trace = (grad_c.transpose(1, 2).bmm(yn) * identity).sum(dim
            =(1, 2), keepdim=True)
        grad_x_extra = (0.5 * grad_cty_trace / x_trace_sqrt - 
            grad_atx_trace / x_trace_sqr).repeat(1, m, m) * identity
        grad_x = grad_a / x_trace + grad_x_extra
        return grad_x, None


class Triuvec(torch.autograd.Function):
    """
    Extract upper triangular part of matrix into vector form.
    """

    @staticmethod
    def forward(ctx, x):
        batch, cols, rows = x.size()
        assert cols == rows
        n = cols
        triuvec_inds = torch.ones(n, n).triu().view(n * n).nonzero()
        x_vec = x.reshape(batch, -1)
        y = x_vec[:, (triuvec_inds)]
        ctx.save_for_backward(x, triuvec_inds)
        return y

    @staticmethod
    def backward(ctx, grad_y):
        x, triuvec_inds = ctx.saved_tensors
        batch, n, _ = x.size()
        grad_x = torch.zeros_like(x).view(batch, -1)
        grad_x[:, (triuvec_inds)] = grad_y
        grad_x = grad_x.view(batch, n, n)
        return grad_x


class iSQRTCOVPool(nn.Module):
    """
    iSQRT-COV pooling layer.

    Parameters:
    ----------
    num_iter : int, default 5
        Number of iterations (num_iter > 1).
    """

    def __init__(self, num_iter=5):
        super(iSQRTCOVPool, self).__init__()
        self.num_iter = num_iter
        self.cov_pool = CovPool.apply
        self.sqrt = NewtonSchulzSqrt.apply
        self.triuvec = Triuvec.apply

    def forward(self, x):
        x = self.cov_pool(x)
        x = self.sqrt(x, self.num_iter)
        x = self.triuvec(x)
        return x


class iSQRTCOVResNet(nn.Module):
    """
    iSQRT-COV-ResNet model from 'Towards Faster Training of Global Covariance Pooling Networks by Iterative Matrix
    Square Root Normalization,' https://arxiv.org/abs/1712.01034.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    final_block_channels : int
        Number of output channels for the final unit.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    conv1_stride : bool
        Whether to use stride in the first or the second convolution layer in units.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, final_block_channels,
        bottleneck, conv1_stride, in_channels=3, in_size=(224, 224),
        num_classes=1000):
        super(iSQRTCOVResNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', ResInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i not in [0, len(channels) - 1] else 1
                stage.add_module('unit{}'.format(j + 1), ResUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, bottleneck=bottleneck, conv1_stride=
                    conv1_stride))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_block', conv1x1_block(in_channels=
            in_channels, out_channels=final_block_channels))
        in_channels = final_block_channels
        self.features.add_module('final_pool', iSQRTCOVPool())
        in_features = in_channels * (in_channels + 1) // 2
        self.output = nn.Linear(in_features=in_features, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class LffdDetectionBranch(nn.Module):
    """
    LFFD specific detection branch.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    bias : bool
        Whether the layer uses a bias vector.
    use_bn : bool
        Whether to use BatchNorm layer.
    """

    def __init__(self, in_channels, out_channels, bias, use_bn):
        super(LffdDetectionBranch, self).__init__()
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            in_channels, bias=bias, use_bn=use_bn)
        self.conv2 = conv1x1_block(in_channels=in_channels, out_channels=
            out_channels, bias=bias, use_bn=use_bn, activation=None)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class LffdDetectionBlock(nn.Module):
    """
    LFFD specific detection block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    mid_channels : int
        Number of middle channels.
    bias : bool
        Whether the layer uses a bias vector.
    use_bn : bool
        Whether to use BatchNorm layer.
    """

    def __init__(self, in_channels, mid_channels, bias, use_bn):
        super(LffdDetectionBlock, self).__init__()
        self.conv = conv1x1_block(in_channels=in_channels, out_channels=
            mid_channels, bias=bias, use_bn=use_bn)
        self.branches = Concurrent()
        self.branches.add_module('bbox_branch', LffdDetectionBranch(
            in_channels=mid_channels, out_channels=4, bias=bias, use_bn=use_bn)
            )
        self.branches.add_module('score_branch', LffdDetectionBranch(
            in_channels=mid_channels, out_channels=2, bias=bias, use_bn=use_bn)
            )

    def forward(self, x):
        x = self.conv(x)
        x = self.branches(x)
        return x


class LwopResBottleneck(nn.Module):
    """
    Bottleneck block for residual path in the residual unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    bias : bool, default True
        Whether the layer uses a bias vector.
    bottleneck_factor : int, default 2
        Bottleneck factor.
    squeeze_out : bool, default False
        Whether to squeeze the output channels.
    """

    def __init__(self, in_channels, out_channels, stride, bias=True,
        bottleneck_factor=2, squeeze_out=False):
        super(LwopResBottleneck, self).__init__()
        mid_channels = (out_channels // bottleneck_factor if squeeze_out else
            in_channels // bottleneck_factor)
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            mid_channels, bias=bias)
        self.conv2 = conv3x3_block(in_channels=mid_channels, out_channels=
            mid_channels, stride=stride, bias=bias)
        self.conv3 = conv1x1_block(in_channels=mid_channels, out_channels=
            out_channels, bias=bias, activation=None)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class LwopResUnit(nn.Module):
    """
    ResNet-like residual unit with residual connection.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    bias : bool, default True
        Whether the layer uses a bias vector.
    bottleneck_factor : int, default 2
        Bottleneck factor.
    squeeze_out : bool, default False
        Whether to squeeze the output channels.
    activate : bool, default False
        Whether to activate the sum.
    """

    def __init__(self, in_channels, out_channels, stride=1, bias=True,
        bottleneck_factor=2, squeeze_out=False, activate=False):
        super(LwopResUnit, self).__init__()
        self.activate = activate
        self.resize_identity = in_channels != out_channels or stride != 1
        self.body = LwopResBottleneck(in_channels=in_channels, out_channels
            =out_channels, stride=stride, bias=bias, bottleneck_factor=
            bottleneck_factor, squeeze_out=squeeze_out)
        if self.resize_identity:
            self.identity_conv = conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride, bias=bias,
                activation=None)
        if self.activate:
            self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        x = x + identity
        if self.activate:
            x = self.activ(x)
        return x


class LwopEncoderFinalBlock(nn.Module):
    """
    Lightweight OpenPose 2D/3D specific encoder final block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(LwopEncoderFinalBlock, self).__init__()
        self.pre_conv = conv1x1_block(in_channels=in_channels, out_channels
            =out_channels, bias=True, use_bn=False)
        self.body = nn.Sequential()
        for i in range(3):
            self.body.add_module('block{}'.format(i + 1), dwsconv3x3_block(
                in_channels=out_channels, out_channels=out_channels, use_bn
                =False, dw_activation=lambda : nn.ELU(inplace=True),
                pw_activation=lambda : nn.ELU(inplace=True)))
        self.post_conv = conv3x3_block(in_channels=out_channels,
            out_channels=out_channels, bias=True, use_bn=False)

    def forward(self, x):
        x = self.pre_conv(x)
        x = x + self.body(x)
        x = self.post_conv(x)
        return x


class LwopRefinementBlock(nn.Module):
    """
    Lightweight OpenPose 2D/3D specific refinement block for decoder units.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(LwopRefinementBlock, self).__init__()
        self.pre_conv = conv1x1_block(in_channels=in_channels, out_channels
            =out_channels, bias=True, use_bn=False)
        self.body = nn.Sequential()
        self.body.add_module('block1', conv3x3_block(in_channels=
            out_channels, out_channels=out_channels, bias=True))
        self.body.add_module('block2', conv3x3_block(in_channels=
            out_channels, out_channels=out_channels, padding=2, dilation=2,
            bias=True))

    def forward(self, x):
        x = self.pre_conv(x)
        x = x + self.body(x)
        return x


class LwopDecoderBend(nn.Module):
    """
    Lightweight OpenPose 2D/3D specific decoder bend block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    mid_channels : int
        Number of middle channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, mid_channels, out_channels):
        super(LwopDecoderBend, self).__init__()
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            mid_channels, bias=True, use_bn=False)
        self.conv2 = conv1x1(in_channels=mid_channels, out_channels=
            out_channels, bias=True)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class LwopDecoderInitBlock(nn.Module):
    """
    Lightweight OpenPose 2D/3D specific decoder init block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    keypoints : int
        Number of keypoints.
    """

    def __init__(self, in_channels, keypoints):
        super(LwopDecoderInitBlock, self).__init__()
        num_heatmap = keypoints
        num_paf = 2 * keypoints
        bend_mid_channels = 512
        self.body = nn.Sequential()
        for i in range(3):
            self.body.add_module('block{}'.format(i + 1), conv3x3_block(
                in_channels=in_channels, out_channels=in_channels, bias=
                True, use_bn=False))
        self.heatmap_bend = LwopDecoderBend(in_channels=in_channels,
            mid_channels=bend_mid_channels, out_channels=num_heatmap)
        self.paf_bend = LwopDecoderBend(in_channels=in_channels,
            mid_channels=bend_mid_channels, out_channels=num_paf)

    def forward(self, x):
        y = self.body(x)
        heatmap = self.heatmap_bend(y)
        paf = self.paf_bend(y)
        y = torch.cat((x, heatmap, paf), dim=1)
        return y


class LwopDecoderUnit(nn.Module):
    """
    Lightweight OpenPose 2D/3D specific decoder init.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    keypoints : int
        Number of keypoints.
    """

    def __init__(self, in_channels, keypoints):
        super(LwopDecoderUnit, self).__init__()
        num_heatmap = keypoints
        num_paf = 2 * keypoints
        self.features_channels = in_channels - num_heatmap - num_paf
        self.body = nn.Sequential()
        for i in range(5):
            self.body.add_module('block{}'.format(i + 1),
                LwopRefinementBlock(in_channels=in_channels, out_channels=
                self.features_channels))
            in_channels = self.features_channels
        self.heatmap_bend = LwopDecoderBend(in_channels=self.
            features_channels, mid_channels=self.features_channels,
            out_channels=num_heatmap)
        self.paf_bend = LwopDecoderBend(in_channels=self.features_channels,
            mid_channels=self.features_channels, out_channels=num_paf)

    def forward(self, x):
        features = x[:, :self.features_channels]
        y = self.body(x)
        heatmap = self.heatmap_bend(y)
        paf = self.paf_bend(y)
        y = torch.cat((features, heatmap, paf), dim=1)
        return y


class LwopDecoderFeaturesBend(nn.Module):
    """
    Lightweight OpenPose 2D/3D specific decoder 3D features bend.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    mid_channels : int
        Number of middle channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, mid_channels, out_channels):
        super(LwopDecoderFeaturesBend, self).__init__()
        self.body = nn.Sequential()
        for i in range(2):
            self.body.add_module('block{}'.format(i + 1),
                LwopRefinementBlock(in_channels=in_channels, out_channels=
                mid_channels))
            in_channels = mid_channels
        self.features_bend = LwopDecoderBend(in_channels=mid_channels,
            mid_channels=mid_channels, out_channels=out_channels)

    def forward(self, x):
        x = self.body(x)
        x = self.features_bend(x)
        return x


class LwopDecoderFinalBlock(nn.Module):
    """
    Lightweight OpenPose 2D/3D specific decoder final block for calcualation 3D poses.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    keypoints : int
        Number of keypoints.
    bottleneck_factor : int
        Bottleneck factor.
    calc_3d_features : bool
        Whether to calculate 3D features.
    """

    def __init__(self, in_channels, keypoints, bottleneck_factor,
        calc_3d_features):
        super(LwopDecoderFinalBlock, self).__init__()
        self.num_heatmap_paf = 3 * keypoints
        self.calc_3d_features = calc_3d_features
        features_out_channels = self.num_heatmap_paf
        features_in_channels = in_channels - features_out_channels
        if self.calc_3d_features:
            self.body = nn.Sequential()
            for i in range(5):
                self.body.add_module('block{}'.format(i + 1), LwopResUnit(
                    in_channels=in_channels, out_channels=
                    features_in_channels, bottleneck_factor=bottleneck_factor))
                in_channels = features_in_channels
            self.features_bend = LwopDecoderFeaturesBend(in_channels=
                features_in_channels, mid_channels=features_in_channels,
                out_channels=features_out_channels)

    def forward(self, x):
        heatmap_paf_2d = x[:, -self.num_heatmap_paf:]
        if not self.calc_3d_features:
            return heatmap_paf_2d
        x = self.body(x)
        x = self.features_bend(x)
        y = torch.cat((heatmap_paf_2d, x), dim=1)
        return y


class LwOpenPose(nn.Module):
    """
    Lightweight OpenPose 2D/3D model from 'Real-time 2D Multi-Person Pose Estimation on CPU: Lightweight OpenPose,'
    https://arxiv.org/abs/1811.12004.

    Parameters:
    ----------
    encoder_channels : list of list of int
        Number of output channels for each encoder unit.
    encoder_paddings : list of list of int
        Padding/dilation value for each encoder unit.
    encoder_init_block_channels : int
        Number of output channels for the encoder initial unit.
    encoder_final_block_channels : int
        Number of output channels for the encoder final unit.
    refinement_units : int
        Number of refinement blocks in the decoder.
    calc_3d_features : bool
        Whether to calculate 3D features.
    return_heatmap : bool, default True
        Whether to return only heatmap.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (256, 192)
        Spatial size of the expected input image.
    keypoints : int, default 19
        Number of keypoints.
    """

    def __init__(self, encoder_channels, encoder_paddings,
        encoder_init_block_channels, encoder_final_block_channels,
        refinement_units, calc_3d_features, return_heatmap=True,
        in_channels=3, in_size=(368, 368), keypoints=19):
        super(LwOpenPose, self).__init__()
        assert in_channels == 3
        self.in_size = in_size
        self.keypoints = keypoints
        self.return_heatmap = return_heatmap
        self.calc_3d_features = calc_3d_features
        num_heatmap_paf = 3 * keypoints
        self.encoder = nn.Sequential()
        backbone = nn.Sequential()
        backbone.add_module('init_block', conv3x3_block(in_channels=
            in_channels, out_channels=encoder_init_block_channels, stride=2))
        in_channels = encoder_init_block_channels
        for i, channels_per_stage in enumerate(encoder_channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                padding = encoder_paddings[i][j]
                stage.add_module('unit{}'.format(j + 1), dwsconv3x3_block(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, padding=padding, dilation=padding))
                in_channels = out_channels
            backbone.add_module('stage{}'.format(i + 1), stage)
        self.encoder.add_module('backbone', backbone)
        self.encoder.add_module('final_block', LwopEncoderFinalBlock(
            in_channels=in_channels, out_channels=encoder_final_block_channels)
            )
        in_channels = encoder_final_block_channels
        self.decoder = nn.Sequential()
        self.decoder.add_module('init_block', LwopDecoderInitBlock(
            in_channels=in_channels, keypoints=keypoints))
        in_channels = encoder_final_block_channels + num_heatmap_paf
        for i in range(refinement_units):
            self.decoder.add_module('unit{}'.format(i + 1), LwopDecoderUnit
                (in_channels=in_channels, keypoints=keypoints))
        self.decoder.add_module('final_block', LwopDecoderFinalBlock(
            in_channels=in_channels, keypoints=keypoints, bottleneck_factor
            =2, calc_3d_features=calc_3d_features))
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                nn.init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        if self.return_heatmap:
            return x
        else:
            return x


def depthwise_conv3x3(channels, stride):
    """
    Depthwise convolution 3x3 layer.

    Parameters:
    ----------
    channels : int
        Number of input/output channels.
    strides : int or tuple/list of 2 int
        Strides of the convolution.
    """
    return nn.Conv2d(in_channels=channels, out_channels=channels,
        kernel_size=3, stride=stride, padding=1, groups=channels, bias=False)


class MEUnit(nn.Module):
    """
    MENet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    side_channels : int
        Number of side channels.
    groups : int
        Number of groups in convolution layers.
    downsample : bool
        Whether do downsample.
    ignore_group : bool
        Whether ignore group value in the first convolution layer.
    """

    def __init__(self, in_channels, out_channels, side_channels, groups,
        downsample, ignore_group):
        super(MEUnit, self).__init__()
        self.downsample = downsample
        mid_channels = out_channels // 4
        if downsample:
            out_channels -= in_channels
        self.compress_conv1 = conv1x1(in_channels=in_channels, out_channels
            =mid_channels, groups=1 if ignore_group else groups)
        self.compress_bn1 = nn.BatchNorm2d(num_features=mid_channels)
        self.c_shuffle = ChannelShuffle(channels=mid_channels, groups=groups)
        self.dw_conv2 = depthwise_conv3x3(channels=mid_channels, stride=2 if
            self.downsample else 1)
        self.dw_bn2 = nn.BatchNorm2d(num_features=mid_channels)
        self.expand_conv3 = conv1x1(in_channels=mid_channels, out_channels=
            out_channels, groups=groups)
        self.expand_bn3 = nn.BatchNorm2d(num_features=out_channels)
        if downsample:
            self.avgpool = nn.AvgPool2d(kernel_size=3, stride=2, padding=1)
        self.activ = nn.ReLU(inplace=True)
        self.s_merge_conv = conv1x1(in_channels=mid_channels, out_channels=
            side_channels)
        self.s_merge_bn = nn.BatchNorm2d(num_features=side_channels)
        self.s_conv = conv3x3(in_channels=side_channels, out_channels=
            side_channels, stride=2 if self.downsample else 1)
        self.s_conv_bn = nn.BatchNorm2d(num_features=side_channels)
        self.s_evolve_conv = conv1x1(in_channels=side_channels,
            out_channels=mid_channels)
        self.s_evolve_bn = nn.BatchNorm2d(num_features=mid_channels)

    def forward(self, x):
        identity = x
        x = self.compress_conv1(x)
        x = self.compress_bn1(x)
        x = self.activ(x)
        x = self.c_shuffle(x)
        y = self.s_merge_conv(x)
        y = self.s_merge_bn(y)
        y = self.activ(y)
        x = self.dw_conv2(x)
        x = self.dw_bn2(x)
        y = self.s_conv(y)
        y = self.s_conv_bn(y)
        y = self.activ(y)
        y = self.s_evolve_conv(y)
        y = self.s_evolve_bn(y)
        y = torch.sigmoid(y)
        x = x * y
        x = self.expand_conv3(x)
        x = self.expand_bn3(x)
        if self.downsample:
            identity = self.avgpool(identity)
            x = torch.cat((x, identity), dim=1)
        else:
            x = x + identity
        x = self.activ(x)
        return x


class MEInitBlock(nn.Module):
    """
    MENet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(MEInitBlock, self).__init__()
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=3, stride=2, padding=1, bias=False)
        self.bn = nn.BatchNorm2d(num_features=out_channels)
        self.activ = nn.ReLU(inplace=True)
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        x = self.activ(x)
        x = self.pool(x)
        return x


class MENet(nn.Module):
    """
    MENet model from 'Merging and Evolution: Improving Convolutional Neural Networks for Mobile Applications,'
    https://arxiv.org/abs/1803.09127.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    side_channels : int
        Number of side channels in a ME-unit.
    groups : int
        Number of groups in convolution layers.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, side_channels, groups,
        in_channels=3, in_size=(224, 224), num_classes=1000):
        super(MENet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', MEInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                downsample = j == 0
                ignore_group = i == 0 and j == 0
                stage.add_module('unit{}'.format(j + 1), MEUnit(in_channels
                    =in_channels, out_channels=out_channels, side_channels=
                    side_channels, groups=groups, downsample=downsample,
                    ignore_group=ignore_group))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class MixConv(nn.Module):
    """
    Mixed convolution layer from 'MixConv: Mixed Depthwise Convolutional Kernels,' https://arxiv.org/abs/1907.09595.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of int, or tuple/list of tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of int, or tuple/list of tuple/list of 2 int
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    axis : int, default 1
        The axis on which to concatenate the outputs.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, dilation=1, groups=1, bias=False, axis=1):
        super(MixConv, self).__init__()
        kernel_size = kernel_size if isinstance(kernel_size, list) else [
            kernel_size]
        padding = padding if isinstance(padding, list) else [padding]
        kernel_count = len(kernel_size)
        self.splitted_in_channels = self.split_channels(in_channels,
            kernel_count)
        splitted_out_channels = self.split_channels(out_channels, kernel_count)
        for i, kernel_size_i in enumerate(kernel_size):
            in_channels_i = self.splitted_in_channels[i]
            out_channels_i = splitted_out_channels[i]
            padding_i = padding[i]
            self.add_module(name=str(i), module=nn.Conv2d(in_channels=
                in_channels_i, out_channels=out_channels_i, kernel_size=
                kernel_size_i, stride=stride, padding=padding_i, dilation=
                dilation, groups=out_channels_i if out_channels == groups else
                groups, bias=bias))
        self.axis = axis

    def forward(self, x):
        xx = torch.split(x, self.splitted_in_channels, dim=self.axis)
        out = [conv_i(x_i) for x_i, conv_i in zip(xx, self._modules.values())]
        x = torch.cat(tuple(out), dim=self.axis)
        return x

    @staticmethod
    def split_channels(channels, kernel_count):
        splitted_channels = [channels // kernel_count] * kernel_count
        splitted_channels[0] += channels - sum(splitted_channels)
        return splitted_channels


class MixConvBlock(nn.Module):
    """
    Mixed convolution block with Batch normalization and activation.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of int, or tuple/list of tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of int, or tuple/list of tuple/list of 2 int
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    use_bn : bool, default True
        Whether to use BatchNorm layer.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function or name of activation function.
    activate : bool, default True
        Whether activate the convolution block.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, dilation=1, groups=1, bias=False, use_bn=True, bn_eps=
        1e-05, activation=lambda : nn.ReLU(inplace=True)):
        super(MixConvBlock, self).__init__()
        self.activate = activation is not None
        self.use_bn = use_bn
        self.conv = MixConv(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, dilation=dilation, groups=groups, bias=bias)
        if self.use_bn:
            self.bn = nn.BatchNorm2d(num_features=out_channels, eps=bn_eps)
        if self.activate:
            self.activ = get_activation_layer(activation)

    def forward(self, x):
        x = self.conv(x)
        if self.use_bn:
            x = self.bn(x)
        if self.activate:
            x = self.activ(x)
        return x


def mixconv1x1_block(in_channels, out_channels, kernel_count, stride=1,
    groups=1, bias=False, use_bn=True, bn_eps=1e-05, activation=lambda : nn
    .ReLU(inplace=True)):
    """
    1x1 version of the mixed convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_count : int
        Kernel count.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    use_bn : bool, default True
        Whether to use BatchNorm layer.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    activation : function or str, or None, default nn.ReLU(inplace=True)
        Activation function or name of activation function.
    """
    return MixConvBlock(in_channels=in_channels, out_channels=out_channels,
        kernel_size=[1] * kernel_count, stride=stride, padding=[0] *
        kernel_count, groups=groups, bias=bias, use_bn=use_bn, bn_eps=
        bn_eps, activation=activation)


class MixUnit(nn.Module):
    """
    MixNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    exp_channels : int
        Number of middle (expanded) channels.
    stride : int or tuple/list of 2 int
        Strides of the second convolution layer.
    exp_kernel_count : int
        Expansion convolution kernel count for each unit.
    conv1_kernel_count : int
        Conv1 kernel count for each unit.
    conv2_kernel_count : int
        Conv2 kernel count for each unit.
    exp_factor : int
        Expansion factor for each unit.
    se_factor : int
        SE reduction factor for each unit.
    activation : str
        Activation function or name of activation function.
    """

    def __init__(self, in_channels, out_channels, stride, exp_kernel_count,
        conv1_kernel_count, conv2_kernel_count, exp_factor, se_factor,
        activation):
        super(MixUnit, self).__init__()
        assert exp_factor >= 1
        assert se_factor >= 0
        self.residual = in_channels == out_channels and stride == 1
        self.use_se = se_factor > 0
        mid_channels = exp_factor * in_channels
        self.use_exp_conv = exp_factor > 1
        if self.use_exp_conv:
            if exp_kernel_count == 1:
                self.exp_conv = conv1x1_block(in_channels=in_channels,
                    out_channels=mid_channels, activation=activation)
            else:
                self.exp_conv = mixconv1x1_block(in_channels=in_channels,
                    out_channels=mid_channels, kernel_count=
                    exp_kernel_count, activation=activation)
        if conv1_kernel_count == 1:
            self.conv1 = dwconv3x3_block(in_channels=mid_channels,
                out_channels=mid_channels, stride=stride, activation=activation
                )
        else:
            self.conv1 = MixConvBlock(in_channels=mid_channels,
                out_channels=mid_channels, kernel_size=[(3 + 2 * i) for i in
                range(conv1_kernel_count)], stride=stride, padding=[(1 + i) for
                i in range(conv1_kernel_count)], groups=mid_channels,
                activation=activation)
        if self.use_se:
            self.se = SEBlock(channels=mid_channels, reduction=exp_factor *
                se_factor, round_mid=False, mid_activation=activation)
        if conv2_kernel_count == 1:
            self.conv2 = conv1x1_block(in_channels=mid_channels,
                out_channels=out_channels, activation=None)
        else:
            self.conv2 = mixconv1x1_block(in_channels=mid_channels,
                out_channels=out_channels, kernel_count=conv2_kernel_count,
                activation=None)

    def forward(self, x):
        if self.residual:
            identity = x
        if self.use_exp_conv:
            x = self.exp_conv(x)
        x = self.conv1(x)
        if self.use_se:
            x = self.se(x)
        x = self.conv2(x)
        if self.residual:
            x = x + identity
        return x


class MixInitBlock(nn.Module):
    """
    MixNet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(MixInitBlock, self).__init__()
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            out_channels, stride=2)
        self.conv2 = MixUnit(in_channels=out_channels, out_channels=
            out_channels, stride=1, exp_kernel_count=1, conv1_kernel_count=
            1, conv2_kernel_count=1, exp_factor=1, se_factor=0, activation=
            'relu')

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class MixNet(nn.Module):
    """
    MixNet model from 'MixConv: Mixed Depthwise Convolutional Kernels,' https://arxiv.org/abs/1907.09595.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    final_block_channels : int
        Number of output channels for the final block of the feature extractor.
    exp_kernel_counts : list of list of int
        Expansion convolution kernel count for each unit.
    conv1_kernel_counts : list of list of int
        Conv1 kernel count for each unit.
    conv2_kernel_counts : list of list of int
        Conv2 kernel count for each unit.
    exp_factors : list of list of int
        Expansion factor for each unit.
    se_factors : list of list of int
        SE reduction factor for each unit.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, final_block_channels,
        exp_kernel_counts, conv1_kernel_counts, conv2_kernel_counts,
        exp_factors, se_factors, in_channels=3, in_size=(224, 224),
        num_classes=1000):
        super(MixNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', MixInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 3 or j == len(channels_per_stage
                    ) // 2 and i == 3 else 1
                exp_kernel_count = exp_kernel_counts[i][j]
                conv1_kernel_count = conv1_kernel_counts[i][j]
                conv2_kernel_count = conv2_kernel_counts[i][j]
                exp_factor = exp_factors[i][j]
                se_factor = se_factors[i][j]
                activation = 'relu' if i == 0 else 'swish'
                stage.add_module('unit{}'.format(j + 1), MixUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, exp_kernel_count=exp_kernel_count,
                    conv1_kernel_count=conv1_kernel_count,
                    conv2_kernel_count=conv2_kernel_count, exp_factor=
                    exp_factor, se_factor=se_factor, activation=activation))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_block', conv1x1_block(in_channels=
            in_channels, out_channels=final_block_channels))
        in_channels = final_block_channels
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class DwsExpSEResUnit(nn.Module):
    """
    Depthwise separable expanded residual unit with SE-block. Here it used as MnasNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the second convolution layer.
    use_kernel3 : bool, default True
        Whether to use 3x3 (instead of 5x5) kernel.
    exp_factor : int, default 1
        Expansion factor for each unit.
    se_factor : int, default 0
        SE reduction factor for each unit.
    use_skip : bool, default True
        Whether to use skip connection.
    activation : str, default 'relu'
        Activation function or name of activation function.
    """

    def __init__(self, in_channels, out_channels, stride=1, use_kernel3=
        True, exp_factor=1, se_factor=0, use_skip=True, activation='relu'):
        super(DwsExpSEResUnit, self).__init__()
        assert exp_factor >= 1
        self.residual = (in_channels == out_channels and stride == 1 and
            use_skip)
        self.use_exp_conv = exp_factor > 1
        self.use_se = se_factor > 0
        mid_channels = exp_factor * in_channels
        dwconv_block_fn = dwconv3x3_block if use_kernel3 else dwconv5x5_block
        if self.use_exp_conv:
            self.exp_conv = conv1x1_block(in_channels=in_channels,
                out_channels=mid_channels, activation=activation)
        self.dw_conv = dwconv_block_fn(in_channels=mid_channels,
            out_channels=mid_channels, stride=stride, activation=activation)
        if self.use_se:
            self.se = SEBlock(channels=mid_channels, reduction=exp_factor *
                se_factor, round_mid=False, mid_activation=activation)
        self.pw_conv = conv1x1_block(in_channels=mid_channels, out_channels
            =out_channels, activation=None)

    def forward(self, x):
        if self.residual:
            identity = x
        if self.use_exp_conv:
            x = self.exp_conv(x)
        x = self.dw_conv(x)
        if self.use_se:
            x = self.se(x)
        x = self.pw_conv(x)
        if self.residual:
            x = x + identity
        return x


class MnasInitBlock(nn.Module):
    """
    MnasNet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    mid_channels : int
        Number of middle channels.
    use_skip : bool
        Whether to use skip connection in the second block.
    """

    def __init__(self, in_channels, out_channels, mid_channels, use_skip):
        super(MnasInitBlock, self).__init__()
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            mid_channels, stride=2)
        self.conv2 = DwsExpSEResUnit(in_channels=mid_channels, out_channels
            =out_channels, use_skip=use_skip)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class MnasFinalBlock(nn.Module):
    """
    MnasNet specific final block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    mid_channels : int
        Number of middle channels.
    use_skip : bool
        Whether to use skip connection in the second block.
    """

    def __init__(self, in_channels, out_channels, mid_channels, use_skip):
        super(MnasFinalBlock, self).__init__()
        self.conv1 = DwsExpSEResUnit(in_channels=in_channels, out_channels=
            mid_channels, exp_factor=6, use_skip=use_skip)
        self.conv2 = conv1x1_block(in_channels=mid_channels, out_channels=
            out_channels)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class MnasNet(nn.Module):
    """
    MnasNet model from 'MnasNet: Platform-Aware Neural Architecture Search for Mobile,'
    https://arxiv.org/abs/1807.11626.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : list of 2 int
        Number of output channels for the initial unit.
    final_block_channels : list of 2 int
        Number of output channels for the final block of the feature extractor.
    kernels3 : list of list of int/bool
        Using 3x3 (instead of 5x5) kernel for each unit.
    exp_factors : list of list of int
        Expansion factor for each unit.
    se_factors : list of list of int
        SE reduction factor for each unit.
    init_block_use_skip : bool
        Whether to use skip connection in the initial unit.
    final_block_use_skip : bool
        Whether to use skip connection in the final block of the feature extractor.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, final_block_channels,
        kernels3, exp_factors, se_factors, init_block_use_skip,
        final_block_use_skip, in_channels=3, in_size=(224, 224),
        num_classes=1000):
        super(MnasNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', MnasInitBlock(in_channels=
            in_channels, out_channels=init_block_channels[1], mid_channels=
            init_block_channels[0], use_skip=init_block_use_skip))
        in_channels = init_block_channels[1]
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 else 1
                use_kernel3 = kernels3[i][j] == 1
                exp_factor = exp_factors[i][j]
                se_factor = se_factors[i][j]
                stage.add_module('unit{}'.format(j + 1), DwsExpSEResUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, use_kernel3=use_kernel3, exp_factor=
                    exp_factor, se_factor=se_factor))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_block', MnasFinalBlock(in_channels=
            in_channels, out_channels=final_block_channels[1], mid_channels
            =final_block_channels[0], use_skip=final_block_use_skip))
        in_channels = final_block_channels[1]
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class MobileNet(nn.Module):
    """
    MobileNet model from 'MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications,'
    https://arxiv.org/abs/1704.04861.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    first_stage_stride : bool
        Whether stride is used at the first stage.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, first_stage_stride, in_channels=3, in_size
        =(224, 224), num_classes=1000):
        super(MobileNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        init_block_channels = channels[0][0]
        self.features.add_module('init_block', conv3x3_block(in_channels=
            in_channels, out_channels=init_block_channels, stride=2))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels[1:]):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and (i != 0 or first_stage_stride) else 1
                stage.add_module('unit{}'.format(j + 1), dwsconv3x3_block(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if 'dw_conv.conv' in name:
                nn.init.kaiming_normal_(module.weight, mode='fan_in')
            elif name == 'init_block.conv' or 'pw_conv.conv' in name:
                nn.init.kaiming_normal_(module.weight, mode='fan_out')
            elif 'bn' in name:
                nn.init.constant_(module.weight, 1)
                nn.init.constant_(module.bias, 0)
            elif 'output' in name:
                nn.init.kaiming_normal_(module.weight, mode='fan_out')
                nn.init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class LinearBottleneck(nn.Module):
    """
    So-called 'Linear Bottleneck' layer. It is used as a MobileNetV2 unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the second convolution layer.
    expansion : bool
        Whether do expansion of channels.
    remove_exp_conv : bool
        Whether to remove expansion convolution.
    """

    def __init__(self, in_channels, out_channels, stride, expansion,
        remove_exp_conv):
        super(LinearBottleneck, self).__init__()
        self.residual = in_channels == out_channels and stride == 1
        mid_channels = in_channels * 6 if expansion else in_channels
        self.use_exp_conv = expansion or not remove_exp_conv
        if self.use_exp_conv:
            self.conv1 = conv1x1_block(in_channels=in_channels,
                out_channels=mid_channels, activation='relu6')
        self.conv2 = dwconv3x3_block(in_channels=mid_channels, out_channels
            =mid_channels, stride=stride, activation='relu6')
        self.conv3 = conv1x1_block(in_channels=mid_channels, out_channels=
            out_channels, activation=None)

    def forward(self, x):
        if self.residual:
            identity = x
        if self.use_exp_conv:
            x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        if self.residual:
            x = x + identity
        return x


class MobileNetV2(nn.Module):
    """
    MobileNetV2 model from 'MobileNetV2: Inverted Residuals and Linear Bottlenecks,' https://arxiv.org/abs/1801.04381.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    final_block_channels : int
        Number of output channels for the final block of the feature extractor.
    remove_exp_conv : bool
        Whether to remove expansion convolution.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, final_block_channels,
        remove_exp_conv, in_channels=3, in_size=(224, 224), num_classes=1000):
        super(MobileNetV2, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', conv3x3_block(in_channels=
            in_channels, out_channels=init_block_channels, stride=2,
            activation='relu6'))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                expansion = i != 0 or j != 0
                stage.add_module('unit{}'.format(j + 1), LinearBottleneck(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, expansion=expansion, remove_exp_conv=
                    remove_exp_conv))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_block', conv1x1_block(in_channels=
            in_channels, out_channels=final_block_channels, activation='relu6')
            )
        in_channels = final_block_channels
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = conv1x1(in_channels=in_channels, out_channels=
            num_classes, bias=False)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = self.output(x)
        x = x.view(x.size(0), -1)
        return x


class MobileNetV3Unit(nn.Module):
    """
    MobileNetV3 unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    exp_channels : int
        Number of middle (expanded) channels.
    stride : int or tuple/list of 2 int
        Strides of the second convolution layer.
    use_kernel3 : bool
        Whether to use 3x3 (instead of 5x5) kernel.
    activation : str
        Activation function or name of activation function.
    use_se : bool
        Whether to use SE-module.
    """

    def __init__(self, in_channels, out_channels, exp_channels, stride,
        use_kernel3, activation, use_se):
        super(MobileNetV3Unit, self).__init__()
        assert exp_channels >= out_channels
        self.residual = in_channels == out_channels and stride == 1
        self.use_se = use_se
        self.use_exp_conv = exp_channels != out_channels
        mid_channels = exp_channels
        if self.use_exp_conv:
            self.exp_conv = conv1x1_block(in_channels=in_channels,
                out_channels=mid_channels, activation=activation)
        if use_kernel3:
            self.conv1 = dwconv3x3_block(in_channels=mid_channels,
                out_channels=mid_channels, stride=stride, activation=activation
                )
        else:
            self.conv1 = dwconv5x5_block(in_channels=mid_channels,
                out_channels=mid_channels, stride=stride, activation=activation
                )
        if self.use_se:
            self.se = SEBlock(channels=mid_channels, reduction=4, round_mid
                =True, out_activation='hsigmoid')
        self.conv2 = conv1x1_block(in_channels=mid_channels, out_channels=
            out_channels, activation=None)

    def forward(self, x):
        if self.residual:
            identity = x
        if self.use_exp_conv:
            x = self.exp_conv(x)
        x = self.conv1(x)
        if self.use_se:
            x = self.se(x)
        x = self.conv2(x)
        if self.residual:
            x = x + identity
        return x


class MobileNetV3FinalBlock(nn.Module):
    """
    MobileNetV3 final block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    use_se : bool
        Whether to use SE-module.
    """

    def __init__(self, in_channels, out_channels, use_se):
        super(MobileNetV3FinalBlock, self).__init__()
        self.use_se = use_se
        self.conv = conv1x1_block(in_channels=in_channels, out_channels=
            out_channels, activation='hswish')
        if self.use_se:
            self.se = SEBlock(channels=out_channels, reduction=4, round_mid
                =True, out_activation='hsigmoid')

    def forward(self, x):
        x = self.conv(x)
        if self.use_se:
            x = self.se(x)
        return x


class MobileNetV3Classifier(nn.Module):
    """
    MobileNetV3 classifier.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    mid_channels : int
        Number of middle channels.
    dropout_rate : float
        Parameter of Dropout layer. Faction of the input units to drop.
    """

    def __init__(self, in_channels, out_channels, mid_channels, dropout_rate):
        super(MobileNetV3Classifier, self).__init__()
        self.use_dropout = dropout_rate != 0.0
        self.conv1 = conv1x1(in_channels=in_channels, out_channels=mid_channels
            )
        self.activ = HSwish(inplace=True)
        if self.use_dropout:
            self.dropout = nn.Dropout(p=dropout_rate)
        self.conv2 = conv1x1(in_channels=mid_channels, out_channels=
            out_channels, bias=True)

    def forward(self, x):
        x = self.conv1(x)
        x = self.activ(x)
        if self.use_dropout:
            x = self.dropout(x)
        x = self.conv2(x)
        return x


class MobileNetV3(nn.Module):
    """
    MobileNetV3 model from 'Searching for MobileNetV3,' https://arxiv.org/abs/1905.02244.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    exp_channels : list of list of int
        Number of middle (expanded) channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    final_block_channels : int
        Number of output channels for the final block of the feature extractor.
    classifier_mid_channels : int
        Number of middle channels for classifier.
    kernels3 : list of list of int/bool
        Using 3x3 (instead of 5x5) kernel for each unit.
    use_relu : list of list of int/bool
        Using ReLU activation flag for each unit.
    use_se : list of list of int/bool
        Using SE-block flag for each unit.
    first_stride : bool
        Whether to use stride for the first stage.
    final_use_se : bool
        Whether to use SE-module in the final block.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, exp_channels, init_block_channels,
        final_block_channels, classifier_mid_channels, kernels3, use_relu,
        use_se, first_stride, final_use_se, in_channels=3, in_size=(224, 
        224), num_classes=1000):
        super(MobileNetV3, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', conv3x3_block(in_channels=
            in_channels, out_channels=init_block_channels, stride=2,
            activation='hswish'))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                exp_channels_ij = exp_channels[i][j]
                stride = 2 if j == 0 and (i != 0 or first_stride) else 1
                use_kernel3 = kernels3[i][j] == 1
                activation = 'relu' if use_relu[i][j] == 1 else 'hswish'
                use_se_flag = use_se[i][j] == 1
                stage.add_module('unit{}'.format(j + 1), MobileNetV3Unit(
                    in_channels=in_channels, out_channels=out_channels,
                    exp_channels=exp_channels_ij, use_kernel3=use_kernel3,
                    stride=stride, activation=activation, use_se=use_se_flag))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_block', MobileNetV3FinalBlock(
            in_channels=in_channels, out_channels=final_block_channels,
            use_se=final_use_se))
        in_channels = final_block_channels
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = MobileNetV3Classifier(in_channels=in_channels,
            out_channels=num_classes, mid_channels=classifier_mid_channels,
            dropout_rate=0.2)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = self.output(x)
        x = x.view(x.size(0), -1)
        return x


class MultiOutputSequential(nn.Sequential):
    """
    A sequential container for modules. Modules will be executed in the order they are added. Output value contains
    results from all modules.
    """

    def __init__(self, *args):
        super(MultiOutputSequential, self).__init__(*args)

    def forward(self, x):
        outs = []
        for module in self._modules.values():
            x = module(x)
            outs.append(x)
        return outs


class MultiBlockSequential(nn.Sequential):
    """
    A sequential container for modules. Modules will be executed in the order they are added. Input is a list with
    length equal to number of modules.
    """

    def __init__(self, *args):
        super(MultiBlockSequential, self).__init__(*args)

    def forward(self, x):
        outs = []
        for module, x_i in zip(self._modules.values(), x):
            y = module(x_i)
            outs.append(y)
        return outs


class MSDBaseBlock(nn.Module):
    """
    MSDNet base block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    use_bottleneck : bool
        Whether to use a bottleneck.
    bottleneck_factor : int
        Bottleneck factor.
    """

    def __init__(self, in_channels, out_channels, stride, use_bottleneck,
        bottleneck_factor):
        super(MSDBaseBlock, self).__init__()
        self.use_bottleneck = use_bottleneck
        mid_channels = min(in_channels, bottleneck_factor * out_channels
            ) if use_bottleneck else in_channels
        if self.use_bottleneck:
            self.bn_conv = conv1x1_block(in_channels=in_channels,
                out_channels=mid_channels)
        self.conv = conv3x3_block(in_channels=mid_channels, out_channels=
            out_channels, stride=stride)

    def forward(self, x):
        if self.use_bottleneck:
            x = self.bn_conv(x)
        x = self.conv(x)
        return x


class MSDFirstScaleBlock(nn.Module):
    """
    MSDNet first scale dense block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    use_bottleneck : bool
        Whether to use a bottleneck.
    bottleneck_factor : int
        Bottleneck factor.
    """

    def __init__(self, in_channels, out_channels, use_bottleneck,
        bottleneck_factor):
        super(MSDFirstScaleBlock, self).__init__()
        assert out_channels > in_channels
        inc_channels = out_channels - in_channels
        self.block = MSDBaseBlock(in_channels=in_channels, out_channels=
            inc_channels, stride=1, use_bottleneck=use_bottleneck,
            bottleneck_factor=bottleneck_factor)

    def forward(self, x):
        y = self.block(x)
        y = torch.cat((x, y), dim=1)
        return y


class MSDScaleBlock(nn.Module):
    """
    MSDNet ordinary scale dense block.

    Parameters:
    ----------
    in_channels_prev : int
        Number of input channels for the previous scale.
    in_channels : int
        Number of input channels for the current scale.
    out_channels : int
        Number of output channels.
    use_bottleneck : bool
        Whether to use a bottleneck.
    bottleneck_factor_prev : int
        Bottleneck factor for the previous scale.
    bottleneck_factor : int
        Bottleneck factor for the current scale.
    """

    def __init__(self, in_channels_prev, in_channels, out_channels,
        use_bottleneck, bottleneck_factor_prev, bottleneck_factor):
        super(MSDScaleBlock, self).__init__()
        assert out_channels > in_channels
        assert out_channels % 2 == 0
        inc_channels = out_channels - in_channels
        mid_channels = inc_channels // 2
        self.down_block = MSDBaseBlock(in_channels=in_channels_prev,
            out_channels=mid_channels, stride=2, use_bottleneck=
            use_bottleneck, bottleneck_factor=bottleneck_factor_prev)
        self.curr_block = MSDBaseBlock(in_channels=in_channels,
            out_channels=mid_channels, stride=1, use_bottleneck=
            use_bottleneck, bottleneck_factor=bottleneck_factor)

    def forward(self, x_prev, x):
        y_prev = self.down_block(x_prev)
        y = self.curr_block(x)
        x = torch.cat((x, y_prev, y), dim=1)
        return x


class MSDInitLayer(nn.Module):
    """
    MSDNet initial (so-called first) layer.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : list/tuple of int
        Number of output channels for each scale.
    """

    def __init__(self, in_channels, out_channels):
        super(MSDInitLayer, self).__init__()
        self.scale_blocks = MultiOutputSequential()
        for i, out_channels_per_scale in enumerate(out_channels):
            if i == 0:
                self.scale_blocks.add_module('scale_block{}'.format(i + 1),
                    ResInitBlock(in_channels=in_channels, out_channels=
                    out_channels_per_scale))
            else:
                self.scale_blocks.add_module('scale_block{}'.format(i + 1),
                    conv3x3_block(in_channels=in_channels, out_channels=
                    out_channels_per_scale, stride=2))
            in_channels = out_channels_per_scale

    def forward(self, x):
        y = self.scale_blocks(x)
        return y


class MSDLayer(nn.Module):
    """
    MSDNet ordinary layer.

    Parameters:
    ----------
    in_channels : list/tuple of int
        Number of input channels for each input scale.
    out_channels : list/tuple of int
        Number of output channels for each output scale.
    use_bottleneck : bool
        Whether to use a bottleneck.
    bottleneck_factors : list/tuple of int
        Bottleneck factor for each input scale.
    """

    def __init__(self, in_channels, out_channels, use_bottleneck,
        bottleneck_factors):
        super(MSDLayer, self).__init__()
        in_scales = len(in_channels)
        out_scales = len(out_channels)
        self.dec_scales = in_scales - out_scales
        assert self.dec_scales >= 0
        self.scale_blocks = nn.Sequential()
        for i in range(out_scales):
            if i == 0 and self.dec_scales == 0:
                self.scale_blocks.add_module('scale_block{}'.format(i + 1),
                    MSDFirstScaleBlock(in_channels=in_channels[self.
                    dec_scales + i], out_channels=out_channels[i],
                    use_bottleneck=use_bottleneck, bottleneck_factor=
                    bottleneck_factors[self.dec_scales + i]))
            else:
                self.scale_blocks.add_module('scale_block{}'.format(i + 1),
                    MSDScaleBlock(in_channels_prev=in_channels[self.
                    dec_scales + i - 1], in_channels=in_channels[self.
                    dec_scales + i], out_channels=out_channels[i],
                    use_bottleneck=use_bottleneck, bottleneck_factor_prev=
                    bottleneck_factors[self.dec_scales + i - 1],
                    bottleneck_factor=bottleneck_factors[self.dec_scales + i]))

    def forward(self, x):
        outs = []
        for i in range(len(self.scale_blocks)):
            if i == 0 and self.dec_scales == 0:
                y = self.scale_blocks[i](x[i])
            else:
                y = self.scale_blocks[i](x_prev=x[self.dec_scales + i - 1],
                    x=x[self.dec_scales + i])
            outs.append(y)
        return outs


class MSDTransitionLayer(nn.Module):
    """
    MSDNet transition layer.

    Parameters:
    ----------
    in_channels : list/tuple of int
        Number of input channels for each scale.
    out_channels : list/tuple of int
        Number of output channels for each scale.
    """

    def __init__(self, in_channels, out_channels):
        super(MSDTransitionLayer, self).__init__()
        assert len(in_channels) == len(out_channels)
        self.scale_blocks = MultiBlockSequential()
        for i in range(len(out_channels)):
            self.scale_blocks.add_module('scale_block{}'.format(i + 1),
                conv1x1_block(in_channels=in_channels[i], out_channels=
                out_channels[i]))

    def forward(self, x):
        y = self.scale_blocks(x)
        return y


class MSDFeatureBlock(nn.Module):
    """
    MSDNet feature block (stage of cascade, so-called block).

    Parameters:
    ----------
    in_channels : list of list of int
        Number of input channels for each layer and for each input scale.
    out_channels : list of list of int
        Number of output channels for each layer and for each output scale.
    use_bottleneck : bool
        Whether to use a bottleneck.
    bottleneck_factors : list of list of int
        Bottleneck factor for each layer and for each input scale.
    """

    def __init__(self, in_channels, out_channels, use_bottleneck,
        bottleneck_factors):
        super(MSDFeatureBlock, self).__init__()
        self.blocks = nn.Sequential()
        for i, out_channels_per_layer in enumerate(out_channels):
            if len(bottleneck_factors[i]) == 0:
                self.blocks.add_module('trans{}'.format(i + 1),
                    MSDTransitionLayer(in_channels=in_channels,
                    out_channels=out_channels_per_layer))
            else:
                self.blocks.add_module('layer{}'.format(i + 1), MSDLayer(
                    in_channels=in_channels, out_channels=
                    out_channels_per_layer, use_bottleneck=use_bottleneck,
                    bottleneck_factors=bottleneck_factors[i]))
            in_channels = out_channels_per_layer

    def forward(self, x):
        x = self.blocks(x)
        return x


class MSDClassifier(nn.Module):
    """
    MSDNet classifier.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    num_classes : int
        Number of classification classes.
    """

    def __init__(self, in_channels, num_classes):
        super(MSDClassifier, self).__init__()
        self.features = nn.Sequential()
        self.features.add_module('conv1', conv3x3_block(in_channels=
            in_channels, out_channels=in_channels, stride=2))
        self.features.add_module('conv2', conv3x3_block(in_channels=
            in_channels, out_channels=in_channels, stride=2))
        self.features.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class MSDNet(nn.Module):
    """
    MSDNet model from 'Multi-Scale Dense Networks for Resource Efficient Image Classification,'
    https://arxiv.org/abs/1703.09844.

    Parameters:
    ----------
    channels : list of list of list of int
        Number of output channels for each unit.
    init_layer_channels : list of int
        Number of output channels for the initial layer.
    num_feature_blocks : int
        Number of subnets.
    use_bottleneck : bool
        Whether to use a bottleneck.
    bottleneck_factors : list of list of int
        Bottleneck factor for each layers and for each input scale.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_layer_channels, num_feature_blocks,
        use_bottleneck, bottleneck_factors, in_channels=3, in_size=(224, 
        224), num_classes=1000):
        super(MSDNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.init_layer = MSDInitLayer(in_channels=in_channels,
            out_channels=init_layer_channels)
        in_channels = init_layer_channels
        self.feature_blocks = nn.Sequential()
        self.classifiers = nn.Sequential()
        for i in range(num_feature_blocks):
            self.feature_blocks.add_module('block{}'.format(i + 1),
                MSDFeatureBlock(in_channels=in_channels, out_channels=
                channels[i], use_bottleneck=use_bottleneck,
                bottleneck_factors=bottleneck_factors[i]))
            in_channels = channels[i][-1]
            self.classifiers.add_module('classifier{}'.format(i + 1),
                MSDClassifier(in_channels=in_channels[-1], num_classes=
                num_classes))
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x, only_last=True):
        x = self.init_layer(x)
        outs = []
        for feature_block, classifier in zip(self.feature_blocks, self.
            classifiers):
            x = feature_block(x)
            y = classifier(x[-1])
            outs.append(y)
        if only_last:
            return outs[-1]
        else:
            return outs


class CIFAR10MSDInitLayer(nn.Module):
    """
    MSDNet initial (so-called first) layer for CIFAR-10.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : list/tuple of int
        Number of output channels for each scale.
    """

    def __init__(self, in_channels, out_channels):
        super(CIFAR10MSDInitLayer, self).__init__()
        self.scale_blocks = MultiOutputSequential()
        for i, out_channels_per_scale in enumerate(out_channels):
            stride = 1 if i == 0 else 2
            self.scale_blocks.add_module('scale_block{}'.format(i + 1),
                conv3x3_block(in_channels=in_channels, out_channels=
                out_channels_per_scale, stride=stride))
            in_channels = out_channels_per_scale

    def forward(self, x):
        y = self.scale_blocks(x)
        return y


class CIFAR10MSDClassifier(nn.Module):
    """
    MSDNet classifier for CIFAR-10.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    num_classes : int
        Number of classification classes.
    """

    def __init__(self, in_channels, num_classes):
        super(CIFAR10MSDClassifier, self).__init__()
        mid_channels = 128
        self.features = nn.Sequential()
        self.features.add_module('conv1', conv3x3_block(in_channels=
            in_channels, out_channels=mid_channels, stride=2))
        self.features.add_module('conv2', conv3x3_block(in_channels=
            mid_channels, out_channels=mid_channels, stride=2))
        self.features.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))
        self.output = nn.Linear(in_features=mid_channels, out_features=
            num_classes)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class CIFAR10MSDNet(nn.Module):
    """
    MSDNet model for CIFAR-10 from 'Multi-Scale Dense Networks for Resource Efficient Image Classification,'
    https://arxiv.org/abs/1703.09844.

    Parameters:
    ----------
    channels : list of list of list of int
        Number of output channels for each unit.
    init_layer_channels : list of int
        Number of output channels for the initial layer.
    num_feature_blocks : int
        Number of subnets.
    use_bottleneck : bool
        Whether to use a bottleneck.
    bottleneck_factors : list of list of int
        Bottleneck factor for each layers and for each input scale.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (32, 32)
        Spatial size of the expected input image.
    num_classes : int, default 10
        Number of classification classes.
    """

    def __init__(self, channels, init_layer_channels, num_feature_blocks,
        use_bottleneck, bottleneck_factors, in_channels=3, in_size=(32, 32),
        num_classes=10):
        super(CIFAR10MSDNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.init_layer = CIFAR10MSDInitLayer(in_channels=in_channels,
            out_channels=init_layer_channels)
        in_channels = init_layer_channels
        self.feature_blocks = nn.Sequential()
        self.classifiers = nn.Sequential()
        for i in range(num_feature_blocks):
            self.feature_blocks.add_module('block{}'.format(i + 1),
                MSDFeatureBlock(in_channels=in_channels, out_channels=
                channels[i], use_bottleneck=use_bottleneck,
                bottleneck_factors=bottleneck_factors[i]))
            in_channels = channels[i][-1]
            self.classifiers.add_module('classifier{}'.format(i + 1),
                CIFAR10MSDClassifier(in_channels=in_channels[-1],
                num_classes=num_classes))
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x, only_last=True):
        x = self.init_layer(x)
        outs = []
        for feature_block, classifier in zip(self.feature_blocks, self.
            classifiers):
            x = feature_block(x)
            y = classifier(x[-1])
            outs.append(y)
        if only_last:
            return outs[-1]
        else:
            return outs


class NasMaxPoolBlock(nn.Module):
    """
    NASNet specific Max pooling layer with extra padding.

    Parameters:
    ----------
    extra_padding : bool, default False
        Whether to use extra padding.
    """

    def __init__(self, extra_padding=False):
        super(NasMaxPoolBlock, self).__init__()
        self.extra_padding = extra_padding
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        if self.extra_padding:
            self.pad = nn.ZeroPad2d(padding=(1, 0, 1, 0))

    def forward(self, x):
        if self.extra_padding:
            x = self.pad(x)
        x = self.pool(x)
        if self.extra_padding:
            x = x[:, :, 1:, 1:].contiguous()
        return x


class NasAvgPoolBlock(nn.Module):
    """
    NASNet specific 3x3 Average pooling layer with extra padding.

    Parameters:
    ----------
    extra_padding : bool, default False
        Whether to use extra padding.
    """

    def __init__(self, extra_padding=False):
        super(NasAvgPoolBlock, self).__init__()
        self.extra_padding = extra_padding
        self.pool = nn.AvgPool2d(kernel_size=3, stride=2, padding=1,
            count_include_pad=False)
        if self.extra_padding:
            self.pad = nn.ZeroPad2d(padding=(1, 0, 1, 0))

    def forward(self, x):
        if self.extra_padding:
            x = self.pad(x)
        x = self.pool(x)
        if self.extra_padding:
            x = x[:, :, 1:, 1:].contiguous()
        return x


def nasnet_batch_norm(channels):
    """
    NASNet specific Batch normalization layer.

    Parameters:
    ----------
    channels : int
        Number of channels in input data.
    """
    return nn.BatchNorm2d(num_features=channels, eps=0.001, momentum=0.1,
        affine=True)


class NasConv(nn.Module):
    """
    NASNet specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    groups : int
        Number of groups.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, groups):
        super(NasConv, self).__init__()
        self.activ = nn.ReLU()
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, groups=groups, bias=False)
        self.bn = nasnet_batch_norm(channels=out_channels)

    def forward(self, x):
        x = self.activ(x)
        x = self.conv(x)
        x = self.bn(x)
        return x


class DwsConv(nn.Module):
    """
    Standard depthwise separable convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    bias : bool, default False
        Whether the layers use a bias vector.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, bias=False):
        super(DwsConv, self).__init__()
        self.dw_conv = nn.Conv2d(in_channels=in_channels, out_channels=
            in_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, groups=in_channels, bias=bias)
        self.pw_conv = conv1x1(in_channels=in_channels, out_channels=
            out_channels, bias=bias)

    def forward(self, x):
        x = self.dw_conv(x)
        x = self.pw_conv(x)
        return x


class NasDwsConv(nn.Module):
    """
    NASNet specific depthwise separable convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    extra_padding : bool, default False
        Whether to use extra padding.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, extra_padding=False):
        super(NasDwsConv, self).__init__()
        self.extra_padding = extra_padding
        self.activ = nn.ReLU()
        self.conv = DwsConv(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, bias=False)
        self.bn = nasnet_batch_norm(channels=out_channels)
        if self.extra_padding:
            self.pad = nn.ZeroPad2d(padding=(1, 0, 1, 0))

    def forward(self, x):
        x = self.activ(x)
        if self.extra_padding:
            x = self.pad(x)
        x = self.conv(x)
        if self.extra_padding:
            x = x[:, :, 1:, 1:].contiguous()
        x = self.bn(x)
        return x


class DwsBranch(nn.Module):
    """
    NASNet specific block with depthwise separable convolution layers.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    extra_padding : bool, default False
        Whether to use extra padding.
    stem : bool, default False
        Whether to use squeeze reduction if False.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, extra_padding=False, stem=False):
        super(DwsBranch, self).__init__()
        assert not stem or not extra_padding
        mid_channels = out_channels if stem else in_channels
        self.conv1 = NasDwsConv(in_channels=in_channels, out_channels=
            mid_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, extra_padding=extra_padding)
        self.conv2 = NasDwsConv(in_channels=mid_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=1, padding=padding)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


def nasnet_avgpool1x1_s2():
    """
    NASNet specific 1x1 Average pooling layer with stride 2.
    """
    return nn.AvgPool2d(kernel_size=1, stride=2, count_include_pad=False)


class NasPathBranch(nn.Module):
    """
    NASNet specific `path` branch (auxiliary block).

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    extra_padding : bool, default False
        Whether to use extra padding.
    """

    def __init__(self, in_channels, out_channels, extra_padding=False):
        super(NasPathBranch, self).__init__()
        self.extra_padding = extra_padding
        self.avgpool = nasnet_avgpool1x1_s2()
        self.conv = conv1x1(in_channels=in_channels, out_channels=out_channels)
        if self.extra_padding:
            self.pad = nn.ZeroPad2d(padding=(0, 1, 0, 1))

    def forward(self, x):
        if self.extra_padding:
            x = self.pad(x)
            x = x[:, :, 1:, 1:].contiguous()
        x = self.avgpool(x)
        x = self.conv(x)
        return x


class NasPathBlock(nn.Module):
    """
    NASNet specific `path` block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(NasPathBlock, self).__init__()
        mid_channels = out_channels // 2
        self.activ = nn.ReLU()
        self.path1 = NasPathBranch(in_channels=in_channels, out_channels=
            mid_channels)
        self.path2 = NasPathBranch(in_channels=in_channels, out_channels=
            mid_channels, extra_padding=True)
        self.bn = nasnet_batch_norm(channels=out_channels)

    def forward(self, x):
        x = self.activ(x)
        x1 = self.path1(x)
        x2 = self.path2(x)
        x = torch.cat((x1, x2), dim=1)
        x = self.bn(x)
        return x


def nas_conv1x1(in_channels, out_channels):
    """
    1x1 version of the NASNet specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """
    return NasConv(in_channels=in_channels, out_channels=out_channels,
        kernel_size=1, stride=1, padding=0, groups=1)


def dws_branch_k3_s1_p1(in_channels, out_channels, extra_padding=False):
    """
    3x3/1/1 version of the NASNet specific depthwise separable convolution branch.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    extra_padding : bool, default False
        Whether to use extra padding.
    """
    return DwsBranch(in_channels=in_channels, out_channels=out_channels,
        kernel_size=3, stride=1, padding=1, extra_padding=extra_padding)


def nasnet_avgpool3x3_s1():
    """
    NASNet specific 3x3 Average pooling layer with stride 1.
    """
    return nn.AvgPool2d(kernel_size=3, stride=1, padding=1,
        count_include_pad=False)


def nasnet_avgpool3x3_s2():
    """
    NASNet specific 3x3 Average pooling layer with stride 2.
    """
    return nn.AvgPool2d(kernel_size=3, stride=2, padding=1,
        count_include_pad=False)


def dws_branch_k5_s2_p2(in_channels, out_channels, extra_padding=False,
    stem=False):
    """
    5x5/2/2 version of the NASNet specific depthwise separable convolution branch.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    extra_padding : bool, default False
        Whether to use extra padding.
    stem : bool, default False
        Whether to use squeeze reduction if False.
    """
    return DwsBranch(in_channels=in_channels, out_channels=out_channels,
        kernel_size=5, stride=2, padding=2, extra_padding=extra_padding,
        stem=stem)


def dws_branch_k7_s2_p3(in_channels, out_channels, extra_padding=False,
    stem=False):
    """
    7x7/2/3 version of the NASNet specific depthwise separable convolution branch.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    extra_padding : bool, default False
        Whether to use extra padding.
    stem : bool, default False
        Whether to use squeeze reduction if False.
    """
    return DwsBranch(in_channels=in_channels, out_channels=out_channels,
        kernel_size=7, stride=2, padding=3, extra_padding=extra_padding,
        stem=stem)


class Stem1Unit(nn.Module):
    """
    NASNet Stem1 unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(Stem1Unit, self).__init__()
        mid_channels = out_channels // 4
        self.conv1x1 = nas_conv1x1(in_channels=in_channels, out_channels=
            mid_channels)
        self.comb0_left = dws_branch_k5_s2_p2(in_channels=mid_channels,
            out_channels=mid_channels)
        self.comb0_right = dws_branch_k7_s2_p3(in_channels=in_channels,
            out_channels=mid_channels, stem=True)
        self.comb1_left = NasMaxPoolBlock(extra_padding=False)
        self.comb1_right = dws_branch_k7_s2_p3(in_channels=in_channels,
            out_channels=mid_channels, stem=True)
        self.comb2_left = nasnet_avgpool3x3_s2()
        self.comb2_right = dws_branch_k5_s2_p2(in_channels=in_channels,
            out_channels=mid_channels, stem=True)
        self.comb3_right = nasnet_avgpool3x3_s1()
        self.comb4_left = dws_branch_k3_s1_p1(in_channels=mid_channels,
            out_channels=mid_channels)
        self.comb4_right = NasMaxPoolBlock(extra_padding=False)

    def forward(self, x, _=None):
        x_left = self.conv1x1(x)
        x_right = x
        x0 = self.comb0_left(x_left) + self.comb0_right(x_right)
        x1 = self.comb1_left(x_left) + self.comb1_right(x_right)
        x2 = self.comb2_left(x_left) + self.comb2_right(x_right)
        x3 = x1 + self.comb3_right(x0)
        x4 = self.comb4_left(x0) + self.comb4_right(x_left)
        x_out = torch.cat((x1, x2, x3, x4), dim=1)
        return x_out


class Stem2Unit(nn.Module):
    """
    NASNet Stem2 unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    prev_in_channels : int
        Number of input channels in previous input.
    out_channels : int
        Number of output channels.
    extra_padding : bool
        Whether to use extra padding.
    """

    def __init__(self, in_channels, prev_in_channels, out_channels,
        extra_padding):
        super(Stem2Unit, self).__init__()
        mid_channels = out_channels // 4
        self.conv1x1 = nas_conv1x1(in_channels=in_channels, out_channels=
            mid_channels)
        self.path = NasPathBlock(in_channels=prev_in_channels, out_channels
            =mid_channels)
        self.comb0_left = dws_branch_k5_s2_p2(in_channels=mid_channels,
            out_channels=mid_channels, extra_padding=extra_padding)
        self.comb0_right = dws_branch_k7_s2_p3(in_channels=mid_channels,
            out_channels=mid_channels, extra_padding=extra_padding)
        self.comb1_left = NasMaxPoolBlock(extra_padding=extra_padding)
        self.comb1_right = dws_branch_k7_s2_p3(in_channels=mid_channels,
            out_channels=mid_channels, extra_padding=extra_padding)
        self.comb2_left = NasAvgPoolBlock(extra_padding=extra_padding)
        self.comb2_right = dws_branch_k5_s2_p2(in_channels=mid_channels,
            out_channels=mid_channels, extra_padding=extra_padding)
        self.comb3_right = nasnet_avgpool3x3_s1()
        self.comb4_left = dws_branch_k3_s1_p1(in_channels=mid_channels,
            out_channels=mid_channels, extra_padding=extra_padding)
        self.comb4_right = NasMaxPoolBlock(extra_padding=extra_padding)

    def forward(self, x, x_prev):
        x_left = self.conv1x1(x)
        x_right = self.path(x_prev)
        x0 = self.comb0_left(x_left) + self.comb0_right(x_right)
        x1 = self.comb1_left(x_left) + self.comb1_right(x_right)
        x2 = self.comb2_left(x_left) + self.comb2_right(x_right)
        x3 = x1 + self.comb3_right(x0)
        x4 = self.comb4_left(x0) + self.comb4_right(x_left)
        x_out = torch.cat((x1, x2, x3, x4), dim=1)
        return x_out


def dws_branch_k5_s1_p2(in_channels, out_channels, extra_padding=False):
    """
    5x5/1/2 version of the NASNet specific depthwise separable convolution branch.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    extra_padding : bool, default False
        Whether to use extra padding.
    """
    return DwsBranch(in_channels=in_channels, out_channels=out_channels,
        kernel_size=5, stride=1, padding=2, extra_padding=extra_padding)


class FirstUnit(nn.Module):
    """
    NASNet First unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    prev_in_channels : int
        Number of input channels in previous input.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, prev_in_channels, out_channels):
        super(FirstUnit, self).__init__()
        mid_channels = out_channels // 6
        self.conv1x1 = nas_conv1x1(in_channels=in_channels, out_channels=
            mid_channels)
        self.path = NasPathBlock(in_channels=prev_in_channels, out_channels
            =mid_channels)
        self.comb0_left = dws_branch_k5_s1_p2(in_channels=mid_channels,
            out_channels=mid_channels)
        self.comb0_right = dws_branch_k3_s1_p1(in_channels=mid_channels,
            out_channels=mid_channels)
        self.comb1_left = dws_branch_k5_s1_p2(in_channels=mid_channels,
            out_channels=mid_channels)
        self.comb1_right = dws_branch_k3_s1_p1(in_channels=mid_channels,
            out_channels=mid_channels)
        self.comb2_left = nasnet_avgpool3x3_s1()
        self.comb3_left = nasnet_avgpool3x3_s1()
        self.comb3_right = nasnet_avgpool3x3_s1()
        self.comb4_left = dws_branch_k3_s1_p1(in_channels=mid_channels,
            out_channels=mid_channels)

    def forward(self, x, x_prev):
        x_left = self.conv1x1(x)
        x_right = self.path(x_prev)
        x0 = self.comb0_left(x_left) + self.comb0_right(x_right)
        x1 = self.comb1_left(x_right) + self.comb1_right(x_right)
        x2 = self.comb2_left(x_left) + x_right
        x3 = self.comb3_left(x_right) + self.comb3_right(x_right)
        x4 = self.comb4_left(x_left) + x_left
        x_out = torch.cat((x_right, x0, x1, x2, x3, x4), dim=1)
        return x_out


class NormalUnit(nn.Module):
    """
    NASNet Normal unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    prev_in_channels : int
        Number of input channels in previous input.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, prev_in_channels, out_channels):
        super(NormalUnit, self).__init__()
        mid_channels = out_channels // 6
        self.conv1x1_prev = nas_conv1x1(in_channels=prev_in_channels,
            out_channels=mid_channels)
        self.conv1x1 = nas_conv1x1(in_channels=in_channels, out_channels=
            mid_channels)
        self.comb0_left = dws_branch_k5_s1_p2(in_channels=mid_channels,
            out_channels=mid_channels)
        self.comb0_right = dws_branch_k3_s1_p1(in_channels=mid_channels,
            out_channels=mid_channels)
        self.comb1_left = dws_branch_k5_s1_p2(in_channels=mid_channels,
            out_channels=mid_channels)
        self.comb1_right = dws_branch_k3_s1_p1(in_channels=mid_channels,
            out_channels=mid_channels)
        self.comb2_left = nasnet_avgpool3x3_s1()
        self.comb3_left = nasnet_avgpool3x3_s1()
        self.comb3_right = nasnet_avgpool3x3_s1()
        self.comb4_left = dws_branch_k3_s1_p1(in_channels=mid_channels,
            out_channels=mid_channels)

    def forward(self, x, x_prev):
        x_left = self.conv1x1(x)
        x_right = self.conv1x1_prev(x_prev)
        x0 = self.comb0_left(x_left) + self.comb0_right(x_right)
        x1 = self.comb1_left(x_right) + self.comb1_right(x_right)
        x2 = self.comb2_left(x_left) + x_right
        x3 = self.comb3_left(x_right) + self.comb3_right(x_right)
        x4 = self.comb4_left(x_left) + x_left
        x_out = torch.cat((x_right, x0, x1, x2, x3, x4), dim=1)
        return x_out


class ReductionBaseUnit(nn.Module):
    """
    NASNet Reduction base unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    prev_in_channels : int
        Number of input channels in previous input.
    out_channels : int
        Number of output channels.
    extra_padding : bool, default True
        Whether to use extra padding.
    """

    def __init__(self, in_channels, prev_in_channels, out_channels,
        extra_padding=True):
        super(ReductionBaseUnit, self).__init__()
        self.skip_input = True
        mid_channels = out_channels // 4
        self.conv1x1_prev = nas_conv1x1(in_channels=prev_in_channels,
            out_channels=mid_channels)
        self.conv1x1 = nas_conv1x1(in_channels=in_channels, out_channels=
            mid_channels)
        self.comb0_left = dws_branch_k5_s2_p2(in_channels=mid_channels,
            out_channels=mid_channels, extra_padding=extra_padding)
        self.comb0_right = dws_branch_k7_s2_p3(in_channels=mid_channels,
            out_channels=mid_channels, extra_padding=extra_padding)
        self.comb1_left = NasMaxPoolBlock(extra_padding=extra_padding)
        self.comb1_right = dws_branch_k7_s2_p3(in_channels=mid_channels,
            out_channels=mid_channels, extra_padding=extra_padding)
        self.comb2_left = NasAvgPoolBlock(extra_padding=extra_padding)
        self.comb2_right = dws_branch_k5_s2_p2(in_channels=mid_channels,
            out_channels=mid_channels, extra_padding=extra_padding)
        self.comb3_right = nasnet_avgpool3x3_s1()
        self.comb4_left = dws_branch_k3_s1_p1(in_channels=mid_channels,
            out_channels=mid_channels, extra_padding=extra_padding)
        self.comb4_right = NasMaxPoolBlock(extra_padding=extra_padding)

    def forward(self, x, x_prev):
        x_left = self.conv1x1(x)
        x_right = self.conv1x1_prev(x_prev)
        x0 = self.comb0_left(x_left) + self.comb0_right(x_right)
        x1 = self.comb1_left(x_left) + self.comb1_right(x_right)
        x2 = self.comb2_left(x_left) + self.comb2_right(x_right)
        x3 = x1 + self.comb3_right(x0)
        x4 = self.comb4_left(x0) + self.comb4_right(x_left)
        x_out = torch.cat((x1, x2, x3, x4), dim=1)
        return x_out


class NASNetInitBlock(nn.Module):
    """
    NASNet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(NASNetInitBlock, self).__init__()
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=3, stride=2, padding=0, bias=False)
        self.bn = nasnet_batch_norm(channels=out_channels)

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        return x


class Reduction2Unit(ReductionBaseUnit):
    """
    NASNet Reduction2 unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    prev_in_channels : int
        Number of input channels in previous input.
    out_channels : int
        Number of output channels.
    extra_padding : bool
        Whether to use extra padding.
    """

    def __init__(self, in_channels, prev_in_channels, out_channels,
        extra_padding):
        super(Reduction2Unit, self).__init__(in_channels=in_channels,
            prev_in_channels=prev_in_channels, out_channels=out_channels,
            extra_padding=extra_padding)


class Reduction1Unit(ReductionBaseUnit):
    """
    NASNet Reduction1 unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    prev_in_channels : int
        Number of input channels in previous input.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, prev_in_channels, out_channels):
        super(Reduction1Unit, self).__init__(in_channels=in_channels,
            prev_in_channels=prev_in_channels, out_channels=out_channels,
            extra_padding=True)


class NASNet(nn.Module):
    """
    NASNet-A model from 'Learning Transferable Architectures for Scalable Image Recognition,'
    https://arxiv.org/abs/1707.07012.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    stem_blocks_channels : list of 2 int
        Number of output channels for the Stem units.
    final_pool_size : int
        Size of the pooling windows for final pool.
    extra_padding : bool
        Whether to use extra padding.
    skip_reduction_layer_input : bool
        Whether to skip the reduction layers when calculating the previous layer to connect to.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, stem_blocks_channels,
        final_pool_size, extra_padding, skip_reduction_layer_input,
        in_channels=3, in_size=(224, 224), num_classes=1000):
        super(NASNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        reduction_units = [Reduction1Unit, Reduction2Unit]
        self.features = nasnet_dual_path_sequential(return_two=False,
            first_ordinals=1, last_ordinals=2)
        self.features.add_module('init_block', NASNetInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        out_channels = stem_blocks_channels[0]
        self.features.add_module('stem1_unit', Stem1Unit(in_channels=
            in_channels, out_channels=out_channels))
        prev_in_channels = in_channels
        in_channels = out_channels
        out_channels = stem_blocks_channels[1]
        self.features.add_module('stem2_unit', Stem2Unit(in_channels=
            in_channels, prev_in_channels=prev_in_channels, out_channels=
            out_channels, extra_padding=extra_padding))
        prev_in_channels = in_channels
        in_channels = out_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nasnet_dual_path_sequential(can_skip_input=
                skip_reduction_layer_input)
            for j, out_channels in enumerate(channels_per_stage):
                if j == 0 and i != 0:
                    unit = reduction_units[i - 1]
                elif i == 0 and j == 0 or i != 0 and j == 1:
                    unit = FirstUnit
                else:
                    unit = NormalUnit
                if unit == Reduction2Unit:
                    stage.add_module('unit{}'.format(j + 1), Reduction2Unit
                        (in_channels=in_channels, prev_in_channels=
                        prev_in_channels, out_channels=out_channels,
                        extra_padding=extra_padding))
                else:
                    stage.add_module('unit{}'.format(j + 1), unit(
                        in_channels=in_channels, prev_in_channels=
                        prev_in_channels, out_channels=out_channels))
                prev_in_channels = in_channels
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('activ', nn.ReLU())
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=
            final_pool_size, stride=1))
        self.output = nn.Sequential()
        self.output.add_module('dropout', nn.Dropout(p=0.5))
        self.output.add_module('fc', nn.Linear(in_features=in_channels,
            out_features=num_classes))
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class NINConv(nn.Module):
    """
    NIN specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 0
        Padding value for convolution layer.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride=1,
        padding=0):
        super(NINConv, self).__init__()
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, bias=True)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.conv(x)
        x = self.activ(x)
        return x


class CIFARNIN(nn.Module):
    """
    NIN model for CIFAR from 'Network In Network,' https://arxiv.org/abs/1312.4400.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    first_kernel_sizes : list of int
        Convolution window sizes for the first units in each stage.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (32, 32)
        Spatial size of the expected input image.
    num_classes : int, default 10
        Number of classification classes.
    """

    def __init__(self, channels, first_kernel_sizes, in_channels=3, in_size
        =(32, 32), num_classes=10):
        super(CIFARNIN, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                if j == 0 and i != 0:
                    if i == 1:
                        stage.add_module('pool{}'.format(i + 1), nn.
                            MaxPool2d(kernel_size=3, stride=2, padding=1))
                    else:
                        stage.add_module('pool{}'.format(i + 1), nn.
                            AvgPool2d(kernel_size=3, stride=2, padding=1))
                    stage.add_module('dropout{}'.format(i + 1), nn.Dropout(
                        p=0.5))
                kernel_size = first_kernel_sizes[i] if j == 0 else 1
                padding = (kernel_size - 1) // 2
                stage.add_module('unit{}'.format(j + 1), NINConv(
                    in_channels=in_channels, out_channels=out_channels,
                    kernel_size=kernel_size, padding=padding))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.output = nn.Sequential()
        self.output.add_module('final_conv', NINConv(in_channels=
            in_channels, out_channels=num_classes, kernel_size=1))
        self.output.add_module('final_pool', nn.AvgPool2d(kernel_size=8,
            stride=1))
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = self.output(x)
        x = x.view(x.size(0), -1)
        return x


class NavigatorBranch(nn.Module):
    """
    Navigator branch block for Navigator unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    """

    def __init__(self, in_channels, out_channels, stride):
        super(NavigatorBranch, self).__init__()
        mid_channels = 128
        self.down_conv = conv3x3(in_channels=in_channels, out_channels=
            mid_channels, stride=stride, bias=True)
        self.activ = nn.ReLU(inplace=False)
        self.tidy_conv = conv1x1(in_channels=mid_channels, out_channels=
            out_channels, bias=True)
        self.flatten = Flatten()

    def forward(self, x):
        y = self.down_conv(x)
        y = self.activ(y)
        z = self.tidy_conv(y)
        z = self.flatten(z)
        return z, y


class NavigatorUnit(nn.Module):
    """
    Navigator init.
    """

    def __init__(self):
        super(NavigatorUnit, self).__init__()
        self.branch1 = NavigatorBranch(in_channels=2048, out_channels=6,
            stride=1)
        self.branch2 = NavigatorBranch(in_channels=128, out_channels=6,
            stride=2)
        self.branch3 = NavigatorBranch(in_channels=128, out_channels=9,
            stride=2)

    def forward(self, x):
        t1, x = self.branch1(x)
        t2, x = self.branch2(x)
        t3, _ = self.branch3(x)
        return torch.cat((t1, t2, t3), dim=1)


def hard_nms(cdds, top_n=10, iou_thresh=0.25):
    """
    Hard Non-Maximum Suppression.

    Parameters:
    ----------
    cdds : np.array
        Borders.
    top_n : int, default 10
        Number of top-K informative regions.
    iou_thresh : float, default 0.25
        IoU threshold.

    Returns
    -------
    np.array
        Filtered borders.
    """
    assert type(cdds) == np.ndarray
    assert len(cdds.shape) == 2
    assert cdds.shape[1] >= 5
    cdds = cdds.copy()
    indices = np.argsort(cdds[:, (0)])
    cdds = cdds[indices]
    cdd_results = []
    res = cdds
    while res.any():
        cdd = res[-1]
        cdd_results.append(cdd)
        if len(cdd_results) == top_n:
            return np.array(cdd_results)
        res = res[:-1]
        start_max = np.maximum(res[:, 1:3], cdd[1:3])
        end_min = np.minimum(res[:, 3:5], cdd[3:5])
        lengths = end_min - start_max
        intersec_map = lengths[:, (0)] * lengths[:, (1)]
        intersec_map[np.logical_or(lengths[:, (0)] < 0, lengths[:, (1)] < 0)
            ] = 0
        iou_map_cur = intersec_map / ((res[:, (3)] - res[:, (1)]) * (res[:,
            (4)] - res[:, (2)]) + (cdd[3] - cdd[1]) * (cdd[4] - cdd[2]) -
            intersec_map)
        res = res[iou_map_cur < iou_thresh]
    return np.array(cdd_results)


class NTSNet(nn.Module):
    """
    NTS-Net model from 'Learning to Navigate for Fine-grained Classification,' https://arxiv.org/abs/1809.00287.

    Parameters:
    ----------
    backbone : nn.Sequential
        Feature extractor.
    aux : bool, default False
        Whether to output auxiliary results.
    top_n : int, default 4
        Number of extra top-K informative regions.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, backbone, aux=False, top_n=4, in_channels=3, in_size
        =(448, 448), num_classes=200):
        super(NTSNet, self).__init__()
        assert in_channels > 0
        self.in_size = in_size
        self.num_classes = num_classes
        pad_side = 224
        pad_width = pad_side, pad_side, pad_side, pad_side
        self.top_n = top_n
        self.aux = aux
        self.num_cat = 4
        _, edge_anchors, _ = self._generate_default_anchor_maps()
        self.edge_anchors = (edge_anchors + 224).astype(np.int)
        self.edge_anchors = np.concatenate((self.edge_anchors.copy(), np.
            arange(0, len(self.edge_anchors)).reshape(-1, 1)), axis=1)
        self.backbone = backbone
        self.backbone_tail = nn.Sequential()
        self.backbone_tail.add_module('final_pool', nn.AdaptiveAvgPool2d(1))
        self.backbone_tail.add_module('flatten', Flatten())
        self.backbone_tail.add_module('dropout', nn.Dropout(p=0.5))
        self.backbone_classifier = nn.Linear(in_features=512 * 4,
            out_features=num_classes)
        self.pad = nn.ZeroPad2d(padding=pad_width)
        self.navigator_unit = NavigatorUnit()
        self.concat_net = nn.Linear(in_features=2048 * (self.num_cat + 1),
            out_features=num_classes)
        if self.aux:
            self.partcls_net = nn.Linear(in_features=512 * 4, out_features=
                num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        raw_pre_features = self.backbone(x)
        rpn_score = self.navigator_unit(raw_pre_features)
        all_cdds = [np.concatenate((y.reshape(-1, 1), self.edge_anchors.
            copy()), axis=1) for y in rpn_score.detach().cpu().numpy()]
        top_n_cdds = [hard_nms(y, top_n=self.top_n, iou_thresh=0.25) for y in
            all_cdds]
        top_n_cdds = np.array(top_n_cdds)
        top_n_index = top_n_cdds[:, :, (-1)].astype(np.int64)
        top_n_index = torch.from_numpy(top_n_index).long().to(x.device)
        top_n_prob = torch.gather(rpn_score, dim=1, index=top_n_index)
        batch = x.size(0)
        part_imgs = torch.zeros(batch, self.top_n, 3, 224, 224, dtype=x.
            dtype, device=x.device)
        x_pad = self.pad(x)
        for i in range(batch):
            for j in range(self.top_n):
                y0, x0, y1, x1 = tuple(top_n_cdds[i][(j), 1:5].astype(np.int64)
                    )
                part_imgs[i:i + 1, (j)] = F.interpolate(input=x_pad[i:i + 1,
                    :, y0:y1, x0:x1], size=(224, 224), mode='bilinear',
                    align_corners=True)
        part_imgs = part_imgs.view(batch * self.top_n, 3, 224, 224)
        part_features = self.backbone_tail(self.backbone(part_imgs.detach()))
        part_feature = part_features.view(batch, self.top_n, -1)
        part_feature = part_feature[:, :self.num_cat, :].contiguous()
        part_feature = part_feature.view(batch, -1)
        raw_features = self.backbone_tail(raw_pre_features.detach())
        concat_out = torch.cat((part_feature, raw_features), dim=1)
        concat_logits = self.concat_net(concat_out)
        if self.aux:
            raw_logits = self.backbone_classifier(raw_features)
            part_logits = self.partcls_net(part_features).view(batch, self.
                top_n, -1)
            return concat_logits, raw_logits, part_logits, top_n_prob
        else:
            return concat_logits

    @staticmethod
    def _generate_default_anchor_maps(input_shape=(448, 448)):
        """
        Generate default anchor maps.

        Parameters:
        ----------
        input_shape : tuple of 2 int
            Input image size.

        Returns
        -------
        center_anchors : np.array
            anchors * 4 (oy, ox, h, w).
        edge_anchors : np.array
            anchors * 4 (y0, x0, y1, x1).
        anchor_area : np.array
            anchors * 1 (area).
        """
        anchor_scale = [2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]
        anchor_aspect_ratio = [0.667, 1, 1.5]
        anchors_setting = dict(layer='p3', stride=32, size=48, scale=
            anchor_scale, aspect_ratio=anchor_aspect_ratio), dict(layer=
            'p4', stride=64, size=96, scale=anchor_scale, aspect_ratio=
            anchor_aspect_ratio), dict(layer='p5', stride=128, size=192,
            scale=[1, anchor_scale[0], anchor_scale[1]], aspect_ratio=
            anchor_aspect_ratio)
        center_anchors = np.zeros((0, 4), dtype=np.float32)
        edge_anchors = np.zeros((0, 4), dtype=np.float32)
        anchor_areas = np.zeros((0,), dtype=np.float32)
        input_shape = np.array(input_shape, dtype=int)
        for anchor_info in anchors_setting:
            stride = anchor_info['stride']
            size = anchor_info['size']
            scales = anchor_info['scale']
            aspect_ratios = anchor_info['aspect_ratio']
            output_map_shape = np.ceil(input_shape.astype(np.float32) / stride)
            output_map_shape = output_map_shape.astype(np.int)
            output_shape = tuple(output_map_shape) + (4,)
            ostart = stride / 2.0
            oy = np.arange(ostart, ostart + stride * output_shape[0], stride)
            oy = oy.reshape(output_shape[0], 1)
            ox = np.arange(ostart, ostart + stride * output_shape[1], stride)
            ox = ox.reshape(1, output_shape[1])
            center_anchor_map_template = np.zeros(output_shape, dtype=np.
                float32)
            center_anchor_map_template[:, :, (0)] = oy
            center_anchor_map_template[:, :, (1)] = ox
            for anchor_scale in scales:
                for anchor_aspect_ratio in aspect_ratios:
                    center_anchor_map = center_anchor_map_template.copy()
                    center_anchor_map[:, :, (2)] = size * anchor_scale / float(
                        anchor_aspect_ratio) ** 0.5
                    center_anchor_map[:, :, (3)] = size * anchor_scale * float(
                        anchor_aspect_ratio) ** 0.5
                    edge_anchor_map = np.concatenate((center_anchor_map[:,
                        :, :2] - center_anchor_map[:, :, 2:4] / 2.0, 
                        center_anchor_map[:, :, :2] + center_anchor_map[:,
                        :, 2:4] / 2.0), axis=-1)
                    anchor_area_map = center_anchor_map[:, :, (2)
                        ] * center_anchor_map[:, :, (3)]
                    center_anchors = np.concatenate((center_anchors,
                        center_anchor_map.reshape(-1, 4)))
                    edge_anchors = np.concatenate((edge_anchors,
                        edge_anchor_map.reshape(-1, 4)))
                    anchor_areas = np.concatenate((anchor_areas,
                        anchor_area_map.reshape(-1)))
        return center_anchors, edge_anchors, anchor_areas


class OctConv(nn.Conv2d):
    """
    Octave convolution layer.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 1
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    oct_alpha : float, default 0.0
        Octave alpha coefficient.
    oct_mode : str, default 'std'
        Octave convolution mode. It can be 'first', 'norm', 'last', or 'std'.
    oct_value : int, default 2
        Octave value.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding=1, dilation=1, groups=1, bias=False, oct_alpha=0.0,
        oct_mode='std', oct_value=2):
        if isinstance(stride, int):
            stride = stride, stride
        self.downsample = stride[0] > 1 or stride[1] > 1
        assert stride[0] in [1, oct_value] and stride[1] in [1, oct_value]
        stride = 1, 1
        if oct_mode == 'first':
            in_alpha = 0.0
            out_alpha = oct_alpha
        elif oct_mode == 'norm':
            in_alpha = oct_alpha
            out_alpha = oct_alpha
        elif oct_mode == 'last':
            in_alpha = oct_alpha
            out_alpha = 0.0
        elif oct_mode == 'std':
            in_alpha = 0.0
            out_alpha = 0.0
        else:
            raise ValueError('Unsupported octave convolution mode: {}'.
                format(oct_mode))
        self.h_in_channels = int(in_channels * (1.0 - in_alpha))
        self.h_out_channels = int(out_channels * (1.0 - out_alpha))
        self.l_out_channels = out_channels - self.h_out_channels
        self.oct_alpha = oct_alpha
        self.oct_mode = oct_mode
        self.oct_value = oct_value
        super(OctConv, self).__init__(in_channels=in_channels, out_channels
            =out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, dilation=dilation, groups=groups, bias=bias)
        self.conv_kwargs = {'stride': stride, 'padding': padding,
            'dilation': dilation, 'groups': groups}

    def forward(self, hx, lx=None):
        if self.oct_mode == 'std':
            return F.conv2d(input=hx, weight=self.weight, bias=self.bias,
                **self.conv_kwargs), None
        if self.downsample:
            hx = F.avg_pool2d(input=hx, kernel_size=(self.oct_value, self.
                oct_value), stride=(self.oct_value, self.oct_value))
        hhy = F.conv2d(input=hx, weight=self.weight[0:self.h_out_channels, 
            0:self.h_in_channels, :, :], bias=self.bias[0:self.
            h_out_channels] if self.bias is not None else None, **self.
            conv_kwargs)
        if self.oct_mode != 'first':
            hlx = F.conv2d(input=lx, weight=self.weight[0:self.
                h_out_channels, self.h_in_channels:, :, :], bias=self.bias[
                0:self.h_out_channels] if self.bias is not None else None,
                **self.conv_kwargs)
        if self.oct_mode == 'last':
            hy = hhy + hlx
            ly = None
            return hy, ly
        lhx = F.avg_pool2d(input=hx, kernel_size=(self.oct_value, self.
            oct_value), stride=(self.oct_value, self.oct_value))
        lhy = F.conv2d(input=lhx, weight=self.weight[self.h_out_channels:, 
            0:self.h_in_channels, :, :], bias=self.bias[self.h_out_channels
            :] if self.bias is not None else None, **self.conv_kwargs)
        if self.oct_mode == 'first':
            hy = hhy
            ly = lhy
            return hy, ly
        if self.downsample:
            hly = hlx
            llx = F.avg_pool2d(input=lx, kernel_size=(self.oct_value, self.
                oct_value), stride=(self.oct_value, self.oct_value))
        else:
            hly = F.interpolate(input=hlx, scale_factor=self.oct_value,
                mode='nearest')
            llx = lx
        lly = F.conv2d(input=llx, weight=self.weight[self.h_out_channels:,
            self.h_in_channels:, :, :], bias=self.bias[self.h_out_channels:
            ] if self.bias is not None else None, **self.conv_kwargs)
        hy = hhy + hly
        ly = lhy + lly
        return hy, ly


class OctConvBlock(nn.Module):
    """
    Octave convolution block with Batch normalization and ReLU/ReLU6 activation.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    oct_alpha : float, default 0.0
        Octave alpha coefficient.
    oct_mode : str, default 'std'
        Octave convolution mode. It can be 'first', 'norm', 'last', or 'std'.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function or name of activation function.
    activate : bool, default True
        Whether activate the convolution block.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, dilation=1, groups=1, bias=False, oct_alpha=0.0, oct_mode=
        'std', bn_eps=1e-05, activation=lambda : nn.ReLU(inplace=True),
        activate=True):
        super(OctConvBlock, self).__init__()
        self.activate = activate
        self.last = oct_mode == 'last' or oct_mode == 'std'
        out_alpha = 0.0 if self.last else oct_alpha
        h_out_channels = int(out_channels * (1.0 - out_alpha))
        l_out_channels = out_channels - h_out_channels
        self.conv = OctConv(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, dilation=dilation, groups=groups, bias=bias, oct_alpha
            =oct_alpha, oct_mode=oct_mode)
        self.h_bn = nn.BatchNorm2d(num_features=h_out_channels, eps=bn_eps)
        if not self.last:
            self.l_bn = nn.BatchNorm2d(num_features=l_out_channels, eps=bn_eps)
        if self.activate:
            assert activation is not None
            if isfunction(activation):
                self.activ = activation()
            elif isinstance(activation, str):
                if activation == 'relu':
                    self.activ = nn.ReLU(inplace=True)
                elif activation == 'relu6':
                    self.activ = nn.ReLU6(inplace=True)
                else:
                    raise NotImplementedError()
            else:
                self.activ = activation

    def forward(self, hx, lx=None):
        hx, lx = self.conv(hx, lx)
        hx = self.h_bn(hx)
        if self.activate:
            hx = self.activ(hx)
        if not self.last:
            lx = self.l_bn(lx)
            if self.activate:
                lx = self.activ(lx)
        return hx, lx


def oct_conv3x3_block(in_channels, out_channels, stride=1, padding=1,
    dilation=1, groups=1, bias=False, oct_alpha=0.0, oct_mode='std', bn_eps
    =1e-05, activation=lambda : nn.ReLU(inplace=True), activate=True):
    """
    3x3 version of the octave convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 1
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    oct_alpha : float, default 0.0
        Octave alpha coefficient.
    oct_mode : str, default 'std'
        Octave convolution mode. It can be 'first', 'norm', 'last', or 'std'.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function or name of activation function.
    activate : bool, default True
        Whether activate the convolution block.
    """
    return OctConvBlock(in_channels=in_channels, out_channels=out_channels,
        kernel_size=3, stride=stride, padding=padding, dilation=dilation,
        groups=groups, bias=bias, oct_alpha=oct_alpha, oct_mode=oct_mode,
        bn_eps=bn_eps, activation=activation, activate=activate)


class OctResBlock(nn.Module):
    """
    Simple Oct-ResNet block for residual path in Oct-ResNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    oct_alpha : float, default 0.0
        Octave alpha coefficient.
    oct_mode : str, default 'std'
        Octave convolution mode. It can be 'first', 'norm', 'last', or 'std'.
    """

    def __init__(self, in_channels, out_channels, stride, oct_alpha=0.0,
        oct_mode='std'):
        super(OctResBlock, self).__init__()
        self.conv1 = oct_conv3x3_block(in_channels=in_channels,
            out_channels=out_channels, stride=stride, oct_alpha=oct_alpha,
            oct_mode=oct_mode)
        self.conv2 = oct_conv3x3_block(in_channels=out_channels,
            out_channels=out_channels, oct_alpha=oct_alpha, oct_mode='std' if
            oct_mode == 'last' else oct_mode if oct_mode != 'first' else
            'norm', activation=None, activate=False)

    def forward(self, hx, lx=None):
        hx, lx = self.conv1(hx, lx)
        hx, lx = self.conv2(hx, lx)
        return hx, lx


def oct_conv1x1_block(in_channels, out_channels, stride=1, groups=1, bias=
    False, oct_alpha=0.0, oct_mode='std', bn_eps=1e-05, activation=lambda :
    nn.ReLU(inplace=True), activate=True):
    """
    1x1 version of the octave convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    oct_alpha : float, default 0.0
        Octave alpha coefficient.
    oct_mode : str, default 'std'
        Octave convolution mode. It can be 'first', 'norm', 'last', or 'std'.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function or name of activation function.
    activate : bool, default True
        Whether activate the convolution block.
    """
    return OctConvBlock(in_channels=in_channels, out_channels=out_channels,
        kernel_size=1, stride=stride, padding=0, groups=groups, bias=bias,
        oct_alpha=oct_alpha, oct_mode=oct_mode, bn_eps=bn_eps, activation=
        activation, activate=activate)


class OctResBottleneck(nn.Module):
    """
    Oct-ResNet bottleneck block for residual path in Oct-ResNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 1
        Padding value for the second convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for the second convolution layer.
    oct_alpha : float, default 0.0
        Octave alpha coefficient.
    oct_mode : str, default 'std'
        Octave convolution mode. It can be 'first', 'norm', 'last', or 'std'.
    conv1_stride : bool, default False
        Whether to use stride in the first or the second convolution layer of the block.
    bottleneck_factor : int, default 4
        Bottleneck factor.
    """

    def __init__(self, in_channels, out_channels, stride, padding=1,
        dilation=1, oct_alpha=0.0, oct_mode='std', conv1_stride=False,
        bottleneck_factor=4):
        super(OctResBottleneck, self).__init__()
        mid_channels = out_channels // bottleneck_factor
        self.conv1 = oct_conv1x1_block(in_channels=in_channels,
            out_channels=mid_channels, stride=stride if conv1_stride else 1,
            oct_alpha=oct_alpha, oct_mode=oct_mode if oct_mode != 'last' else
            'norm')
        self.conv2 = oct_conv3x3_block(in_channels=mid_channels,
            out_channels=mid_channels, stride=1 if conv1_stride else stride,
            padding=padding, dilation=dilation, oct_alpha=oct_alpha,
            oct_mode=oct_mode if oct_mode != 'first' else 'norm')
        self.conv3 = oct_conv1x1_block(in_channels=mid_channels,
            out_channels=out_channels, oct_alpha=oct_alpha, oct_mode='std' if
            oct_mode == 'last' else oct_mode if oct_mode != 'first' else
            'norm', activation=None, activate=False)

    def forward(self, hx, lx=None):
        hx, lx = self.conv1(hx, lx)
        hx, lx = self.conv2(hx, lx)
        hx, lx = self.conv3(hx, lx)
        return hx, lx


class OctResUnit(nn.Module):
    """
    Oct-ResNet unit with residual connection.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 1
        Padding value for the second convolution layer in bottleneck.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for the second convolution layer in bottleneck.
    oct_alpha : float, default 0.0
        Octave alpha coefficient.
    oct_mode : str, default 'std'
        Octave convolution mode. It can be 'first', 'norm', 'last', or 'std'.
    bottleneck : bool, default True
        Whether to use a bottleneck or simple block in units.
    conv1_stride : bool, default False
        Whether to use stride in the first or the second convolution layer of the block.
    """

    def __init__(self, in_channels, out_channels, stride, padding=1,
        dilation=1, oct_alpha=0.0, oct_mode='std', bottleneck=True,
        conv1_stride=False):
        super(OctResUnit, self).__init__()
        self.resize_identity = (in_channels != out_channels or stride != 1 or
            oct_mode == 'first' and oct_alpha != 0.0)
        if bottleneck:
            self.body = OctResBottleneck(in_channels=in_channels,
                out_channels=out_channels, stride=stride, padding=padding,
                dilation=dilation, oct_alpha=oct_alpha, oct_mode=oct_mode,
                conv1_stride=conv1_stride)
        else:
            self.body = OctResBlock(in_channels=in_channels, out_channels=
                out_channels, stride=stride, oct_alpha=oct_alpha, oct_mode=
                oct_mode)
        if self.resize_identity:
            self.identity_conv = oct_conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride, oct_alpha=
                oct_alpha, oct_mode=oct_mode, activation=None, activate=False)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, hx, lx=None):
        if self.resize_identity:
            h_identity, l_identity = self.identity_conv(hx, lx)
        else:
            h_identity, l_identity = hx, lx
        hx, lx = self.body(hx, lx)
        hx = hx + h_identity
        hx = self.activ(hx)
        if lx is not None:
            lx = lx + l_identity
            lx = self.activ(lx)
        return hx, lx


class OctResNet(nn.Module):
    """
    Oct-ResNet model from 'Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave
    Convolution,' https://arxiv.org/abs/1904.05049.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    conv1_stride : bool
        Whether to use stride in the first or the second convolution layer in units.
    oct_alpha : float, default 0.5
        Octave alpha coefficient.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, bottleneck,
        conv1_stride, oct_alpha=0.5, in_channels=3, in_size=(224, 224),
        num_classes=1000):
        super(OctResNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = DualPathSequential(return_two=False, first_ordinals
            =1, last_ordinals=1)
        self.features.add_module('init_block', ResInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = DualPathSequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                if i == 0 and j == 0:
                    oct_mode = 'first'
                elif i == len(channels) - 1 and j == 0:
                    oct_mode = 'last'
                elif i == len(channels) - 1 and j != 0:
                    oct_mode = 'std'
                else:
                    oct_mode = 'norm'
                stage.add_module('unit{}'.format(j + 1), OctResUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, oct_alpha=oct_alpha, oct_mode=oct_mode,
                    bottleneck=bottleneck, conv1_stride=conv1_stride))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class ConvBNReLU(nn.Module):

    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1,
        padding=1):
        super(ConvBNReLU, self).__init__()
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, bias=False)
        self.bn = nn.BatchNorm2d(out_channels)

    def forward(self, x):
        x = self.conv(x)
        x = F.relu(self.bn(x))
        return x


class BasicBlock(nn.Module):

    def __init__(self, in_channels, out_channels, stride=1):
        super(BasicBlock, self).__init__()
        self.conv1 = conv3x3(in_channels, out_channels, stride)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = conv3x3(out_channels, out_channels)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = None
        if in_channels != out_channels or stride != 1:
            self.downsample = nn.Sequential(nn.Conv2d(in_channels,
                out_channels, kernel_size=1, stride=stride, bias=False), nn
                .BatchNorm2d(out_channels))

    def forward(self, x):
        residual = self.conv1(x)
        residual = F.relu(self.bn1(residual))
        residual = self.conv2(residual)
        residual = self.bn2(residual)
        shortcut = x
        if self.downsample is not None:
            shortcut = self.downsample(x)
        out = shortcut + residual
        out = self.relu(out)
        return out


class Resnet18(nn.Module):

    def __init__(self):
        super(Resnet18, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,
            bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self.create_layer_basic(64, 64, bnum=2, stride=1)
        self.layer2 = self.create_layer_basic(64, 128, bnum=2, stride=2)
        self.layer3 = self.create_layer_basic(128, 256, bnum=2, stride=2)
        self.layer4 = self.create_layer_basic(256, 512, bnum=2, stride=2)

    @staticmethod
    def create_layer_basic(in_chan, out_chan, bnum, stride=1):
        layers = [BasicBlock(in_chan, out_chan, stride=stride)]
        for i in range(bnum - 1):
            layers.append(BasicBlock(out_chan, out_chan, stride=1))
        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.conv1(x)
        x = F.relu(self.bn1(x))
        x = self.maxpool(x)
        x = self.layer1(x)
        feat8 = self.layer2(x)
        feat16 = self.layer3(feat8)
        feat32 = self.layer4(feat16)
        return feat8, feat16, feat32


class AttentionRefinementModule(nn.Module):

    def __init__(self, in_channels, out_channels):
        super(AttentionRefinementModule, self).__init__()
        self.conv = ConvBNReLU(in_channels=in_channels, out_channels=
            out_channels, kernel_size=3, stride=1, padding=1)
        self.pool = nn.AdaptiveAvgPool2d(1)
        self.conv_atten = nn.Conv2d(in_channels=out_channels, out_channels=
            out_channels, kernel_size=1, bias=False)
        self.bn_atten = nn.BatchNorm2d(out_channels)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.conv(x)
        w = self.pool(x)
        w = self.conv_atten(w)
        w = self.bn_atten(w)
        w = self.sigmoid(w)
        x = x * w
        return x


class ContextPath(nn.Module):

    def __init__(self):
        super(ContextPath, self).__init__()
        self.resnet = Resnet18()
        self.arm16 = AttentionRefinementModule(256, 128)
        self.arm32 = AttentionRefinementModule(512, 128)
        self.conv_head32 = ConvBNReLU(128, 128, kernel_size=3, stride=1,
            padding=1)
        self.conv_head16 = ConvBNReLU(128, 128, kernel_size=3, stride=1,
            padding=1)
        self.conv_avg = ConvBNReLU(512, 128, kernel_size=1, stride=1, padding=0
            )
        self.pool = nn.AdaptiveAvgPool2d(1)

    def forward(self, x):
        feat8, feat16, feat32 = self.resnet(x)
        H8, W8 = feat8.size()[2:]
        H16, W16 = feat16.size()[2:]
        H32, W32 = feat32.size()[2:]
        avg = self.pool(feat32)
        avg = self.conv_avg(avg)
        avg_up = F.interpolate(avg, (H32, W32), mode='nearest')
        feat32_arm = self.arm32(feat32)
        feat32_sum = feat32_arm + avg_up
        feat32_up = F.interpolate(feat32_sum, (H16, W16), mode='nearest')
        feat32_up = self.conv_head32(feat32_up)
        feat16_arm = self.arm16(feat16)
        feat16_sum = feat16_arm + feat32_up
        feat16_up = F.interpolate(feat16_sum, (H8, W8), mode='nearest')
        feat16_up = self.conv_head16(feat16_up)
        return feat8, feat16_up, feat32_up


class FeatureFusionModule(nn.Module):

    def __init__(self, in_channels, out_channels):
        super(FeatureFusionModule, self).__init__()
        self.convblk = ConvBNReLU(in_channels, out_channels, kernel_size=1,
            stride=1, padding=0)
        self.pool = nn.AdaptiveAvgPool2d(1)
        self.conv1 = nn.Conv2d(out_channels, out_channels // 4, kernel_size
            =1, stride=1, padding=0, bias=False)
        self.conv2 = nn.Conv2d(out_channels // 4, out_channels, kernel_size
            =1, stride=1, padding=0, bias=False)
        self.relu = nn.ReLU(inplace=True)
        self.sigmoid = nn.Sigmoid()

    def forward(self, fsp, fcp):
        fcat = torch.cat([fsp, fcp], dim=1)
        feat = self.convblk(fcat)
        atten = self.pool(feat)
        atten = self.conv1(atten)
        atten = self.relu(atten)
        atten = self.conv2(atten)
        atten = self.sigmoid(atten)
        feat_atten = torch.mul(feat, atten)
        feat_out = feat_atten + feat
        return feat_out


class BiSeNetOutput(nn.Module):

    def __init__(self, in_channels, mid_channels, out_channels):
        super(BiSeNetOutput, self).__init__()
        self.conv = ConvBNReLU(in_channels, mid_channels, kernel_size=3,
            stride=1, padding=1)
        self.conv_out = nn.Conv2d(mid_channels, out_channels, kernel_size=1,
            bias=False)

    def forward(self, x):
        x = self.conv(x)
        x = self.conv_out(x)
        return x


class BiSeNet(nn.Module):

    def __init__(self, num_classes=19):
        super(BiSeNet, self).__init__()
        self.num_classes = num_classes
        self.cp = ContextPath()
        self.ffm = FeatureFusionModule(256, 256)
        self.conv_out = BiSeNetOutput(256, 256, num_classes)
        self.conv_out16 = BiSeNetOutput(128, 64, num_classes)
        self.conv_out32 = BiSeNetOutput(128, 64, num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                nn.init.kaiming_normal_(module.weight, a=1)
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)

    def forward(self, x):
        H, W = x.size()[2:]
        feat_res8, feat_cp8, feat_cp16 = self.cp(x)
        feat_sp = feat_res8
        feat_fuse = self.ffm(feat_sp, feat_cp8)
        feat_out = self.conv_out(feat_fuse)
        feat_out16 = self.conv_out16(feat_cp8)
        feat_out32 = self.conv_out32(feat_cp16)
        feat_out = F.interpolate(feat_out, size=(H, W), mode='bilinear',
            align_corners=True)
        feat_out16 = F.interpolate(feat_out16, size=(H, W), mode='bilinear',
            align_corners=True)
        feat_out32 = F.interpolate(feat_out32, size=(H, W), mode='bilinear',
            align_corners=True)
        return feat_out, feat_out16, feat_out32


class Residual(nn.Module):
    """Residual Block modified by us"""

    def __init__(self, ins, outs, bn=True, relu=True):
        super(Residual, self).__init__()
        self.relu_flag = relu
        self.convBlock = nn.Sequential(nn.Conv2d(ins, outs // 2, 1, bias=
            False), nn.BatchNorm2d(outs // 2), nn.LeakyReLU(negative_slope=
            0.01, inplace=True), nn.Conv2d(outs // 2, outs // 2, 3, 1, 1,
            bias=False), nn.BatchNorm2d(outs // 2), nn.LeakyReLU(
            negative_slope=0.01, inplace=True), nn.Conv2d(outs // 2, outs, 
            1, bias=False), nn.BatchNorm2d(outs))
        if ins != outs:
            self.skipConv = nn.Sequential(nn.Conv2d(ins, outs, 1, bias=
                False), nn.BatchNorm2d(outs))
        self.relu = nn.LeakyReLU(negative_slope=0.01, inplace=True)
        self.ins = ins
        self.outs = outs

    def forward(self, x):
        residual = x
        x = self.convBlock(x)
        if self.ins != self.outs:
            residual = self.skipConv(residual)
        x += residual
        if self.relu_flag:
            x = self.relu(x)
            return x
        else:
            return x


class Conv(nn.Module):

    def __init__(self, inp_dim, out_dim, kernel_size=3, stride=1, bn=True,
        relu=True, dropout=False, dialated=1):
        super(Conv, self).__init__()
        self.inp_dim = inp_dim
        self.relu = None
        self.bn = None
        self.dropout = dropout
        if relu:
            self.relu = nn.LeakyReLU(negative_slope=0.01, inplace=True)
        if bn:
            self.conv = nn.Conv2d(inp_dim, out_dim, kernel_size, stride,
                padding=(kernel_size - 1) // 2, bias=False, dilation=1)
            self.bn = nn.BatchNorm2d(out_dim)
        else:
            self.conv = nn.Conv2d(inp_dim, out_dim, kernel_size, stride,
                padding=(kernel_size - 1) // 2, bias=True, dilation=1)

    def forward(self, x):
        assert x.size()[1
            ] == self.inp_dim, 'input channel {} dese not fit kernel channel {}'.format(
            x.size()[1], self.inp_dim)
        if self.dropout:
            x = F.dropout(x, p=0.2, training=self.training, inplace=False)
        x = self.conv(x)
        if self.bn is not None:
            x = self.bn(x)
        if self.relu is not None:
            x = self.relu(x)
        return x


class DilatedConv(nn.Module):
    """
    Dilated convolutional layer of stride=1 only!
    """

    def __init__(self, inp_dim, out_dim, kernel_size=3, stride=1, bn=True,
        relu=True, dropout=False, dialation=3):
        super(DilatedConv, self).__init__()
        self.inp_dim = inp_dim
        self.relu = None
        self.bn = None
        self.dropout = dropout
        if relu:
            self.relu = nn.LeakyReLU(negative_slope=0.01, inplace=True)
        if bn:
            self.conv = nn.Conv2d(inp_dim, out_dim, kernel_size, stride,
                padding=dialation, bias=False, dilation=dialation)
            self.bn = nn.BatchNorm2d(out_dim)
        else:
            self.conv = nn.Conv2d(inp_dim, out_dim, kernel_size, stride,
                padding=dialation, bias=True, dilation=dialation)

    def forward(self, x):
        assert x.size()[1
            ] == self.inp_dim, 'input channel {} dese not fit kernel channel {}'.format(
            x.size()[1], self.inp_dim)
        if self.dropout:
            x = F.dropout(x, p=0.2, training=self.training, inplace=False)
        x = self.conv(x)
        if self.bn is not None:
            x = self.bn(x)
        if self.relu is not None:
            x = self.relu(x)
        return x


class Backbone(nn.Module):
    """
    Input Tensor: a batch of images with shape (N, C, H, W)
    """

    def __init__(self, nFeat=256, inplanes=3, resBlock=Residual,
        dilatedBlock=DilatedConv):
        super(Backbone, self).__init__()
        self.nFeat = nFeat
        self.resBlock = resBlock
        self.inplanes = inplanes
        self.conv1 = nn.Conv2d(self.inplanes, 64, kernel_size=7, stride=2,
            padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.LeakyReLU(negative_slope=0.01, inplace=True)
        self.res1 = self.resBlock(64, 128)
        self.pool = nn.MaxPool2d(2, 2)
        self.res2 = self.resBlock(128, 128)
        self.dilation = nn.Sequential(dilatedBlock(128, 128, dialation=3),
            dilatedBlock(128, 128, dialation=3), dilatedBlock(128, 128,
            dialation=4), dilatedBlock(128, 128, dialation=4), dilatedBlock
            (128, 128, dialation=5), dilatedBlock(128, 128, dialation=5))

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.res1(x)
        x = self.pool(x)
        x = self.res2(x)
        x1 = self.dilation(x)
        concat_merge = torch.cat([x, x1], dim=1)
        return concat_merge


class Hourglass(nn.Module):
    """Instantiate an n order Hourglass Network block using recursive trick."""

    def __init__(self, depth, nFeat, increase=128, bn=False, resBlock=
        Residual, convBlock=Conv):
        super(Hourglass, self).__init__()
        self.depth = depth
        self.nFeat = nFeat
        self.increase = increase
        self.bn = bn
        self.resBlock = resBlock
        self.convBlock = convBlock
        self.hg = self._make_hour_glass()
        self.downsample = nn.MaxPool2d(2, 2)
        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')

    def _make_single_residual(self, depth_id):
        return self.resBlock(self.nFeat + self.increase * (depth_id + 1), 
            self.nFeat + self.increase * (depth_id + 1), bn=self.bn)

    def _make_lower_residual(self, depth_id):
        pack_layers = [self.resBlock(self.nFeat + self.increase * depth_id,
            self.nFeat + self.increase * depth_id, bn=self.bn), self.
            resBlock(self.nFeat + self.increase * depth_id, self.nFeat + 
            self.increase * (depth_id + 1), bn=self.bn), self.resBlock(self
            .nFeat + self.increase * (depth_id + 1), self.nFeat + self.
            increase * depth_id, bn=self.bn), self.convBlock(self.nFeat + 
            self.increase * depth_id, self.nFeat + self.increase * depth_id,
            bn=self.bn)]
        return pack_layers

    def _make_hour_glass(self):
        """
        pack conve layers modules of hourglass block
        :return: conve layers packed in n hourglass blocks
        """
        hg = []
        for i in range(self.depth):
            res = self._make_lower_residual(i)
            if i == self.depth - 1:
                res.append(self._make_single_residual(i))
            hg.append(nn.ModuleList(res))
        return nn.ModuleList(hg)

    def _hour_glass_forward(self, depth_id, x, up_fms):
        """
        built an hourglass block whose order is depth_id
        :param depth_id: oder number of hourglass block
        :param x: input tensor
        :return: output tensor through an hourglass block
        """
        up1 = self.hg[depth_id][0](x)
        low1 = self.downsample(x)
        low1 = self.hg[depth_id][1](low1)
        if depth_id == self.depth - 1:
            low2 = self.hg[depth_id][4](low1)
        else:
            low2 = self._hour_glass_forward(depth_id + 1, low1, up_fms)
        low3 = self.hg[depth_id][2](low2)
        up_fms.append(low2)
        up2 = self.upsample(low3)
        deconv1 = self.hg[depth_id][3](up2)
        return up1 + deconv1

    def forward(self, x):
        """
        :param: x a input tensor warpped wrapped as a list
        :return: 5 different scales of feature maps, 128*128, 64*64, 32*32, 16*16, 8*8
        """
        up_fms = []
        feature_map = self._hour_glass_forward(0, x, up_fms)
        return [feature_map] + up_fms[::-1]


class SELayer(nn.Module):

    def __init__(self, inp_dim, reduction=16):
        """
        Squeeze and Excitation
        :param inp_dim: the channel of input tensor
        :param reduction: channel compression ratio
        :return output the tensor with the same shape of input
        """
        super(SELayer, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(nn.Linear(inp_dim, inp_dim // reduction),
            nn.LeakyReLU(inplace=True), nn.Linear(inp_dim // reduction,
            inp_dim), nn.Sigmoid())

    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return x * y


class Merge(nn.Module):
    """Change the channel dimension of the input tensor"""

    def __init__(self, x_dim, y_dim, bn=False):
        super(Merge, self).__init__()
        self.conv = Conv(x_dim, y_dim, 1, relu=False, bn=bn)

    def forward(self, x):
        return self.conv(x)


class Features(nn.Module):
    """Input: feature maps produced by hourglass block
       Return: 5 different scales of feature maps, 128*128, 64*64, 32*32, 16*16, 8*8"""

    def __init__(self, inp_dim, increase=128, bn=False):
        super(Features, self).__init__()
        self.before_regress = nn.ModuleList([nn.Sequential(Conv(inp_dim + i *
            increase, inp_dim, 3, bn=bn, dropout=False), Conv(inp_dim,
            inp_dim, 3, bn=bn, dropout=False), SELayer(inp_dim)) for i in
            range(5)])

    def forward(self, fms):
        assert len(fms
            ) == 5, 'hourglass output {} tensors,but 5 scale heatmaps are supervised'.format(
            len(fms))
        return [self.before_regress[i](fms[i]) for i in range(5)]


class PoseNet(nn.Module):

    def __init__(self, nstack, inp_dim, oup_dim, bn=False, increase=128,
        init_weights=True, **kwargs):
        """
        Pack or initialize the trainable parameters of the network
        :param nstack: number of stack
        :param inp_dim: input tensor channels fed into the hourglass block
        :param oup_dim: channels of regressed feature maps
        :param bn: use batch normalization
        :param increase: increased channels once down-sampling
        :param kwargs:
        """
        super(PoseNet, self).__init__()
        self.pre = Backbone(nFeat=inp_dim)
        self.hourglass = nn.ModuleList([Hourglass(4, inp_dim, increase, bn=
            bn) for _ in range(nstack)])
        self.features = nn.ModuleList([Features(inp_dim, increase=increase,
            bn=bn) for _ in range(nstack)])
        self.outs = nn.ModuleList([nn.ModuleList([Conv(inp_dim, oup_dim, 1,
            relu=False, bn=False) for j in range(5)]) for i in range(nstack)])
        self.merge_features = nn.ModuleList([nn.ModuleList([Merge(inp_dim, 
            inp_dim + j * increase, bn=bn) for j in range(5)]) for i in
            range(nstack - 1)])
        self.merge_preds = nn.ModuleList([nn.ModuleList([Merge(oup_dim, 
            inp_dim + j * increase, bn=bn) for j in range(5)]) for i in
            range(nstack - 1)])
        self.nstack = nstack
        if init_weights:
            self._initialize_weights()

    def forward(self, imgs):
        x = imgs
        x = self.pre(x)
        pred = []
        for i in range(self.nstack):
            preds_instack = []
            hourglass_feature = self.hourglass[i](x)
            if i == 0:
                features_cache = [torch.zeros_like(hourglass_feature[scale]
                    ) for scale in range(5)]
            else:
                hourglass_feature = [(hourglass_feature[scale] +
                    features_cache[scale]) for scale in range(5)]
            features_instack = self.features[i](hourglass_feature)
            for j in range(5):
                preds_instack.append(self.outs[i][j](features_instack[j]))
                if i != self.nstack - 1:
                    if j == 0:
                        x = x + self.merge_preds[i][j](preds_instack[j]
                            ) + self.merge_features[i][j](features_instack[j])
                        features_cache[j] = self.merge_preds[i][j](
                            preds_instack[j]) + self.merge_features[i][j](
                            features_instack[j])
                    else:
                        features_cache[j] = self.merge_preds[i][j](
                            preds_instack[j]) + self.merge_features[i][j](
                            features_instack[j])
            pred.append(preds_instack)
        return pred[-1][0]

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                m.weight.data.normal_(0, 0.001)
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()
            elif isinstance(m, nn.Linear):
                torch.nn.init.normal_(m.weight.data, 0, 0.01)
                m.bias.data.zero_()


class Residual(nn.Module):
    """Residual Block modified by us"""

    def __init__(self, ins, outs, bn=True, relu=True):
        super(Residual, self).__init__()
        self.relu_flag = relu
        self.convBlock = nn.Sequential(nn.Conv2d(ins, outs // 2, 1, bias=
            False), nn.BatchNorm2d(outs // 2), nn.LeakyReLU(negative_slope=
            0.01, inplace=True), nn.Conv2d(outs // 2, outs // 2, 3, 1, 1,
            bias=False), nn.BatchNorm2d(outs // 2), nn.LeakyReLU(
            negative_slope=0.01, inplace=True), nn.Conv2d(outs // 2, outs, 
            1, bias=False), nn.BatchNorm2d(outs))
        if ins != outs:
            self.skipConv = nn.Sequential(nn.Conv2d(ins, outs, 1, bias=
                False), nn.BatchNorm2d(outs))
        self.relu = nn.LeakyReLU(negative_slope=0.01, inplace=True)
        self.ins = ins
        self.outs = outs

    def forward(self, x):
        residual = x
        x = self.convBlock(x)
        if self.ins != self.outs:
            residual = self.skipConv(residual)
        x += residual
        if self.relu_flag:
            x = self.relu(x)
            return x
        else:
            return x


class Conv(nn.Module):

    def __init__(self, inp_dim, out_dim, kernel_size=3, stride=1, bn=True,
        relu=True, dropout=False, dialated=1):
        super(Conv, self).__init__()
        self.inp_dim = inp_dim
        self.relu = None
        self.bn = None
        self.dropout = dropout
        if relu:
            self.relu = nn.LeakyReLU(negative_slope=0.01, inplace=True)
        if bn:
            self.conv = nn.Conv2d(inp_dim, out_dim, kernel_size, stride,
                padding=(kernel_size - 1) // 2, bias=False, dilation=1)
            self.bn = nn.BatchNorm2d(out_dim)
        else:
            self.conv = nn.Conv2d(inp_dim, out_dim, kernel_size, stride,
                padding=(kernel_size - 1) // 2, bias=True, dilation=1)

    def forward(self, x):
        assert x.size()[1
            ] == self.inp_dim, 'input channel {} dese not fit kernel channel {}'.format(
            x.size()[1], self.inp_dim)
        if self.dropout:
            x = F.dropout(x, p=0.2, training=self.training, inplace=False)
        x = self.conv(x)
        if self.bn is not None:
            x = self.bn(x)
        if self.relu is not None:
            x = self.relu(x)
        return x


class DilatedConv(nn.Module):
    """
    Dilated convolutional layer of stride=1 only!
    """

    def __init__(self, inp_dim, out_dim, kernel_size=3, stride=1, bn=True,
        relu=True, dropout=False, dialation=3):
        super(DilatedConv, self).__init__()
        self.inp_dim = inp_dim
        self.relu = None
        self.bn = None
        self.dropout = dropout
        if relu:
            self.relu = nn.LeakyReLU(negative_slope=0.01, inplace=True)
        if bn:
            self.conv = nn.Conv2d(inp_dim, out_dim, kernel_size, stride,
                padding=dialation, bias=False, dilation=dialation)
            self.bn = nn.BatchNorm2d(out_dim)
        else:
            self.conv = nn.Conv2d(inp_dim, out_dim, kernel_size, stride,
                padding=dialation, bias=True, dilation=dialation)

    def forward(self, x):
        assert x.size()[1
            ] == self.inp_dim, 'input channel {} dese not fit kernel channel {}'.format(
            x.size()[1], self.inp_dim)
        if self.dropout:
            x = F.dropout(x, p=0.2, training=self.training, inplace=False)
        x = self.conv(x)
        if self.bn is not None:
            x = self.bn(x)
        if self.relu is not None:
            x = self.relu(x)
        return x


class Backbone(nn.Module):
    """
    Input Tensor: a batch of images with shape (N, C, H, W)
    """

    def __init__(self, nFeat=256, inplanes=3, resBlock=Residual,
        dilatedBlock=DilatedConv):
        super(Backbone, self).__init__()
        self.nFeat = nFeat
        self.resBlock = resBlock
        self.inplanes = inplanes
        self.conv1 = nn.Conv2d(self.inplanes, 64, kernel_size=7, stride=2,
            padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.LeakyReLU(negative_slope=0.01, inplace=True)
        self.res1 = self.resBlock(64, 128)
        self.pool = nn.MaxPool2d(2, 2)
        self.res2 = self.resBlock(128, 128)
        self.dilation = nn.Sequential(dilatedBlock(128, 128, dialation=3),
            dilatedBlock(128, 128, dialation=3), dilatedBlock(128, 128,
            dialation=4), dilatedBlock(128, 128, dialation=4), dilatedBlock
            (128, 128, dialation=5), dilatedBlock(128, 128, dialation=5))

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.res1(x)
        x = self.pool(x)
        x = self.res2(x)
        x1 = self.dilation(x)
        concat_merge = torch.cat([x, x1], dim=1)
        return concat_merge


class Hourglass(nn.Module):
    """Instantiate an n order Hourglass Network block using recursive trick."""

    def __init__(self, depth, nFeat, increase=128, bn=False, resBlock=
        Residual, convBlock=Conv):
        super(Hourglass, self).__init__()
        self.depth = depth
        self.nFeat = nFeat
        self.increase = increase
        self.bn = bn
        self.resBlock = resBlock
        self.convBlock = convBlock
        self.hg = self._make_hour_glass()
        self.downsample = nn.MaxPool2d(2, 2)
        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')

    def _make_single_residual(self, depth_id):
        return self.resBlock(self.nFeat + self.increase * (depth_id + 1), 
            self.nFeat + self.increase * (depth_id + 1), bn=self.bn)

    def _make_lower_residual(self, depth_id):
        pack_layers = [self.resBlock(self.nFeat + self.increase * depth_id,
            self.nFeat + self.increase * depth_id, bn=self.bn), self.
            resBlock(self.nFeat + self.increase * depth_id, self.nFeat + 
            self.increase * (depth_id + 1), bn=self.bn), self.resBlock(self
            .nFeat + self.increase * (depth_id + 1), self.nFeat + self.
            increase * depth_id, bn=self.bn), self.convBlock(self.nFeat + 
            self.increase * depth_id, self.nFeat + self.increase * depth_id,
            bn=self.bn)]
        return pack_layers

    def _make_hour_glass(self):
        """
        pack conve layers modules of hourglass block
        :return: conve layers packed in n hourglass blocks
        """
        hg = []
        for i in range(self.depth):
            res = self._make_lower_residual(i)
            if i == self.depth - 1:
                res.append(self._make_single_residual(i))
            hg.append(nn.ModuleList(res))
        return nn.ModuleList(hg)

    def _hour_glass_forward(self, depth_id, x, up_fms):
        """
        built an hourglass block whose order is depth_id
        :param depth_id: oder number of hourglass block
        :param x: input tensor
        :return: output tensor through an hourglass block
        """
        up1 = self.hg[depth_id][0](x)
        low1 = self.downsample(x)
        low1 = self.hg[depth_id][1](low1)
        if depth_id == self.depth - 1:
            low2 = self.hg[depth_id][4](low1)
        else:
            low2 = self._hour_glass_forward(depth_id + 1, low1, up_fms)
        low3 = self.hg[depth_id][2](low2)
        up_fms.append(low2)
        up2 = self.upsample(low3)
        deconv1 = self.hg[depth_id][3](up2)
        return up1 + deconv1

    def forward(self, x):
        """
        :param: x a input tensor warpped wrapped as a list
        :return: 5 different scales of feature maps, 128*128, 64*64, 32*32, 16*16, 8*8
        """
        up_fms = []
        feature_map = self._hour_glass_forward(0, x, up_fms)
        return [feature_map] + up_fms[::-1]


class SELayer(nn.Module):

    def __init__(self, inp_dim, reduction=16):
        """
        Squeeze and Excitation
        :param inp_dim: the channel of input tensor
        :param reduction: channel compression ratio
        :return output the tensor with the same shape of input
        """
        super(SELayer, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(nn.Linear(inp_dim, inp_dim // reduction),
            nn.LeakyReLU(inplace=True), nn.Linear(inp_dim // reduction,
            inp_dim), nn.Sigmoid())

    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return x * y


class Merge(nn.Module):
    """Change the channel dimension of the input tensor"""

    def __init__(self, x_dim, y_dim, bn=False):
        super(Merge, self).__init__()
        self.conv = Conv(x_dim, y_dim, 1, relu=False, bn=bn)

    def forward(self, x):
        return self.conv(x)


class Features(nn.Module):
    """Input: feature maps produced by hourglass block
       Return: 5 different scales of feature maps, 128*128, 64*64, 32*32, 16*16, 8*8"""

    def __init__(self, inp_dim, increase=128, bn=False):
        super(Features, self).__init__()
        self.before_regress = nn.ModuleList([nn.Sequential(Conv(inp_dim + i *
            increase, inp_dim, 3, bn=bn, dropout=False), Conv(inp_dim,
            inp_dim, 3, bn=bn, dropout=False), SELayer(inp_dim)) for i in
            range(5)])

    def forward(self, fms):
        assert len(fms
            ) == 5, 'hourglass output {} tensors,but 5 scale heatmaps are supervised'.format(
            len(fms))
        return [self.before_regress[i](fms[i]) for i in range(5)]


class PoseNet(nn.Module):

    def __init__(self, nstack, inp_dim, oup_dim, bn=False, increase=128,
        init_weights=True, **kwargs):
        """
        Pack or initialize the trainable parameters of the network
        :param nstack: number of stack
        :param inp_dim: input tensor channels fed into the hourglass block
        :param oup_dim: channels of regressed feature maps
        :param bn: use batch normalization
        :param increase: increased channels once down-sampling
        :param kwargs:
        """
        super(PoseNet, self).__init__()
        self.pre = Backbone(nFeat=inp_dim)
        self.hourglass = nn.ModuleList([Hourglass(4, inp_dim, increase, bn=
            bn) for _ in range(nstack)])
        self.features = nn.ModuleList([Features(inp_dim, increase=increase,
            bn=bn) for _ in range(nstack)])
        self.outs = nn.ModuleList([nn.ModuleList([Conv(inp_dim, oup_dim, 1,
            relu=False, bn=False) for j in range(5)]) for i in range(nstack)])
        self.merge_features = nn.ModuleList([nn.ModuleList([Merge(inp_dim, 
            inp_dim + j * increase, bn=bn) for j in range(5)]) for i in
            range(nstack - 1)])
        self.merge_preds = nn.ModuleList([nn.ModuleList([Merge(oup_dim, 
            inp_dim + j * increase, bn=bn) for j in range(5)]) for i in
            range(nstack - 1)])
        self.nstack = nstack
        if init_weights:
            self._initialize_weights()

    def forward(self, imgs):
        x = imgs
        x = self.pre(x)
        pred = []
        for i in range(self.nstack):
            preds_instack = []
            hourglass_feature = self.hourglass[i](x)
            if i == 0:
                features_cache = [torch.zeros_like(hourglass_feature[scale]
                    ) for scale in range(5)]
            else:
                hourglass_feature = [(hourglass_feature[scale] +
                    features_cache[scale]) for scale in range(5)]
            features_instack = self.features[i](hourglass_feature)
            for j in range(5):
                preds_instack.append(self.outs[i][j](features_instack[j]))
                if i != self.nstack - 1:
                    if j == 0:
                        x = x + self.merge_preds[i][j](preds_instack[j]
                            ) + self.merge_features[i][j](features_instack[j])
                        features_cache[j] = self.merge_preds[i][j](
                            preds_instack[j]) + self.merge_features[i][j](
                            features_instack[j])
                    else:
                        features_cache[j] = self.merge_preds[i][j](
                            preds_instack[j]) + self.merge_features[i][j](
                            features_instack[j])
            pred.append(preds_instack)
        y = pred[-1][0]
        return y

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                m.weight.data.normal_(0, 0.001)
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()
            elif isinstance(m, nn.Linear):
                torch.nn.init.normal_(m.weight.data, 0, 0.01)
                m.bias.data.zero_()


class Resv2Block(nn.Module):
    """ResNet v2 block without bn"""

    def __init__(self, in_channels, out_channels, stride=1, is_branch=False):
        super(Resv2Block, self).__init__()
        self.is_branch = is_branch
        self.relu1 = nn.ReLU()
        self.conv1 = conv3x3(in_channels=in_channels, out_channels=
            out_channels, stride=stride)
        self.relu2 = nn.ReLU()
        self.conv2 = conv3x3(in_channels=out_channels, out_channels=
            out_channels, stride=stride)

    def forward(self, x):
        out_branch = self.relu1(x)
        out = self.conv1(out_branch)
        out = self.relu2(out)
        out = self.conv2(out)
        out += x
        if self.is_branch:
            return out, out_branch
        else:
            return out


class BranchBlock(nn.Module):
    """
    Simple branch block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(BranchBlock, self).__init__()
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            in_channels, bias=True, use_bn=False)
        self.conv2 = conv1x1_block(in_channels=in_channels, out_channels=
            out_channels, bias=True, use_bn=False, activation=None)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class BranchUnit(nn.Module):
    """
    Simple branch unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    mid_channels : int
        Number of middle channels.
    """

    def __init__(self, in_channels, mid_channels):
        super(BranchUnit, self).__init__()
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            mid_channels, bias=True, use_bn=False)
        self.conv_score = BranchBlock(in_channels=mid_channels, out_channels=2)
        self.conv_bbox = BranchBlock(in_channels=mid_channels, out_channels=4)

    def forward(self, x):
        out = self.conv1(x)
        out_score = self.conv_score(out)
        out_bbox = self.conv_bbox(out)
        return out_score, out_bbox


class NaiveNet(nn.Module):
    """NaiveNet for Fast Single Class Object Detection. 
    The entire backbone and branches only consists of conv 33, 
    conv 11, ReLU and residual connection.
    """

    def __init__(self, arch, block, layers):
        super(NaiveNet, self).__init__()
        self.arch = arch
        self.block = block
        num_filters_list = [32, 64, 128, 256]
        if self.arch == 'naivenet20':
            self.conv1 = conv3x3(in_channels=3, out_channels=
                num_filters_list[1], stride=2, padding=0)
            self.relu1 = nn.ReLU()
            self.layer1 = self._make_layer(num_filters_list[1],
                num_filters_list[1], blocks=layers[0])
            self.branch1 = nn.Sequential(BranchUnit(num_filters_list[1],
                num_filters_list[2]))
            self.layer2 = self._make_layer(num_filters_list[1],
                num_filters_list[1], blocks=layers[1])
            self.branch2 = nn.Sequential(BranchUnit(num_filters_list[1],
                num_filters_list[2]))
            self.layer3 = self._make_layer(num_filters_list[1],
                num_filters_list[1], blocks=layers[2])
            self.branch3 = nn.Sequential(BranchUnit(num_filters_list[1],
                num_filters_list[2]))
            self.layer4 = self._make_layer(num_filters_list[1],
                num_filters_list[2], blocks=layers[3])
            self.branch4 = nn.Sequential(BranchUnit(num_filters_list[2],
                num_filters_list[2]))
            self.layer5 = self._make_layer(num_filters_list[2],
                num_filters_list[2], blocks=layers[4])
            self.branch5 = nn.Sequential(BranchUnit(num_filters_list[2],
                num_filters_list[2]))
        elif self.arch == 'naivenet25':
            self.conv1 = conv3x3(in_channels=3, out_channels=
                num_filters_list[1], stride=2, padding=0)
            self.relu1 = nn.ReLU()
            self.stage1_1 = self._make_layer(num_filters_list[1],
                num_filters_list[1], blocks=layers[0] - 1)
            self.stage1_2_branch1 = nn.Sequential(self.block(
                num_filters_list[1], num_filters_list[1], stride=1,
                is_branch=True))
            self.branch1 = nn.Sequential(BranchUnit(num_filters_list[1],
                num_filters_list[2]))
            self.stage1_3_branch2 = nn.Sequential(nn.ReLU())
            self.branch2 = nn.Sequential(BranchUnit(num_filters_list[1],
                num_filters_list[2]))
            self.stage2_1 = nn.Sequential(conv3x3(num_filters_list[1],
                num_filters_list[1], stride=2, padding=0), Resv2Block(
                num_filters_list[1], num_filters_list[1], stride=1,
                is_branch=False))
            self.stage2_2_branch3 = nn.Sequential(Resv2Block(
                num_filters_list[1], num_filters_list[1], stride=1,
                is_branch=True))
            self.branch3 = nn.Sequential(BranchUnit(num_filters_list[1],
                num_filters_list[2]))
            self.stage2_3_branch4 = nn.Sequential(nn.ReLU())
            self.branch4 = nn.Sequential(BranchUnit(num_filters_list[1],
                num_filters_list[2]))
            self.stage3_1 = nn.Sequential(conv3x3(num_filters_list[1],
                num_filters_list[2], stride=2, padding=0), Resv2Block(
                num_filters_list[2], num_filters_list[2], stride=1,
                is_branch=False))
            self.stage3_2_branch5 = nn.Sequential(nn.ReLU())
            self.branch5 = nn.Sequential(BranchUnit(num_filters_list[2],
                num_filters_list[2]))
            self.stage4_1 = nn.Sequential(conv3x3(num_filters_list[2],
                num_filters_list[2], stride=2, padding=0), Resv2Block(
                num_filters_list[2], num_filters_list[2], stride=1,
                is_branch=False))
            self.stage4_2_branch6 = nn.Sequential(Resv2Block(
                num_filters_list[2], num_filters_list[2], stride=1,
                is_branch=True))
            self.branch6 = nn.Sequential(BranchUnit(num_filters_list[2],
                num_filters_list[2]))
            self.stage4_3_branch7 = nn.Sequential(Resv2Block(
                num_filters_list[2], num_filters_list[2], stride=1,
                is_branch=True))
            self.branch7 = nn.Sequential(BranchUnit(num_filters_list[2],
                num_filters_list[2]))
            self.stage4_4_branch8 = nn.Sequential(nn.ReLU())
            self.branch8 = nn.Sequential(BranchUnit(num_filters_list[2],
                num_filters_list[2]))
        else:
            raise TypeError('Unsupported NaiveNet Version.')

    def _make_layer(self, in_channels, out_channels, blocks):
        stride = 2
        layers = []
        if self.arch == 'naivenet25':
            layers.append(conv3x3(in_channels=in_channels, out_channels=
                out_channels, stride=stride, padding=0))
            for _ in range(blocks):
                layers.append(self.block(out_channels, out_channels, stride=1))
        elif self.arch == 'naivenet20':
            layers.append(conv3x3(in_channels=in_channels, out_channels=
                out_channels, stride=stride, padding=0))
            for _ in range(blocks):
                layers.append(self.block(out_channels, out_channels, stride=1))
            layers.append(nn.ReLU())
        else:
            raise TypeError('Unsupported NaiveNet Version.')
        return nn.Sequential(*layers)

    def forward(self, x):
        if self.arch == 'naivenet20':
            x = self.conv1(x)
            x = self.relu1(x)
            x = self.layer1(x)
            score1, bbox1 = self.branch1(x)
            x = self.layer2(x)
            score2, bbox2 = self.branch2(x)
            x = self.layer3(x)
            score3, bbox3 = self.branch3(x)
            x = self.layer4(x)
            score4, bbox4 = self.branch4(x)
            x = self.layer5(x)
            score5, bbox5 = self.branch5(x)
            outs = [score1, bbox1, score2, bbox2, score3, bbox3, score4,
                bbox4, score5, bbox5]
            return outs
        if self.arch == 'naivenet25':
            x = self.conv1(x)
            x = self.relu1(x)
            x = self.stage1_1(x)
            x, b1 = self.stage1_2_branch1(x)
            score1, bbox1 = self.branch1(b1)
            x = b2 = self.stage1_3_branch2(x)
            score2, bbox2 = self.branch2(b2)
            x = self.stage2_1(x)
            x, b3 = self.stage2_2_branch3(x)
            score3, bbox3 = self.branch3(b3)
            x = b4 = self.stage2_3_branch4(x)
            score4, bbox4 = self.branch4(b4)
            x = self.stage3_1(x)
            x = b5 = self.stage3_2_branch5(x)
            score5, bbox5 = self.branch5(b5)
            x = self.stage4_1(x)
            x, b6 = self.stage4_2_branch6(x)
            score6, bbox6 = self.branch6(b6)
            x, b7 = self.stage4_3_branch7(x)
            score7, bbox7 = self.branch7(b7)
            x = b8 = self.stage4_4_branch8(x)
            score8, bbox8 = self.branch8(b8)
            outs = [score1, bbox1, score2, bbox2, score3, bbox3, score4,
                bbox4, score5, bbox5, score6, bbox6, score7, bbox7, score8,
                bbox8]
            return outs


class Resv2Block(nn.Module):
    """ResNet v2 block without bn"""

    def __init__(self, in_channels, out_channels, stride=1, is_branch=False):
        super(Resv2Block, self).__init__()
        self.is_branch = is_branch
        self.relu1 = nn.ReLU()
        self.conv1 = conv3x3(in_channels=in_channels, out_channels=
            out_channels, stride=stride)
        self.relu2 = nn.ReLU()
        self.conv2 = conv3x3(in_channels=out_channels, out_channels=
            out_channels, stride=stride)

    def forward(self, x):
        out_branch = self.relu1(x)
        out = self.conv1(out_branch)
        out = self.relu2(out)
        out = self.conv2(out)
        out += x
        if self.is_branch:
            return out, out_branch
        else:
            return out


class BranchBlock(nn.Module):
    """
    Simple branch block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(BranchBlock, self).__init__()
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            in_channels, bias=True, use_bn=False)
        self.conv2 = conv1x1_block(in_channels=in_channels, out_channels=
            out_channels, bias=True, use_bn=False, activation=None)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class BranchUnit(nn.Module):
    """
    Simple branch unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    mid_channels : int
        Number of middle channels.
    """

    def __init__(self, in_channels, mid_channels):
        super(BranchUnit, self).__init__()
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            mid_channels, bias=True, use_bn=False)
        self.conv_score = BranchBlock(in_channels=mid_channels, out_channels=2)
        self.conv_bbox = BranchBlock(in_channels=mid_channels, out_channels=4)

    def forward(self, x):
        out = self.conv1(x)
        out_score = self.conv_score(out)
        out_bbox = self.conv_bbox(out)
        return out_score, out_bbox


class NaiveNet(nn.Module):
    """NaiveNet for Fast Single Class Object Detection. 
    The entire backbone and branches only consists of conv 33, 
    conv 11, ReLU and residual connection.
    """

    def __init__(self):
        super(NaiveNet, self).__init__()
        self.block = Resv2Block
        num_filters_list = [32, 64, 128, 256]
        layers = [4, 2, 1, 3]
        self.conv1 = conv3x3(in_channels=3, out_channels=num_filters_list[1
            ], stride=2, padding=0)
        self.relu1 = nn.ReLU()
        self.stage1_1 = self._make_layer(num_filters_list[1],
            num_filters_list[1], blocks=layers[0] - 1)
        self.stage1_2_branch1 = nn.Sequential(self.block(num_filters_list[1
            ], num_filters_list[1], stride=1, is_branch=True))
        self.branch1 = nn.Sequential(BranchUnit(num_filters_list[1],
            num_filters_list[2]))
        self.stage1_3_branch2 = nn.Sequential(nn.ReLU())
        self.branch2 = nn.Sequential(BranchUnit(num_filters_list[1],
            num_filters_list[2]))
        self.stage2_1 = nn.Sequential(conv3x3(num_filters_list[1],
            num_filters_list[1], stride=2, padding=0), Resv2Block(
            num_filters_list[1], num_filters_list[1], stride=1, is_branch=
            False))
        self.stage2_2_branch3 = nn.Sequential(Resv2Block(num_filters_list[1
            ], num_filters_list[1], stride=1, is_branch=True))
        self.branch3 = nn.Sequential(BranchUnit(num_filters_list[1],
            num_filters_list[2]))
        self.stage2_3_branch4 = nn.Sequential(nn.ReLU())
        self.branch4 = nn.Sequential(BranchUnit(num_filters_list[1],
            num_filters_list[2]))
        self.stage3_1 = nn.Sequential(conv3x3(num_filters_list[1],
            num_filters_list[2], stride=2, padding=0), Resv2Block(
            num_filters_list[2], num_filters_list[2], stride=1, is_branch=
            False))
        self.stage3_2_branch5 = nn.Sequential(nn.ReLU())
        self.branch5 = nn.Sequential(BranchUnit(num_filters_list[2],
            num_filters_list[2]))
        self.stage4_1 = nn.Sequential(conv3x3(num_filters_list[2],
            num_filters_list[2], stride=2, padding=0), Resv2Block(
            num_filters_list[2], num_filters_list[2], stride=1, is_branch=
            False))
        self.stage4_2_branch6 = nn.Sequential(Resv2Block(num_filters_list[2
            ], num_filters_list[2], stride=1, is_branch=True))
        self.branch6 = nn.Sequential(BranchUnit(num_filters_list[2],
            num_filters_list[2]))
        self.stage4_3_branch7 = nn.Sequential(Resv2Block(num_filters_list[2
            ], num_filters_list[2], stride=1, is_branch=True))
        self.branch7 = nn.Sequential(BranchUnit(num_filters_list[2],
            num_filters_list[2]))
        self.stage4_4_branch8 = nn.Sequential(nn.ReLU())
        self.branch8 = nn.Sequential(BranchUnit(num_filters_list[2],
            num_filters_list[2]))

    def _make_layer(self, in_channels, out_channels, blocks):
        stride = 2
        layers = []
        layers.append(conv3x3(in_channels=in_channels, out_channels=
            out_channels, stride=stride, padding=0))
        for _ in range(blocks):
            layers.append(self.block(out_channels, out_channels, stride=1))
        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.conv1(x)
        x = self.relu1(x)
        x = self.stage1_1(x)
        x, b1 = self.stage1_2_branch1(x)
        score1, bbox1 = self.branch1(b1)
        x = b2 = self.stage1_3_branch2(x)
        score2, bbox2 = self.branch2(b2)
        x = self.stage2_1(x)
        x, b3 = self.stage2_2_branch3(x)
        score3, bbox3 = self.branch3(b3)
        x = b4 = self.stage2_3_branch4(x)
        score4, bbox4 = self.branch4(b4)
        x = self.stage3_1(x)
        x = b5 = self.stage3_2_branch5(x)
        score5, bbox5 = self.branch5(b5)
        x = self.stage4_1(x)
        x, b6 = self.stage4_2_branch6(x)
        score6, bbox6 = self.branch6(b6)
        x, b7 = self.stage4_3_branch7(x)
        score7, bbox7 = self.branch7(b7)
        x = b8 = self.stage4_4_branch8(x)
        score8, bbox8 = self.branch8(b8)
        outs = [score1, bbox1, score2, bbox2, score3, bbox3, score4, bbox4,
            score5, bbox5, score6, bbox6, score7, bbox7, score8, bbox8]
        return outs


def conv(in_channels, out_channels, kernel_size=3, padding=1, bn=True,
    dilation=1, stride=1, relu=True, bias=True):
    modules = [nn.Conv2d(in_channels, out_channels, kernel_size, stride,
        padding, dilation, bias=bias)]
    if bn:
        modules.append(nn.BatchNorm2d(out_channels))
    if relu:
        modules.append(nn.ReLU(inplace=True))
    return nn.Sequential(*modules)


def conv_dw_no_bn(in_channels, out_channels, kernel_size=3, padding=1,
    stride=1, dilation=1):
    return nn.Sequential(nn.Conv2d(in_channels, in_channels, kernel_size,
        stride, padding, dilation=dilation, groups=in_channels, bias=False),
        nn.ELU(inplace=True), nn.Conv2d(in_channels, out_channels, 1, 1, 0,
        bias=False), nn.ELU(inplace=True))


class Cpm(nn.Module):

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.align = conv(in_channels, out_channels, kernel_size=1, padding
            =0, bn=False)
        self.trunk = nn.Sequential(conv_dw_no_bn(out_channels, out_channels
            ), conv_dw_no_bn(out_channels, out_channels), conv_dw_no_bn(
            out_channels, out_channels))
        self.conv = conv(out_channels, out_channels, bn=False)

    def forward(self, x):
        x = self.align(x)
        x = self.conv(x + self.trunk(x))
        return x


class InitialStage(nn.Module):

    def __init__(self, num_channels, num_heatmaps, num_pafs):
        super().__init__()
        self.trunk = nn.Sequential(conv(num_channels, num_channels, bn=
            False), conv(num_channels, num_channels, bn=False), conv(
            num_channels, num_channels, bn=False))
        self.heatmaps = nn.Sequential(conv(num_channels, 512, kernel_size=1,
            padding=0, bn=False), conv(512, num_heatmaps, kernel_size=1,
            padding=0, bn=False, relu=False))
        self.pafs = nn.Sequential(conv(num_channels, 512, kernel_size=1,
            padding=0, bn=False), conv(512, num_pafs, kernel_size=1,
            padding=0, bn=False, relu=False))

    def forward(self, x):
        trunk_features = self.trunk(x)
        heatmaps = self.heatmaps(trunk_features)
        pafs = self.pafs(trunk_features)
        return [heatmaps, pafs]


class RefinementStageBlock(nn.Module):

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.initial = conv(in_channels, out_channels, kernel_size=1,
            padding=0, bn=False)
        self.trunk = nn.Sequential(conv(out_channels, out_channels), conv(
            out_channels, out_channels, dilation=2, padding=2))

    def forward(self, x):
        initial_features = self.initial(x)
        trunk_features = self.trunk(initial_features)
        return initial_features + trunk_features


class RefinementStage(nn.Module):

    def __init__(self, in_channels, out_channels, num_heatmaps, num_pafs):
        super().__init__()
        self.trunk = nn.Sequential(RefinementStageBlock(in_channels,
            out_channels), RefinementStageBlock(out_channels, out_channels),
            RefinementStageBlock(out_channels, out_channels),
            RefinementStageBlock(out_channels, out_channels),
            RefinementStageBlock(out_channels, out_channels))
        self.heatmaps = nn.Sequential(conv(out_channels, out_channels,
            kernel_size=1, padding=0, bn=False), conv(out_channels,
            num_heatmaps, kernel_size=1, padding=0, bn=False, relu=False))
        self.pafs = nn.Sequential(conv(out_channels, out_channels,
            kernel_size=1, padding=0, bn=False), conv(out_channels,
            num_pafs, kernel_size=1, padding=0, bn=False, relu=False))

    def forward(self, x):
        trunk_features = self.trunk(x)
        heatmaps = self.heatmaps(trunk_features)
        pafs = self.pafs(trunk_features)
        return [heatmaps, pafs]


def conv_dw(in_channels, out_channels, kernel_size=3, padding=1, stride=1,
    dilation=1):
    return nn.Sequential(nn.Conv2d(in_channels, in_channels, kernel_size,
        stride, padding, dilation=dilation, groups=in_channels, bias=False),
        nn.BatchNorm2d(in_channels), nn.ReLU(inplace=True), nn.Conv2d(
        in_channels, out_channels, 1, 1, 0, bias=False), nn.BatchNorm2d(
        out_channels), nn.ReLU(inplace=True))


class PoseEstimationWithMobileNet2d(nn.Module):

    def __init__(self, num_refinement_stages=1, num_channels=128,
        num_heatmaps=19, num_pafs=38):
        super().__init__()
        self.model = nn.Sequential(conv(3, 32, stride=2, bias=False),
            conv_dw(32, 64), conv_dw(64, 128, stride=2), conv_dw(128, 128),
            conv_dw(128, 256, stride=2), conv_dw(256, 256), conv_dw(256, 
            512), conv_dw(512, 512, dilation=2, padding=2), conv_dw(512, 
            512), conv_dw(512, 512), conv_dw(512, 512), conv_dw(512, 512))
        self.cpm = Cpm(512, num_channels)
        self.initial_stage = InitialStage(num_channels, num_heatmaps, num_pafs)
        self.refinement_stages = nn.ModuleList()
        for idx in range(num_refinement_stages):
            self.refinement_stages.append(RefinementStage(num_channels +
                num_heatmaps + num_pafs, num_channels, num_heatmaps, num_pafs))

    def forward(self, x):
        backbone_features = self.model(x)
        backbone_features = self.cpm(backbone_features)
        stages_output = self.initial_stage(backbone_features)
        for refinement_stage in self.refinement_stages:
            stages_output.extend(refinement_stage(torch.cat([
                backbone_features, stages_output[-2], stages_output[-1]],
                dim=1)))
        stages_output = stages_output[-2:]
        y = torch.cat(stages_output, dim=1)
        return y


class Cpm(nn.Module):

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.align = conv(in_channels, out_channels, kernel_size=1, padding
            =0, bn=False)
        self.trunk = nn.Sequential(conv_dw_no_bn(out_channels, out_channels
            ), conv_dw_no_bn(out_channels, out_channels), conv_dw_no_bn(
            out_channels, out_channels))
        self.conv = conv(out_channels, out_channels, bn=False)

    def forward(self, x):
        x = self.align(x)
        x = self.conv(x + self.trunk(x))
        return x


class InitialStage(nn.Module):

    def __init__(self, num_channels, num_heatmaps, num_pafs):
        super().__init__()
        self.trunk = nn.Sequential(conv(num_channels, num_channels, bn=
            False), conv(num_channels, num_channels, bn=False), conv(
            num_channels, num_channels, bn=False))
        self.heatmaps = nn.Sequential(conv(num_channels, 512, kernel_size=1,
            padding=0, bn=False), conv(512, num_heatmaps, kernel_size=1,
            padding=0, bn=False, relu=False))
        self.pafs = nn.Sequential(conv(num_channels, 512, kernel_size=1,
            padding=0, bn=False), conv(512, num_pafs, kernel_size=1,
            padding=0, bn=False, relu=False))

    def forward(self, x):
        trunk_features = self.trunk(x)
        heatmaps = self.heatmaps(trunk_features)
        pafs = self.pafs(trunk_features)
        return [heatmaps, pafs]


class RefinementStageBlock(nn.Module):

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.initial = conv(in_channels, out_channels, kernel_size=1,
            padding=0, bn=False)
        self.trunk = nn.Sequential(conv(out_channels, out_channels), conv(
            out_channels, out_channels, dilation=2, padding=2))

    def forward(self, x):
        initial_features = self.initial(x)
        trunk_features = self.trunk(initial_features)
        return initial_features + trunk_features


class RefinementStage(nn.Module):

    def __init__(self, in_channels, out_channels, num_heatmaps, num_pafs):
        super().__init__()
        self.trunk = nn.Sequential(RefinementStageBlock(in_channels,
            out_channels), RefinementStageBlock(out_channels, out_channels),
            RefinementStageBlock(out_channels, out_channels),
            RefinementStageBlock(out_channels, out_channels),
            RefinementStageBlock(out_channels, out_channels))
        self.heatmaps = nn.Sequential(conv(out_channels, out_channels,
            kernel_size=1, padding=0, bn=False), conv(out_channels,
            num_heatmaps, kernel_size=1, padding=0, bn=False, relu=False))
        self.pafs = nn.Sequential(conv(out_channels, out_channels,
            kernel_size=1, padding=0, bn=False), conv(out_channels,
            num_pafs, kernel_size=1, padding=0, bn=False, relu=False))

    def forward(self, x):
        trunk_features = self.trunk(x)
        heatmaps = self.heatmaps(trunk_features)
        pafs = self.pafs(trunk_features)
        return [heatmaps, pafs]


class RefinementStageLight(nn.Module):

    def __init__(self, in_channels, mid_channels, out_channels):
        super().__init__()
        self.trunk = nn.Sequential(RefinementStageBlock(in_channels,
            mid_channels), RefinementStageBlock(mid_channels, mid_channels))
        self.feature_maps = nn.Sequential(conv(mid_channels, mid_channels,
            kernel_size=1, padding=0, bn=False), conv(mid_channels,
            out_channels, kernel_size=1, padding=0, bn=False, relu=False))

    def forward(self, x):
        trunk_features = self.trunk(x)
        feature_maps = self.feature_maps(trunk_features)
        return [feature_maps]


class ResBlock(nn.Module):

    def __init__(self, in_channels, out_channels, ratio, should_align=False):
        super().__init__()
        self.should_align = should_align
        self.bottleneck = nn.Sequential(conv(in_channels, in_channels //
            ratio, kernel_size=1, padding=0), conv(in_channels // ratio, 
            in_channels // ratio), conv(in_channels // ratio, out_channels,
            kernel_size=1, padding=0))
        if self.should_align:
            self.align = conv(in_channels, out_channels, kernel_size=1,
                padding=0)

    def forward(self, x):
        res = self.bottleneck(x)
        if self.should_align:
            x = self.align(x)
        return x + res


class Pose3D(nn.Module):

    def __init__(self, in_channels, num_2d_heatmaps, ratio=2, out_channels=57):
        super().__init__()
        self.stem = nn.Sequential(ResBlock(in_channels + num_2d_heatmaps,
            in_channels, ratio, should_align=True), ResBlock(in_channels,
            in_channels, ratio), ResBlock(in_channels, in_channels, ratio),
            ResBlock(in_channels, in_channels, ratio), ResBlock(in_channels,
            in_channels, ratio))
        self.prediction = RefinementStageLight(in_channels, in_channels,
            out_channels)

    def forward(self, x, feature_maps_2d):
        stem = self.stem(torch.cat([x, feature_maps_2d], 1))
        feature_maps = self.prediction(stem)
        return feature_maps


class PoseEstimationWithMobileNet3d(nn.Module):

    def __init__(self, num_refinement_stages=1, num_channels=128,
        num_heatmaps=19, num_pafs=38, is_convertible_by_mo=False):
        super().__init__()
        self.is_convertible_by_mo = is_convertible_by_mo
        self.model = nn.Sequential(conv(3, 32, stride=2, bias=False),
            conv_dw(32, 64), conv_dw(64, 128, stride=2), conv_dw(128, 128),
            conv_dw(128, 256, stride=2), conv_dw(256, 256), conv_dw(256, 
            512), conv_dw(512, 512, dilation=2, padding=2), conv_dw(512, 
            512), conv_dw(512, 512), conv_dw(512, 512), conv_dw(512, 512))
        self.cpm = Cpm(512, num_channels)
        self.initial_stage = InitialStage(num_channels, num_heatmaps, num_pafs)
        self.refinement_stages = nn.ModuleList()
        for idx in range(num_refinement_stages):
            self.refinement_stages.append(RefinementStage(num_channels +
                num_heatmaps + num_pafs, num_channels, num_heatmaps, num_pafs))
        self.Pose3D = Pose3D(128, num_2d_heatmaps=57)
        if self.is_convertible_by_mo:
            self.fake_conv_heatmaps = nn.Conv2d(num_heatmaps, num_heatmaps,
                kernel_size=1, bias=False)
            self.fake_conv_heatmaps.weight = nn.Parameter(torch.zeros(
                num_heatmaps, num_heatmaps, 1, 1))
            self.fake_conv_pafs = nn.Conv2d(num_pafs, num_pafs, kernel_size
                =1, bias=False)
            self.fake_conv_pafs.weight = nn.Parameter(torch.zeros(num_pafs,
                num_pafs, 1, 1))

    def forward(self, x):
        model_features = self.model(x)
        backbone_features = self.cpm(model_features)
        stages_output = self.initial_stage(backbone_features)
        for refinement_stage in self.refinement_stages:
            stages_output.extend(refinement_stage(torch.cat([
                backbone_features, stages_output[-2], stages_output[-1]],
                dim=1)))
        keypoints2d_maps = stages_output[-2]
        paf_maps = stages_output[-1]
        if self.is_convertible_by_mo:
            keypoints2d_maps = stages_output[-2] + self.fake_conv_heatmaps(
                stages_output[-2])
            paf_maps = stages_output[-1] + self.fake_conv_pafs(stages_output
                [-1])
        out = self.Pose3D(backbone_features, torch.cat([stages_output[-2],
            stages_output[-1]], dim=1))
        y = torch.cat((keypoints2d_maps, paf_maps, out[0]), dim=1)
        return y


class Resv1Block(nn.Module):
    """ResNet v1 block without bn"""

    def __init__(self, inplanes, planes, stride=1):
        super(Resv1Block, self).__init__()
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.relu1 = nn.ReLU()
        self.conv2 = conv3x3(planes, planes, stride)
        self.relu2 = nn.ReLU()

    def forward(self, x):
        out = self.conv1(x)
        out = self.relu1(out)
        out = self.conv2(out)
        out += x
        out = self.relu2(out)
        return out


class Resv2Block(nn.Module):
    """ResNet v2 block without bn"""

    def __init__(self, inplanes, planes, stride=1, is_branch=False):
        super(Resv2Block, self).__init__()
        self.is_branch = is_branch
        self.relu1 = nn.ReLU()
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.relu2 = nn.ReLU()
        self.conv2 = conv3x3(planes, planes, stride)

    def forward(self, x):
        out_branch = self.relu1(x)
        out = self.conv1(out_branch)
        out = self.relu2(out)
        out = self.conv2(out)
        out += x
        if self.is_branch:
            return out, out_branch
        else:
            return out


class BranchNet(nn.Module):
    """
    The branch of NaiveNet is the network output and 
    only consists of conv 11 and ReLU.
    """

    def __init__(self, inplanes, planes):
        super(BranchNet, self).__init__()
        self.conv1 = conv1x1(inplanes, planes)
        self.conv2_score = conv1x1(planes, planes)
        self.conv3_score = conv1x1(planes, 2)
        self.conv2_bbox = conv1x1(planes, planes)
        self.conv3_bbox = conv1x1(planes, 4)
        self.relu = nn.ReLU()

    def forward(self, x):
        out = self.conv1(x)
        out = self.relu(out)
        out_score = self.conv2_score(out)
        out_score = self.relu(out_score)
        out_score = self.conv3_score(out_score)
        out_bbox = self.conv2_bbox(out)
        out_bbox = self.relu(out_bbox)
        out_bbox = self.conv3_bbox(out_bbox)
        return out_score, out_bbox


num_filters_list = [32, 64, 128, 256]


class NaiveNet(nn.Module):
    """NaiveNet for Fast Single Class Object Detection. 
    The entire backbone and branches only consists of conv 33, 
    conv 11, ReLU and residual connection.
    """

    def __init__(self, arch, block, layers):
        super(NaiveNet, self).__init__()
        self.arch = arch
        self.block = block
        if self.arch == 'naivenet25':
            if self.block == Resv2Block:
                self.conv1 = conv3x3(3, num_filters_list[1], stride=2,
                    padding=0)
                self.relu1 = nn.ReLU()
                self.stage1_1 = self._make_layer(self.arch, self.block,
                    num_filters_list[1], num_filters_list[1], layers[0] - 1,
                    stride=2)
                self.stage1_2_branch1 = nn.Sequential(self.block(
                    num_filters_list[1], num_filters_list[1], stride=1,
                    is_branch=True))
                self.branch1 = nn.Sequential(BranchNet(num_filters_list[1],
                    num_filters_list[2]))
                self.stage1_3_branch2 = nn.Sequential(nn.ReLU())
                self.branch2 = nn.Sequential(BranchNet(num_filters_list[1],
                    num_filters_list[2]))
                self.stage2_1 = nn.Sequential(conv3x3(num_filters_list[1],
                    num_filters_list[1], stride=2, padding=0), Resv2Block(
                    num_filters_list[1], num_filters_list[1], stride=1,
                    is_branch=False))
                self.stage2_2_branch3 = nn.Sequential(Resv2Block(
                    num_filters_list[1], num_filters_list[1], stride=1,
                    is_branch=True))
                self.branch3 = nn.Sequential(BranchNet(num_filters_list[1],
                    num_filters_list[2]))
                self.stage2_3_branch4 = nn.Sequential(nn.ReLU())
                self.branch4 = nn.Sequential(BranchNet(num_filters_list[1],
                    num_filters_list[2]))
                self.stage3_1 = nn.Sequential(conv3x3(num_filters_list[1],
                    num_filters_list[2], stride=2, padding=0), Resv2Block(
                    num_filters_list[2], num_filters_list[2], stride=1,
                    is_branch=False))
                self.stage3_2_branch5 = nn.Sequential(nn.ReLU())
                self.branch5 = nn.Sequential(BranchNet(num_filters_list[2],
                    num_filters_list[2]))
                self.stage4_1 = nn.Sequential(conv3x3(num_filters_list[2],
                    num_filters_list[2], stride=2, padding=0), Resv2Block(
                    num_filters_list[2], num_filters_list[2], stride=1,
                    is_branch=False))
                self.stage4_2_branch6 = nn.Sequential(Resv2Block(
                    num_filters_list[2], num_filters_list[2], stride=1,
                    is_branch=True))
                self.branch6 = nn.Sequential(BranchNet(num_filters_list[2],
                    num_filters_list[2]))
                self.stage4_3_branch7 = nn.Sequential(Resv2Block(
                    num_filters_list[2], num_filters_list[2], stride=1,
                    is_branch=True))
                self.branch7 = nn.Sequential(BranchNet(num_filters_list[2],
                    num_filters_list[2]))
                self.stage4_4_branch8 = nn.Sequential(nn.ReLU())
                self.branch8 = nn.Sequential(BranchNet(num_filters_list[2],
                    num_filters_list[2]))
            elif self.block == Resv1Block:
                self.conv1 = conv3x3(3, num_filters_list[1], stride=2,
                    padding=0)
                self.relu1 = nn.ReLU()
                self.stage1_1 = self._make_layer(self.arch, self.block,
                    num_filters_list[1], num_filters_list[1], layers[0] - 1,
                    stride=2)
                self.branch1 = nn.Sequential(BranchNet(num_filters_list[1],
                    num_filters_list[2]))
                self.stage1_2 = nn.Sequential(self.block(num_filters_list[1
                    ], num_filters_list[1], stride=1))
                self.branch2 = nn.Sequential(BranchNet(num_filters_list[1],
                    num_filters_list[2]))
                self.stage2_1 = self._make_layer(self.arch, self.block,
                    num_filters_list[1], num_filters_list[1], layers[1] - 1,
                    stride=2)
                self.branch3 = nn.Sequential(BranchNet(num_filters_list[1],
                    num_filters_list[2]))
                self.stage2_2 = nn.Sequential(self.block(num_filters_list[1
                    ], num_filters_list[1], stride=1))
                self.branch4 = nn.Sequential(BranchNet(num_filters_list[1],
                    num_filters_list[2]))
                self.stage3_1 = self._make_layer(self.arch, self.block,
                    num_filters_list[1], num_filters_list[2], layers[2],
                    stride=2)
                self.branch5 = nn.Sequential(BranchNet(num_filters_list[2],
                    num_filters_list[2]))
                self.stage4_1 = self._make_layer(self.arch, self.block,
                    num_filters_list[2], num_filters_list[2], layers[3] - 2,
                    stride=2)
                self.branch6 = nn.Sequential(BranchNet(num_filters_list[2],
                    num_filters_list[2]))
                self.stage4_2 = nn.Sequential(self.block(num_filters_list[2
                    ], num_filters_list[2], stride=1))
                self.branch7 = nn.Sequential(BranchNet(num_filters_list[2],
                    num_filters_list[2]))
                self.stage4_3 = nn.Sequential(self.block(num_filters_list[2
                    ], num_filters_list[2], stride=1))
                self.branch8 = nn.Sequential(BranchNet(num_filters_list[2],
                    num_filters_list[2]))
            else:
                raise TypeError('Unsupported ResNet Block Version.')
        elif self.arch == 'naivenet20':
            self.conv1 = conv3x3(3, num_filters_list[1], stride=2, padding=0)
            self.relu1 = nn.ReLU()
            self.layer1 = self._make_layer(self.arch, self.block,
                num_filters_list[1], num_filters_list[1], layers[0], stride=2)
            self.branch1 = nn.Sequential(BranchNet(num_filters_list[1],
                num_filters_list[2]))
            self.layer2 = self._make_layer(self.arch, self.block,
                num_filters_list[1], num_filters_list[1], layers[1], stride=2)
            self.branch2 = nn.Sequential(BranchNet(num_filters_list[1],
                num_filters_list[2]))
            self.layer3 = self._make_layer(self.arch, self.block,
                num_filters_list[1], num_filters_list[1], layers[2], stride=2)
            self.branch3 = nn.Sequential(BranchNet(num_filters_list[1],
                num_filters_list[2]))
            self.layer4 = self._make_layer(self.arch, self.block,
                num_filters_list[1], num_filters_list[2], layers[3], stride=2)
            self.branch4 = nn.Sequential(BranchNet(num_filters_list[2],
                num_filters_list[2]))
            self.layer5 = self._make_layer(self.arch, self.block,
                num_filters_list[2], num_filters_list[2], layers[4], stride=2)
            self.branch5 = nn.Sequential(BranchNet(num_filters_list[2],
                num_filters_list[2]))
        else:
            raise TypeError('Unsupported NaiveNet Version.')

    def _make_layer(self, arch, block, inplanes, planes, blocks, stride=2):
        layers = []
        if self.arch == 'naivenet25':
            if block == Resv2Block:
                layers.append(conv3x3(inplanes, planes, stride=stride,
                    padding=0))
                for _ in range(blocks):
                    layers.append(block(planes, planes, stride=1))
            elif block == Resv1Block:
                layers.append(conv3x3(inplanes, planes, stride=stride,
                    padding=0))
                layers.append(nn.ReLU())
                for _ in range(blocks):
                    layers.append(block(planes, planes, stride=1))
            else:
                raise TypeError('Unsupported ResNet Block Version.')
        elif self.arch == 'naivenet20':
            if block == Resv2Block:
                layers.append(conv3x3(inplanes, planes, stride=stride,
                    padding=0))
                for _ in range(blocks):
                    layers.append(block(planes, planes, stride=1))
                layers.append(nn.ReLU())
            elif block == Resv1Block:
                layers.append(conv3x3(inplanes, planes, stride=stride,
                    padding=0))
                layers.append(nn.ReLU())
                for _ in range(blocks):
                    layers.append(block(planes, planes, stride=1))
            else:
                raise TypeError('Unsupported ResNet Block Version.')
        else:
            raise TypeError('Unsupported NaiveNet Version.')
        return nn.Sequential(*layers)

    def forward(self, x):
        if self.arch == 'naivenet25':
            if self.block == Resv2Block:
                x = self.conv1(x)
                x = self.relu1(x)
                x = self.stage1_1(x)
                x, b1 = self.stage1_2_branch1(x)
                score1, bbox1 = self.branch1(b1)
                x = b2 = self.stage1_3_branch2(x)
                score2, bbox2 = self.branch2(b2)
                x = self.stage2_1(x)
                x, b3 = self.stage2_2_branch3(x)
                score3, bbox3 = self.branch3(b3)
                x = b4 = self.stage2_3_branch4(x)
                score4, bbox4 = self.branch4(b4)
                x = self.stage3_1(x)
                x = b5 = self.stage3_2_branch5(x)
                score5, bbox5 = self.branch5(b5)
                x = self.stage4_1(x)
                x, b6 = self.stage4_2_branch6(x)
                score6, bbox6 = self.branch6(b6)
                x, b7 = self.stage4_3_branch7(x)
                score7, bbox7 = self.branch7(b7)
                x = b8 = self.stage4_4_branch8(x)
                score8, bbox8 = self.branch8(b8)
            elif self.block == Resv1Block:
                x = self.conv1(x)
                x = self.relu1(x)
                x = self.stage1_1(x)
                score1, bbox1 = self.branch1(x)
                x = self.stage1_2(x)
                score2, bbox2 = self.branch2(x)
                x = self.stage2_1(x)
                score3, bbox3 = self.branch3(x)
                x = self.stage2_2(x)
                score4, bbox4 = self.branch4(x)
                x = self.stage3_1(x)
                score5, bbox5 = self.branch5(x)
                x = self.stage4_1(x)
                score6, bbox6 = self.branch6(x)
                x = self.stage4_2(x)
                score7, bbox7 = self.branch7(x)
                x = self.stage4_3(x)
                score8, bbox8 = self.branch8(x)
            outs = [score1, bbox1, score2, bbox2, score3, bbox3, score4,
                bbox4, score5, bbox5, score6, bbox6, score7, bbox7, score8,
                bbox8]
            return outs
        if self.arch == 'naivenet20':
            x = self.conv1(x)
            x = self.relu1(x)
            x = self.layer1(x)
            score1, bbox1 = self.branch1(x)
            x = self.layer2(x)
            score2, bbox2 = self.branch2(x)
            x = self.layer3(x)
            score3, bbox3 = self.branch3(x)
            x = self.layer4(x)
            score4, bbox4 = self.branch4(x)
            x = self.layer5(x)
            score5, bbox5 = self.branch5(x)
            outs = [score1, bbox1, score2, bbox2, score3, bbox3, score4,
                bbox4, score5, bbox5]
            return outs


class HeatmapMaxDetBlock(nn.Module):
    """
    Heatmap maximum detector block (for human pose estimation task).
    """

    def __init__(self):
        super(HeatmapMaxDetBlock, self).__init__()

    def forward(self, x):
        heatmap = x
        vector_dim = 2
        batch = heatmap.shape[0]
        channels = heatmap.shape[1]
        in_size = x.shape[2:]
        heatmap_vector = heatmap.view(batch, channels, -1)
        scores, indices = heatmap_vector.max(dim=vector_dim, keepdims=True)
        scores_mask = (scores > 0.0).float()
        pts_x = indices % in_size[1] * scores_mask
        pts_y = indices // in_size[1] * scores_mask
        pts = torch.cat((pts_x, pts_y, scores), dim=vector_dim)
        for b in range(batch):
            for k in range(channels):
                hm = heatmap[(b), (k), :, :]
                px = int(pts[b, k, 0])
                py = int(pts[b, k, 1])
                if 0 < px < in_size[1] - 1 and 0 < py < in_size[0] - 1:
                    pts[b, k, 0] += (hm[py, px + 1] - hm[py, px - 1]).sign(
                        ) * 0.25
                    pts[b, k, 1] += (hm[py + 1, px] - hm[py - 1, px]).sign(
                        ) * 0.25
        return pts

    @staticmethod
    def calc_flops(x):
        assert x.shape[0] == 1
        num_flops = x.numel() + 26 * x.shape[1]
        num_macs = 0
        return num_flops, num_macs


BN_MOMENTUM = 0.1


class BasicBlock(nn.Module):
    expansion = 1

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(BasicBlock, self).__init__()
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        residual = x
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        if self.downsample is not None:
            residual = self.downsample(x)
        out += residual
        out = self.relu(out)
        return out


class Bottleneck(nn.Module):
    expansion = 4

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(Bottleneck, self).__init__()
        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)
        self.bn1 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)
        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,
            padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)
        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size
            =1, bias=False)
        self.bn3 = nn.BatchNorm2d(planes * self.expansion, momentum=BN_MOMENTUM
            )
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        residual = x
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)
        out = self.conv3(out)
        out = self.bn3(out)
        if self.downsample is not None:
            residual = self.downsample(x)
        out += residual
        out = self.relu(out)
        return out


class Bottleneck_CAFFE(nn.Module):
    expansion = 4

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(Bottleneck_CAFFE, self).__init__()
        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=
            stride, bias=False)
        self.bn1 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)
        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,
            padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)
        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size
            =1, bias=False)
        self.bn3 = nn.BatchNorm2d(planes * self.expansion, momentum=BN_MOMENTUM
            )
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        residual = x
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)
        out = self.conv3(out)
        out = self.bn3(out)
        if self.downsample is not None:
            residual = self.downsample(x)
        out += residual
        out = self.relu(out)
        return out


logger = logging.getLogger(__name__)


class PoseResNet(nn.Module):

    def __init__(self, block, layers, **kwargs):
        extra_DECONV_WITH_BIAS = False
        extra_NUM_DECONV_LAYERS = 3
        extra_NUM_DECONV_FILTERS = [256, 256, 256]
        extra_NUM_DECONV_KERNELS = [4, 4, 4]
        extra_FINAL_CONV_KERNEL = 1
        MODEL_NUM_JOINTS = 17
        self.inplanes = 64
        self.deconv_with_bias = extra_DECONV_WITH_BIAS
        super(PoseResNet, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,
            bias=False)
        self.bn1 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)
        self.deconv_layers = self._make_deconv_layer(extra_NUM_DECONV_LAYERS,
            extra_NUM_DECONV_FILTERS, extra_NUM_DECONV_KERNELS)
        self.final_layer = nn.Conv2d(in_channels=extra_NUM_DECONV_FILTERS[-
            1], out_channels=MODEL_NUM_JOINTS, kernel_size=
            extra_FINAL_CONV_KERNEL, stride=1, padding=1 if 
            extra_FINAL_CONV_KERNEL == 3 else 0)
        self.heatmap_max_det = HeatmapMaxDetBlock()

    def _make_layer(self, block, planes, blocks, stride=1):
        downsample = None
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(nn.Conv2d(self.inplanes, planes *
                block.expansion, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(planes * block.expansion, momentum=BN_MOMENTUM))
        layers = []
        layers.append(block(self.inplanes, planes, stride, downsample))
        self.inplanes = planes * block.expansion
        for i in range(1, blocks):
            layers.append(block(self.inplanes, planes))
        return nn.Sequential(*layers)

    def _get_deconv_cfg(self, deconv_kernel, index):
        if deconv_kernel == 4:
            padding = 1
            output_padding = 0
        elif deconv_kernel == 3:
            padding = 1
            output_padding = 1
        elif deconv_kernel == 2:
            padding = 0
            output_padding = 0
        return deconv_kernel, padding, output_padding

    def _make_deconv_layer(self, num_layers, num_filters, num_kernels):
        assert num_layers == len(num_filters
            ), 'ERROR: num_deconv_layers is different len(num_deconv_filters)'
        assert num_layers == len(num_kernels
            ), 'ERROR: num_deconv_layers is different len(num_deconv_filters)'
        layers = []
        for i in range(num_layers):
            kernel, padding, output_padding = self._get_deconv_cfg(num_kernels
                [i], i)
            planes = num_filters[i]
            layers.append(nn.ConvTranspose2d(in_channels=self.inplanes,
                out_channels=planes, kernel_size=kernel, stride=2, padding=
                padding, output_padding=output_padding, bias=self.
                deconv_with_bias))
            layers.append(nn.BatchNorm2d(planes, momentum=BN_MOMENTUM))
            layers.append(nn.ReLU(inplace=True))
            self.inplanes = planes
        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        x = self.deconv_layers(x)
        x = self.final_layer(x)
        keypoints = self.heatmap_max_det(x)
        return keypoints

    def init_weights(self, pretrained=''):
        if os.path.isfile(pretrained):
            logger.info('=> init deconv weights from normal distribution')
            for name, m in self.deconv_layers.named_modules():
                if isinstance(m, nn.ConvTranspose2d):
                    logger.info('=> init {}.weight as normal(0, 0.001)'.
                        format(name))
                    logger.info('=> init {}.bias as 0'.format(name))
                    nn.init.normal_(m.weight, std=0.001)
                    if self.deconv_with_bias:
                        nn.init.constant_(m.bias, 0)
                elif isinstance(m, nn.BatchNorm2d):
                    logger.info('=> init {}.weight as 1'.format(name))
                    logger.info('=> init {}.bias as 0'.format(name))
                    nn.init.constant_(m.weight, 1)
                    nn.init.constant_(m.bias, 0)
            logger.info('=> init final conv weights from normal distribution')
            for m in self.final_layer.modules():
                if isinstance(m, nn.Conv2d):
                    logger.info('=> init {}.weight as normal(0, 0.001)'.
                        format(name))
                    logger.info('=> init {}.bias as 0'.format(name))
                    nn.init.normal_(m.weight, std=0.001)
                    nn.init.constant_(m.bias, 0)
            logger.info('=> loading pretrained model {}'.format(pretrained))
            checkpoint = torch.load(pretrained)
            if isinstance(checkpoint, OrderedDict):
                state_dict = checkpoint
            elif isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
                state_dict_old = checkpoint['state_dict']
                state_dict = OrderedDict()
                for key in state_dict_old.keys():
                    if key.startswith('module.'):
                        state_dict[key[7:]] = state_dict_old[key]
                    else:
                        state_dict[key] = state_dict_old[key]
            else:
                raise RuntimeError('No state_dict found in checkpoint file {}'
                    .format(pretrained))
            self.load_state_dict(state_dict, strict=False)
        else:
            logger.error('=> imagenet pretrained model dose not exist')
            logger.error('=> please download it first')
            raise ValueError('imagenet pretrained model does not exist')


def padding_same_conv2d(input_size, in_c, out_c, kernel_size=4, stride=1):
    output_size = input_size // stride
    padding_num = stride * (output_size - 1) - input_size + kernel_size
    if padding_num % 2 == 0:
        return nn.Sequential(nn.Conv2d(in_c, out_c, kernel_size=kernel_size,
            stride=stride, padding=padding_num // 2, bias=False))
    else:
        return nn.Sequential(nn.ConstantPad2d((padding_num // 2, 
            padding_num // 2 + 1, padding_num // 2, padding_num // 2 + 1), 
            0), nn.Conv2d(in_c, out_c, kernel_size=kernel_size, stride=
            stride, padding=0, bias=False))


class resBlock(nn.Module):

    def __init__(self, in_c, out_c, kernel_size=4, stride=1, input_size=None):
        super().__init__()
        assert kernel_size == 4
        self.shortcut = lambda x: x
        if in_c != out_c:
            self.shortcut = nn.Conv2d(in_c, out_c, kernel_size=1, stride=
                stride, bias=False)
        main_layers = [nn.Conv2d(in_c, out_c // 2, kernel_size=1, stride=1,
            padding=0, bias=False), nn.BatchNorm2d(out_c // 2, eps=0.001,
            momentum=0.001), nn.ReLU(inplace=True)]
        main_layers += list(padding_same_conv2d(input_size, out_c // 2, 
            out_c // 2, kernel_size=kernel_size, stride=stride)._modules.
            values())
        main_layers.extend([nn.BatchNorm2d(out_c // 2, eps=0.001, momentum=
            0.001), nn.ReLU(inplace=True)])
        main_layers.extend(padding_same_conv2d(input_size, out_c // 2,
            out_c, kernel_size=1, stride=1))
        self.main = nn.Sequential(*main_layers)
        self.activate = nn.Sequential(nn.BatchNorm2d(out_c, eps=0.001,
            momentum=0.001), nn.ReLU(inplace=True))

    def forward(self, x):
        shortcut_x = self.shortcut(x)
        main_x = self.main(x)
        x = self.activate(shortcut_x + main_x)
        return x


class upBlock(nn.Module):

    def __init__(self, in_c, out_c, conv_num=2):
        super().__init__()
        additional_conv = []
        layer_length = 4
        for i in range(1, conv_num + 1):
            additional_conv += [nn.ConstantPad2d((2, 1, 2, 1), 0), nn.
                ConvTranspose2d(out_c, out_c, kernel_size=4, stride=1,
                padding=3, bias=False), nn.BatchNorm2d(out_c, eps=0.001,
                momentum=0.001), nn.ReLU(inplace=True)]
        self.main = nn.Sequential(nn.ConvTranspose2d(in_c, out_c,
            kernel_size=4, stride=2, padding=1, bias=False), nn.BatchNorm2d
            (out_c, eps=0.001, momentum=0.001), nn.ReLU(inplace=True), *
            additional_conv)

    def forward(self, x):
        x = self.main(x)
        return x


class PRNet(nn.Module):

    def __init__(self, in_channel, out_channel=3, pretrained=False):
        super().__init__()
        size = 16
        self.input_conv = nn.Sequential(*(list(padding_same_conv2d(256,
            in_channel, size, kernel_size=4, stride=1)._modules.values()) +
            [nn.BatchNorm2d(size, eps=0.001, momentum=0.001), nn.ReLU(
            inplace=True)]))
        self.down_conv_1 = resBlock(size, size * 2, kernel_size=4, stride=2,
            input_size=256)
        self.down_conv_2 = resBlock(size * 2, size * 2, kernel_size=4,
            stride=1, input_size=128)
        self.down_conv_3 = resBlock(size * 2, size * 4, kernel_size=4,
            stride=2, input_size=128)
        self.down_conv_4 = resBlock(size * 4, size * 4, kernel_size=4,
            stride=1, input_size=64)
        self.down_conv_5 = resBlock(size * 4, size * 8, kernel_size=4,
            stride=2, input_size=64)
        self.down_conv_6 = resBlock(size * 8, size * 8, kernel_size=4,
            stride=1, input_size=32)
        self.down_conv_7 = resBlock(size * 8, size * 16, kernel_size=4,
            stride=2, input_size=32)
        self.down_conv_8 = resBlock(size * 16, size * 16, kernel_size=4,
            stride=1, input_size=16)
        self.down_conv_9 = resBlock(size * 16, size * 32, kernel_size=4,
            stride=2, input_size=16)
        self.down_conv_10 = resBlock(size * 32, size * 32, kernel_size=4,
            stride=1, input_size=8)
        self.center_conv = nn.Sequential(nn.ConstantPad2d((2, 1, 2, 1), 0),
            nn.ConvTranspose2d(size * 32, size * 32, kernel_size=4, stride=
            1, padding=3, bias=False), nn.BatchNorm2d(size * 32, eps=0.001,
            momentum=0.001), nn.ReLU(inplace=True))
        self.up_conv_5 = upBlock(size * 32, size * 16)
        self.up_conv_4 = upBlock(size * 16, size * 8)
        self.up_conv_3 = upBlock(size * 8, size * 4)
        self.up_conv_2 = upBlock(size * 4, size * 2, 1)
        self.up_conv_1 = upBlock(size * 2, size, 1)
        self.output_conv = nn.Sequential(nn.ConstantPad2d((2, 1, 2, 1), 0),
            nn.ConvTranspose2d(size, 3, kernel_size=4, stride=1, padding=3,
            bias=False), nn.BatchNorm2d(3, eps=0.001, momentum=0.001), nn.
            ReLU(inplace=True), nn.ConstantPad2d((2, 1, 2, 1), 0), nn.
            ConvTranspose2d(3, 3, kernel_size=4, stride=1, padding=3, bias=
            False), nn.BatchNorm2d(3, eps=0.001, momentum=0.001), nn.ReLU(
            inplace=True), nn.ConstantPad2d((2, 1, 2, 1), 0), nn.
            ConvTranspose2d(3, 3, kernel_size=4, stride=1, padding=3, bias=
            False), nn.BatchNorm2d(3, eps=0.001, momentum=0.001), nn.Sigmoid())

    def forward(self, x):
        x = self.input_conv(x)
        x = self.down_conv_1(x)
        x = self.down_conv_2(x)
        x = self.down_conv_3(x)
        x = self.down_conv_4(x)
        x = self.down_conv_5(x)
        x = self.down_conv_6(x)
        x = self.down_conv_7(x)
        x = self.down_conv_8(x)
        x = self.down_conv_9(x)
        x = self.down_conv_10(x)
        x = self.center_conv(x)
        x = self.up_conv_5(x)
        x = self.up_conv_4(x)
        x = self.up_conv_3(x)
        x = self.up_conv_2(x)
        x = self.up_conv_1(x)
        x = self.output_conv(x)
        return x


BN_moment = 0.1


class CBR(nn.Module):
    """
    This class defines the convolution layer with batch normalization and PReLU activation
    """

    def __init__(self, nIn, nOut, kSize, stride=1):
        """

        :param nIn: number of input channels
        :param nOut: number of output channels
        :param kSize: kernel size
        :param stride: stride rate for down-sampling. Default is 1
        """
        super().__init__()
        padding = int((kSize - 1) / 2)
        self.conv = nn.Conv2d(nIn, nOut, (kSize, kSize), stride=stride,
            padding=(padding, padding), bias=False)
        self.bn = nn.BatchNorm2d(nOut, eps=0.001, momentum=BN_moment)
        self.act = nn.PReLU(nOut)

    def forward(self, input):
        """
        :param input: input feature map
        :return: transformed feature map
        """
        output = self.conv(input)
        output = self.bn(output)
        output = self.act(output)
        return output


class separableCBR(nn.Module):
    """
    This class defines the convolution layer with batch normalization and PReLU activation
    """

    def __init__(self, nIn, nOut, kSize, stride=1):
        """

        :param nIn: number of input channels
        :param nOut: number of output channels
        :param kSize: kernel size
        :param stride: stride rate for down-sampling. Default is 1
        """
        super().__init__()
        padding = int((kSize - 1) / 2)
        self.conv = nn.Sequential(nn.Conv2d(nIn, nIn, (kSize, kSize),
            stride=stride, padding=(padding, padding), groups=nIn, bias=
            False), nn.Conv2d(nIn, nOut, kernel_size=1, stride=1, bias=False))
        self.bn = nn.BatchNorm2d(nOut, eps=0.001, momentum=BN_moment)
        self.act = nn.PReLU(nOut)

    def forward(self, input):
        """
        :param input: input feature map
        :return: transformed feature map
        """
        output = self.conv(input)
        output = self.bn(output)
        output = self.act(output)
        return output


class SqueezeBlock(nn.Module):

    def __init__(self, exp_size, divide=4.0):
        super(SqueezeBlock, self).__init__()
        if divide > 1:
            self.dense = nn.Sequential(nn.Linear(exp_size, int(exp_size /
                divide)), nn.PReLU(int(exp_size / divide)), nn.Linear(int(
                exp_size / divide), exp_size), nn.PReLU(exp_size))
        else:
            self.dense = nn.Sequential(nn.Linear(exp_size, exp_size), nn.
                PReLU(exp_size))

    def forward(self, x):
        batch, channels, height, width = x.size()
        out = torch.nn.functional.avg_pool2d(x, kernel_size=[height, width]
            ).view(batch, -1)
        out = self.dense(out)
        out = out.view(batch, channels, 1, 1)
        return out * x


class SEseparableCBR(nn.Module):
    """
    This class defines the convolution layer with batch normalization and PReLU activation
    """

    def __init__(self, nIn, nOut, kSize, stride=1, divide=2.0):
        """

        :param nIn: number of input channels
        :param nOut: number of output channels
        :param kSize: kernel size
        :param stride: stride rate for down-sampling. Default is 1
        """
        super().__init__()
        padding = int((kSize - 1) / 2)
        self.conv = nn.Sequential(nn.Conv2d(nIn, nIn, (kSize, kSize),
            stride=stride, padding=(padding, padding), groups=nIn, bias=
            False), SqueezeBlock(nIn, divide=divide), nn.Conv2d(nIn, nOut,
            kernel_size=1, stride=1, bias=False))
        self.bn = nn.BatchNorm2d(nOut, eps=0.001, momentum=BN_moment)
        self.act = nn.PReLU(nOut)

    def forward(self, input):
        """
        :param input: input feature map
        :return: transformed feature map
        """
        output = self.conv(input)
        output = self.bn(output)
        output = self.act(output)
        return output


class BR(nn.Module):
    """
        This class groups the batch normalization and PReLU activation
    """

    def __init__(self, nOut):
        """
        :param nOut: output feature maps
        """
        super().__init__()
        self.bn = nn.BatchNorm2d(nOut, eps=0.001, momentum=BN_moment)
        self.act = nn.PReLU(nOut)

    def forward(self, input):
        """
        :param input: input feature map
        :return: normalized and thresholded feature map
        """
        output = self.bn(input)
        output = self.act(output)
        return output


class CB(nn.Module):
    """
       This class groups the convolution and batch normalization
    """

    def __init__(self, nIn, nOut, kSize, stride=1):
        """
        :param nIn: number of input channels
        :param nOut: number of output channels
        :param kSize: kernel size
        :param stride: optinal stide for down-sampling
        """
        super().__init__()
        padding = int((kSize - 1) / 2)
        self.conv = nn.Conv2d(nIn, nOut, (kSize, kSize), stride=stride,
            padding=(padding, padding), bias=False)
        self.bn = nn.BatchNorm2d(nOut, eps=0.001, momentum=BN_moment)

    def forward(self, input):
        """

        :param input: input feature map
        :return: transformed feature map
        """
        output = self.conv(input)
        output = self.bn(output)
        return output


class C(nn.Module):
    """
    This class is for a convolutional layer.
    """

    def __init__(self, nIn, nOut, kSize, stride=1, group=1):
        """

        :param nIn: number of input channels
        :param nOut: number of output channels
        :param kSize: kernel size
        :param stride: optional stride rate for down-sampling
        """
        super().__init__()
        padding = int((kSize - 1) / 2)
        self.conv = nn.Conv2d(nIn, nOut, (kSize, kSize), stride=stride,
            padding=(padding, padding), bias=False, groups=group)

    def forward(self, input):
        """
        :param input: input feature map
        :return: transformed feature map
        """
        output = self.conv(input)
        return output


class SBblock(nn.Module):
    """
    This class defines the dilated convolution.
    """

    def __init__(self, nIn, nOut, config):
        """
        :param nIn: number of input channels
        :param nOut: number of output channels
        :param kSize: kernel size
        :param stride: optional stride rate for down-sampling
        :param d: optional dilation rate
        """
        super().__init__()
        kSize = config[0]
        avgsize = config[1]
        self.SB = True if avgsize > 0 else False
        if avgsize == 0:
            self.conv = nn.Sequential(nn.Conv2d(nIn, nIn, kernel_size=3,
                stride=1, padding=1, bias=False, groups=nIn), nn.
                BatchNorm2d(nIn, eps=0.001, momentum=BN_moment))
        else:
            self.resolution_down = False
            if avgsize > 1:
                self.resolution_down = True
                self.down_res = nn.AvgPool2d(avgsize, avgsize)
                self.up_res = nn.UpsamplingBilinear2d(scale_factor=avgsize)
            padding = int((kSize - 1) / 2)
            self.vertical = nn.Conv2d(nIn, nIn, kernel_size=(kSize, 1),
                stride=1, padding=(padding, 0), groups=nIn, bias=False)
            self.horizontal = nn.Conv2d(nIn, nIn, kernel_size=(1, kSize),
                stride=1, padding=(0, padding), groups=nIn, bias=False)
            self.B_v = nn.BatchNorm2d(nIn, eps=0.001, momentum=BN_moment)
            self.B_h = nn.BatchNorm2d(nIn, eps=0.001, momentum=BN_moment)
        self.act_conv1x1 = nn.Sequential(nn.PReLU(nIn), nn.Conv2d(nIn, nOut,
            kernel_size=1, stride=1, bias=False))
        self.bn = nn.BatchNorm2d(nOut, eps=0.001, momentum=BN_moment)

    def forward(self, input):
        """
        :param input: input feature map
        :return: transformed feature map
        """
        if self.SB:
            if self.resolution_down:
                input = self.down_res(input)
            output_v = self.B_v(self.vertical(input))
            output_h = self.B_h(self.horizontal(input))
            output = output_v + output_h
        else:
            output = self.conv(input)
        output = self.act_conv1x1(output)
        if self.SB and self.resolution_down:
            output = self.up_res(output)
        return self.bn(output)


class SBmodule(nn.Module):
    """
    This class defines the ESP block, which is based on the following principle
        Reduce ---> Split ---> Transform --> Merge
    """

    def __init__(self, nIn, nOut, add=True, config=[[3, 1], [5, 1]]):
        """
        :param nIn: number of input channels
        :param nOut: number of output channels
        :param add: if true, add a residual connection through identity operation. You can use projection too as
                in ResNet paper, but we avoid to use it if the dimensions are not the same because we do not want to
                increase the module complexity
        """
        super().__init__()
        None
        group_n = len(config)
        n = int(nOut / group_n)
        n1 = nOut - group_n * n
        self.c1 = C(nIn, n, 1, 1, group=group_n)
        for i in range(group_n):
            var_name = 'd{}'.format(i + 1)
            if i == 0:
                self.__dict__['_modules'][var_name] = SBblock(n, n + n1,
                    config[i])
            else:
                self.__dict__['_modules'][var_name] = SBblock(n, n, config[i])
        self.BR = BR(nOut)
        self.add = add
        self.group_n = group_n

    def forward(self, input):
        """
        :param input: input feature map
        :return: transformed feature map
        """
        output1 = self.c1(input)
        output1 = channel_shuffle(output1, self.group_n)
        for i in range(self.group_n):
            var_name = 'd{}'.format(i + 1)
            result_d = self.__dict__['_modules'][var_name](output1)
            if i == 0:
                combine = result_d
            else:
                combine = torch.cat([combine, result_d], 1)
        if self.add:
            combine = input + combine
        output = self.BR(combine)
        return output


class InputProjectionA(nn.Module):
    """
    This class projects the input image to the same spatial dimensions as the feature map.
    For example, if the input image is 512 x512 x3 and spatial dimensions of feature map size are 56x56xF, then
    this class will generate an output of 56x56x3
    """

    def __init__(self, samplingTimes):
        """
        :param samplingTimes: The rate at which you want to down-sample the image
        """
        super().__init__()
        self.pool = nn.ModuleList()
        for i in range(0, samplingTimes):
            self.pool.append(nn.AvgPool2d(2, stride=2))

    def forward(self, input):
        """
        :param input: Input RGB Image
        :return: down-sampled image (pyramid-based approach)
        """
        for pool in self.pool:
            input = pool(input)
        return input


class SBNet_Encoder(nn.Module):

    def __init__(self, config, classes=20, p=5, q=3, chnn=1.0):
        """
        :param classes: number of classes in the dataset. Default is 20 for the cityscapes
        :param p: depth multiplier
        :param q: depth multiplier
        """
        super().__init__()
        None
        None
        dim1 = 24
        dim2 = 48 + 4 * (chnn - 1)
        dim3 = 72 + 4 * (chnn - 1)
        dim4 = 96 + 4 * (chnn - 1)
        self.level1 = CBR(3, 16, 3, 2)
        self.level2_0 = SEseparableCBR(16, classes, 3, 2, divide=1)
        self.level3_0 = SEseparableCBR(classes, dim1, 3, 2, divide=1)
        self.level3 = nn.ModuleList()
        for i in range(0, p):
            if i == 0:
                self.level3.append(SBmodule(dim1, dim2, config=config[i],
                    add=False))
            else:
                self.level3.append(SBmodule(dim2, dim2, config=config[i]))
        self.BR3 = BR(dim2 + dim1)
        self.level4_0 = SEseparableCBR(dim2 + dim1, dim2, 3, 2, divide=2)
        self.level4 = nn.ModuleList()
        for i in range(0, q // 2):
            if i == 0:
                self.level4.append(SBmodule(dim2, dim3, config=config[p + i
                    ], add=False))
            else:
                self.level4.append(SBmodule(dim3, dim3, config=config[p + i]))
        for i in range(q // 2, q):
            if i == q // 2:
                self.level4.append(SBmodule(dim3, dim4, config=config[p + i
                    ], add=False))
            else:
                self.level4.append(SBmodule(dim4, dim4, config=config[p + i]))
        self.BR4 = BR(dim4 + dim2)
        self.classifier = C(dim4 + dim2, classes, 1, 1)

    def forward(self, input):
        """
        :param input: Receives the input RGB image
        :return: the transformed feature map with spatial dimensions 1/8th of the input image
        """
        output1 = self.level1(input)
        output2_0 = self.level2_0(output1)
        output3_0 = self.level3_0(output2_0)
        for i, layer in enumerate(self.level3):
            if i == 0:
                output3 = layer(output3_0)
            else:
                output3 = layer(output3)
        output4_0 = self.level4_0(self.BR3(torch.cat([output3_0, output3], 1)))
        for i, layer in enumerate(self.level4):
            if i == 0:
                output4 = layer(output4_0)
            else:
                output4 = layer(output4)
        output4_cat = self.BR4(torch.cat([output4_0, output4], 1))
        classifier = self.classifier(output4_cat)
        return classifier


class PeleeBranch1(nn.Module):
    """
    PeleeNet branch type 1 block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    mid_channels : int
        Number of intermediate channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the second convolution.
    """

    def __init__(self, in_channels, out_channels, mid_channels, stride=1):
        super(PeleeBranch1, self).__init__()
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            mid_channels)
        self.conv2 = conv3x3_block(in_channels=mid_channels, out_channels=
            out_channels, stride=stride)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class PeleeBranch2(nn.Module):
    """
    PeleeNet branch type 2 block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    mid_channels : int
        Number of intermediate channels.
    """

    def __init__(self, in_channels, out_channels, mid_channels):
        super(PeleeBranch2, self).__init__()
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            mid_channels)
        self.conv2 = conv3x3_block(in_channels=mid_channels, out_channels=
            out_channels)
        self.conv3 = conv3x3_block(in_channels=out_channels, out_channels=
            out_channels)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class StemBlock(nn.Module):
    """
    PeleeNet stem block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(StemBlock, self).__init__()
        mid1_channels = out_channels // 2
        mid2_channels = out_channels * 2
        self.first_conv = conv3x3_block(in_channels=in_channels,
            out_channels=out_channels, stride=2)
        self.branches = Concurrent()
        self.branches.add_module('branch1', PeleeBranch1(in_channels=
            out_channels, out_channels=out_channels, mid_channels=
            mid1_channels, stride=2))
        self.branches.add_module('branch2', nn.MaxPool2d(kernel_size=2,
            stride=2, padding=0))
        self.last_conv = conv1x1_block(in_channels=mid2_channels,
            out_channels=out_channels)

    def forward(self, x):
        x = self.first_conv(x)
        x = self.branches(x)
        x = self.last_conv(x)
        return x


class DenseBlock(nn.Module):
    """
    PeleeNet dense block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    bottleneck_size : int
        Bottleneck width.
    """

    def __init__(self, in_channels, out_channels, bottleneck_size):
        super(DenseBlock, self).__init__()
        inc_channels = (out_channels - in_channels) // 2
        mid_channels = inc_channels * bottleneck_size
        self.branch1 = PeleeBranch1(in_channels=in_channels, out_channels=
            inc_channels, mid_channels=mid_channels)
        self.branch2 = PeleeBranch2(in_channels=in_channels, out_channels=
            inc_channels, mid_channels=mid_channels)

    def forward(self, x):
        x1 = self.branch1(x)
        x2 = self.branch2(x)
        x = torch.cat((x, x1, x2), dim=1)
        return x


class TransitionBlock(nn.Module):
    """
    PeleeNet's transition block, like in DensNet, but with ordinary convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(TransitionBlock, self).__init__()
        self.conv = conv1x1_block(in_channels=in_channels, out_channels=
            out_channels)
        self.pool = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)

    def forward(self, x):
        x = self.conv(x)
        x = self.pool(x)
        return x


class PeleeNet(nn.Module):
    """
    PeleeNet model from 'Pelee: A Real-Time Object Detection System on Mobile Devices,'
    https://arxiv.org/abs/1804.06882.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bottleneck_sizes : list of int
        Bottleneck sizes for each stage.
    dropout_rate : float, default 0.5
        Parameter of Dropout layer. Faction of the input units to drop.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, bottleneck_sizes,
        dropout_rate=0.5, in_channels=3, in_size=(224, 224), num_classes=1000):
        super(PeleeNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', StemBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            bottleneck_size = bottleneck_sizes[i]
            stage = nn.Sequential()
            if i != 0:
                stage.add_module('trans{}'.format(i + 1), TransitionBlock(
                    in_channels=in_channels, out_channels=in_channels))
            for j, out_channels in enumerate(channels_per_stage):
                stage.add_module('unit{}'.format(j + 1), DenseBlock(
                    in_channels=in_channels, out_channels=out_channels,
                    bottleneck_size=bottleneck_size))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_block', conv1x1_block(in_channels=
            in_channels, out_channels=in_channels))
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Sequential()
        self.output.add_module('dropout', nn.Dropout(p=dropout_rate))
        self.output.add_module('fc', nn.Linear(in_features=in_channels,
            out_features=num_classes))
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class PnasMaxPoolBlock(nn.Module):
    """
    PNASNet specific Max pooling layer with extra padding.

    Parameters:
    ----------
    stride : int or tuple/list of 2 int, default 2
        Strides of the convolution.
    extra_padding : bool, default False
        Whether to use extra padding.
    """

    def __init__(self, stride=2, extra_padding=False):
        super(PnasMaxPoolBlock, self).__init__()
        self.extra_padding = extra_padding
        self.pool = nn.MaxPool2d(kernel_size=3, stride=stride, padding=1)
        if self.extra_padding:
            self.pad = nn.ZeroPad2d(padding=(1, 0, 1, 0))

    def forward(self, x):
        if self.extra_padding:
            x = self.pad(x)
        x = self.pool(x)
        if self.extra_padding:
            x = x[:, :, 1:, 1:].contiguous()
        return x


class DwsBranch(nn.Module):
    """
    PNASNet specific block with depthwise separable convolution layers.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    extra_padding : bool, default False
        Whether to use extra padding.
    stem : bool, default False
        Whether to use squeeze reduction if False.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        extra_padding=False, stem=False):
        super(DwsBranch, self).__init__()
        assert not stem or not extra_padding
        mid_channels = out_channels if stem else in_channels
        padding = kernel_size // 2
        self.conv1 = NasDwsConv(in_channels=in_channels, out_channels=
            mid_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, extra_padding=extra_padding)
        self.conv2 = NasDwsConv(in_channels=mid_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=1, padding=padding)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class PnasMaxPathBlock(nn.Module):
    """
    PNASNet specific `max path` auxiliary block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(PnasMaxPathBlock, self).__init__()
        self.maxpool = PnasMaxPoolBlock()
        self.conv = conv1x1(in_channels=in_channels, out_channels=out_channels)
        self.bn = nasnet_batch_norm(channels=out_channels)

    def forward(self, x):
        x = self.maxpool(x)
        x = self.conv(x)
        x = self.bn(x)
        return x


class PnasBaseUnit(nn.Module):
    """
    PNASNet base unit.
    """

    def __init__(self):
        super(PnasBaseUnit, self).__init__()

    def cell_forward(self, x, x_prev):
        assert hasattr(self, 'comb0_left')
        x_left = x_prev
        x_right = x
        x0 = self.comb0_left(x_left) + self.comb0_right(x_left)
        x1 = self.comb1_left(x_right) + self.comb1_right(x_right)
        x2 = self.comb2_left(x_right) + self.comb2_right(x_right)
        x3 = self.comb3_left(x2) + self.comb3_right(x_right)
        x4 = self.comb4_left(x_left) + (self.comb4_right(x_right) if self.
            comb4_right else x_right)
        x_out = torch.cat((x0, x1, x2, x3, x4), dim=1)
        return x_out


def dws_branch_k5(in_channels, out_channels, stride=2, extra_padding=False,
    stem=False):
    """
    5x5 version of the PNASNet specific depthwise separable convolution branch.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 2
        Strides of the convolution.
    extra_padding : bool, default False
        Whether to use extra padding.
    stem : bool, default False
        Whether to use squeeze reduction if False.
    """
    return DwsBranch(in_channels=in_channels, out_channels=out_channels,
        kernel_size=5, stride=stride, extra_padding=extra_padding, stem=stem)


def dws_branch_k7(in_channels, out_channels, stride=2, extra_padding=False):
    """
    7x7 version of the PNASNet specific depthwise separable convolution branch.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 2
        Strides of the convolution.
    extra_padding : bool, default False
        Whether to use extra padding.
    """
    return DwsBranch(in_channels=in_channels, out_channels=out_channels,
        kernel_size=7, stride=stride, extra_padding=extra_padding, stem=False)


def pnas_conv1x1(in_channels, out_channels, stride=1):
    """
    1x1 version of the PNASNet specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    """
    return NasConv(in_channels=in_channels, out_channels=out_channels,
        kernel_size=1, stride=stride, padding=0, groups=1)


def dws_branch_k3(in_channels, out_channels, stride=2, extra_padding=False,
    stem=False):
    """
    3x3 version of the PNASNet specific depthwise separable convolution branch.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 2
        Strides of the convolution.
    extra_padding : bool, default False
        Whether to use extra padding.
    stem : bool, default False
        Whether to use squeeze reduction if False.
    """
    return DwsBranch(in_channels=in_channels, out_channels=out_channels,
        kernel_size=3, stride=stride, extra_padding=extra_padding, stem=stem)


class PnasUnit(PnasBaseUnit):
    """
    PNASNet ordinary unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    prev_in_channels : int
        Number of input channels in previous input.
    out_channels : int
        Number of output channels.
    reduction : bool, default False
        Whether to use reduction.
    extra_padding : bool, default False
        Whether to use extra padding.
    match_prev_layer_dimensions : bool, default False
        Whether to match previous layer dimensions.
    """

    def __init__(self, in_channels, prev_in_channels, out_channels,
        reduction=False, extra_padding=False, match_prev_layer_dimensions=False
        ):
        super(PnasUnit, self).__init__()
        mid_channels = out_channels // 5
        stride = 2 if reduction else 1
        if match_prev_layer_dimensions:
            self.conv_prev_1x1 = NasPathBlock(in_channels=prev_in_channels,
                out_channels=mid_channels)
        else:
            self.conv_prev_1x1 = pnas_conv1x1(in_channels=prev_in_channels,
                out_channels=mid_channels)
        self.conv_1x1 = pnas_conv1x1(in_channels=in_channels, out_channels=
            mid_channels)
        self.comb0_left = dws_branch_k5(in_channels=mid_channels,
            out_channels=mid_channels, stride=stride, extra_padding=
            extra_padding)
        self.comb0_right = PnasMaxPoolBlock(stride=stride, extra_padding=
            extra_padding)
        self.comb1_left = dws_branch_k7(in_channels=mid_channels,
            out_channels=mid_channels, stride=stride, extra_padding=
            extra_padding)
        self.comb1_right = PnasMaxPoolBlock(stride=stride, extra_padding=
            extra_padding)
        self.comb2_left = dws_branch_k5(in_channels=mid_channels,
            out_channels=mid_channels, stride=stride, extra_padding=
            extra_padding)
        self.comb2_right = dws_branch_k3(in_channels=mid_channels,
            out_channels=mid_channels, stride=stride, extra_padding=
            extra_padding)
        self.comb3_left = dws_branch_k3(in_channels=mid_channels,
            out_channels=mid_channels, stride=1)
        self.comb3_right = PnasMaxPoolBlock(stride=stride, extra_padding=
            extra_padding)
        self.comb4_left = dws_branch_k3(in_channels=mid_channels,
            out_channels=mid_channels, stride=stride, extra_padding=
            extra_padding)
        if reduction:
            self.comb4_right = pnas_conv1x1(in_channels=mid_channels,
                out_channels=mid_channels, stride=stride)
        else:
            self.comb4_right = None

    def forward(self, x, x_prev):
        x_prev = self.conv_prev_1x1(x_prev)
        x = self.conv_1x1(x)
        x_out = self.cell_forward(x, x_prev)
        return x_out


class PNASNet(nn.Module):
    """
    PNASNet model from 'Progressive Neural Architecture Search,' https://arxiv.org/abs/1712.00559.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    stem1_blocks_channels : list of 2 int
        Number of output channels for the Stem1 unit.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (331, 331)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, stem1_blocks_channels,
        in_channels=3, in_size=(331, 331), num_classes=1000):
        super(PNASNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nasnet_dual_path_sequential(return_two=False,
            first_ordinals=2, last_ordinals=2)
        self.features.add_module('init_block', NASNetInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        self.features.add_module('stem1_unit', Stem1Unit(in_channels=
            in_channels, out_channels=stem1_blocks_channels))
        prev_in_channels = in_channels
        in_channels = stem1_blocks_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nasnet_dual_path_sequential()
            for j, out_channels in enumerate(channels_per_stage):
                reduction = j == 0
                extra_padding = j == 0 and i not in [0, 2]
                match_prev_layer_dimensions = j == 1 or j == 0 and i == 0
                stage.add_module('unit{}'.format(j + 1), PnasUnit(
                    in_channels=in_channels, prev_in_channels=
                    prev_in_channels, out_channels=out_channels, reduction=
                    reduction, extra_padding=extra_padding,
                    match_prev_layer_dimensions=match_prev_layer_dimensions))
                prev_in_channels = in_channels
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('activ', nn.ReLU())
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=11,
            stride=1))
        self.output = nn.Sequential()
        self.output.add_module('dropout', nn.Dropout(p=0.5))
        self.output.add_module('fc', nn.Linear(in_features=in_channels,
            out_features=num_classes))
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class PolyConv(nn.Module):
    """
    PolyNet specific convolution block. A block that is used inside poly-N (poly-2, poly-3, and so on) modules.
    The Convolution layer is shared between all Inception blocks inside a poly-N module. BatchNorm layers are not
    shared between Inception blocks and therefore the number of BatchNorm layers is equal to the number of Inception
    blocks inside a poly-N module.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    num_blocks : int
        Number of blocks (BatchNorm layers).
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, num_blocks):
        super(PolyConv, self).__init__()
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, bias=False)
        self.bns = nn.ModuleList()
        for i in range(num_blocks):
            self.bns.append(nn.BatchNorm2d(num_features=out_channels))
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x, index):
        x = self.conv(x)
        x = self.bns[index](x)
        x = self.activ(x)
        return x


class MaxPoolBranch(nn.Module):
    """
    PolyNet specific max pooling branch block.
    """

    def __init__(self):
        super(MaxPoolBranch, self).__init__()
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)

    def forward(self, x):
        x = self.pool(x)
        return x


class Conv1x1Branch(nn.Module):
    """
    PolyNet specific convolutional 1x1 branch block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(Conv1x1Branch, self).__init__()
        self.conv = conv1x1_block(in_channels=in_channels, out_channels=
            out_channels)

    def forward(self, x):
        x = self.conv(x)
        return x


class Conv3x3Branch(nn.Module):
    """
    PolyNet specific convolutional 3x3 branch block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(Conv3x3Branch, self).__init__()
        self.conv = conv3x3_block(in_channels=in_channels, out_channels=
            out_channels, stride=2, padding=0)

    def forward(self, x):
        x = self.conv(x)
        return x


class ConvSeqBranch(nn.Module):
    """
    PolyNet specific convolutional sequence branch block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels_list : list of tuple of int
        List of numbers of output channels.
    kernel_size_list : list of tuple of int or tuple of tuple/list of 2 int
        List of convolution window sizes.
    strides_list : list of tuple of int or tuple of tuple/list of 2 int
        List of strides of the convolution.
    padding_list : list of tuple of int or tuple of tuple/list of 2 int
        List of padding values for convolution layers.
    """

    def __init__(self, in_channels, out_channels_list, kernel_size_list,
        strides_list, padding_list):
        super(ConvSeqBranch, self).__init__()
        assert len(out_channels_list) == len(kernel_size_list)
        assert len(out_channels_list) == len(strides_list)
        assert len(out_channels_list) == len(padding_list)
        self.conv_list = nn.Sequential()
        for i, (out_channels, kernel_size, strides, padding) in enumerate(zip
            (out_channels_list, kernel_size_list, strides_list, padding_list)):
            self.conv_list.add_module('conv{}'.format(i + 1), ConvBlock(
                in_channels=in_channels, out_channels=out_channels,
                kernel_size=kernel_size, stride=strides, padding=padding))
            in_channels = out_channels

    def forward(self, x):
        x = self.conv_list(x)
        return x


class PolyConvSeqBranch(nn.Module):
    """
    PolyNet specific convolutional sequence branch block with internal PolyNet specific convolution blocks.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels_list : list of tuple of int
        List of numbers of output channels.
    kernel_size_list : list of tuple of int or tuple of tuple/list of 2 int
        List of convolution window sizes.
    strides_list : list of tuple of int or tuple of tuple/list of 2 int
        List of strides of the convolution.
    padding_list : list of tuple of int or tuple of tuple/list of 2 int
        List of padding values for convolution layers.
    num_blocks : int
        Number of blocks for PolyConv.
    """

    def __init__(self, in_channels, out_channels_list, kernel_size_list,
        strides_list, padding_list, num_blocks):
        super(PolyConvSeqBranch, self).__init__()
        assert len(out_channels_list) == len(kernel_size_list)
        assert len(out_channels_list) == len(strides_list)
        assert len(out_channels_list) == len(padding_list)
        self.conv_list = ParametricSequential()
        for i, (out_channels, kernel_size, strides, padding) in enumerate(zip
            (out_channels_list, kernel_size_list, strides_list, padding_list)):
            self.conv_list.add_module('conv{}'.format(i + 1), PolyConv(
                in_channels=in_channels, out_channels=out_channels,
                kernel_size=kernel_size, stride=strides, padding=padding,
                num_blocks=num_blocks))
            in_channels = out_channels

    def forward(self, x, index):
        x = self.conv_list(x, index=index)
        return x


class TwoWayABlock(nn.Module):
    """
    PolyNet type Inception-A block.
    """

    def __init__(self):
        super(TwoWayABlock, self).__init__()
        in_channels = 384
        self.branches = Concurrent()
        self.branches.add_module('branch1', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(32, 48, 64), kernel_size_list=(
            1, 3, 3), strides_list=(1, 1, 1), padding_list=(0, 1, 1)))
        self.branches.add_module('branch2', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(32, 32), kernel_size_list=(1, 3
            ), strides_list=(1, 1), padding_list=(0, 1)))
        self.branches.add_module('branch3', Conv1x1Branch(in_channels=
            in_channels, out_channels=32))
        self.conv = conv1x1_block(in_channels=128, out_channels=in_channels,
            activation=None)

    def forward(self, x):
        x = self.branches(x)
        x = self.conv(x)
        return x


class TwoWayBBlock(nn.Module):
    """
    PolyNet type Inception-B block.
    """

    def __init__(self):
        super(TwoWayBBlock, self).__init__()
        in_channels = 1152
        self.branches = Concurrent()
        self.branches.add_module('branch1', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(128, 160, 192),
            kernel_size_list=(1, (1, 7), (7, 1)), strides_list=(1, 1, 1),
            padding_list=(0, (0, 3), (3, 0))))
        self.branches.add_module('branch2', Conv1x1Branch(in_channels=
            in_channels, out_channels=192))
        self.conv = conv1x1_block(in_channels=384, out_channels=in_channels,
            activation=None)

    def forward(self, x):
        x = self.branches(x)
        x = self.conv(x)
        return x


class TwoWayCBlock(nn.Module):
    """
    PolyNet type Inception-C block.
    """

    def __init__(self):
        super(TwoWayCBlock, self).__init__()
        in_channels = 2048
        self.branches = Concurrent()
        self.branches.add_module('branch1', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(192, 224, 256),
            kernel_size_list=(1, (1, 3), (3, 1)), strides_list=(1, 1, 1),
            padding_list=(0, (0, 1), (1, 0))))
        self.branches.add_module('branch2', Conv1x1Branch(in_channels=
            in_channels, out_channels=192))
        self.conv = conv1x1_block(in_channels=448, out_channels=in_channels,
            activation=None)

    def forward(self, x):
        x = self.branches(x)
        x = self.conv(x)
        return x


def poly_conv1x1(in_channels, out_channels, num_blocks):
    """
    1x1 version of the PolyNet specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    num_blocks : int
        Number of blocks (BatchNorm layers).
    """
    return PolyConv(in_channels=in_channels, out_channels=out_channels,
        kernel_size=1, stride=1, padding=0, num_blocks=num_blocks)


class PolyPreBBlock(nn.Module):
    """
    PolyNet type PolyResidual-Pre-B block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    num_blocks : int
        Number of blocks (BatchNorm layers).
    """

    def __init__(self, num_blocks):
        super(PolyPreBBlock, self).__init__()
        in_channels = 1152
        self.branches = ParametricConcurrent()
        self.branches.add_module('branch1', PolyConvSeqBranch(in_channels=
            in_channels, out_channels_list=(128, 160, 192),
            kernel_size_list=(1, (1, 7), (7, 1)), strides_list=(1, 1, 1),
            padding_list=(0, (0, 3), (3, 0)), num_blocks=num_blocks))
        self.branches.add_module('branch2', poly_conv1x1(in_channels=
            in_channels, out_channels=192, num_blocks=num_blocks))

    def forward(self, x, index):
        x = self.branches(x, index=index)
        return x


class PolyPreCBlock(nn.Module):
    """
    PolyNet type PolyResidual-Pre-C block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    num_blocks : int
        Number of blocks (BatchNorm layers).
    """

    def __init__(self, num_blocks):
        super(PolyPreCBlock, self).__init__()
        in_channels = 2048
        self.branches = ParametricConcurrent()
        self.branches.add_module('branch1', PolyConvSeqBranch(in_channels=
            in_channels, out_channels_list=(192, 224, 256),
            kernel_size_list=(1, (1, 3), (3, 1)), strides_list=(1, 1, 1),
            padding_list=(0, (0, 1), (1, 0)), num_blocks=num_blocks))
        self.branches.add_module('branch2', poly_conv1x1(in_channels=
            in_channels, out_channels=192, num_blocks=num_blocks))

    def forward(self, x, index):
        x = self.branches(x, index=index)
        return x


class MultiResidual(nn.Module):
    """
    Base class for constructing N-way modules (2-way, 3-way, and so on). Actually it is for 2-way modules.

    Parameters:
    ----------
    scale : float, default 1.0
        Scale value for each residual branch.
    res_block : Module class
        Residual branch block.
    num_blocks : int
        Number of residual branches.
    """

    def __init__(self, scale, res_block, num_blocks):
        super(MultiResidual, self).__init__()
        assert num_blocks >= 1
        self.scale = scale
        self.res_blocks = nn.ModuleList([res_block() for _ in range(
            num_blocks)])
        self.activ = nn.ReLU(inplace=False)

    def forward(self, x):
        out = x
        for res_block in self.res_blocks:
            out = out + self.scale * res_block(x)
        out = self.activ(out)
        return out


class PolyResidual(nn.Module):
    """
    The other base class for constructing N-way poly-modules. Actually it is for 3-way poly-modules.

    Parameters:
    ----------
    scale : float, default 1.0
        Scale value for each residual branch.
    res_block : Module class
        Residual branch block.
    num_blocks : int
        Number of residual branches.
    pre_block : Module class
        Preliminary block.
    """

    def __init__(self, scale, res_block, num_blocks, pre_block):
        super(PolyResidual, self).__init__()
        assert num_blocks >= 1
        self.scale = scale
        self.pre_block = pre_block(num_blocks=num_blocks)
        self.res_blocks = nn.ModuleList([res_block() for _ in range(
            num_blocks)])
        self.activ = nn.ReLU(inplace=False)

    def forward(self, x):
        out = x
        for index, res_block in enumerate(self.res_blocks):
            x = self.pre_block(x, index)
            x = res_block(x)
            out = out + self.scale * x
            x = self.activ(x)
        out = self.activ(out)
        return out


class PolyBaseUnit(nn.Module):
    """
    PolyNet unit base class.

    Parameters:
    ----------
    two_way_scale : float
        Scale value for 2-way stage.
    two_way_block : Module class
        Residual branch block for 2-way-stage.
    poly_scale : float, default 0.0
        Scale value for 2-way stage.
    poly_res_block : Module class, default None
        Residual branch block for poly-stage.
    poly_pre_block : Module class, default None
        Preliminary branch block for poly-stage.
    """

    def __init__(self, two_way_scale, two_way_block, poly_scale=0.0,
        poly_res_block=None, poly_pre_block=None):
        super(PolyBaseUnit, self).__init__()
        if poly_res_block is not None:
            assert poly_scale != 0.0
            assert poly_pre_block is not None
            self.poly = PolyResidual(scale=poly_scale, res_block=
                poly_res_block, num_blocks=3, pre_block=poly_pre_block)
        else:
            assert poly_scale == 0.0
            assert poly_pre_block is None
            self.poly = None
        self.twoway = MultiResidual(scale=two_way_scale, res_block=
            two_way_block, num_blocks=2)

    def forward(self, x):
        if self.poly is not None:
            x = self.poly(x)
        x = self.twoway(x)
        return x


class ReductionAUnit(nn.Module):
    """
    PolyNet type Reduction-A unit.
    """

    def __init__(self):
        super(ReductionAUnit, self).__init__()
        in_channels = 384
        self.branches = Concurrent()
        self.branches.add_module('branch1', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(256, 256, 384),
            kernel_size_list=(1, 3, 3), strides_list=(1, 1, 2),
            padding_list=(0, 1, 0)))
        self.branches.add_module('branch2', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(384,), kernel_size_list=(3,),
            strides_list=(2,), padding_list=(0,)))
        self.branches.add_module('branch3', MaxPoolBranch())

    def forward(self, x):
        x = self.branches(x)
        return x


class ReductionBUnit(nn.Module):
    """
    PolyNet type Reduction-B unit.
    """

    def __init__(self):
        super(ReductionBUnit, self).__init__()
        in_channels = 1152
        self.branches = Concurrent()
        self.branches.add_module('branch1', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(256, 256, 256),
            kernel_size_list=(1, 3, 3), strides_list=(1, 1, 2),
            padding_list=(0, 1, 0)))
        self.branches.add_module('branch2', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(256, 256), kernel_size_list=(1,
            3), strides_list=(1, 2), padding_list=(0, 0)))
        self.branches.add_module('branch3', ConvSeqBranch(in_channels=
            in_channels, out_channels_list=(256, 384), kernel_size_list=(1,
            3), strides_list=(1, 2), padding_list=(0, 0)))
        self.branches.add_module('branch4', MaxPoolBranch())

    def forward(self, x):
        x = self.branches(x)
        return x


class PolyBlock3a(nn.Module):
    """
    PolyNet type Mixed-3a block.
    """

    def __init__(self):
        super(PolyBlock3a, self).__init__()
        self.branches = Concurrent()
        self.branches.add_module('branch1', MaxPoolBranch())
        self.branches.add_module('branch2', Conv3x3Branch(in_channels=64,
            out_channels=96))

    def forward(self, x):
        x = self.branches(x)
        return x


class PolyBlock4a(nn.Module):
    """
    PolyNet type Mixed-4a block.
    """

    def __init__(self):
        super(PolyBlock4a, self).__init__()
        self.branches = Concurrent()
        self.branches.add_module('branch1', ConvSeqBranch(in_channels=160,
            out_channels_list=(64, 96), kernel_size_list=(1, 3),
            strides_list=(1, 1), padding_list=(0, 0)))
        self.branches.add_module('branch2', ConvSeqBranch(in_channels=160,
            out_channels_list=(64, 64, 64, 96), kernel_size_list=(1, (7, 1),
            (1, 7), 3), strides_list=(1, 1, 1, 1), padding_list=(0, (3, 0),
            (0, 3), 0)))

    def forward(self, x):
        x = self.branches(x)
        return x


class PolyBlock5a(nn.Module):
    """
    PolyNet type Mixed-5a block.
    """

    def __init__(self):
        super(PolyBlock5a, self).__init__()
        self.branches = Concurrent()
        self.branches.add_module('branch1', MaxPoolBranch())
        self.branches.add_module('branch2', Conv3x3Branch(in_channels=192,
            out_channels=192))

    def forward(self, x):
        x = self.branches(x)
        return x


class PolyInitBlock(nn.Module):
    """
    PolyNet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    """

    def __init__(self, in_channels):
        super(PolyInitBlock, self).__init__()
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=32,
            stride=2, padding=0)
        self.conv2 = conv3x3_block(in_channels=32, out_channels=32, padding=0)
        self.conv3 = conv3x3_block(in_channels=32, out_channels=64)
        self.block1 = PolyBlock3a()
        self.block2 = PolyBlock4a()
        self.block3 = PolyBlock5a()

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.block1(x)
        x = self.block2(x)
        x = self.block3(x)
        return x


def poly_res_c_block():
    """
    PolyNet type PolyResidual-Res-C block.
    """
    return conv1x1_block(in_channels=448, out_channels=2048, stride=1,
        activation=None)


class PolyCUnit(PolyBaseUnit):
    """
    PolyNet type C unit.

    Parameters:
    ----------
    two_way_scale : float
        Scale value for 2-way stage.
    poly_scale : float
        Scale value for 2-way stage.
    """

    def __init__(self, two_way_scale, poly_scale):
        super(PolyCUnit, self).__init__(two_way_scale=two_way_scale,
            two_way_block=TwoWayCBlock, poly_scale=poly_scale,
            poly_res_block=poly_res_c_block, poly_pre_block=PolyPreCBlock)


def poly_res_b_block():
    """
    PolyNet type PolyResidual-Res-B block.
    """
    return conv1x1_block(in_channels=384, out_channels=1152, stride=1,
        activation=None)


class PolyBUnit(PolyBaseUnit):
    """
    PolyNet type B unit.

    Parameters:
    ----------
    two_way_scale : float
        Scale value for 2-way stage.
    poly_scale : float
        Scale value for 2-way stage.
    """

    def __init__(self, two_way_scale, poly_scale):
        super(PolyBUnit, self).__init__(two_way_scale=two_way_scale,
            two_way_block=TwoWayBBlock, poly_scale=poly_scale,
            poly_res_block=poly_res_b_block, poly_pre_block=PolyPreBBlock)


class PolyAUnit(PolyBaseUnit):
    """
    PolyNet type A unit.

    Parameters:
    ----------
    two_way_scale : float
        Scale value for 2-way stage.
    poly_scale : float
        Scale value for 2-way stage.
    """

    def __init__(self, two_way_scale, poly_scale=0.0):
        super(PolyAUnit, self).__init__(two_way_scale=two_way_scale,
            two_way_block=TwoWayABlock)
        assert poly_scale == 0.0


class PolyNet(nn.Module):
    """
    PolyNet model from 'PolyNet: A Pursuit of Structural Diversity in Very Deep Networks,'
    https://arxiv.org/abs/1611.05725.

    Parameters:
    ----------
    two_way_scales : list of list of floats
        Two way scale values for each normal unit.
    poly_scales : list of list of floats
        Three way scale values for each normal unit.
    dropout_rate : float, default 0.2
        Fraction of the input units to drop. Must be a number between 0 and 1.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (331, 331)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, two_way_scales, poly_scales, dropout_rate=0.2,
        in_channels=3, in_size=(331, 331), num_classes=1000):
        super(PolyNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        normal_units = [PolyAUnit, PolyBUnit, PolyCUnit]
        reduction_units = [ReductionAUnit, ReductionBUnit]
        self.features = nn.Sequential()
        self.features.add_module('init_block', PolyInitBlock(in_channels=
            in_channels))
        for i, (two_way_scales_per_stage, poly_scales_per_stage) in enumerate(
            zip(two_way_scales, poly_scales)):
            stage = nn.Sequential()
            for j, (two_way_scale, poly_scale) in enumerate(zip(
                two_way_scales_per_stage, poly_scales_per_stage)):
                if j == 0 and i != 0:
                    unit = reduction_units[i - 1]
                    stage.add_module('unit{}'.format(j + 1), unit())
                else:
                    unit = normal_units[i]
                    stage.add_module('unit{}'.format(j + 1), unit(
                        two_way_scale=two_way_scale, poly_scale=poly_scale))
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=9,
            stride=1))
        self.output = nn.Sequential()
        self.output.add_module('dropout', nn.Dropout(p=dropout_rate))
        self.output.add_module('fc', nn.Linear(in_features=2048,
            out_features=num_classes))
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class PreResBlock(nn.Module):
    """
    Simple PreResNet block for residual path in PreResNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    bias : bool, default False
        Whether the layer uses a bias vector.
    use_bn : bool, default True
        Whether to use BatchNorm layer.
    """

    def __init__(self, in_channels, out_channels, stride, bias=False,
        use_bn=True):
        super(PreResBlock, self).__init__()
        self.conv1 = pre_conv3x3_block(in_channels=in_channels,
            out_channels=out_channels, stride=stride, bias=bias, use_bn=
            use_bn, return_preact=True)
        self.conv2 = pre_conv3x3_block(in_channels=out_channels,
            out_channels=out_channels, bias=bias, use_bn=use_bn)

    def forward(self, x):
        x, x_pre_activ = self.conv1(x)
        x = self.conv2(x)
        return x, x_pre_activ


class PreResBottleneck(nn.Module):
    """
    PreResNet bottleneck block for residual path in PreResNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    conv1_stride : bool
        Whether to use stride in the first or the second convolution layer of the block.
    """

    def __init__(self, in_channels, out_channels, stride, conv1_stride):
        super(PreResBottleneck, self).__init__()
        mid_channels = out_channels // 4
        self.conv1 = pre_conv1x1_block(in_channels=in_channels,
            out_channels=mid_channels, stride=stride if conv1_stride else 1,
            return_preact=True)
        self.conv2 = pre_conv3x3_block(in_channels=mid_channels,
            out_channels=mid_channels, stride=1 if conv1_stride else stride)
        self.conv3 = pre_conv1x1_block(in_channels=mid_channels,
            out_channels=out_channels)

    def forward(self, x):
        x, x_pre_activ = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x, x_pre_activ


class PreResUnit(nn.Module):
    """
    PreResNet unit with residual connection.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    bias : bool, default False
        Whether the layer uses a bias vector.
    use_bn : bool, default True
        Whether to use BatchNorm layer.
    bottleneck : bool, default True
        Whether to use a bottleneck or simple block in units.
    conv1_stride : bool, default False
        Whether to use stride in the first or the second convolution layer of the block.
    """

    def __init__(self, in_channels, out_channels, stride, bias=False,
        use_bn=True, bottleneck=True, conv1_stride=False):
        super(PreResUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        if bottleneck:
            self.body = PreResBottleneck(in_channels=in_channels,
                out_channels=out_channels, stride=stride, conv1_stride=
                conv1_stride)
        else:
            self.body = PreResBlock(in_channels=in_channels, out_channels=
                out_channels, stride=stride, bias=bias, use_bn=use_bn)
        if self.resize_identity:
            self.identity_conv = conv1x1(in_channels=in_channels,
                out_channels=out_channels, stride=stride, bias=bias)

    def forward(self, x):
        identity = x
        x, x_pre_activ = self.body(x)
        if self.resize_identity:
            identity = self.identity_conv(x_pre_activ)
        x = x + identity
        return x


class PreResInitBlock(nn.Module):
    """
    PreResNet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(PreResInitBlock, self).__init__()
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn = nn.BatchNorm2d(num_features=out_channels)
        self.activ = nn.ReLU(inplace=True)
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        x = self.activ(x)
        x = self.pool(x)
        return x


class PreResActivation(nn.Module):
    """
    PreResNet pure pre-activation block without convolution layer. It's used by itself as the final block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    """

    def __init__(self, in_channels):
        super(PreResActivation, self).__init__()
        self.bn = nn.BatchNorm2d(num_features=in_channels)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.bn(x)
        x = self.activ(x)
        return x


class PreResNet(nn.Module):
    """
    PreResNet model from 'Identity Mappings in Deep Residual Networks,' https://arxiv.org/abs/1603.05027.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    conv1_stride : bool
        Whether to use stride in the first or the second convolution layer in units.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, bottleneck,
        conv1_stride, in_channels=3, in_size=(224, 224), num_classes=1000):
        super(PreResNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', PreResInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 1 if i == 0 or j != 0 else 2
                stage.add_module('unit{}'.format(j + 1), PreResUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, bottleneck=bottleneck, conv1_stride=
                    conv1_stride))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('post_activ', PreResActivation(in_channels
            =in_channels))
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class CIFARPreResNet(nn.Module):
    """
    PreResNet model for CIFAR from 'Identity Mappings in Deep Residual Networks,' https://arxiv.org/abs/1603.05027.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (32, 32)
        Spatial size of the expected input image.
    num_classes : int, default 10
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, bottleneck,
        in_channels=3, in_size=(32, 32), num_classes=10):
        super(CIFARPreResNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', conv3x3(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), PreResUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, bottleneck=bottleneck, conv1_stride=False))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('post_activ', PreResActivation(in_channels
            =in_channels))
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=8,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


def conv4x4_block(in_channels, out_channels, stride=1, padding=(1, 2, 1, 2),
    dilation=1, groups=1, bias=False, use_bn=True, bn_eps=1e-05, activation
    =lambda : nn.ReLU(inplace=True)):
    """
    4x4 version of the standard convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    padding : int, or tuple/list of 2 int, or tuple/list of 4 int, default (1, 2, 1, 2)
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    use_bn : bool, default True
        Whether to use BatchNorm layer.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function or name of activation function.
    """
    return ConvBlock(in_channels=in_channels, out_channels=out_channels,
        kernel_size=4, stride=stride, padding=padding, dilation=dilation,
        groups=groups, bias=bias, use_bn=use_bn, bn_eps=bn_eps, activation=
        activation)


class PRResBottleneck(nn.Module):
    """
    PRNet specific bottleneck block for residual path in residual unit unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for the second convolution layer in bottleneck.
    bn_eps : float
        Small float added to variance in Batch norm.
    bottleneck_factor : int, default 2
        Bottleneck factor.
    """

    def __init__(self, in_channels, out_channels, stride, padding, bn_eps,
        bottleneck_factor=2):
        super(PRResBottleneck, self).__init__()
        mid_channels = out_channels // bottleneck_factor
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            mid_channels, bn_eps=bn_eps)
        self.conv2 = conv4x4_block(in_channels=mid_channels, out_channels=
            mid_channels, stride=stride, padding=padding, bn_eps=bn_eps)
        self.conv3 = conv1x1(in_channels=mid_channels, out_channels=
            out_channels)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class PRResUnit(nn.Module):
    """
    PRNet specific ResNet unit with residual connection.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for the second convolution layer in bottleneck.
    bn_eps : float
        Small float added to variance in Batch norm.
    """

    def __init__(self, in_channels, out_channels, padding, bn_eps, stride):
        super(PRResUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        if self.resize_identity:
            self.identity_conv = conv1x1(in_channels=in_channels,
                out_channels=out_channels, stride=stride)
        self.body = PRResBottleneck(in_channels=in_channels, out_channels=
            out_channels, bn_eps=bn_eps, stride=stride, padding=padding)
        self.norm_activ = NormActivation(in_channels=out_channels, bn_eps=
            bn_eps)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        x = x + identity
        x = self.norm_activ(x)
        return x


def deconv4x4_block(in_channels, out_channels, stride=1, padding=3,
    ext_padding=(2, 1, 2, 1), out_padding=0, dilation=1, groups=1, bias=
    False, use_bn=True, bn_eps=1e-05, activation=lambda : nn.ReLU(inplace=True)
    ):
    """
    4x4 version of the standard deconvolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default (2, 1, 2, 1)
        Padding value for deconvolution layer.
    ext_padding : tuple/list of 4 int, default None
        Extra padding value for deconvolution layer.
    out_padding : int or tuple/list of 2 int
        Output padding value for deconvolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    use_bn : bool, default True
        Whether to use BatchNorm layer.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function or name of activation function.
    """
    return DeconvBlock(in_channels=in_channels, out_channels=out_channels,
        kernel_size=4, stride=stride, padding=padding, ext_padding=
        ext_padding, out_padding=out_padding, dilation=dilation, groups=
        groups, bias=bias, use_bn=use_bn, bn_eps=bn_eps, activation=activation)


class PROutputBlock(nn.Module):
    """
    PRNet specific output block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    bn_eps : float
        Small float added to variance in Batch norm.
    """

    def __init__(self, in_channels, out_channels, bn_eps):
        super(PROutputBlock, self).__init__()
        self.conv1 = deconv4x4_block(in_channels=in_channels, out_channels=
            out_channels, bn_eps=bn_eps)
        self.conv2 = deconv4x4_block(in_channels=out_channels, out_channels
            =out_channels, bn_eps=bn_eps)
        self.conv3 = deconv4x4_block(in_channels=out_channels, out_channels
            =out_channels, bn_eps=bn_eps, activation=nn.Sigmoid())

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class PRNet(nn.Module):
    """
    PRNet model from 'Joint 3D Face Reconstruction and Dense Alignment with Position Map Regression Network,'
    https://arxiv.org/abs/1803.07835.

    Parameters:
    ----------
    channels : list of list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (256, 256)
        Spatial size of the expected input image.
    num_classes : int, default 3
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, bn_eps=1e-05,
        in_channels=3, in_size=(256, 256), num_classes=3):
        super(PRNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', conv4x4_block(in_channels=
            in_channels, out_channels=init_block_channels, bn_eps=bn_eps))
        in_channels = init_block_channels
        encoder = nn.Sequential()
        for i, channels_per_stage in enumerate(channels[0]):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 else 1
                padding = (1, 2, 1, 2) if stride == 1 else 1
                stage.add_module('unit{}'.format(j + 1), PRResUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, padding=padding, bn_eps=bn_eps))
                in_channels = out_channels
            encoder.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('encoder', encoder)
        decoder = nn.Sequential()
        for i, channels_per_stage in enumerate(channels[1]):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                padding = 3 if stride == 1 else 1
                ext_padding = (2, 1, 2, 1) if stride == 1 else None
                stage.add_module('unit{}'.format(j + 1), deconv4x4_block(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, padding=padding, ext_padding=ext_padding,
                    bn_eps=bn_eps))
                in_channels = out_channels
            decoder.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('decoder', decoder)
        self.output = PROutputBlock(in_channels=in_channels, out_channels=
            num_classes, bn_eps=bn_eps)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                nn.init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = self.output(x)
        return x


class ProxylessBlock(nn.Module):
    """
    ProxylessNAS block for residual path in ProxylessNAS unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int
        Convolution window size.
    stride : int
        Strides of the convolution.
    bn_eps : float
        Small float added to variance in Batch norm.
    expansion : int
        Expansion ratio.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        bn_eps, expansion):
        super(ProxylessBlock, self).__init__()
        self.use_bc = expansion > 1
        mid_channels = in_channels * expansion
        if self.use_bc:
            self.bc_conv = conv1x1_block(in_channels=in_channels,
                out_channels=mid_channels, bn_eps=bn_eps, activation='relu6')
        padding = (kernel_size - 1) // 2
        self.dw_conv = ConvBlock(in_channels=mid_channels, out_channels=
            mid_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, groups=mid_channels, bn_eps=bn_eps, activation='relu6')
        self.pw_conv = conv1x1_block(in_channels=mid_channels, out_channels
            =out_channels, bn_eps=bn_eps, activation=None)

    def forward(self, x):
        if self.use_bc:
            x = self.bc_conv(x)
        x = self.dw_conv(x)
        x = self.pw_conv(x)
        return x


class ProxylessUnit(nn.Module):
    """
    ProxylessNAS unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int
        Convolution window size for body block.
    stride : int
        Strides of the convolution.
    bn_eps : float
        Small float added to variance in Batch norm.
    expansion : int
        Expansion ratio for body block.
    residual : bool
        Whether to use residual branch.
    shortcut : bool
        Whether to use identity branch.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        bn_eps, expansion, residual, shortcut):
        super(ProxylessUnit, self).__init__()
        assert residual or shortcut
        self.residual = residual
        self.shortcut = shortcut
        if self.residual:
            self.body = ProxylessBlock(in_channels=in_channels,
                out_channels=out_channels, kernel_size=kernel_size, stride=
                stride, bn_eps=bn_eps, expansion=expansion)

    def forward(self, x):
        if not self.residual:
            return x
        if not self.shortcut:
            return self.body(x)
        identity = x
        x = self.body(x)
        x = identity + x
        return x


class ProxylessNAS(nn.Module):
    """
    ProxylessNAS model from 'ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware,'
    https://arxiv.org/abs/1812.00332.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    final_block_channels : int
        Number of output channels for the final unit.
    residuals : list of list of int
        Whether to use residual branch in units.
    shortcuts : list of list of int
        Whether to use identity branch in units.
    kernel_sizes : list of list of int
        Convolution window size for each units.
    expansions : list of list of int
        Expansion ratio for each units.
    bn_eps : float, default 1e-3
        Small float added to variance in Batch norm.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, final_block_channels,
        residuals, shortcuts, kernel_sizes, expansions, bn_eps=0.001,
        in_channels=3, in_size=(224, 224), num_classes=1000):
        super(ProxylessNAS, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', conv3x3_block(in_channels=
            in_channels, out_channels=init_block_channels, stride=2, bn_eps
            =bn_eps, activation='relu6'))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            residuals_per_stage = residuals[i]
            shortcuts_per_stage = shortcuts[i]
            kernel_sizes_per_stage = kernel_sizes[i]
            expansions_per_stage = expansions[i]
            for j, out_channels in enumerate(channels_per_stage):
                residual = residuals_per_stage[j] == 1
                shortcut = shortcuts_per_stage[j] == 1
                kernel_size = kernel_sizes_per_stage[j]
                expansion = expansions_per_stage[j]
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), ProxylessUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    kernel_size=kernel_size, stride=stride, bn_eps=bn_eps,
                    expansion=expansion, residual=residual, shortcut=shortcut))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_block', conv1x1_block(in_channels=
            in_channels, out_channels=final_block_channels, bn_eps=bn_eps,
            activation='relu6'))
        in_channels = final_block_channels
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class PSPFinalBlock(nn.Module):
    """
    PSPNet final block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    bottleneck_factor : int, default 4
        Bottleneck factor.
    """

    def __init__(self, in_channels, out_channels, bottleneck_factor=4):
        super(PSPFinalBlock, self).__init__()
        assert in_channels % bottleneck_factor == 0
        mid_channels = in_channels // bottleneck_factor
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            mid_channels)
        self.dropout = nn.Dropout(p=0.1, inplace=False)
        self.conv2 = conv1x1(in_channels=mid_channels, out_channels=
            out_channels, bias=True)

    def forward(self, x, out_size):
        x = self.conv1(x)
        x = self.dropout(x)
        x = self.conv2(x)
        x = F.interpolate(x, size=out_size, mode='bilinear', align_corners=True
            )
        return x


class PyramidPoolingBranch(nn.Module):
    """
    Pyramid Pooling branch.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    pool_out_size : int
        Target output size of the image.
    upscale_out_size : tuple of 2 int
        Spatial size of output image for the bilinear upsampling operation.
    """

    def __init__(self, in_channels, out_channels, pool_out_size,
        upscale_out_size):
        super(PyramidPoolingBranch, self).__init__()
        self.upscale_out_size = upscale_out_size
        self.pool = nn.AdaptiveAvgPool2d(pool_out_size)
        self.conv = conv1x1_block(in_channels=in_channels, out_channels=
            out_channels)

    def forward(self, x):
        in_size = (self.upscale_out_size if self.upscale_out_size is not
            None else x.shape[2:])
        x = self.pool(x)
        x = self.conv(x)
        x = F.interpolate(x, size=in_size, mode='bilinear', align_corners=True)
        return x


class PyramidPooling(nn.Module):
    """
    Pyramid Pooling module.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    upscale_out_size : tuple of 2 int
        Spatial size of the input tensor for the bilinear upsampling operation.
    """

    def __init__(self, in_channels, upscale_out_size):
        super(PyramidPooling, self).__init__()
        pool_out_sizes = [1, 2, 3, 6]
        assert len(pool_out_sizes) == 4
        assert in_channels % 4 == 0
        mid_channels = in_channels // 4
        self.branches = Concurrent()
        self.branches.add_module('branch1', Identity())
        for i, pool_out_size in enumerate(pool_out_sizes):
            self.branches.add_module('branch{}'.format(i + 2),
                PyramidPoolingBranch(in_channels=in_channels, out_channels=
                mid_channels, pool_out_size=pool_out_size, upscale_out_size
                =upscale_out_size))

    def forward(self, x):
        x = self.branches(x)
        return x


class PSPNet(nn.Module):
    """
    PSPNet model from 'Pyramid Scene Parsing Network,' https://arxiv.org/abs/1612.01105.

    Parameters:
    ----------
    backbone : nn.Sequential
        Feature extractor.
    backbone_out_channels : int, default 2048
        Number of output channels form feature extractor.
    aux : bool, default False
        Whether to output an auxiliary result.
    fixed_size : bool, default True
        Whether to expect fixed spatial size of input image.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (480, 480)
        Spatial size of the expected input image.
    num_classes : int, default 21
        Number of segmentation classes.
    """

    def __init__(self, backbone, backbone_out_channels=2048, aux=False,
        fixed_size=True, in_channels=3, in_size=(480, 480), num_classes=21):
        super(PSPNet, self).__init__()
        assert in_channels > 0
        assert in_size[0] % 8 == 0 and in_size[1] % 8 == 0
        self.in_size = in_size
        self.num_classes = num_classes
        self.aux = aux
        self.fixed_size = fixed_size
        self.backbone = backbone
        pool_out_size = (self.in_size[0] // 8, self.in_size[1] // 8
            ) if fixed_size else None
        self.pool = PyramidPooling(in_channels=backbone_out_channels,
            upscale_out_size=pool_out_size)
        pool_out_channels = 2 * backbone_out_channels
        self.final_block = PSPFinalBlock(in_channels=pool_out_channels,
            out_channels=num_classes, bottleneck_factor=8)
        if self.aux:
            aux_out_channels = backbone_out_channels // 2
            self.aux_block = PSPFinalBlock(in_channels=aux_out_channels,
                out_channels=num_classes, bottleneck_factor=4)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                nn.init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)

    def forward(self, x):
        in_size = self.in_size if self.fixed_size else x.shape[2:]
        x, y = self.backbone(x)
        x = self.pool(x)
        x = self.final_block(x, in_size)
        if self.aux:
            y = self.aux_block(y, in_size)
            return x, y
        else:
            return x


class PyrBlock(nn.Module):
    """
    Simple PyramidNet block for residual path in PyramidNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    """

    def __init__(self, in_channels, out_channels, stride):
        super(PyrBlock, self).__init__()
        self.conv1 = pre_conv3x3_block(in_channels=in_channels,
            out_channels=out_channels, stride=stride, activate=False)
        self.conv2 = pre_conv3x3_block(in_channels=out_channels,
            out_channels=out_channels)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class PyrBottleneck(nn.Module):
    """
    PyramidNet bottleneck block for residual path in PyramidNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    """

    def __init__(self, in_channels, out_channels, stride):
        super(PyrBottleneck, self).__init__()
        mid_channels = out_channels // 4
        self.conv1 = pre_conv1x1_block(in_channels=in_channels,
            out_channels=mid_channels, activate=False)
        self.conv2 = pre_conv3x3_block(in_channels=mid_channels,
            out_channels=mid_channels, stride=stride)
        self.conv3 = pre_conv1x1_block(in_channels=mid_channels,
            out_channels=out_channels)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class PyrUnit(nn.Module):
    """
    PyramidNet unit with residual connection.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    """

    def __init__(self, in_channels, out_channels, stride, bottleneck):
        super(PyrUnit, self).__init__()
        assert out_channels >= in_channels
        self.resize_identity = stride != 1
        self.identity_pad_width = 0, 0, 0, 0, 0, out_channels - in_channels
        if bottleneck:
            self.body = PyrBottleneck(in_channels=in_channels, out_channels
                =out_channels, stride=stride)
        else:
            self.body = PyrBlock(in_channels=in_channels, out_channels=
                out_channels, stride=stride)
        self.bn = nn.BatchNorm2d(num_features=out_channels)
        if self.resize_identity:
            self.identity_pool = nn.AvgPool2d(kernel_size=2, stride=stride,
                ceil_mode=True)

    def forward(self, x):
        identity = x
        x = self.body(x)
        x = self.bn(x)
        if self.resize_identity:
            identity = self.identity_pool(identity)
        identity = F.pad(identity, pad=self.identity_pad_width)
        x = x + identity
        return x


class PyrInitBlock(nn.Module):
    """
    PyramidNet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(PyrInitBlock, self).__init__()
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn = nn.BatchNorm2d(num_features=out_channels)
        self.activ = nn.ReLU(inplace=True)
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        x = self.activ(x)
        x = self.pool(x)
        return x


class PyramidNet(nn.Module):
    """
    PyramidNet model from 'Deep Pyramidal Residual Networks,' https://arxiv.org/abs/1610.02915.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, bottleneck,
        in_channels=3, in_size=(224, 224), num_classes=1000):
        super(PyramidNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', PyrInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 1 if i == 0 or j != 0 else 2
                stage.add_module('unit{}'.format(j + 1), PyrUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, bottleneck=bottleneck))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('post_activ', PreResActivation(in_channels
            =in_channels))
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class CIFARPyramidNet(nn.Module):
    """
    PyramidNet model for CIFAR from 'Deep Pyramidal Residual Networks,' https://arxiv.org/abs/1610.02915.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (32, 32)
        Spatial size of the expected input image.
    num_classes : int, default 10
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, bottleneck,
        in_channels=3, in_size=(32, 32), num_classes=10):
        super(CIFARPyramidNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', conv3x3_block(in_channels=
            in_channels, out_channels=init_block_channels, activation=None))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 1 if i == 0 or j != 0 else 2
                stage.add_module('unit{}'.format(j + 1), PyrUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, bottleneck=bottleneck))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('post_activ', PreResActivation(in_channels
            =in_channels))
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=8,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class PreResBottleneck(nn.Module):
    """
    PreResNet bottleneck block for residual path in PreResNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    """

    def __init__(self, in_channels, out_channels, stride):
        super(PreResBottleneck, self).__init__()
        mid_channels = out_channels // 4
        self.conv1 = pre_conv1x1_block(in_channels=in_channels,
            out_channels=mid_channels, return_preact=True)
        self.conv2 = pre_conv3x3_block(in_channels=mid_channels,
            out_channels=mid_channels, stride=stride)
        self.conv3 = pre_conv1x1_block(in_channels=mid_channels,
            out_channels=out_channels)

    def forward(self, x):
        x, x_pre_activ = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x, x_pre_activ


class ResBlock(nn.Module):
    """
    Residual block with pre-activation.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    """

    def __init__(self, in_channels, out_channels, stride=1):
        super(ResBlock, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        self.body = PreResBottleneck(in_channels=in_channels, out_channels=
            out_channels, stride=stride)
        if self.resize_identity:
            self.identity_conv = conv1x1(in_channels=in_channels,
                out_channels=out_channels, stride=stride)

    def forward(self, x):
        identity = x
        x, x_pre_activ = self.body(x)
        if self.resize_identity:
            identity = self.identity_conv(x_pre_activ)
        x = x + identity
        return x


class InterpolationBlock(nn.Module):
    """
    Interpolation block.

    Parameters:
    ----------
    scale_factor : float
        Multiplier for spatial size.
    """

    def __init__(self, scale_factor):
        super(InterpolationBlock, self).__init__()
        self.scale_factor = scale_factor

    def forward(self, x):
        return F.interpolate(input=x, scale_factor=self.scale_factor, mode=
            'bilinear', align_corners=True)


class DoubleSkipBlock(nn.Module):
    """
    Double skip connection block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(DoubleSkipBlock, self).__init__()
        self.skip1 = ResBlock(in_channels=in_channels, out_channels=
            out_channels)

    def forward(self, x):
        x = x + self.skip1(x)
        return x


class ResBlockSequence(nn.Module):
    """
    Sequence of residual blocks with pre-activation.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    length : int
        Length of sequence.
    """

    def __init__(self, in_channels, out_channels, length):
        super(ResBlockSequence, self).__init__()
        self.blocks = nn.Sequential()
        for i in range(length):
            self.blocks.add_module('block{}'.format(i + 1), ResBlock(
                in_channels=in_channels, out_channels=out_channels))

    def forward(self, x):
        x = self.blocks(x)
        return x


class DownAttBlock(nn.Module):
    """
    Down sub-block for hourglass of attention block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    length : int
        Length of residual blocks list.
    """

    def __init__(self, in_channels, out_channels, length):
        super(DownAttBlock, self).__init__()
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.res_blocks = ResBlockSequence(in_channels=in_channels,
            out_channels=out_channels, length=length)

    def forward(self, x):
        x = self.pool(x)
        x = self.res_blocks(x)
        return x


class UpAttBlock(nn.Module):
    """
    Up sub-block for hourglass of attention block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    length : int
        Length of residual blocks list.
    scale_factor : float
        Multiplier for spatial size.
    """

    def __init__(self, in_channels, out_channels, length, scale_factor):
        super(UpAttBlock, self).__init__()
        self.res_blocks = ResBlockSequence(in_channels=in_channels,
            out_channels=out_channels, length=length)
        self.upsample = InterpolationBlock(scale_factor)

    def forward(self, x):
        x = self.res_blocks(x)
        x = self.upsample(x)
        return x


class MiddleAttBlock(nn.Module):
    """
    Middle sub-block for attention block.

    Parameters:
    ----------
    channels : int
        Number of input/output channels.
    """

    def __init__(self, channels):
        super(MiddleAttBlock, self).__init__()
        self.conv1 = pre_conv1x1_block(in_channels=channels, out_channels=
            channels)
        self.conv2 = pre_conv1x1_block(in_channels=channels, out_channels=
            channels)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.sigmoid(x)
        return x


class AttBlock(nn.Module):
    """
    Attention block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    hourglass_depth : int
        Depth of hourglass block.
    att_scales : list of int
        Attention block specific scales.
    """

    def __init__(self, in_channels, out_channels, hourglass_depth, att_scales):
        super(AttBlock, self).__init__()
        assert len(att_scales) == 3
        scale_factor = 2
        scale_p, scale_t, scale_r = att_scales
        self.init_blocks = ResBlockSequence(in_channels=in_channels,
            out_channels=out_channels, length=scale_p)
        down_seq = nn.Sequential()
        up_seq = nn.Sequential()
        skip_seq = nn.Sequential()
        for i in range(hourglass_depth):
            down_seq.add_module('down{}'.format(i + 1), DownAttBlock(
                in_channels=in_channels, out_channels=out_channels, length=
                scale_r))
            up_seq.add_module('up{}'.format(i + 1), UpAttBlock(in_channels=
                in_channels, out_channels=out_channels, length=scale_r,
                scale_factor=scale_factor))
            if i == 0:
                skip_seq.add_module('skip1', ResBlockSequence(in_channels=
                    in_channels, out_channels=out_channels, length=scale_t))
            else:
                skip_seq.add_module('skip{}'.format(i + 1), DoubleSkipBlock
                    (in_channels=in_channels, out_channels=out_channels))
        self.hg = Hourglass(down_seq=down_seq, up_seq=up_seq, skip_seq=
            skip_seq, return_first_skip=True)
        self.middle_block = MiddleAttBlock(channels=out_channels)
        self.final_block = ResBlock(in_channels=in_channels, out_channels=
            out_channels)

    def forward(self, x):
        x = self.init_blocks(x)
        x, y = self.hg(x)
        x = self.middle_block(x)
        x = (1 + x) * y
        x = self.final_block(x)
        return x


class ResAttInitBlock(nn.Module):
    """
    ResAttNet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(ResAttInitBlock, self).__init__()
        self.conv = conv7x7_block(in_channels=in_channels, out_channels=
            out_channels, stride=2)
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

    def forward(self, x):
        x = self.conv(x)
        x = self.pool(x)
        return x


class PreActivation(nn.Module):
    """
    Pre-activation block without convolution layer. It's used by itself as the final block in PreResNet.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    """

    def __init__(self, in_channels):
        super(PreActivation, self).__init__()
        self.bn = nn.BatchNorm2d(num_features=in_channels)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.bn(x)
        x = self.activ(x)
        return x


class ResAttNet(nn.Module):
    """
    ResAttNet model from 'Residual Attention Network for Image Classification,' https://arxiv.org/abs/1704.06904.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    attentions : list of list of int
        Whether to use a attention unit or residual one.
    att_scales : list of int
        Attention block specific scales.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, attentions,
        att_scales, in_channels=3, in_size=(224, 224), num_classes=1000):
        super(ResAttNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', ResAttInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            hourglass_depth = len(channels) - 1 - i
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 1 if i == 0 or j != 0 else 2
                if attentions[i][j]:
                    stage.add_module('unit{}'.format(j + 1), AttBlock(
                        in_channels=in_channels, out_channels=out_channels,
                        hourglass_depth=hourglass_depth, att_scales=att_scales)
                        )
                else:
                    stage.add_module('unit{}'.format(j + 1), ResBlock(
                        in_channels=in_channels, out_channels=out_channels,
                        stride=stride))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('post_activ', PreActivation(in_channels=
            in_channels))
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class ResDropResUnit(nn.Module):
    """
    ResDrop-ResNet unit with residual connection.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    life_prob : float
        Residual branch life probability.
    """

    def __init__(self, in_channels, out_channels, stride, bottleneck, life_prob
        ):
        super(ResDropResUnit, self).__init__()
        self.life_prob = life_prob
        self.resize_identity = in_channels != out_channels or stride != 1
        body_class = ResBottleneck if bottleneck else ResBlock
        self.body = body_class(in_channels=in_channels, out_channels=
            out_channels, stride=stride)
        if self.resize_identity:
            self.identity_conv = conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride, activation=None)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        if self.training:
            b = torch.bernoulli(torch.full((1,), self.life_prob, dtype=x.
                dtype, device=x.device))
            x = float(b) / self.life_prob * x
        x = x + identity
        x = self.activ(x)
        return x


class CIFARResDropResNet(nn.Module):
    """
    ResDrop-ResNet model for CIFAR from 'Deep Networks with Stochastic Depth,' https://arxiv.org/abs/1603.09382.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    life_probs : list of float
        Residual branch life probability for each unit.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (32, 32)
        Spatial size of the expected input image.
    num_classes : int, default 10
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, bottleneck,
        life_probs, in_channels=3, in_size=(32, 32), num_classes=10):
        super(CIFARResDropResNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', conv3x3_block(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        k = 0
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), ResDropResUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, bottleneck=bottleneck, life_prob=
                    life_probs[k]))
                in_channels = out_channels
                k += 1
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=8,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class ResBlock(nn.Module):
    """
    Simple ResNet block for residual path in ResNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    bias : bool, default False
        Whether the layer uses a bias vector.
    use_bn : bool, default True
        Whether to use BatchNorm layer.
    """

    def __init__(self, in_channels, out_channels, stride, bias=False,
        use_bn=True):
        super(ResBlock, self).__init__()
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            out_channels, stride=stride, bias=bias, use_bn=use_bn)
        self.conv2 = conv3x3_block(in_channels=out_channels, out_channels=
            out_channels, bias=bias, use_bn=use_bn, activation=None)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class ResBottleneck(nn.Module):
    """
    ResNet bottleneck block for residual path in ResNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 1
        Padding value for the second convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for the second convolution layer.
    conv1_stride : bool, default False
        Whether to use stride in the first or the second convolution layer of the block.
    bottleneck_factor : int, default 4
        Bottleneck factor.
    """

    def __init__(self, in_channels, out_channels, stride, padding=1,
        dilation=1, conv1_stride=False, bottleneck_factor=4):
        super(ResBottleneck, self).__init__()
        mid_channels = out_channels // bottleneck_factor
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            mid_channels, stride=stride if conv1_stride else 1)
        self.conv2 = conv3x3_block(in_channels=mid_channels, out_channels=
            mid_channels, stride=1 if conv1_stride else stride, padding=
            padding, dilation=dilation)
        self.conv3 = conv1x1_block(in_channels=mid_channels, out_channels=
            out_channels, activation=None)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class ResUnit(nn.Module):
    """
    ResNet unit with residual connection.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 1
        Padding value for the second convolution layer in bottleneck.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for the second convolution layer in bottleneck.
    bias : bool, default False
        Whether the layer uses a bias vector.
    use_bn : bool, default True
        Whether to use BatchNorm layer.
    bottleneck : bool, default True
        Whether to use a bottleneck or simple block in units.
    conv1_stride : bool, default False
        Whether to use stride in the first or the second convolution layer of the block.
    """

    def __init__(self, in_channels, out_channels, stride, padding=1,
        dilation=1, bias=False, use_bn=True, bottleneck=True, conv1_stride=
        False):
        super(ResUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        if bottleneck:
            self.body = ResBottleneck(in_channels=in_channels, out_channels
                =out_channels, stride=stride, padding=padding, dilation=
                dilation, conv1_stride=conv1_stride)
        else:
            self.body = ResBlock(in_channels=in_channels, out_channels=
                out_channels, stride=stride, bias=bias, use_bn=use_bn)
        if self.resize_identity:
            self.identity_conv = conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride, bias=bias, use_bn
                =use_bn, activation=None)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        x = x + identity
        x = self.activ(x)
        return x


class ResInitBlock(nn.Module):
    """
    ResNet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(ResInitBlock, self).__init__()
        self.conv = conv7x7_block(in_channels=in_channels, out_channels=
            out_channels, stride=2)
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

    def forward(self, x):
        x = self.conv(x)
        x = self.pool(x)
        return x


class ResNet(nn.Module):
    """
    ResNet model from 'Deep Residual Learning for Image Recognition,' https://arxiv.org/abs/1512.03385.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    conv1_stride : bool
        Whether to use stride in the first or the second convolution layer in units.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, bottleneck,
        conv1_stride, in_channels=3, in_size=(224, 224), num_classes=1000):
        super(ResNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', ResInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), ResUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, bottleneck=bottleneck, conv1_stride=
                    conv1_stride))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class CIFARResNet(nn.Module):
    """
    ResNet model for CIFAR from 'Deep Residual Learning for Image Recognition,' https://arxiv.org/abs/1512.03385.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (32, 32)
        Spatial size of the expected input image.
    num_classes : int, default 10
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, bottleneck,
        in_channels=3, in_size=(32, 32), num_classes=10):
        super(CIFARResNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', conv3x3_block(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), ResUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, bottleneck=bottleneck, conv1_stride=False))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=8,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class ResADownBlock(nn.Module):
    """
    ResNet(A) downsample block for the identity branch of a residual unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for the second convolution layer in bottleneck.
    """

    def __init__(self, in_channels, out_channels, stride, dilation=1):
        super(ResADownBlock, self).__init__()
        self.pool = nn.AvgPool2d(kernel_size=stride if dilation == 1 else 1,
            stride=stride if dilation == 1 else 1, ceil_mode=True,
            count_include_pad=False)
        self.conv = conv1x1_block(in_channels=in_channels, out_channels=
            out_channels, activation=None)

    def forward(self, x):
        x = self.pool(x)
        x = self.conv(x)
        return x


class ResAUnit(nn.Module):
    """
    ResNet(A) unit with residual connection.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 1
        Padding value for the second convolution layer in bottleneck.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for the second convolution layer in bottleneck.
    bottleneck : bool, default True
        Whether to use a bottleneck or simple block in units.
    conv1_stride : bool, default False
        Whether to use stride in the first or the second convolution layer of the block.
    """

    def __init__(self, in_channels, out_channels, stride, padding=1,
        dilation=1, bottleneck=True, conv1_stride=False):
        super(ResAUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        if bottleneck:
            self.body = ResBottleneck(in_channels=in_channels, out_channels
                =out_channels, stride=stride, padding=padding, dilation=
                dilation, conv1_stride=conv1_stride)
        else:
            self.body = ResBlock(in_channels=in_channels, out_channels=
                out_channels, stride=stride)
        if self.resize_identity:
            self.identity_block = ResADownBlock(in_channels=in_channels,
                out_channels=out_channels, stride=stride, dilation=dilation)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_block(x)
        else:
            identity = x
        x = self.body(x)
        x = x + identity
        x = self.activ(x)
        return x


class ResNetA(nn.Module):
    """
    ResNet(A) with average downsampling model from 'Deep Residual Learning for Image Recognition,'
    https://arxiv.org/abs/1512.03385.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    conv1_stride : bool
        Whether to use stride in the first or the second convolution layer in units.
    dilated : bool, default False
        Whether to use dilation.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, bottleneck,
        conv1_stride, dilated=False, in_channels=3, in_size=(224, 224),
        num_classes=1000):
        super(ResNetA, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', SEInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                if dilated:
                    stride = 2 if j == 0 and i != 0 and i < 2 else 1
                    dilation = 2 ** max(0, i - 1 - int(j == 0))
                else:
                    stride = 2 if j == 0 and i != 0 else 1
                    dilation = 1
                stage.add_module('unit{}'.format(j + 1), ResAUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, padding=dilation, dilation=dilation,
                    bottleneck=bottleneck, conv1_stride=conv1_stride))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AdaptiveAvgPool2d(
            output_size=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                nn.init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class ResNetD(nn.Module):
    """
    ResNet(D) with dilation model from 'Deep Residual Learning for Image Recognition,' https://arxiv.org/abs/1512.03385.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    conv1_stride : bool
        Whether to use stride in the first or the second convolution layer in units.
    ordinary_init : bool, default False
        Whether to use original initial block or SENet one.
    bends : tuple of int, default None
        Numbers of bends for multiple output.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, bottleneck,
        conv1_stride, ordinary_init=False, bends=None, in_channels=3,
        in_size=(224, 224), num_classes=1000):
        super(ResNetD, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.multi_output = bends is not None
        self.features = MultiOutputSequential()
        if ordinary_init:
            self.features.add_module('init_block', ResInitBlock(in_channels
                =in_channels, out_channels=init_block_channels))
        else:
            init_block_channels = 2 * init_block_channels
            self.features.add_module('init_block', SEInitBlock(in_channels=
                in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 and i < 2 else 1
                dilation = 2 ** max(0, i - 1 - int(j == 0))
                stage.add_module('unit{}'.format(j + 1), ResUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, padding=dilation, dilation=dilation,
                    bottleneck=bottleneck, conv1_stride=conv1_stride))
                in_channels = out_channels
            if self.multi_output and i + 1 in bends:
                stage.do_output = True
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AdaptiveAvgPool2d(
            output_size=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        outs = self.features(x)
        x = outs[0]
        x = x.view(x.size(0), -1)
        x = self.output(x)
        if self.multi_output:
            return [x] + outs[1:]
        else:
            return x


class ResNeXtBottleneck(nn.Module):
    """
    ResNeXt bottleneck block for residual path in ResNeXt unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    cardinality: int
        Number of groups.
    bottleneck_width: int
        Width of bottleneck block.
    bottleneck_factor : int, default 4
        Bottleneck factor.
    """

    def __init__(self, in_channels, out_channels, stride, cardinality,
        bottleneck_width, bottleneck_factor=4):
        super(ResNeXtBottleneck, self).__init__()
        mid_channels = out_channels // bottleneck_factor
        D = int(math.floor(mid_channels * (bottleneck_width / 64.0)))
        group_width = cardinality * D
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            group_width)
        self.conv2 = conv3x3_block(in_channels=group_width, out_channels=
            group_width, stride=stride, groups=cardinality)
        self.conv3 = conv1x1_block(in_channels=group_width, out_channels=
            out_channels, activation=None)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class ResNeXtUnit(nn.Module):
    """
    ResNeXt unit with residual connection.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    cardinality: int
        Number of groups.
    bottleneck_width: int
        Width of bottleneck block.
    """

    def __init__(self, in_channels, out_channels, stride, cardinality,
        bottleneck_width):
        super(ResNeXtUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        self.body = ResNeXtBottleneck(in_channels=in_channels, out_channels
            =out_channels, stride=stride, cardinality=cardinality,
            bottleneck_width=bottleneck_width)
        if self.resize_identity:
            self.identity_conv = conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride, activation=None)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        x = x + identity
        x = self.activ(x)
        return x


class ResNeXt(nn.Module):
    """
    ResNeXt model from 'Aggregated Residual Transformations for Deep Neural Networks,' http://arxiv.org/abs/1611.05431.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    cardinality: int
        Number of groups.
    bottleneck_width: int
        Width of bottleneck block.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, cardinality,
        bottleneck_width, in_channels=3, in_size=(224, 224), num_classes=1000):
        super(ResNeXt, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', ResInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), ResNeXtUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, cardinality=cardinality,
                    bottleneck_width=bottleneck_width))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class CIFARResNeXt(nn.Module):
    """
    ResNeXt model for CIFAR from 'Aggregated Residual Transformations for Deep Neural Networks,'
    http://arxiv.org/abs/1611.05431.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    cardinality: int
        Number of groups.
    bottleneck_width: int
        Width of bottleneck block.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (32, 32)
        Spatial size of the expected input image.
    num_classes : int, default 10
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, cardinality,
        bottleneck_width, in_channels=3, in_size=(32, 32), num_classes=10):
        super(CIFARResNeXt, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', conv3x3_block(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), ResNeXtUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, cardinality=cardinality,
                    bottleneck_width=bottleneck_width))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=8,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


use_context_mans = int(torch.__version__[0]) * 100 + int(torch.__version__[2]
    ) - (1 if 'a' in torch.__version__ else 0) > 3


class RevResBlock(nn.Module):
    """
    Simple RevNet block for residual path in RevNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    preactivate : bool
        Whether use pre-activation for the first convolution block.
    """

    def __init__(self, in_channels, out_channels, stride, preactivate):
        super(RevResBlock, self).__init__()
        if preactivate:
            self.conv1 = pre_conv3x3_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride)
        else:
            self.conv1 = conv3x3(in_channels=in_channels, out_channels=
                out_channels, stride=stride)
        self.conv2 = pre_conv3x3_block(in_channels=out_channels,
            out_channels=out_channels)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class RevResBottleneck(nn.Module):
    """
    RevNet bottleneck block for residual path in RevNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    preactivate : bool
        Whether use pre-activation for the first convolution block.
    bottleneck_factor : int, default 4
        Bottleneck factor.
    """

    def __init__(self, in_channels, out_channels, stride, preactivate,
        bottleneck_factor=4):
        super(RevResBottleneck, self).__init__()
        mid_channels = out_channels // bottleneck_factor
        if preactivate:
            self.conv1 = pre_conv1x1_block(in_channels=in_channels,
                out_channels=mid_channels)
        else:
            self.conv1 = conv1x1(in_channels=in_channels, out_channels=
                mid_channels)
        self.conv2 = pre_conv3x3_block(in_channels=mid_channels,
            out_channels=mid_channels, stride=stride)
        self.conv3 = pre_conv1x1_block(in_channels=mid_channels,
            out_channels=out_channels)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class RevUnit(nn.Module):
    """
    RevNet unit with residual connection.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    preactivate : bool
        Whether use pre-activation for the first convolution block.
    """

    def __init__(self, in_channels, out_channels, stride, bottleneck,
        preactivate):
        super(RevUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        body_class = RevResBottleneck if bottleneck else RevResBlock
        if not self.resize_identity and stride == 1:
            assert in_channels % 2 == 0
            assert out_channels % 2 == 0
            in_channels2 = in_channels // 2
            out_channels2 = out_channels // 2
            gm = body_class(in_channels=in_channels2, out_channels=
                out_channels2, stride=1, preactivate=preactivate)
            fm = body_class(in_channels=in_channels2, out_channels=
                out_channels2, stride=1, preactivate=preactivate)
            self.body = ReversibleBlock(gm, fm)
        else:
            self.body = body_class(in_channels=in_channels, out_channels=
                out_channels, stride=stride, preactivate=preactivate)
        if self.resize_identity:
            self.identity_conv = conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride, activation=None)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
            x = self.body(x)
            x = x + identity
        else:
            x = self.body(x)
        return x


class RevPostActivation(nn.Module):
    """
    RevNet specific post-activation block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    """

    def __init__(self, in_channels):
        super(RevPostActivation, self).__init__()
        self.bn = nn.BatchNorm2d(num_features=in_channels)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.bn(x)
        x = self.activ(x)
        return x


class RevNet(nn.Module):
    """
    RevNet model from 'The Reversible Residual Network: Backpropagation Without Storing Activations,'
    https://arxiv.org/abs/1707.04585.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, bottleneck,
        in_channels=3, in_size=(224, 224), num_classes=1000):
        super(RevNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', conv3x3_block(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                preactivate = j != 0 or i != 0
                stage.add_module('unit{}'.format(j + 1), RevUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, bottleneck=bottleneck, preactivate=
                    preactivate))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_postactiv', RevPostActivation(
            in_channels=in_channels))
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=56,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class PostActivation(nn.Module):
    """
    Pure pre-activation block without convolution layer.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    """

    def __init__(self, in_channels):
        super(PostActivation, self).__init__()
        self.bn = nn.BatchNorm2d(num_features=in_channels)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.bn(x)
        x = self.activ(x)
        return x


class RiRUnit(nn.Module):
    """
    RiR unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    """

    def __init__(self, in_channels, out_channels, stride):
        super(RiRUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        self.res_pass_conv = conv3x3(in_channels=in_channels, out_channels=
            out_channels, stride=stride)
        self.trans_pass_conv = conv3x3(in_channels=in_channels,
            out_channels=out_channels, stride=stride)
        self.res_cross_conv = conv3x3(in_channels=in_channels, out_channels
            =out_channels, stride=stride)
        self.trans_cross_conv = conv3x3(in_channels=in_channels,
            out_channels=out_channels, stride=stride)
        self.res_postactiv = PostActivation(in_channels=out_channels)
        self.trans_postactiv = PostActivation(in_channels=out_channels)
        if self.resize_identity:
            self.identity_conv = conv1x1(in_channels=in_channels,
                out_channels=out_channels, stride=stride)

    def forward(self, x_res, x_trans):
        if self.resize_identity:
            x_res_identity = self.identity_conv(x_res)
        else:
            x_res_identity = x_res
        y_res = self.res_cross_conv(x_res)
        y_trans = self.trans_cross_conv(x_trans)
        x_res = self.res_pass_conv(x_res)
        x_trans = self.trans_pass_conv(x_trans)
        x_res = x_res + x_res_identity + y_trans
        x_trans = x_trans + y_res
        x_res = self.res_postactiv(x_res)
        x_trans = self.trans_postactiv(x_trans)
        return x_res, x_trans


class RiRInitBlock(nn.Module):
    """
    RiR initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(RiRInitBlock, self).__init__()
        self.res_conv = conv3x3_block(in_channels=in_channels, out_channels
            =out_channels)
        self.trans_conv = conv3x3_block(in_channels=in_channels,
            out_channels=out_channels)

    def forward(self, x, _):
        x_res = self.res_conv(x)
        x_trans = self.trans_conv(x)
        return x_res, x_trans


class RiRFinalBlock(nn.Module):
    """
    RiR final block.
    """

    def __init__(self):
        super(RiRFinalBlock, self).__init__()

    def forward(self, x_res, x_trans):
        x = torch.cat((x_res, x_trans), dim=1)
        return x, None


class CIFARRiR(nn.Module):
    """
    RiR model for CIFAR from 'Resnet in Resnet: Generalizing Residual Architectures,' https://arxiv.org/abs/1603.08029.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    final_block_channels : int
        Number of output channels for the final unit.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (32, 32)
        Spatial size of the expected input image.
    num_classes : int, default 10
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, final_block_channels,
        in_channels=3, in_size=(32, 32), num_classes=10):
        super(CIFARRiR, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = DualPathSequential(return_two=False, first_ordinals
            =0, last_ordinals=0)
        self.features.add_module('init_block', RiRInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = DualPathSequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), RiRUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_block', RiRFinalBlock())
        in_channels = final_block_channels
        self.output = nn.Sequential()
        self.output.add_module('final_conv', conv1x1_block(in_channels=
            in_channels, out_channels=num_classes, activation=None))
        self.output.add_module('final_pool', nn.AvgPool2d(kernel_size=8,
            stride=1))
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = self.output(x)
        x = x.view(x.size(0), -1)
        return x


class RoRBlock(nn.Module):
    """
    RoR-3 block for residual path in residual unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    dropout_rate : float
        Parameter of Dropout layer. Faction of the input units to drop.
    """

    def __init__(self, in_channels, out_channels, dropout_rate):
        super(RoRBlock, self).__init__()
        self.use_dropout = dropout_rate != 0.0
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            out_channels)
        self.conv2 = conv3x3_block(in_channels=out_channels, out_channels=
            out_channels, activation=None)
        if self.use_dropout:
            self.dropout = nn.Dropout(p=dropout_rate)

    def forward(self, x):
        x = self.conv1(x)
        if self.use_dropout:
            x = self.dropout(x)
        x = self.conv2(x)
        return x


class RoRResUnit(nn.Module):
    """
    RoR-3 residual unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    dropout_rate : float
        Parameter of Dropout layer. Faction of the input units to drop.
    last_activate : bool, default True
        Whether activate output.
    """

    def __init__(self, in_channels, out_channels, dropout_rate,
        last_activate=True):
        super(RoRResUnit, self).__init__()
        self.last_activate = last_activate
        self.resize_identity = in_channels != out_channels
        self.body = RoRBlock(in_channels=in_channels, out_channels=
            out_channels, dropout_rate=dropout_rate)
        if self.resize_identity:
            self.identity_conv = conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, activation=None)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        x = x + identity
        if self.last_activate:
            x = self.activ(x)
        return x


class RoRResStage(nn.Module):
    """
    RoR-3 residual stage.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels_list : list of int
        Number of output channels for each unit.
    dropout_rate : float
        Parameter of Dropout layer. Faction of the input units to drop.
    downsample : bool, default True
        Whether downsample output.
    """

    def __init__(self, in_channels, out_channels_list, dropout_rate,
        downsample=True):
        super(RoRResStage, self).__init__()
        self.downsample = downsample
        self.shortcut = conv1x1_block(in_channels=in_channels, out_channels
            =out_channels_list[-1], activation=None)
        self.units = nn.Sequential()
        for i, out_channels in enumerate(out_channels_list):
            last_activate = i != len(out_channels_list) - 1
            self.units.add_module('unit{}'.format(i + 1), RoRResUnit(
                in_channels=in_channels, out_channels=out_channels,
                dropout_rate=dropout_rate, last_activate=last_activate))
            in_channels = out_channels
        if self.downsample:
            self.activ = nn.ReLU(inplace=True)
            self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)

    def forward(self, x):
        identity = self.shortcut(x)
        x = self.units(x)
        x = x + identity
        if self.downsample:
            x = self.activ(x)
            x = self.pool(x)
        return x


class RoRResBody(nn.Module):
    """
    RoR-3 residual body (main feature path).

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels_lists : list of list of int
        Number of output channels for each stage.
    dropout_rate : float
        Parameter of Dropout layer. Faction of the input units to drop.
    """

    def __init__(self, in_channels, out_channels_lists, dropout_rate):
        super(RoRResBody, self).__init__()
        self.shortcut = conv1x1_block(in_channels=in_channels, out_channels
            =out_channels_lists[-1][-1], stride=4, activation=None)
        self.stages = nn.Sequential()
        for i, channels_per_stage in enumerate(out_channels_lists):
            downsample = i != len(out_channels_lists) - 1
            self.stages.add_module('stage{}'.format(i + 1), RoRResStage(
                in_channels=in_channels, out_channels_list=
                channels_per_stage, dropout_rate=dropout_rate, downsample=
                downsample))
            in_channels = channels_per_stage[-1]
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        identity = self.shortcut(x)
        x = self.stages(x)
        x = x + identity
        x = self.activ(x)
        return x


class CIFARRoR(nn.Module):
    """
    RoR-3 model for CIFAR from 'Residual Networks of Residual Networks: Multilevel Residual Networks,'
    https://arxiv.org/abs/1608.02908.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    dropout_rate : float, default 0.0
        Parameter of Dropout layer. Faction of the input units to drop.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (32, 32)
        Spatial size of the expected input image.
    num_classes : int, default 10
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, dropout_rate=0.0,
        in_channels=3, in_size=(32, 32), num_classes=10):
        super(CIFARRoR, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', conv3x3_block(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        self.features.add_module('body', RoRResBody(in_channels=in_channels,
            out_channels_lists=channels, dropout_rate=dropout_rate))
        in_channels = channels[-1][-1]
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=8,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class SelecSLSBlock(nn.Module):
    """
    SelecSLS block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(SelecSLSBlock, self).__init__()
        mid_channels = 2 * out_channels
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            mid_channels)
        self.conv2 = conv3x3_block(in_channels=mid_channels, out_channels=
            out_channels)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class SelecSLSUnit(nn.Module):
    """
    SelecSLS unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    skip_channels : int
        Number of skipped channels.
    mid_channels : int
        Number of middle channels.
    stride : int or tuple/list of 2 int
        Strides of the branch convolution layers.
    """

    def __init__(self, in_channels, out_channels, skip_channels,
        mid_channels, stride):
        super(SelecSLSUnit, self).__init__()
        self.resize = stride == 2
        mid2_channels = mid_channels // 2
        last_channels = 2 * mid_channels + (skip_channels if stride == 1 else 0
            )
        self.branch1 = conv3x3_block(in_channels=in_channels, out_channels=
            mid_channels, stride=stride)
        self.branch2 = SelecSLSBlock(in_channels=mid_channels, out_channels
            =mid2_channels)
        self.branch3 = SelecSLSBlock(in_channels=mid2_channels,
            out_channels=mid2_channels)
        self.last_conv = conv1x1_block(in_channels=last_channels,
            out_channels=out_channels)

    def forward(self, x, x0):
        x1 = self.branch1(x)
        x2 = self.branch2(x1)
        x3 = self.branch3(x2)
        if self.resize:
            y = torch.cat((x1, x2, x3), dim=1)
            y = self.last_conv(y)
            return y, y
        else:
            y = torch.cat((x1, x2, x3, x0), dim=1)
            y = self.last_conv(y)
            return y, x0


class SelecSLS(nn.Module):
    """
    SelecSLS model from 'XNect: Real-time Multi-person 3D Human Pose Estimation with a Single RGB Camera,'
    https://arxiv.org/abs/1907.00837.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    skip_channels : list of list of int
        Number of skipped channels for each unit.
    mid_channels : list of list of int
        Number of middle channels for each unit.
    kernels3 : list of list of int/bool
        Using 3x3 (instead of 1x1) kernel for each head unit.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, skip_channels, mid_channels, kernels3,
        in_channels=3, in_size=(224, 224), num_classes=1000):
        super(SelecSLS, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        init_block_channels = 32
        self.features = DualPathSequential(return_two=False, first_ordinals
            =1, last_ordinals=1 + len(kernels3))
        self.features.add_module('init_block', conv3x3_block(in_channels=
            in_channels, out_channels=init_block_channels, stride=2))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            k = i - len(skip_channels)
            stage = DualPathSequential() if k < 0 else nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 else 1
                if k < 0:
                    unit = SelecSLSUnit(in_channels=in_channels,
                        out_channels=out_channels, skip_channels=
                        skip_channels[i][j], mid_channels=mid_channels[i][j
                        ], stride=stride)
                else:
                    conv_block_class = conv3x3_block if kernels3[k][j
                        ] == 1 else conv1x1_block
                    unit = conv_block_class(in_channels=in_channels,
                        out_channels=out_channels, stride=stride)
                stage.add_module('unit{}'.format(j + 1), unit)
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=4,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                nn.init.kaiming_uniform_(module.weight, mode='fan_out',
                    nonlinearity='relu')
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)
            elif isinstance(module, nn.BatchNorm2d):
                nn.init.constant_(module.weight, 1)
                nn.init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class SENetBottleneck(nn.Module):
    """
    SENet bottleneck block for residual path in SENet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    cardinality: int
        Number of groups.
    bottleneck_width: int
        Width of bottleneck block.
    """

    def __init__(self, in_channels, out_channels, stride, cardinality,
        bottleneck_width):
        super(SENetBottleneck, self).__init__()
        mid_channels = out_channels // 4
        D = int(math.floor(mid_channels * (bottleneck_width / 64.0)))
        group_width = cardinality * D
        group_width2 = group_width // 2
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            group_width2)
        self.conv2 = conv3x3_block(in_channels=group_width2, out_channels=
            group_width, stride=stride, groups=cardinality)
        self.conv3 = conv1x1_block(in_channels=group_width, out_channels=
            out_channels, activation=None)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class SENetUnit(nn.Module):
    """
    SENet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    cardinality: int
        Number of groups.
    bottleneck_width: int
        Width of bottleneck block.
    identity_conv3x3 : bool, default False
        Whether to use 3x3 convolution in the identity link.
    """

    def __init__(self, in_channels, out_channels, stride, cardinality,
        bottleneck_width, identity_conv3x3):
        super(SENetUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        self.body = SENetBottleneck(in_channels=in_channels, out_channels=
            out_channels, stride=stride, cardinality=cardinality,
            bottleneck_width=bottleneck_width)
        self.se = SEBlock(channels=out_channels)
        if self.resize_identity:
            if identity_conv3x3:
                self.identity_conv = conv3x3_block(in_channels=in_channels,
                    out_channels=out_channels, stride=stride, activation=None)
            else:
                self.identity_conv = conv1x1_block(in_channels=in_channels,
                    out_channels=out_channels, stride=stride, activation=None)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        x = self.se(x)
        x = x + identity
        x = self.activ(x)
        return x


class SEInitBlock(nn.Module):
    """
    SENet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(SEInitBlock, self).__init__()
        mid_channels = out_channels // 2
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            mid_channels, stride=2)
        self.conv2 = conv3x3_block(in_channels=mid_channels, out_channels=
            mid_channels)
        self.conv3 = conv3x3_block(in_channels=mid_channels, out_channels=
            out_channels)
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.pool(x)
        return x


class SENet(nn.Module):
    """
    SENet model from 'Squeeze-and-Excitation Networks,' https://arxiv.org/abs/1709.01507.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    cardinality: int
        Number of groups.
    bottleneck_width: int
        Width of bottleneck block.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, cardinality,
        bottleneck_width, in_channels=3, in_size=(224, 224), num_classes=1000):
        super(SENet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', SEInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            identity_conv3x3 = i != 0
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), SENetUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, cardinality=cardinality,
                    bottleneck_width=bottleneck_width, identity_conv3x3=
                    identity_conv3x3))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Sequential()
        self.output.add_module('dropout', nn.Dropout(p=0.2))
        self.output.add_module('fc', nn.Linear(in_features=in_channels,
            out_features=num_classes))
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class SEPreResUnit(nn.Module):
    """
    SE-PreResNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    conv1_stride : bool
        Whether to use stride in the first or the second convolution layer of the block.
    """

    def __init__(self, in_channels, out_channels, stride, bottleneck,
        conv1_stride):
        super(SEPreResUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        if bottleneck:
            self.body = PreResBottleneck(in_channels=in_channels,
                out_channels=out_channels, stride=stride, conv1_stride=
                conv1_stride)
        else:
            self.body = PreResBlock(in_channels=in_channels, out_channels=
                out_channels, stride=stride)
        self.se = SEBlock(channels=out_channels)
        if self.resize_identity:
            self.identity_conv = conv1x1(in_channels=in_channels,
                out_channels=out_channels, stride=stride)

    def forward(self, x):
        identity = x
        x, x_pre_activ = self.body(x)
        x = self.se(x)
        if self.resize_identity:
            identity = self.identity_conv(x_pre_activ)
        x = x + identity
        return x


class SEPreResNet(nn.Module):
    """
    SE-PreResNet model from 'Squeeze-and-Excitation Networks,' https://arxiv.org/abs/1709.01507.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    conv1_stride : bool
        Whether to use stride in the first or the second convolution layer in units.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, bottleneck,
        conv1_stride, in_channels=3, in_size=(224, 224), num_classes=1000):
        super(SEPreResNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', PreResInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 1 if i == 0 or j != 0 else 2
                stage.add_module('unit{}'.format(j + 1), SEPreResUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, bottleneck=bottleneck, conv1_stride=
                    conv1_stride))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('post_activ', PreResActivation(in_channels
            =in_channels))
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class CIFARSEPreResNet(nn.Module):
    """
    SE-PreResNet model for CIFAR from 'Squeeze-and-Excitation Networks,' https://arxiv.org/abs/1709.01507.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (32, 32)
        Spatial size of the expected input image.
    num_classes : int, default 10
        Number of classification num_classes.
    """

    def __init__(self, channels, init_block_channels, bottleneck,
        in_channels=3, in_size=(32, 32), num_classes=10):
        super(CIFARSEPreResNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', conv3x3_block(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), SEPreResUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, bottleneck=bottleneck, conv1_stride=False))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=8,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class SEResUnit(nn.Module):
    """
    SE-ResNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    conv1_stride : bool
        Whether to use stride in the first or the second convolution layer of the block.
    """

    def __init__(self, in_channels, out_channels, stride, bottleneck,
        conv1_stride):
        super(SEResUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        if bottleneck:
            self.body = ResBottleneck(in_channels=in_channels, out_channels
                =out_channels, stride=stride, conv1_stride=conv1_stride)
        else:
            self.body = ResBlock(in_channels=in_channels, out_channels=
                out_channels, stride=stride)
        self.se = SEBlock(channels=out_channels)
        if self.resize_identity:
            self.identity_conv = conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride, activation=None)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        x = self.se(x)
        x = x + identity
        x = self.activ(x)
        return x


class SEResNet(nn.Module):
    """
    SE-ResNet model from 'Squeeze-and-Excitation Networks,' https://arxiv.org/abs/1709.01507.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    conv1_stride : bool
        Whether to use stride in the first or the second convolution layer in units.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, bottleneck,
        conv1_stride, in_channels=3, in_size=(224, 224), num_classes=1000):
        super(SEResNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', ResInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), SEResUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, bottleneck=bottleneck, conv1_stride=
                    conv1_stride))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class CIFARSEResNet(nn.Module):
    """
    SE-ResNet model for CIFAR from 'Squeeze-and-Excitation Networks,' https://arxiv.org/abs/1709.01507.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (32, 32)
        Spatial size of the expected input image.
    num_classes : int, default 10
        Number of classification num_classes.
    """

    def __init__(self, channels, init_block_channels, bottleneck,
        in_channels=3, in_size=(32, 32), num_classes=10):
        super(CIFARSEResNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', conv3x3_block(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), SEResUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, bottleneck=bottleneck, conv1_stride=False))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=8,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class SEResNeXtUnit(nn.Module):
    """
    SE-ResNeXt unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    cardinality: int
        Number of groups.
    bottleneck_width: int
        Width of bottleneck block.
    """

    def __init__(self, in_channels, out_channels, stride, cardinality,
        bottleneck_width):
        super(SEResNeXtUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        self.body = ResNeXtBottleneck(in_channels=in_channels, out_channels
            =out_channels, stride=stride, cardinality=cardinality,
            bottleneck_width=bottleneck_width)
        self.se = SEBlock(channels=out_channels)
        if self.resize_identity:
            self.identity_conv = conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride, activation=None)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        x = self.se(x)
        x = x + identity
        x = self.activ(x)
        return x


class SEResNeXt(nn.Module):
    """
    SE-ResNeXt model from 'Squeeze-and-Excitation Networks,' https://arxiv.org/abs/1709.01507.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    cardinality: int
        Number of groups.
    bottleneck_width: int
        Width of bottleneck block.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, cardinality,
        bottleneck_width, in_channels=3, in_size=(224, 224), num_classes=1000):
        super(SEResNeXt, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', ResInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), SEResNeXtUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, cardinality=cardinality,
                    bottleneck_width=bottleneck_width))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class ShakeDrop(torch.autograd.Function):
    """
    ShakeDrop function.
    """

    @staticmethod
    def forward(ctx, x, b, alpha):
        y = (b + alpha - b * alpha) * x
        ctx.save_for_backward(b)
        return y

    @staticmethod
    def backward(ctx, dy):
        beta = torch.rand(dy.size(0), dtype=dy.dtype, device=dy.device).view(
            -1, 1, 1, 1)
        b, = ctx.saved_tensors
        return (b + beta - b * beta) * dy, None, None


class ShakeDropResUnit(nn.Module):
    """
    ShakeDrop-ResNet unit with residual connection.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    life_prob : float
        Residual branch life probability.
    """

    def __init__(self, in_channels, out_channels, stride, bottleneck, life_prob
        ):
        super(ShakeDropResUnit, self).__init__()
        self.life_prob = life_prob
        self.resize_identity = in_channels != out_channels or stride != 1
        body_class = ResBottleneck if bottleneck else ResBlock
        self.body = body_class(in_channels=in_channels, out_channels=
            out_channels, stride=stride)
        if self.resize_identity:
            self.identity_conv = conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride, activation=None)
        self.activ = nn.ReLU(inplace=True)
        self.shake_drop = ShakeDrop.apply

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        if self.training:
            b = torch.bernoulli(torch.full((1,), self.life_prob, dtype=x.
                dtype, device=x.device))
            alpha = torch.empty(x.size(0), dtype=x.dtype, device=x.device
                ).view(-1, 1, 1, 1).uniform_(-1.0, 1.0)
            x = self.shake_drop(x, b, alpha)
        else:
            x = self.life_prob * x
        x = x + identity
        x = self.activ(x)
        return x


class CIFARShakeDropResNet(nn.Module):
    """
    ShakeDrop-ResNet model for CIFAR from 'ShakeDrop Regularization for Deep Residual Learning,'
    https://arxiv.org/abs/1802.02375.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    life_probs : list of float
        Residual branch life probability for each unit.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (32, 32)
        Spatial size of the expected input image.
    num_classes : int, default 10
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, bottleneck,
        life_probs, in_channels=3, in_size=(32, 32), num_classes=10):
        super(CIFARShakeDropResNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', conv3x3_block(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        k = 0
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), ShakeDropResUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, bottleneck=bottleneck, life_prob=
                    life_probs[k]))
                in_channels = out_channels
                k += 1
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=8,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class ShakeShakeShortcut(nn.Module):
    """
    Shake-Shake-ResNet shortcut.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    """

    def __init__(self, in_channels, out_channels, stride):
        super(ShakeShakeShortcut, self).__init__()
        assert out_channels % 2 == 0
        mid_channels = out_channels // 2
        self.pool = nn.AvgPool2d(kernel_size=1, stride=stride)
        self.conv1 = conv1x1(in_channels=in_channels, out_channels=mid_channels
            )
        self.conv2 = conv1x1(in_channels=in_channels, out_channels=mid_channels
            )
        self.bn = nn.BatchNorm2d(num_features=out_channels)
        self.pad = nn.ZeroPad2d(padding=(1, 0, 1, 0))

    def forward(self, x):
        x1 = self.pool(x)
        x1 = self.conv1(x1)
        x2 = x[:, :, :-1, :-1].contiguous()
        x2 = self.pad(x2)
        x2 = self.pool(x2)
        x2 = self.conv2(x2)
        x = torch.cat((x1, x2), dim=1)
        x = self.bn(x)
        return x


class ShakeShake(torch.autograd.Function):
    """
    Shake-Shake function.
    """

    @staticmethod
    def forward(ctx, x1, x2, alpha):
        y = alpha * x1 + (1 - alpha) * x2
        return y

    @staticmethod
    def backward(ctx, dy):
        beta = torch.rand(dy.size(0), dtype=dy.dtype, device=dy.device).view(
            -1, 1, 1, 1)
        return beta * dy, (1 - beta) * dy, None


class ShakeShakeResUnit(nn.Module):
    """
    Shake-Shake-ResNet unit with residual connection.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    """

    def __init__(self, in_channels, out_channels, stride, bottleneck):
        super(ShakeShakeResUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        branch_class = ResBottleneck if bottleneck else ResBlock
        self.branch1 = branch_class(in_channels=in_channels, out_channels=
            out_channels, stride=stride)
        self.branch2 = branch_class(in_channels=in_channels, out_channels=
            out_channels, stride=stride)
        if self.resize_identity:
            self.identity_branch = ShakeShakeShortcut(in_channels=
                in_channels, out_channels=out_channels, stride=stride)
        self.activ = nn.ReLU(inplace=True)
        self.shake_shake = ShakeShake.apply

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_branch(x)
        else:
            identity = x
        x1 = self.branch1(x)
        x2 = self.branch2(x)
        if self.training:
            alpha = torch.rand(x1.size(0), dtype=x1.dtype, device=x1.device
                ).view(-1, 1, 1, 1)
            x = self.shake_shake(x1, x2, alpha)
        else:
            x = 0.5 * (x1 + x2)
        x = x + identity
        x = self.activ(x)
        return x


class CIFARShakeShakeResNet(nn.Module):
    """
    Shake-Shake-ResNet model for CIFAR from 'Shake-Shake regularization,' https://arxiv.org/abs/1705.07485.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (32, 32)
        Spatial size of the expected input image.
    num_classes : int, default 10
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, bottleneck,
        in_channels=3, in_size=(32, 32), num_classes=10):
        super(CIFARShakeShakeResNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', conv3x3_block(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), ShakeShakeResUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, bottleneck=bottleneck))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=8,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class ShaConvBlock(nn.Module):
    """
    Shared convolution block with Batch normalization and ReLU/ReLU6 activation.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function or name of activation function.
    activate : bool, default True
        Whether activate the convolution block.
    shared_conv : Module, default None
        Shared convolution layer.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, dilation=1, groups=1, bias=False, activation=lambda : nn.
        ReLU(inplace=True), activate=True, shared_conv=None):
        super(ShaConvBlock, self).__init__()
        self.activate = activate
        if shared_conv is None:
            self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
                out_channels, kernel_size=kernel_size, stride=stride,
                padding=padding, dilation=dilation, groups=groups, bias=bias)
        else:
            self.conv = shared_conv
        self.bn = nn.BatchNorm2d(num_features=out_channels)
        if self.activate:
            assert activation is not None
            if isfunction(activation):
                self.activ = activation()
            elif isinstance(activation, str):
                if activation == 'relu':
                    self.activ = nn.ReLU(inplace=True)
                elif activation == 'relu6':
                    self.activ = nn.ReLU6(inplace=True)
                else:
                    raise NotImplementedError()
            else:
                self.activ = activation

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        if self.activate:
            x = self.activ(x)
        return x


def sha_conv3x3_block(in_channels, out_channels, stride=1, padding=1,
    dilation=1, groups=1, bias=False, activation=lambda : nn.ReLU(inplace=
    True), activate=True, shared_conv=None):
    """
    3x3 version of the shared convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 1
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function or name of activation function.
    activate : bool, default True
        Whether activate the convolution block.
    shared_conv : Module, default None
        Shared convolution layer.
    """
    return ShaConvBlock(in_channels=in_channels, out_channels=out_channels,
        kernel_size=3, stride=stride, padding=padding, dilation=dilation,
        groups=groups, bias=bias, activation=activation, activate=activate,
        shared_conv=shared_conv)


class ShaResBlock(nn.Module):
    """
    Simple ShaResNet block for residual path in ShaResNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    shared_conv : Module, default None
        Shared convolution layer.
    """

    def __init__(self, in_channels, out_channels, stride, shared_conv=None):
        super(ShaResBlock, self).__init__()
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            out_channels, stride=stride)
        self.conv2 = sha_conv3x3_block(in_channels=out_channels,
            out_channels=out_channels, activation=None, activate=False,
            shared_conv=shared_conv)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class ShaResBottleneck(nn.Module):
    """
    ShaResNet bottleneck block for residual path in ShaResNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    bottleneck_factor : int, default 4
        Bottleneck factor.
    conv1_stride : bool, default False
        Whether to use stride in the first or the second convolution layer of the block.
    shared_conv : Module, default None
        Shared convolution layer.
    """

    def __init__(self, in_channels, out_channels, stride, conv1_stride=
        False, bottleneck_factor=4, shared_conv=None):
        super(ShaResBottleneck, self).__init__()
        assert conv1_stride or not (stride > 1 and shared_conv is not None)
        mid_channels = out_channels // bottleneck_factor
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            mid_channels, stride=stride if conv1_stride else 1)
        self.conv2 = sha_conv3x3_block(in_channels=mid_channels,
            out_channels=mid_channels, stride=1 if conv1_stride else stride,
            shared_conv=shared_conv)
        self.conv3 = conv1x1_block(in_channels=mid_channels, out_channels=
            out_channels, activation=None)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class ShaResUnit(nn.Module):
    """
    ShaResNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    conv1_stride : bool
        Whether to use stride in the first or the second convolution layer of the block.
    shared_conv : Module, default None
        Shared convolution layer.
    """

    def __init__(self, in_channels, out_channels, stride, bottleneck,
        conv1_stride, shared_conv=None):
        super(ShaResUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        if bottleneck:
            self.body = ShaResBottleneck(in_channels=in_channels,
                out_channels=out_channels, stride=stride, conv1_stride=
                conv1_stride, shared_conv=shared_conv)
        else:
            self.body = ShaResBlock(in_channels=in_channels, out_channels=
                out_channels, stride=stride, shared_conv=shared_conv)
        if self.resize_identity:
            self.identity_conv = conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride, activation=None)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        x = x + identity
        x = self.activ(x)
        return x


class ShaResNet(nn.Module):
    """
    ShaResNet model from 'ShaResNet: reducing residual network parameter number by sharing weights,'
    https://arxiv.org/abs/1702.08782.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    conv1_stride : bool
        Whether to use stride in the first or the second convolution layer in units.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, bottleneck,
        conv1_stride, in_channels=3, in_size=(224, 224), num_classes=1000):
        super(ShaResNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', ResInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            shared_conv = None
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                unit = ShaResUnit(in_channels=in_channels, out_channels=
                    out_channels, stride=stride, bottleneck=bottleneck,
                    conv1_stride=conv1_stride, shared_conv=shared_conv)
                if shared_conv is None and not (bottleneck and not
                    conv1_stride and stride > 1):
                    shared_conv = unit.body.conv2.conv
                stage.add_module('unit{}'.format(j + 1), unit)
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class ShuffleUnit(nn.Module):
    """
    ShuffleNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    groups : int
        Number of groups in convolution layers.
    downsample : bool
        Whether do downsample.
    ignore_group : bool
        Whether ignore group value in the first convolution layer.
    """

    def __init__(self, in_channels, out_channels, groups, downsample,
        ignore_group):
        super(ShuffleUnit, self).__init__()
        self.downsample = downsample
        mid_channels = out_channels // 4
        if downsample:
            out_channels -= in_channels
        self.compress_conv1 = conv1x1(in_channels=in_channels, out_channels
            =mid_channels, groups=1 if ignore_group else groups)
        self.compress_bn1 = nn.BatchNorm2d(num_features=mid_channels)
        self.c_shuffle = ChannelShuffle(channels=mid_channels, groups=groups)
        self.dw_conv2 = depthwise_conv3x3(channels=mid_channels, stride=2 if
            self.downsample else 1)
        self.dw_bn2 = nn.BatchNorm2d(num_features=mid_channels)
        self.expand_conv3 = conv1x1(in_channels=mid_channels, out_channels=
            out_channels, groups=groups)
        self.expand_bn3 = nn.BatchNorm2d(num_features=out_channels)
        if downsample:
            self.avgpool = nn.AvgPool2d(kernel_size=3, stride=2, padding=1)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        identity = x
        x = self.compress_conv1(x)
        x = self.compress_bn1(x)
        x = self.activ(x)
        x = self.c_shuffle(x)
        x = self.dw_conv2(x)
        x = self.dw_bn2(x)
        x = self.expand_conv3(x)
        x = self.expand_bn3(x)
        if self.downsample:
            identity = self.avgpool(identity)
            x = torch.cat((x, identity), dim=1)
        else:
            x = x + identity
        x = self.activ(x)
        return x


class ShuffleInitBlock(nn.Module):
    """
    ShuffleNet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(ShuffleInitBlock, self).__init__()
        self.conv = conv3x3(in_channels=in_channels, out_channels=
            out_channels, stride=2)
        self.bn = nn.BatchNorm2d(num_features=out_channels)
        self.activ = nn.ReLU(inplace=True)
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        x = self.activ(x)
        x = self.pool(x)
        return x


class ShuffleNet(nn.Module):
    """
    ShuffleNet model from 'ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices,'
    https://arxiv.org/abs/1707.01083.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    groups : int
        Number of groups in convolution layers.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, groups, in_channels=3,
        in_size=(224, 224), num_classes=1000):
        super(ShuffleNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', ShuffleInitBlock(in_channels
            =in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                downsample = j == 0
                ignore_group = i == 0 and j == 0
                stage.add_module('unit{}'.format(j + 1), ShuffleUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    groups=groups, downsample=downsample, ignore_group=
                    ignore_group))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class ShuffleUnit(nn.Module):
    """
    ShuffleNetV2 unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    downsample : bool
        Whether do downsample.
    use_se : bool
        Whether to use SE block.
    use_residual : bool
        Whether to use residual connection.
    """

    def __init__(self, in_channels, out_channels, downsample, use_se,
        use_residual):
        super(ShuffleUnit, self).__init__()
        self.downsample = downsample
        self.use_se = use_se
        self.use_residual = use_residual
        mid_channels = out_channels // 2
        self.compress_conv1 = conv1x1(in_channels=in_channels if self.
            downsample else mid_channels, out_channels=mid_channels)
        self.compress_bn1 = nn.BatchNorm2d(num_features=mid_channels)
        self.dw_conv2 = depthwise_conv3x3(channels=mid_channels, stride=2 if
            self.downsample else 1)
        self.dw_bn2 = nn.BatchNorm2d(num_features=mid_channels)
        self.expand_conv3 = conv1x1(in_channels=mid_channels, out_channels=
            mid_channels)
        self.expand_bn3 = nn.BatchNorm2d(num_features=mid_channels)
        if self.use_se:
            self.se = SEBlock(channels=mid_channels)
        if downsample:
            self.dw_conv4 = depthwise_conv3x3(channels=in_channels, stride=2)
            self.dw_bn4 = nn.BatchNorm2d(num_features=in_channels)
            self.expand_conv5 = conv1x1(in_channels=in_channels,
                out_channels=mid_channels)
            self.expand_bn5 = nn.BatchNorm2d(num_features=mid_channels)
        self.activ = nn.ReLU(inplace=True)
        self.c_shuffle = ChannelShuffle(channels=out_channels, groups=2)

    def forward(self, x):
        if self.downsample:
            y1 = self.dw_conv4(x)
            y1 = self.dw_bn4(y1)
            y1 = self.expand_conv5(y1)
            y1 = self.expand_bn5(y1)
            y1 = self.activ(y1)
            x2 = x
        else:
            y1, x2 = torch.chunk(x, chunks=2, dim=1)
        y2 = self.compress_conv1(x2)
        y2 = self.compress_bn1(y2)
        y2 = self.activ(y2)
        y2 = self.dw_conv2(y2)
        y2 = self.dw_bn2(y2)
        y2 = self.expand_conv3(y2)
        y2 = self.expand_bn3(y2)
        y2 = self.activ(y2)
        if self.use_se:
            y2 = self.se(y2)
        if self.use_residual and not self.downsample:
            y2 = y2 + x2
        x = torch.cat((y1, y2), dim=1)
        x = self.c_shuffle(x)
        return x


class ShuffleInitBlock(nn.Module):
    """
    ShuffleNetV2 specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(ShuffleInitBlock, self).__init__()
        self.conv = conv3x3_block(in_channels=in_channels, out_channels=
            out_channels, stride=2)
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0,
            ceil_mode=True)

    def forward(self, x):
        x = self.conv(x)
        x = self.pool(x)
        return x


class ShuffleNetV2(nn.Module):
    """
    ShuffleNetV2 model from 'ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design,'
    https://arxiv.org/abs/1807.11164.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    final_block_channels : int
        Number of output channels for the final block of the feature extractor.
    use_se : bool, default False
        Whether to use SE block.
    use_residual : bool, default False
        Whether to use residual connections.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, final_block_channels,
        use_se=False, use_residual=False, in_channels=3, in_size=(224, 224),
        num_classes=1000):
        super(ShuffleNetV2, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', ShuffleInitBlock(in_channels
            =in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                downsample = j == 0
                stage.add_module('unit{}'.format(j + 1), ShuffleUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    downsample=downsample, use_se=use_se, use_residual=
                    use_residual))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_block', conv1x1_block(in_channels=
            in_channels, out_channels=final_block_channels))
        in_channels = final_block_channels
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class ShuffleUnit(nn.Module):
    """
    ShuffleNetV2(b) unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    downsample : bool
        Whether do downsample.
    use_se : bool
        Whether to use SE block.
    use_residual : bool
        Whether to use residual connection.
    shuffle_group_first : bool
        Whether to use channel shuffle in group first mode.
    """

    def __init__(self, in_channels, out_channels, downsample, use_se,
        use_residual, shuffle_group_first):
        super(ShuffleUnit, self).__init__()
        self.downsample = downsample
        self.use_se = use_se
        self.use_residual = use_residual
        mid_channels = out_channels // 2
        in_channels2 = in_channels // 2
        assert in_channels % 2 == 0
        y2_in_channels = in_channels if downsample else in_channels2
        y2_out_channels = out_channels - y2_in_channels
        self.conv1 = conv1x1_block(in_channels=y2_in_channels, out_channels
            =mid_channels)
        self.dconv = dwconv3x3_block(in_channels=mid_channels, out_channels
            =mid_channels, stride=2 if self.downsample else 1, activation=None)
        self.conv2 = conv1x1_block(in_channels=mid_channels, out_channels=
            y2_out_channels)
        if self.use_se:
            self.se = SEBlock(channels=y2_out_channels)
        if downsample:
            self.shortcut_dconv = dwconv3x3_block(in_channels=in_channels,
                out_channels=in_channels, stride=2, activation=None)
            self.shortcut_conv = conv1x1_block(in_channels=in_channels,
                out_channels=in_channels)
        if shuffle_group_first:
            self.c_shuffle = ChannelShuffle(channels=out_channels, groups=2)
        else:
            self.c_shuffle = ChannelShuffle2(channels=out_channels, groups=2)

    def forward(self, x):
        if self.downsample:
            y1 = self.shortcut_dconv(x)
            y1 = self.shortcut_conv(y1)
            x2 = x
        else:
            y1, x2 = torch.chunk(x, chunks=2, dim=1)
        y2 = self.conv1(x2)
        y2 = self.dconv(y2)
        y2 = self.conv2(y2)
        if self.use_se:
            y2 = self.se(y2)
        if self.use_residual and not self.downsample:
            y2 = y2 + x2
        x = torch.cat((y1, y2), dim=1)
        x = self.c_shuffle(x)
        return x


class ShuffleInitBlock(nn.Module):
    """
    ShuffleNetV2(b) specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(ShuffleInitBlock, self).__init__()
        self.conv = conv3x3_block(in_channels=in_channels, out_channels=
            out_channels, stride=2)
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1,
            ceil_mode=False)

    def forward(self, x):
        x = self.conv(x)
        x = self.pool(x)
        return x


class ShuffleNetV2b(nn.Module):
    """
    ShuffleNetV2(b) model from 'ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design,'
    https://arxiv.org/abs/1807.11164.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    final_block_channels : int
        Number of output channels for the final block of the feature extractor.
    use_se : bool, default False
        Whether to use SE block.
    use_residual : bool, default False
        Whether to use residual connections.
    shuffle_group_first : bool, default True
        Whether to use channel shuffle in group first mode.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, final_block_channels,
        use_se=False, use_residual=False, shuffle_group_first=True,
        in_channels=3, in_size=(224, 224), num_classes=1000):
        super(ShuffleNetV2b, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', ShuffleInitBlock(in_channels
            =in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                downsample = j == 0
                stage.add_module('unit{}'.format(j + 1), ShuffleUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    downsample=downsample, use_se=use_se, use_residual=
                    use_residual, shuffle_group_first=shuffle_group_first))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_block', conv1x1_block(in_channels=
            in_channels, out_channels=final_block_channels))
        in_channels = final_block_channels
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class SimplePose(nn.Module):
    """
    SimplePose model from 'Simple Baselines for Human Pose Estimation and Tracking,' https://arxiv.org/abs/1804.06208.

    Parameters:
    ----------
    backbone : nn.Sequential
        Feature extractor.
    backbone_out_channels : int
        Number of output channels for the backbone.
    channels : list of int
        Number of output channels for each decoder unit.
    return_heatmap : bool, default False
        Whether to return only heatmap.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (256, 192)
        Spatial size of the expected input image.
    keypoints : int, default 17
        Number of keypoints.
    """

    def __init__(self, backbone, backbone_out_channels, channels,
        return_heatmap=False, in_channels=3, in_size=(256, 192), keypoints=17):
        super(SimplePose, self).__init__()
        assert in_channels == 3
        self.in_size = in_size
        self.keypoints = keypoints
        self.return_heatmap = return_heatmap
        self.backbone = backbone
        self.decoder = nn.Sequential()
        in_channels = backbone_out_channels
        for i, out_channels in enumerate(channels):
            self.decoder.add_module('unit{}'.format(i + 1), DeconvBlock(
                in_channels=in_channels, out_channels=out_channels,
                kernel_size=4, stride=2, padding=1))
            in_channels = out_channels
        self.decoder.add_module('final_block', conv1x1(in_channels=
            in_channels, out_channels=keypoints, bias=True))
        self.heatmap_max_det = HeatmapMaxDetBlock()
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                nn.init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.backbone(x)
        heatmap = self.decoder(x)
        if self.return_heatmap:
            return heatmap
        else:
            keypoints = self.heatmap_max_det(heatmap)
            return keypoints


class SimplePoseMobile(nn.Module):
    """
    SimplePose(Mobile) model from 'Simple Baselines for Human Pose Estimation and Tracking,'
    https://arxiv.org/abs/1804.06208.

    Parameters:
    ----------
    backbone : nn.Sequential
        Feature extractor.
    backbone_out_channels : int
        Number of output channels for the backbone.
    channels : list of int
        Number of output channels for each decoder unit.
    decoder_init_block_channels : int
        Number of output channels for the initial unit of the decoder.
    return_heatmap : bool, default False
        Whether to return only heatmap.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (256, 192)
        Spatial size of the expected input image.
    keypoints : int, default 17
        Number of keypoints.
    """

    def __init__(self, backbone, backbone_out_channels, channels,
        decoder_init_block_channels, return_heatmap=False, in_channels=3,
        in_size=(256, 192), keypoints=17):
        super(SimplePoseMobile, self).__init__()
        assert in_channels == 3
        self.in_size = in_size
        self.keypoints = keypoints
        self.return_heatmap = return_heatmap
        self.backbone = backbone
        self.decoder = nn.Sequential()
        in_channels = backbone_out_channels
        self.decoder.add_module('init_block', conv1x1(in_channels=
            in_channels, out_channels=decoder_init_block_channels))
        in_channels = decoder_init_block_channels
        for i, out_channels in enumerate(channels):
            self.decoder.add_module('unit{}'.format(i + 1), DucBlock(
                in_channels=in_channels, out_channels=out_channels,
                scale_factor=2))
            in_channels = out_channels
        self.decoder.add_module('final_block', conv1x1(in_channels=
            in_channels, out_channels=keypoints))
        self.heatmap_max_det = HeatmapMaxDetBlock()
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                nn.init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.backbone(x)
        heatmap = self.decoder(x)
        if self.return_heatmap:
            return heatmap
        else:
            keypoints = self.heatmap_max_det(heatmap)
            return keypoints


class SEBlock(nn.Module):
    """
    SINet version of Squeeze-and-Excitation block from 'Squeeze-and-Excitation Networks,'
    https://arxiv.org/abs/1709.01507.

    Parameters:
    ----------
    channels : int
        Number of channels.
    reduction : int, default 16
        Squeeze reduction value.
    round_mid : bool, default False
        Whether to round middle channel number (make divisible by 8).
    activation : function, or str, or nn.Module, default 'relu'
        Activation function after the first convolution.
    out_activation : function, or str, or nn.Module, default 'sigmoid'
        Activation function after the last convolution.
    """

    def __init__(self, channels, reduction=16, round_mid=False,
        mid_activation=lambda : nn.ReLU(inplace=True), out_activation=lambda :
        nn.Sigmoid()):
        super(SEBlock, self).__init__()
        self.use_conv2 = reduction > 1
        mid_channels = (channels // reduction if not round_mid else
            round_channels(float(channels) / reduction))
        self.pool = nn.AdaptiveAvgPool2d(output_size=1)
        self.fc1 = nn.Linear(in_features=channels, out_features=mid_channels)
        if self.use_conv2:
            self.activ = get_activation_layer(mid_activation)
            self.fc2 = nn.Linear(in_features=mid_channels, out_features=
                channels)
        self.sigmoid = get_activation_layer(out_activation)

    def forward(self, x):
        w = self.pool(x)
        w = w.squeeze(dim=-1).squeeze(dim=-1)
        w = self.fc1(w)
        if self.use_conv2:
            w = self.activ(w)
            w = self.fc2(w)
        w = self.sigmoid(w)
        w = w.unsqueeze(dim=-1).unsqueeze(dim=-1)
        x = x * w
        return x


class DwsConvBlock(nn.Module):
    """
    SINet version of depthwise separable convolution block with BatchNorms and activations at each convolution layers.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    bias : bool, default False
        Whether the layer uses a bias vector.
    dw_use_bn : bool, default True
        Whether to use BatchNorm layer (depthwise convolution block).
    pw_use_bn : bool, default True
        Whether to use BatchNorm layer (pointwise convolution block).
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    dw_activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function after the depthwise convolution block.
    pw_activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function after the pointwise convolution block.
    se_reduction : int, default 0
        Squeeze reduction value (0 means no-se).
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, dilation=1, bias=False, dw_use_bn=True, pw_use_bn=True,
        bn_eps=1e-05, dw_activation=lambda : nn.ReLU(inplace=True),
        pw_activation=lambda : nn.ReLU(inplace=True), se_reduction=0):
        super(DwsConvBlock, self).__init__()
        self.use_se = se_reduction > 0
        self.dw_conv = dwconv_block(in_channels=in_channels, out_channels=
            in_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, dilation=dilation, bias=bias, use_bn=dw_use_bn, bn_eps
            =bn_eps, activation=dw_activation)
        if self.use_se:
            self.se = SEBlock(channels=in_channels, reduction=se_reduction,
                round_mid=False, mid_activation=lambda : nn.PReLU(
                in_channels // se_reduction), out_activation=lambda : nn.
                PReLU(in_channels))
        self.pw_conv = conv1x1_block(in_channels=in_channels, out_channels=
            out_channels, bias=bias, use_bn=pw_use_bn, bn_eps=bn_eps,
            activation=pw_activation)

    def forward(self, x):
        x = self.dw_conv(x)
        if self.use_se:
            x = self.se(x)
        x = self.pw_conv(x)
        return x


class FDWConvBlock(nn.Module):
    """
    Factorized depthwise separable convolution block with BatchNorms and activations at each convolution layers.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    bias : bool, default False
        Whether the layer uses a bias vector.
    use_bn : bool, default True
        Whether to use BatchNorm layer.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    activation : function or str or None, default nn.ReLU(inplace=True)
        Activation function after the each convolution block.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, dilation=1, bias=False, use_bn=True, bn_eps=1e-05,
        activation=lambda : nn.ReLU(inplace=True)):
        super(FDWConvBlock, self).__init__()
        assert use_bn
        self.activate = activation is not None
        self.v_conv = dwconv_block(in_channels=in_channels, out_channels=
            out_channels, kernel_size=(kernel_size, 1), stride=stride,
            padding=(padding, 0), dilation=dilation, bias=bias, use_bn=
            use_bn, bn_eps=bn_eps, activation=None)
        self.h_conv = dwconv_block(in_channels=in_channels, out_channels=
            out_channels, kernel_size=(1, kernel_size), stride=stride,
            padding=(0, padding), dilation=dilation, bias=bias, use_bn=
            use_bn, bn_eps=bn_eps, activation=None)
        if self.activate:
            self.act = get_activation_layer(activation)

    def forward(self, x):
        x = self.v_conv(x) + self.h_conv(x)
        if self.activate:
            x = self.act(x)
        return x


def fdwconv5x5_block(in_channels, out_channels, strides=1, padding=2,
    dilation=1, use_bias=False, use_bn=True, bn_eps=1e-05, activation=
    'relu', data_format='channels_last', **kwargs):
    """
    5x5 factorized depthwise version of the standard convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    strides : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    padding : int, default 1
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    use_bias : bool, default False
        Whether the layer uses a bias vector.
    use_bn : bool, default True
        Whether to use BatchNorm layer.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    activation : function or str or None, default 'relu'
        Activation function or name of activation function.
    data_format : str, default 'channels_last'
        The ordering of the dimensions in tensors.
    """
    return FDWConvBlock(in_channels=in_channels, out_channels=out_channels,
        kernel_size=5, strides=strides, padding=padding, dilation=dilation,
        use_bias=use_bias, use_bn=use_bn, bn_eps=bn_eps, activation=
        activation, data_format=data_format, **kwargs)


def fdwconv3x3_block(in_channels, out_channels, strides=1, padding=1,
    dilation=1, use_bias=False, use_bn=True, bn_eps=1e-05, activation=
    'relu', data_format='channels_last', **kwargs):
    """
    3x3 factorized depthwise version of the standard convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    strides : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    padding : int, default 1
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    use_bias : bool, default False
        Whether the layer uses a bias vector.
    use_bn : bool, default True
        Whether to use BatchNorm layer.
    bn_eps : float, default 1e-5
        Small float added to variance in Batch norm.
    activation : function or str or None, default 'relu'
        Activation function or name of activation function.
    data_format : str, default 'channels_last'
        The ordering of the dimensions in tensors.
    """
    return FDWConvBlock(in_channels=in_channels, out_channels=out_channels,
        kernel_size=3, strides=strides, padding=padding, dilation=dilation,
        use_bias=use_bias, use_bn=use_bn, bn_eps=bn_eps, activation=
        activation, data_format=data_format, **kwargs)


class SBBlock(nn.Module):
    """
    SB-block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int
        Convolution window size for a factorized depthwise separable convolution block.
    scale_factor : int
        Scale factor.
    bn_eps : float
        Small float added to variance in Batch norm.
    """

    def __init__(self, in_channels, out_channels, kernel_size, scale_factor,
        bn_eps):
        super(SBBlock, self).__init__()
        self.use_scale = scale_factor > 1
        if self.use_scale:
            self.down_scale = nn.AvgPool2d(kernel_size=scale_factor, stride
                =scale_factor)
            self.up_scale = InterpolationBlock(scale_factor=scale_factor)
        use_fdw = scale_factor > 0
        if use_fdw:
            fdwconv3x3_class = (fdwconv3x3_block if kernel_size == 3 else
                fdwconv5x5_block)
            self.conv1 = fdwconv3x3_class(in_channels=in_channels,
                out_channels=in_channels, bn_eps=bn_eps, activation=lambda :
                nn.PReLU(in_channels))
        else:
            self.conv1 = dwconv3x3_block(in_channels=in_channels,
                out_channels=in_channels, bn_eps=bn_eps, activation=lambda :
                nn.PReLU(in_channels))
        self.conv2 = conv1x1(in_channels=in_channels, out_channels=out_channels
            )
        self.bn = nn.BatchNorm2d(num_features=out_channels, eps=bn_eps)

    def forward(self, x):
        if self.use_scale:
            x = self.down_scale(x)
        x = self.conv1(x)
        x = self.conv2(x)
        if self.use_scale:
            x = self.up_scale(x)
        x = self.bn(x)
        return x


class PreActivation(nn.Module):
    """
    PreResNet like pure pre-activation block without convolution layer.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    bn_eps : float
        Small float added to variance in Batch norm.
    """

    def __init__(self, in_channels, bn_eps):
        super(PreActivation, self).__init__()
        self.bn = nn.BatchNorm2d(num_features=in_channels, eps=bn_eps)
        self.activ = nn.PReLU(num_parameters=in_channels)

    def forward(self, x):
        x = self.bn(x)
        x = self.activ(x)
        return x


class ESPBlock(nn.Module):
    """
    ESP block, which is based on the following principle: Reduce ---> Split ---> Transform --> Merge.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_sizes : list of int
        Convolution window size for branches.
    scale_factors : list of int
        Scale factor for branches.
    use_residual : bool
        Whether to use residual connection.
    bn_eps : float
        Small float added to variance in Batch norm.
    """

    def __init__(self, in_channels, out_channels, kernel_sizes,
        scale_factors, use_residual, bn_eps):
        super(ESPBlock, self).__init__()
        self.use_residual = use_residual
        groups = len(kernel_sizes)
        mid_channels = int(out_channels / groups)
        res_channels = out_channels - groups * mid_channels
        self.conv = conv1x1(in_channels=in_channels, out_channels=
            mid_channels, groups=groups)
        self.c_shuffle = ChannelShuffle(channels=mid_channels, groups=groups)
        self.branches = Concurrent()
        for i in range(groups):
            out_channels_i = (mid_channels + res_channels if i == 0 else
                mid_channels)
            self.branches.add_module('branch{}'.format(i + 1), SBBlock(
                in_channels=mid_channels, out_channels=out_channels_i,
                kernel_size=kernel_sizes[i], scale_factor=scale_factors[i],
                bn_eps=bn_eps))
        self.preactiv = PreActivation(in_channels=out_channels, bn_eps=bn_eps)

    def forward(self, x):
        if self.use_residual:
            identity = x
        x = self.conv(x)
        x = self.c_shuffle(x)
        x = self.branches(x)
        if self.use_residual:
            x = identity + x
        x = self.preactiv(x)
        return x


class SBStage(nn.Module):
    """
    SB stage.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    down_channels : int
        Number of output channels for a downscale block.
    channels_list : list of int
        Number of output channels for all residual block.
    kernel_sizes_list : list of int
        Convolution window size for branches.
    scale_factors_list : list of int
        Scale factor for branches.
    use_residual_list : list of int
        List of flags for using residual in each ESP-block.
    se_reduction : int
        Squeeze reduction value (0 means no-se).
    bn_eps : float
        Small float added to variance in Batch norm.
    """

    def __init__(self, in_channels, down_channels, channels_list,
        kernel_sizes_list, scale_factors_list, use_residual_list,
        se_reduction, bn_eps):
        super(SBStage, self).__init__()
        self.down_conv = dwsconv3x3_block(in_channels=in_channels,
            out_channels=down_channels, stride=2, dw_use_bn=False, bn_eps=
            bn_eps, dw_activation=None, pw_activation=lambda : nn.PReLU(
            down_channels), se_reduction=se_reduction)
        in_channels = down_channels
        self.main_branch = nn.Sequential()
        for i, out_channels in enumerate(channels_list):
            use_residual = use_residual_list[i] == 1
            kernel_sizes = kernel_sizes_list[i]
            scale_factors = scale_factors_list[i]
            self.main_branch.add_module('block{}'.format(i + 1), ESPBlock(
                in_channels=in_channels, out_channels=out_channels,
                kernel_sizes=kernel_sizes, scale_factors=scale_factors,
                use_residual=use_residual, bn_eps=bn_eps))
            in_channels = out_channels
        self.preactiv = PreActivation(in_channels=down_channels +
            in_channels, bn_eps=bn_eps)

    def forward(self, x):
        x = self.down_conv(x)
        y = self.main_branch(x)
        x = torch.cat((x, y), dim=1)
        x = self.preactiv(x)
        return x, y


class SBEncoderInitBlock(nn.Module):
    """
    SB encoder specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    mid_channels : int
        Number of middle channels.
    out_channels : int
        Number of output channels.
    bn_eps : float
        Small float added to variance in Batch norm.
    """

    def __init__(self, in_channels, mid_channels, out_channels, bn_eps):
        super(SBEncoderInitBlock, self).__init__()
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            mid_channels, stride=2, bn_eps=bn_eps, activation=lambda : nn.
            PReLU(mid_channels))
        self.conv2 = dwsconv3x3_block(in_channels=mid_channels,
            out_channels=out_channels, stride=2, dw_use_bn=False, bn_eps=
            bn_eps, dw_activation=None, pw_activation=lambda : nn.PReLU(
            out_channels), se_reduction=1)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class SBEncoder(nn.Module):
    """
    SB encoder for SINet.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of input channels.
    init_block_channels : list int
        Number of output channels for convolutions in the initial block.
    down_channels_list : list of int
        Number of downsample channels for each residual block.
    channels_list : list of list of int
        Number of output channels for all residual block.
    kernel_sizes_list : list of list of int
        Convolution window size for each residual block.
    scale_factors_list : list of list of int
        Scale factor for each residual block.
    use_residual_list : list of list of int
        List of flags for using residual in each residual block.
    bn_eps : float
        Small float added to variance in Batch norm.
    """

    def __init__(self, in_channels, out_channels, init_block_channels,
        down_channels_list, channels_list, kernel_sizes_list,
        scale_factors_list, use_residual_list, bn_eps):
        super(SBEncoder, self).__init__()
        self.init_block = SBEncoderInitBlock(in_channels=in_channels,
            mid_channels=init_block_channels[0], out_channels=
            init_block_channels[1], bn_eps=bn_eps)
        in_channels = init_block_channels[1]
        self.stage1 = SBStage(in_channels=in_channels, down_channels=
            down_channels_list[0], channels_list=channels_list[0],
            kernel_sizes_list=kernel_sizes_list[0], scale_factors_list=
            scale_factors_list[0], use_residual_list=use_residual_list[0],
            se_reduction=1, bn_eps=bn_eps)
        in_channels = down_channels_list[0] + channels_list[0][-1]
        self.stage2 = SBStage(in_channels=in_channels, down_channels=
            down_channels_list[1], channels_list=channels_list[1],
            kernel_sizes_list=kernel_sizes_list[1], scale_factors_list=
            scale_factors_list[1], use_residual_list=use_residual_list[1],
            se_reduction=2, bn_eps=bn_eps)
        in_channels = down_channels_list[1] + channels_list[1][-1]
        self.output = conv1x1(in_channels=in_channels, out_channels=
            out_channels)

    def forward(self, x):
        y1 = self.init_block(x)
        x, y2 = self.stage1(y1)
        x, _ = self.stage2(x)
        x = self.output(x)
        return x, y2, y1


class SBDecodeBlock(nn.Module):
    """
    SB decoder block for SINet.

    Parameters:
    ----------
    channels : int
        Number of output classes.
    bn_eps : float
        Small float added to variance in Batch norm.
    """

    def __init__(self, channels, bn_eps):
        super(SBDecodeBlock, self).__init__()
        self.up = InterpolationBlock(scale_factor=2, align_corners=False)
        self.bn = nn.BatchNorm2d(num_features=channels, eps=bn_eps)
        self.conf = nn.Softmax2d()

    def forward(self, x, y):
        x = self.up(x)
        x = self.bn(x)
        w_conf = self.conf(x)
        w_max = torch.max(w_conf, dim=1)[0].unsqueeze(1).expand_as(x)
        x = y * (1 - w_max) + x
        return x


class SBDecoder(nn.Module):
    """
    SB decoder for SINet.

    Parameters:
    ----------
    dim2 : int
        Size of dimension #2.
    num_classes : int
        Number of segmentation classes.
    bn_eps : float
        Small float added to variance in Batch norm.
    """

    def __init__(self, dim2, num_classes, bn_eps):
        super(SBDecoder, self).__init__()
        self.decode1 = SBDecodeBlock(channels=num_classes, bn_eps=bn_eps)
        self.decode2 = SBDecodeBlock(channels=num_classes, bn_eps=bn_eps)
        self.conv3c = conv1x1_block(in_channels=dim2, out_channels=
            num_classes, bn_eps=bn_eps, activation=lambda : nn.PReLU(
            num_classes))
        self.output = nn.ConvTranspose2d(in_channels=num_classes,
            out_channels=num_classes, kernel_size=2, stride=2, padding=0,
            output_padding=0, bias=False)
        self.up = InterpolationBlock(scale_factor=2)

    def forward(self, y3, y2, y1):
        y2 = self.conv3c(y2)
        x = self.decode1(y3, y2)
        x = self.decode2(x, y1)
        x = self.output(x)
        x = self.up(x)
        return x


class SINet(nn.Module):
    """
    SINet model from 'SINet: Extreme Lightweight Portrait Segmentation Networks with Spatial Squeeze Modules and
    Information Blocking Decoder,' https://arxiv.org/abs/1911.09099.

    Parameters:
    ----------
    down_channels_list : list of int
        Number of downsample channels for each residual block.
    channels_list : list of list of int
        Number of output channels for all residual block.
    kernel_sizes_list : list of list of int
        Convolution window size for each residual block.
    scale_factors_list : list of list of int
        Scale factor for each residual block.
    use_residual_list : list of list of int
        List of flags for using residual in each residual block.
    dim2 : int
        Size of dimension #2.
    bn_eps : float
        Small float added to variance in Batch norm.
    aux : bool, default False
        Whether to output an auxiliary result.
    fixed_size : bool, default False
        Whether to expect fixed spatial size of input image.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (480, 480)
        Spatial size of the expected input image.
    num_classes : int, default 21
        Number of segmentation classes.
    """

    def __init__(self, down_channels_list, channels_list, kernel_sizes_list,
        scale_factors_list, use_residual_list, dim2, bn_eps, aux=False,
        fixed_size=False, in_channels=3, in_size=(1024, 2048), num_classes=21):
        super(SINet, self).__init__()
        assert fixed_size is not None
        assert in_channels > 0
        assert in_size[0] % 64 == 0 and in_size[1] % 64 == 0
        self.in_size = in_size
        self.num_classes = num_classes
        self.aux = aux
        init_block_channels = [16, num_classes]
        out_channels = num_classes
        self.encoder = SBEncoder(in_channels=in_channels, out_channels=
            out_channels, init_block_channels=init_block_channels,
            down_channels_list=down_channels_list, channels_list=
            channels_list, kernel_sizes_list=kernel_sizes_list,
            scale_factors_list=scale_factors_list, use_residual_list=
            use_residual_list, bn_eps=bn_eps)
        self.decoder = SBDecoder(dim2=dim2, num_classes=num_classes, bn_eps
            =bn_eps)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                nn.init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)

    def forward(self, x):
        y3, y2, y1 = self.encoder(x)
        x = self.decoder(y3, y2, y1)
        if self.aux:
            return x, y3
        else:
            return x


class SKConvBlock(nn.Module):
    """
    SKNet specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    groups : int, default 32
        Number of groups in branches.
    num_branches : int, default 2
        Number of branches (`M` parameter in the paper).
    reduction : int, default 16
        Reduction value for intermediate channels (`r` parameter in the paper).
    min_channels : int, default 32
        Minimal number of intermediate channels (`L` parameter in the paper).
    """

    def __init__(self, in_channels, out_channels, stride, groups=32,
        num_branches=2, reduction=16, min_channels=32):
        super(SKConvBlock, self).__init__()
        self.num_branches = num_branches
        self.out_channels = out_channels
        mid_channels = max(in_channels // reduction, min_channels)
        self.branches = Concurrent(stack=True)
        for i in range(num_branches):
            dilation = 1 + i
            self.branches.add_module('branch{}'.format(i + 2),
                conv3x3_block(in_channels=in_channels, out_channels=
                out_channels, stride=stride, padding=dilation, dilation=
                dilation, groups=groups))
        self.pool = nn.AdaptiveAvgPool2d(output_size=1)
        self.fc1 = conv1x1_block(in_channels=out_channels, out_channels=
            mid_channels)
        self.fc2 = conv1x1(in_channels=mid_channels, out_channels=
            out_channels * num_branches)
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        y = self.branches(x)
        u = y.sum(dim=1)
        s = self.pool(u)
        z = self.fc1(s)
        w = self.fc2(z)
        batch = w.size(0)
        w = w.view(batch, self.num_branches, self.out_channels)
        w = self.softmax(w)
        w = w.unsqueeze(-1).unsqueeze(-1)
        y = y * w
        y = y.sum(dim=1)
        return y


class SKNetBottleneck(nn.Module):
    """
    SKNet bottleneck block for residual path in SKNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    bottleneck_factor : int, default 2
        Bottleneck factor.
    """

    def __init__(self, in_channels, out_channels, stride, bottleneck_factor=2):
        super(SKNetBottleneck, self).__init__()
        mid_channels = out_channels // bottleneck_factor
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            mid_channels)
        self.conv2 = SKConvBlock(in_channels=mid_channels, out_channels=
            mid_channels, stride=stride)
        self.conv3 = conv1x1_block(in_channels=mid_channels, out_channels=
            out_channels, activation=None)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class SKNetUnit(nn.Module):
    """
    SKNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    """

    def __init__(self, in_channels, out_channels, stride):
        super(SKNetUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        self.body = SKNetBottleneck(in_channels=in_channels, out_channels=
            out_channels, stride=stride)
        if self.resize_identity:
            self.identity_conv = conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride, activation=None)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        x = x + identity
        x = self.activ(x)
        return x


class SKNet(nn.Module):
    """
    SKNet model from 'Selective Kernel Networks,' https://arxiv.org/abs/1903.06586.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, in_channels=3,
        in_size=(224, 224), num_classes=1000):
        super(SKNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', ResInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), SKNetUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class SparseBlock(nn.Module):
    """
    SparseNet block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    dropout_rate : float
        Parameter of Dropout layer. Faction of the input units to drop.
    """

    def __init__(self, in_channels, out_channels, dropout_rate):
        super(SparseBlock, self).__init__()
        self.use_dropout = dropout_rate != 0.0
        bn_size = 4
        mid_channels = out_channels * bn_size
        self.conv1 = pre_conv1x1_block(in_channels=in_channels,
            out_channels=mid_channels)
        self.conv2 = pre_conv3x3_block(in_channels=mid_channels,
            out_channels=out_channels)
        if self.use_dropout:
            self.dropout = nn.Dropout(p=dropout_rate)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        if self.use_dropout:
            x = self.dropout(x)
        return x


def sparsenet_exponential_fetch(lst):
    """
    SparseNet's specific exponential fetch.

    Parameters:
    ----------
    lst : list
        List of something.

    Returns
    -------
    list
        Filtered list.
    """
    return [lst[len(lst) - 2 ** i] for i in range(1 + math.floor(math.log(
        len(lst), 2)))]


class SparseStage(nn.Module):
    """
    SparseNet stage.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    channels_per_stage : list of int
        Number of output channels for each unit in stage.
    growth_rate : int
        Growth rate for blocks.
    dropout_rate : float
        Parameter of Dropout layer. Faction of the input units to drop.
    do_transition : bool
        Whether use transition block.
    """

    def __init__(self, in_channels, channels_per_stage, growth_rate,
        dropout_rate, do_transition):
        super(SparseStage, self).__init__()
        self.do_transition = do_transition
        if self.do_transition:
            self.trans = TransitionBlock(in_channels=in_channels,
                out_channels=in_channels // 2)
            in_channels = in_channels // 2
        self.blocks = nn.Sequential()
        for i, out_channels in enumerate(channels_per_stage):
            self.blocks.add_module('block{}'.format(i + 1), SparseBlock(
                in_channels=in_channels, out_channels=growth_rate,
                dropout_rate=dropout_rate))
            in_channels = out_channels

    def forward(self, x):
        if self.do_transition:
            x = self.trans(x)
        outs = [x]
        for block in self.blocks._modules.values():
            y = block(x)
            outs.append(y)
            flt_outs = sparsenet_exponential_fetch(outs)
            x = torch.cat(tuple(flt_outs), dim=1)
        return x


class SparseNet(nn.Module):
    """
    SparseNet model from 'Sparsely Aggregated Convolutional Networks,' https://arxiv.org/abs/1801.05895.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    growth_rate : int
        Growth rate for blocks.
    dropout_rate : float, default 0.0
        Parameter of Dropout layer. Faction of the input units to drop.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, growth_rate,
        dropout_rate=0.0, in_channels=3, in_size=(224, 224), num_classes=1000):
        super(SparseNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', PreResInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = SparseStage(in_channels=in_channels, channels_per_stage
                =channels_per_stage, growth_rate=growth_rate, dropout_rate=
                dropout_rate, do_transition=i != 0)
            in_channels = channels_per_stage[-1]
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('post_activ', PreResActivation(in_channels
            =in_channels))
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class SPNASUnit(nn.Module):
    """
    Single-Path NASNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the second convolution layer.
    use_kernel3 : bool
        Whether to use 3x3 (instead of 5x5) kernel.
    exp_factor : int
        Expansion factor for each unit.
    use_skip : bool, default True
        Whether to use skip connection.
    activation : str, default 'relu'
        Activation function or name of activation function.
    """

    def __init__(self, in_channels, out_channels, stride, use_kernel3,
        exp_factor, use_skip=True, activation='relu'):
        super(SPNASUnit, self).__init__()
        assert exp_factor >= 1
        self.residual = (in_channels == out_channels and stride == 1 and
            use_skip)
        self.use_exp_conv = exp_factor > 1
        mid_channels = exp_factor * in_channels
        if self.use_exp_conv:
            self.exp_conv = conv1x1_block(in_channels=in_channels,
                out_channels=mid_channels, activation=activation)
        if use_kernel3:
            self.conv1 = dwconv3x3_block(in_channels=mid_channels,
                out_channels=mid_channels, stride=stride, activation=activation
                )
        else:
            self.conv1 = dwconv5x5_block(in_channels=mid_channels,
                out_channels=mid_channels, stride=stride, activation=activation
                )
        self.conv2 = conv1x1_block(in_channels=mid_channels, out_channels=
            out_channels, activation=None)

    def forward(self, x):
        if self.residual:
            identity = x
        if self.use_exp_conv:
            x = self.exp_conv(x)
        x = self.conv1(x)
        x = self.conv2(x)
        if self.residual:
            x = x + identity
        return x


class SPNASInitBlock(nn.Module):
    """
    Single-Path NASNet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    mid_channels : int
        Number of middle channels.
    """

    def __init__(self, in_channels, out_channels, mid_channels):
        super(SPNASInitBlock, self).__init__()
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            mid_channels, stride=2)
        self.conv2 = SPNASUnit(in_channels=mid_channels, out_channels=
            out_channels, stride=1, use_kernel3=True, exp_factor=1,
            use_skip=False)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class SPNASFinalBlock(nn.Module):
    """
    Single-Path NASNet specific final block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    mid_channels : int
        Number of middle channels.
    """

    def __init__(self, in_channels, out_channels, mid_channels):
        super(SPNASFinalBlock, self).__init__()
        self.conv1 = SPNASUnit(in_channels=in_channels, out_channels=
            mid_channels, stride=1, use_kernel3=True, exp_factor=6,
            use_skip=False)
        self.conv2 = conv1x1_block(in_channels=mid_channels, out_channels=
            out_channels)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class SPNASNet(nn.Module):
    """
    Single-Path NASNet model from 'Single-Path NAS: Designing Hardware-Efficient ConvNets in less than 4 Hours,'
    https://arxiv.org/abs/1904.02877.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : list of 2 int
        Number of output channels for the initial unit.
    final_block_channels : list of 2 int
        Number of output channels for the final block of the feature extractor.
    kernels3 : list of list of int/bool
        Using 3x3 (instead of 5x5) kernel for each unit.
    exp_factors : list of list of int
        Expansion factor for each unit.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, final_block_channels,
        kernels3, exp_factors, in_channels=3, in_size=(224, 224),
        num_classes=1000):
        super(SPNASNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', SPNASInitBlock(in_channels=
            in_channels, out_channels=init_block_channels[1], mid_channels=
            init_block_channels[0]))
        in_channels = init_block_channels[1]
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 3 or j == len(channels_per_stage
                    ) // 2 and i == 3 else 1
                use_kernel3 = kernels3[i][j] == 1
                exp_factor = exp_factors[i][j]
                stage.add_module('unit{}'.format(j + 1), SPNASUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, use_kernel3=use_kernel3, exp_factor=
                    exp_factor))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_block', SPNASFinalBlock(in_channels
            =in_channels, out_channels=final_block_channels[1],
            mid_channels=final_block_channels[0]))
        in_channels = final_block_channels[1]
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class FireConv(nn.Module):
    """
    SqueezeNet specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    """

    def __init__(self, in_channels, out_channels, kernel_size, padding):
        super(FireConv, self).__init__()
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, padding=padding)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.conv(x)
        x = self.activ(x)
        return x


class FireUnit(nn.Module):
    """
    SqueezeNet unit, so-called 'Fire' unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    squeeze_channels : int
        Number of output channels for squeeze convolution blocks.
    expand1x1_channels : int
        Number of output channels for expand 1x1 convolution blocks.
    expand3x3_channels : int
        Number of output channels for expand 3x3 convolution blocks.
    residual : bool
        Whether use residual connection.
    """

    def __init__(self, in_channels, squeeze_channels, expand1x1_channels,
        expand3x3_channels, residual):
        super(FireUnit, self).__init__()
        self.residual = residual
        self.squeeze = FireConv(in_channels=in_channels, out_channels=
            squeeze_channels, kernel_size=1, padding=0)
        self.expand1x1 = FireConv(in_channels=squeeze_channels,
            out_channels=expand1x1_channels, kernel_size=1, padding=0)
        self.expand3x3 = FireConv(in_channels=squeeze_channels,
            out_channels=expand3x3_channels, kernel_size=3, padding=1)

    def forward(self, x):
        if self.residual:
            identity = x
        x = self.squeeze(x)
        y1 = self.expand1x1(x)
        y2 = self.expand3x3(x)
        out = torch.cat((y1, y2), dim=1)
        if self.residual:
            out = out + identity
        return out


class SqueezeInitBlock(nn.Module):
    """
    SqueezeNet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    """

    def __init__(self, in_channels, out_channels, kernel_size):
        super(SqueezeInitBlock, self).__init__()
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=2)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.conv(x)
        x = self.activ(x)
        return x


class SqueezeNet(nn.Module):
    """
    SqueezeNet model from 'SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size,'
    https://arxiv.org/abs/1602.07360.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    residuals : bool
        Whether to use residual units.
    init_block_kernel_size : int or tuple/list of 2 int
        The dimensions of the convolution window for the initial unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, residuals, init_block_kernel_size,
        init_block_channels, in_channels=3, in_size=(224, 224), num_classes
        =1000):
        super(SqueezeNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', SqueezeInitBlock(in_channels
            =in_channels, out_channels=init_block_channels, kernel_size=
            init_block_kernel_size))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            stage.add_module('pool{}'.format(i + 1), nn.MaxPool2d(
                kernel_size=3, stride=2, ceil_mode=True))
            for j, out_channels in enumerate(channels_per_stage):
                expand_channels = out_channels // 2
                squeeze_channels = out_channels // 8
                stage.add_module('unit{}'.format(j + 1), FireUnit(
                    in_channels=in_channels, squeeze_channels=
                    squeeze_channels, expand1x1_channels=expand_channels,
                    expand3x3_channels=expand_channels, residual=residuals
                     is not None and residuals[i][j] == 1))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('dropout', nn.Dropout(p=0.5))
        self.output = nn.Sequential()
        self.output.add_module('final_conv', nn.Conv2d(in_channels=
            in_channels, out_channels=num_classes, kernel_size=1))
        self.output.add_module('final_activ', nn.ReLU(inplace=True))
        self.output.add_module('final_pool', nn.AvgPool2d(kernel_size=13,
            stride=1))
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                if 'final_conv' in name:
                    init.normal_(module.weight, mean=0.0, std=0.01)
                else:
                    init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = self.output(x)
        x = x.view(x.size(0), -1)
        return x


class SqnxtUnit(nn.Module):
    """
    SqueezeNext unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    """

    def __init__(self, in_channels, out_channels, stride):
        super(SqnxtUnit, self).__init__()
        if stride == 2:
            reduction_den = 1
            self.resize_identity = True
        elif in_channels > out_channels:
            reduction_den = 4
            self.resize_identity = True
        else:
            reduction_den = 2
            self.resize_identity = False
        self.conv1 = conv1x1_block(in_channels=in_channels, out_channels=
            in_channels // reduction_den, stride=stride, bias=True)
        self.conv2 = conv1x1_block(in_channels=in_channels // reduction_den,
            out_channels=in_channels // (2 * reduction_den), bias=True)
        self.conv3 = ConvBlock(in_channels=in_channels // (2 *
            reduction_den), out_channels=in_channels // reduction_den,
            kernel_size=(1, 3), stride=1, padding=(0, 1), bias=True)
        self.conv4 = ConvBlock(in_channels=in_channels // reduction_den,
            out_channels=in_channels // reduction_den, kernel_size=(3, 1),
            stride=1, padding=(1, 0), bias=True)
        self.conv5 = conv1x1_block(in_channels=in_channels // reduction_den,
            out_channels=out_channels, bias=True)
        if self.resize_identity:
            self.identity_conv = conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride, bias=True)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.conv4(x)
        x = self.conv5(x)
        x = x + identity
        x = self.activ(x)
        return x


class SqnxtInitBlock(nn.Module):
    """
    SqueezeNext specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(SqnxtInitBlock, self).__init__()
        self.conv = conv7x7_block(in_channels=in_channels, out_channels=
            out_channels, stride=2, padding=1, bias=True)
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)

    def forward(self, x):
        x = self.conv(x)
        x = self.pool(x)
        return x


class SqueezeNext(nn.Module):
    """
    SqueezeNext model from 'SqueezeNext: Hardware-Aware Neural Network Design,' https://arxiv.org/abs/1803.10615.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    final_block_channels : int
        Number of output channels for the final block of the feature extractor.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, final_block_channels,
        in_channels=3, in_size=(224, 224), num_classes=1000):
        super(SqueezeNext, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', SqnxtInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), SqnxtUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_block', conv1x1_block(in_channels=
            in_channels, out_channels=final_block_channels, bias=True))
        in_channels = final_block_channels
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class SPHead(nn.Module):
    """
    SuperPointNet head block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    mid_channels : int
        Number of middle channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, mid_channels, out_channels):
        super(SPHead, self).__init__()
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            mid_channels, bias=True, use_bn=False)
        self.conv2 = conv1x1(in_channels=mid_channels, out_channels=
            out_channels, bias=True)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class SPDetector(nn.Module):
    """
    SuperPointNet detector.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    mid_channels : int
        Number of middle channels.
    conf_thresh : float, default 0.015
        Confidence threshold.
    nms_dist : int, default 4
        NMS distance.
    border_size : int, default 4
        Image border size to remove points.
    reduction : int, default 8
        Feature reduction factor.
    """

    def __init__(self, in_channels, mid_channels, conf_thresh=0.015,
        nms_dist=4, border_size=4, reduction=8):
        super(SPDetector, self).__init__()
        self.conf_thresh = conf_thresh
        self.nms_dist = nms_dist
        self.border_size = border_size
        self.reduction = reduction
        num_classes = reduction * reduction + 1
        self.detector = SPHead(in_channels=in_channels, mid_channels=
            mid_channels, out_channels=num_classes)

    def forward(self, x):
        batch = x.size(0)
        x_height, x_width = x.size()[-2:]
        img_height = x_height * self.reduction
        img_width = x_width * self.reduction
        semi = self.detector(x)
        dense = semi.softmax(dim=1)
        nodust = dense[:, :-1, :, :]
        heatmap = nodust.permute(0, 2, 3, 1)
        heatmap = heatmap.reshape((-1, x_height, x_width, self.reduction,
            self.reduction))
        heatmap = heatmap.permute(0, 1, 3, 2, 4)
        heatmap = heatmap.reshape((-1, 1, x_height * self.reduction, 
            x_width * self.reduction))
        heatmap_mask = heatmap >= self.conf_thresh
        pad = self.nms_dist
        bord = self.border_size + pad
        heatmap_mask2 = F.pad(heatmap_mask, pad=(pad, pad, pad, pad))
        pts_list = []
        confs_list = []
        for i in range(batch):
            heatmap_i = heatmap[i, 0]
            heatmap_mask_i = heatmap_mask[i, 0]
            heatmap_mask2_i = heatmap_mask2[i, 0]
            src_pts = torch.nonzero(heatmap_mask_i)
            src_confs = torch.masked_select(heatmap_i, heatmap_mask_i)
            src_inds = torch.argsort(src_confs, descending=True)
            dst_inds = torch.zeros_like(src_inds)
            dst_pts_count = 0
            for ind_j in src_inds:
                pt = src_pts[ind_j] + pad
                assert pad <= pt[0] < heatmap_mask2_i.shape[0] - pad
                assert pad <= pt[1] < heatmap_mask2_i.shape[1] - pad
                assert 0 <= pt[0] - pad < img_height
                assert 0 <= pt[1] - pad < img_width
                if heatmap_mask2_i[pt[0], pt[1]] == 1:
                    heatmap_mask2_i[pt[0] - pad:pt[0] + pad + 1, pt[1] -
                        pad:pt[1] + pad + 1] = 0
                    if bord < pt[0] - pad <= img_height - bord and bord < pt[1
                        ] - pad <= img_width - bord:
                        dst_inds[dst_pts_count] = ind_j
                        dst_pts_count += 1
            dst_inds = dst_inds[:dst_pts_count]
            dst_pts = torch.index_select(src_pts, dim=0, index=dst_inds)
            dst_confs = torch.index_select(src_confs, dim=0, index=dst_inds)
            pts_list.append(dst_pts)
            confs_list.append(dst_confs)
        return pts_list, confs_list


class SPDescriptor(nn.Module):
    """
    SuperPointNet descriptor generator.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    mid_channels : int
        Number of middle channels.
    descriptor_length : int, default 256
        Descriptor length.
    transpose_descriptors : bool, default True
        Whether transpose descriptors with respect to points.
    reduction : int, default 8
        Feature reduction factor.
    """

    def __init__(self, in_channels, mid_channels, descriptor_length=256,
        transpose_descriptors=True, reduction=8):
        super(SPDescriptor, self).__init__()
        self.desc_length = descriptor_length
        self.transpose_descriptors = transpose_descriptors
        self.reduction = reduction
        self.head = SPHead(in_channels=in_channels, mid_channels=
            mid_channels, out_channels=descriptor_length)

    def forward(self, x, pts_list):
        x_height, x_width = x.size()[-2:]
        coarse_desc_map = self.head(x)
        coarse_desc_map = F.normalize(coarse_desc_map)
        descriptors_list = []
        for i, pts in enumerate(pts_list):
            pts = pts.float()
            pts[:, (0)] = pts[:, (0)] / (0.5 * x_height * self.reduction) - 1.0
            pts[:, (1)] = pts[:, (1)] / (0.5 * x_width * self.reduction) - 1.0
            if self.transpose_descriptors:
                pts = torch.index_select(pts, dim=1, index=torch.tensor([1,
                    0], device=pts.device))
            pts = pts.unsqueeze(0).unsqueeze(0)
            descriptors = F.grid_sample(coarse_desc_map[i:i + 1], pts)
            descriptors = descriptors.squeeze(0).squeeze(1)
            descriptors = descriptors.transpose(0, 1)
            descriptors = F.normalize(descriptors)
            descriptors_list.append(descriptors)
        return descriptors_list


class SuperPointNet(nn.Module):
    """
    SuperPointNet model from 'SuperPoint: Self-Supervised Interest Point Detection and Description,'
    https://arxiv.org/abs/1712.07629.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    final_block_channels : int
        Number of output channels for the final units.
    transpose_descriptors : bool, default True
        Whether transpose descriptors with respect to points.
    in_channels : int, default 1
        Number of input channels.
    """

    def __init__(self, channels, final_block_channels,
        transpose_descriptors=True, in_channels=1):
        super(SuperPointNet, self).__init__()
        self.features = nn.Sequential()
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                if j == 0 and i != 0:
                    stage.add_module('reduce{}'.format(i + 1), nn.MaxPool2d
                        (kernel_size=2, stride=2))
                stage.add_module('unit{}'.format(j + 1), conv3x3_block(
                    in_channels=in_channels, out_channels=out_channels,
                    bias=True, use_bn=False))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.detector = SPDetector(in_channels=in_channels, mid_channels=
            final_block_channels)
        self.descriptor = SPDescriptor(in_channels=in_channels,
            mid_channels=final_block_channels, transpose_descriptors=
            transpose_descriptors)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        assert x.size(1) == 1
        x = self.features(x)
        pts_list, confs_list = self.detector(x)
        descriptors_list = self.descriptor(x, pts_list)
        return pts_list, confs_list, descriptors_list


class VGGDense(nn.Module):
    """
    VGG specific dense block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(VGGDense, self).__init__()
        self.fc = nn.Linear(in_features=in_channels, out_features=out_channels)
        self.activ = nn.ReLU(inplace=True)
        self.dropout = nn.Dropout(p=0.5)

    def forward(self, x):
        x = self.fc(x)
        x = self.activ(x)
        x = self.dropout(x)
        return x


class VGGOutputBlock(nn.Module):
    """
    VGG specific output block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    classes : int
        Number of classification classes.
    """

    def __init__(self, in_channels, classes):
        super(VGGOutputBlock, self).__init__()
        mid_channels = 4096
        self.fc1 = VGGDense(in_channels=in_channels, out_channels=mid_channels)
        self.fc2 = VGGDense(in_channels=mid_channels, out_channels=mid_channels
            )
        self.fc3 = nn.Linear(in_features=mid_channels, out_features=classes)

    def forward(self, x):
        x = self.fc1(x)
        x = self.fc2(x)
        x = self.fc3(x)
        return x


class VGG(nn.Module):
    """
    VGG models from 'Very Deep Convolutional Networks for Large-Scale Image Recognition,'
    https://arxiv.org/abs/1409.1556.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    bias : bool, default True
        Whether the convolution layer uses a bias vector.
    use_bn : bool, default False
        Whether to use BatchNorm layers.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, bias=True, use_bn=False, in_channels=3,
        in_size=(224, 224), num_classes=1000):
        super(VGG, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stage.add_module('unit{}'.format(j + 1), conv3x3_block(
                    in_channels=in_channels, out_channels=out_channels,
                    bias=bias, use_bn=use_bn))
                in_channels = out_channels
            stage.add_module('pool{}'.format(i + 1), nn.MaxPool2d(
                kernel_size=2, stride=2, padding=0))
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.output = VGGOutputBlock(in_channels=in_channels * 7 * 7,
            classes=num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class VocaEncoder(nn.Module):
    """
    VOCA encoder.

    Parameters:
    ----------
    audio_features : int
        Number of audio features (characters/sounds).
    audio_window_size : int
        Size of audio window (for time related audio features).
    base_persons : int
        Number of base persons (subjects).
    encoder_features : int
        Number of encoder features.
    """

    def __init__(self, audio_features, audio_window_size, base_persons,
        encoder_features):
        super(VocaEncoder, self).__init__()
        self.audio_window_size = audio_window_size
        channels = 32, 32, 64, 64
        fc1_channels = 128
        self.bn = nn.BatchNorm2d(num_features=1)
        in_channels = audio_features + base_persons
        self.branch = nn.Sequential()
        for i, out_channels in enumerate(channels):
            self.branch.add_module('conv{}'.format(i + 1), ConvBlock(
                in_channels=in_channels, out_channels=out_channels,
                kernel_size=(3, 1), stride=(2, 1), padding=(1, 0), bias=
                True, use_bn=False))
            in_channels = out_channels
        in_channels += base_persons
        self.fc1 = nn.Linear(in_features=in_channels, out_features=fc1_channels
            )
        self.fc2 = nn.Linear(in_features=fc1_channels, out_features=
            encoder_features)

    def forward(self, x, pid):
        x = self.bn(x)
        x = x.transpose(1, 3).contiguous()
        y = pid.unsqueeze(-1).unsqueeze(-1)
        y = y.repeat(1, 1, self.audio_window_size, 1)
        x = torch.cat((x, y), dim=1)
        x = self.branch(x)
        x = x.view(x.size(0), -1)
        x = torch.cat((x, pid), dim=1)
        x = self.fc1(x)
        x = x.tanh()
        x = self.fc2(x)
        return x


class VOCA(nn.Module):
    """
    VOCA model from 'Capture, Learning, and Synthesis of 3D Speaking Styles,' https://arxiv.org/abs/1905.03079.

    Parameters:
    ----------
    audio_features : int, default 29
        Number of audio features (characters/sounds).
    audio_window_size : int, default 16
        Size of audio window (for time related audio features).
    base_persons : int, default 8
        Number of base persons (subjects).
    encoder_features : int, default 50
        Number of encoder features.
    vertices : int, default 5023
        Number of 3D geometry vertices.
    """

    def __init__(self, audio_features=29, audio_window_size=16,
        base_persons=8, encoder_features=50, vertices=5023):
        super(VOCA, self).__init__()
        self.base_persons = base_persons
        self.encoder = VocaEncoder(audio_features=audio_features,
            audio_window_size=audio_window_size, base_persons=base_persons,
            encoder_features=encoder_features)
        self.decoder = nn.Linear(in_features=encoder_features, out_features
            =3 * vertices)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                nn.init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)

    def forward(self, x, pid):
        pid = F.one_hot(pid.long(), num_classes=self.base_persons).type_as(pid)
        x = self.encoder(x, pid)
        x = self.decoder(x)
        x = x.view(x.size(0), 1, -1, 3)
        return x


class VoVUnit(nn.Module):
    """
    VoVNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    branch_channels : int
        Number of output channels for each branch.
    num_branches : int
        Number of branches.
    resize : bool
        Whether to use resize block.
    use_residual : bool
        Whether to use residual block.
    """

    def __init__(self, in_channels, out_channels, branch_channels,
        num_branches, resize, use_residual):
        super(VoVUnit, self).__init__()
        self.resize = resize
        self.use_residual = use_residual
        if self.resize:
            self.pool = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)
        self.branches = SequentialConcurrent()
        branch_in_channels = in_channels
        for i in range(num_branches):
            self.branches.add_module('branch{}'.format(i + 1),
                conv3x3_block(in_channels=branch_in_channels, out_channels=
                branch_channels))
            branch_in_channels = branch_channels
        self.concat_conv = conv1x1_block(in_channels=in_channels + 
            num_branches * branch_channels, out_channels=out_channels)

    def forward(self, x):
        if self.resize:
            x = self.pool(x)
        if self.use_residual:
            identity = x
        x = self.branches(x)
        x = self.concat_conv(x)
        if self.use_residual:
            x = x + identity
        return x


class VoVInitBlock(nn.Module):
    """
    VoVNet specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(VoVInitBlock, self).__init__()
        mid_channels = out_channels // 2
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=
            mid_channels, stride=2)
        self.conv2 = conv3x3_block(in_channels=mid_channels, out_channels=
            mid_channels)
        self.conv3 = conv3x3_block(in_channels=mid_channels, out_channels=
            out_channels, stride=2)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class VoVNet(nn.Module):
    """
    VoVNet model from 'An Energy and GPU-Computation Efficient Backbone Network for Real-Time Object Detection,'
    https://arxiv.org/abs/1904.09730.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    branch_channels : list of list of int
        Number of branch output channels for each unit.
    num_branches : int
        Number of branches for the each unit.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, branch_channels, num_branches, in_channels
        =3, in_size=(224, 224), num_classes=1000):
        super(VoVNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        init_block_channels = 128
        self.features = nn.Sequential()
        self.features.add_module('init_block', VoVInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                use_residual = j != 0
                resize = j == 0 and i != 0
                stage.add_module('unit{}'.format(j + 1), VoVUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    branch_channels=branch_channels[i][j], num_branches=
                    num_branches, resize=resize, use_residual=use_residual))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                nn.init.kaiming_uniform_(module.weight, mode='fan_out',
                    nonlinearity='relu')
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)
            elif isinstance(module, nn.BatchNorm2d):
                nn.init.constant_(module.weight, 1)
                nn.init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class WRNConv(nn.Module):
    """
    WRN specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    activate : bool
        Whether activate the convolution block.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, activate):
        super(WRNConv, self).__init__()
        self.activate = activate
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, bias=True)
        if self.activate:
            self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.conv(x)
        if self.activate:
            x = self.activ(x)
        return x


def wrn_conv1x1(in_channels, out_channels, stride, activate):
    """
    1x1 version of the WRN specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    activate : bool
        Whether activate the convolution block.
    """
    return WRNConv(in_channels=in_channels, out_channels=out_channels,
        kernel_size=1, stride=stride, padding=0, activate=activate)


def wrn_conv3x3(in_channels, out_channels, stride, activate):
    """
    3x3 version of the WRN specific convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    activate : bool
        Whether activate the convolution block.
    """
    return WRNConv(in_channels=in_channels, out_channels=out_channels,
        kernel_size=3, stride=stride, padding=1, activate=activate)


class WRNBottleneck(nn.Module):
    """
    WRN bottleneck block for residual path in WRN unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    width_factor : float
        Wide scale factor for width of layers.
    """

    def __init__(self, in_channels, out_channels, stride, width_factor):
        super(WRNBottleneck, self).__init__()
        mid_channels = int(round(out_channels // 4 * width_factor))
        self.conv1 = wrn_conv1x1(in_channels=in_channels, out_channels=
            mid_channels, stride=1, activate=True)
        self.conv2 = wrn_conv3x3(in_channels=mid_channels, out_channels=
            mid_channels, stride=stride, activate=True)
        self.conv3 = wrn_conv1x1(in_channels=mid_channels, out_channels=
            out_channels, stride=1, activate=False)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x


class WRNUnit(nn.Module):
    """
    WRN unit with residual connection.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    width_factor : float
        Wide scale factor for width of layers.
    """

    def __init__(self, in_channels, out_channels, stride, width_factor):
        super(WRNUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        self.body = WRNBottleneck(in_channels=in_channels, out_channels=
            out_channels, stride=stride, width_factor=width_factor)
        if self.resize_identity:
            self.identity_conv = wrn_conv1x1(in_channels=in_channels,
                out_channels=out_channels, stride=stride, activate=False)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        x = x + identity
        x = self.activ(x)
        return x


class WRNInitBlock(nn.Module):
    """
    WRN specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    """

    def __init__(self, in_channels, out_channels):
        super(WRNInitBlock, self).__init__()
        self.conv = WRNConv(in_channels=in_channels, out_channels=
            out_channels, kernel_size=7, stride=2, padding=3, activate=True)
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

    def forward(self, x):
        x = self.conv(x)
        x = self.pool(x)
        return x


class WRN(nn.Module):
    """
    WRN model from 'Wide Residual Networks,' https://arxiv.org/abs/1605.07146.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    width_factor : float
        Wide scale factor for width of layers.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, width_factor,
        in_channels=3, in_size=(224, 224), num_classes=1000):
        super(WRN, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', WRNInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), WRNUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, width_factor=width_factor))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class Binarize(torch.autograd.Function):
    """
    Fake sign op for 1-bit weights.
    """

    @staticmethod
    def forward(ctx, x):
        return math.sqrt(2.0 / (x.shape[1] * x.shape[2] * x.shape[3])
            ) * x.sign()

    @staticmethod
    def backward(ctx, dy):
        return dy


class Conv2d1bit(nn.Conv2d):
    """
    Standard convolution block with binarization.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 1
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    binarized : bool, default False
        Whether to use binarization.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding=1, dilation=1, groups=1, bias=False, binarized=False):
        super(Conv2d1bit, self).__init__(in_channels=in_channels,
            out_channels=out_channels, kernel_size=kernel_size, stride=
            stride, padding=padding, dilation=dilation, groups=groups, bias
            =bias)
        self.binarized = binarized

    def forward(self, input):
        weight = Binarize.apply(self.weight) if self.binarized else self.weight
        bias = Binarize.apply(self.bias
            ) if self.bias is not None and self.binarized else self.bias
        return F.conv2d(input=input, weight=weight, bias=bias, stride=self.
            stride, padding=self.padding, dilation=self.dilation, groups=
            self.groups)


class ConvBlock1bit(nn.Module):
    """
    Standard convolution block with Batch normalization and ReLU activation, and binarization.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    bn_affine : bool, default True
        Whether the BatchNorm layer learns affine parameters.
    activate : bool, default True
        Whether activate the convolution block.
    binarized : bool, default False
        Whether to use binarization.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, dilation=1, groups=1, bias=False, bn_affine=True, activate
        =True, binarized=False):
        super(ConvBlock1bit, self).__init__()
        self.activate = activate
        self.conv = Conv2d1bit(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, dilation=dilation, groups=groups, bias=bias, binarized
            =binarized)
        self.bn = nn.BatchNorm2d(num_features=out_channels, affine=bn_affine)
        if self.activate:
            self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        if self.activate:
            x = self.activ(x)
        return x


class PreConvBlock1bit(nn.Module):
    """
    Convolution block with Batch normalization and ReLU pre-activation, and binarization.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    bias : bool, default False
        Whether the layer uses a bias vector.
    bn_affine : bool, default True
        Whether the BatchNorm layer learns affine parameters.
    return_preact : bool, default False
        Whether return pre-activation. It's used by PreResNet.
    activate : bool, default True
        Whether activate the convolution block.
    binarized : bool, default False
        Whether to use binarization.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, dilation=1, bias=False, bn_affine=True, return_preact=
        False, activate=True, binarized=False):
        super(PreConvBlock1bit, self).__init__()
        self.return_preact = return_preact
        self.activate = activate
        self.bn = nn.BatchNorm2d(num_features=in_channels, affine=bn_affine)
        if self.activate:
            self.activ = nn.ReLU(inplace=True)
        self.conv = Conv2d1bit(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, dilation=dilation, bias=bias, binarized=binarized)

    def forward(self, x):
        x = self.bn(x)
        if self.activate:
            x = self.activ(x)
        if self.return_preact:
            x_pre_activ = x
        x = self.conv(x)
        if self.return_preact:
            return x, x_pre_activ
        else:
            return x


def pre_conv3x3_block_1bit(in_channels, out_channels, stride=1, padding=1,
    dilation=1, bn_affine=True, return_preact=False, activate=True,
    binarized=False):
    """
    3x3 version of the pre-activated convolution block with binarization.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 1
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    bn_affine : bool, default True
        Whether the BatchNorm layer learns affine parameters.
    return_preact : bool, default False
        Whether return pre-activation.
    activate : bool, default True
        Whether activate the convolution block.
    binarized : bool, default False
        Whether to use binarization.
    """
    return PreConvBlock1bit(in_channels=in_channels, out_channels=
        out_channels, kernel_size=3, stride=stride, padding=padding,
        dilation=dilation, bn_affine=bn_affine, return_preact=return_preact,
        activate=activate, binarized=binarized)


class PreResBlock1bit(nn.Module):
    """
    Simple PreResNet block for residual path in ResNet unit (with binarization).

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    binarized : bool, default False
        Whether to use binarization.
    """

    def __init__(self, in_channels, out_channels, stride, binarized=False):
        super(PreResBlock1bit, self).__init__()
        self.conv1 = pre_conv3x3_block_1bit(in_channels=in_channels,
            out_channels=out_channels, stride=stride, bn_affine=False,
            return_preact=False, binarized=binarized)
        self.conv2 = pre_conv3x3_block_1bit(in_channels=out_channels,
            out_channels=out_channels, bn_affine=False, binarized=binarized)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class PreResUnit1bit(nn.Module):
    """
    PreResNet unit with residual connection (with binarization).

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    binarized : bool, default False
        Whether to use binarization.
    """

    def __init__(self, in_channels, out_channels, stride, binarized=False):
        super(PreResUnit1bit, self).__init__()
        self.resize_identity = stride != 1
        self.body = PreResBlock1bit(in_channels=in_channels, out_channels=
            out_channels, stride=stride, binarized=binarized)
        if self.resize_identity:
            self.identity_pool = nn.AvgPool2d(kernel_size=3, stride=2,
                padding=1)

    def forward(self, x):
        identity = x
        x = self.body(x)
        if self.resize_identity:
            identity = self.identity_pool(identity)
            identity = torch.cat((identity, torch.zeros_like(identity)), dim=1)
        x = x + identity
        return x


class PreResActivation(nn.Module):
    """
    PreResNet pure pre-activation block without convolution layer. It's used by itself as the final block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    bn_affine : bool, default True
        Whether the BatchNorm layer learns affine parameters.
    """

    def __init__(self, in_channels, bn_affine=True):
        super(PreResActivation, self).__init__()
        self.bn = nn.BatchNorm2d(num_features=in_channels, affine=bn_affine)
        self.activ = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.bn(x)
        x = self.activ(x)
        return x


def conv3x3_1bit(in_channels, out_channels, stride=1, padding=1, dilation=1,
    groups=1, bias=False, binarized=False):
    """
    Convolution 3x3 layer with binarization.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 1
        Padding value for convolution layer.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    binarized : bool, default False
        Whether to use binarization.
    """
    return Conv2d1bit(in_channels=in_channels, out_channels=out_channels,
        kernel_size=3, stride=stride, padding=padding, dilation=dilation,
        groups=groups, bias=bias, binarized=binarized)


def conv1x1_block_1bit(in_channels, out_channels, stride=1, padding=0,
    groups=1, bias=False, bn_affine=True, activate=True, binarized=False):
    """
    1x1 version of the standard convolution block with binarization.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 0
        Padding value for convolution layer.
    groups : int, default 1
        Number of groups.
    bias : bool, default False
        Whether the layer uses a bias vector.
    bn_affine : bool, default True
        Whether the BatchNorm layer learns affine parameters.
    activate : bool, default True
        Whether activate the convolution block.
    binarized : bool, default False
        Whether to use binarization.
    """
    return ConvBlock1bit(in_channels=in_channels, out_channels=out_channels,
        kernel_size=1, stride=stride, padding=padding, groups=groups, bias=
        bias, bn_affine=bn_affine, activate=activate, binarized=binarized)


class CIFARWRN1bit(nn.Module):
    """
    WRN-1bit model for CIFAR from 'Wide Residual Networks,' https://arxiv.org/abs/1605.07146.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    binarized : bool, default True
        Whether to use binarization.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (32, 32)
        Spatial size of the expected input image.
    num_classes : int, default 10
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, binarized=True,
        in_channels=3, in_size=(32, 32), num_classes=10):
        super(CIFARWRN1bit, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', conv3x3_1bit(in_channels=
            in_channels, out_channels=init_block_channels, binarized=binarized)
            )
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), PreResUnit1bit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, binarized=binarized))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('post_activ', PreResActivation(in_channels
            =in_channels, bn_affine=False))
        self.output = nn.Sequential()
        self.output.add_module('final_conv', conv1x1_block_1bit(in_channels
            =in_channels, out_channels=num_classes, activate=False,
            binarized=binarized))
        self.output.add_module('final_pool', nn.AvgPool2d(kernel_size=8,
            stride=1))
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = self.output(x)
        x = x.view(x.size(0), -1)
        return x


class CIFARWRN(nn.Module):
    """
    WRN model for CIFAR from 'Wide Residual Networks,' https://arxiv.org/abs/1605.07146.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (32, 32)
        Spatial size of the expected input image.
    num_classes : int, default 10
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, in_channels=3,
        in_size=(32, 32), num_classes=10):
        super(CIFARWRN, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', conv3x3(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stride = 2 if j == 0 and i != 0 else 1
                stage.add_module('unit{}'.format(j + 1), PreResUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=stride, bottleneck=False, conv1_stride=False))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('post_activ', PreResActivation(in_channels
            =in_channels))
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=8,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class DwsConv(nn.Module):
    """
    Depthwise separable convolution layer.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 0
        Padding value for convolution layer.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride=1,
        padding=0):
        super(DwsConv, self).__init__()
        self.dw_conv = nn.Conv2d(in_channels=in_channels, out_channels=
            in_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, groups=in_channels, bias=False)
        self.pw_conv = nn.Conv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=1, bias=False)

    def forward(self, x):
        x = self.dw_conv(x)
        x = self.pw_conv(x)
        return x


class DwsConvBlock(nn.Module):
    """
    Depthwise separable convolution block with batchnorm and ReLU pre-activation.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    activate : bool
        Whether activate the convolution block.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, activate):
        super(DwsConvBlock, self).__init__()
        self.activate = activate
        if self.activate:
            self.activ = nn.ReLU(inplace=False)
        self.conv = DwsConv(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding)
        self.bn = nn.BatchNorm2d(num_features=out_channels)

    def forward(self, x):
        if self.activate:
            x = self.activ(x)
        x = self.conv(x)
        x = self.bn(x)
        return x


def dws_conv3x3_block(in_channels, out_channels, activate):
    """
    3x3 version of the depthwise separable convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    activate : bool
        Whether activate the convolution block.
    """
    return DwsConvBlock(in_channels=in_channels, out_channels=out_channels,
        kernel_size=3, stride=1, padding=1, activate=activate)


class XceptionUnit(nn.Module):
    """
    Xception unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int
        Strides of the downsample polling.
    reps : int
        Number of repetitions.
    start_with_relu : bool, default True
        Whether start with ReLU activation.
    grow_first : bool, default True
        Whether start from growing.
    """

    def __init__(self, in_channels, out_channels, stride, reps,
        start_with_relu=True, grow_first=True):
        super(XceptionUnit, self).__init__()
        self.resize_identity = in_channels != out_channels or stride != 1
        if self.resize_identity:
            self.identity_conv = conv1x1_block(in_channels=in_channels,
                out_channels=out_channels, stride=stride, activation=None)
        self.body = nn.Sequential()
        for i in range(reps):
            if grow_first and i == 0 or not grow_first and i == reps - 1:
                in_channels_i = in_channels
                out_channels_i = out_channels
            elif grow_first:
                in_channels_i = out_channels
                out_channels_i = out_channels
            else:
                in_channels_i = in_channels
                out_channels_i = in_channels
            activate = start_with_relu if i == 0 else True
            self.body.add_module('block{}'.format(i + 1), dws_conv3x3_block
                (in_channels=in_channels_i, out_channels=out_channels_i,
                activate=activate))
        if stride != 1:
            self.body.add_module('pool', nn.MaxPool2d(kernel_size=3, stride
                =stride, padding=1))

    def forward(self, x):
        if self.resize_identity:
            identity = self.identity_conv(x)
        else:
            identity = x
        x = self.body(x)
        x = x + identity
        return x


class XceptionInitBlock(nn.Module):
    """
    Xception specific initial block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    """

    def __init__(self, in_channels):
        super(XceptionInitBlock, self).__init__()
        self.conv1 = conv3x3_block(in_channels=in_channels, out_channels=32,
            stride=2, padding=0)
        self.conv2 = conv3x3_block(in_channels=32, out_channels=64, stride=
            1, padding=0)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


class XceptionFinalBlock(nn.Module):
    """
    Xception specific final block.
    """

    def __init__(self):
        super(XceptionFinalBlock, self).__init__()
        self.conv1 = dws_conv3x3_block(in_channels=1024, out_channels=1536,
            activate=False)
        self.conv2 = dws_conv3x3_block(in_channels=1536, out_channels=2048,
            activate=True)
        self.activ = nn.ReLU(inplace=True)
        self.pool = nn.AvgPool2d(kernel_size=10, stride=1)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.activ(x)
        x = self.pool(x)
        return x


class Xception(nn.Module):
    """
    Xception model from 'Xception: Deep Learning with Depthwise Separable Convolutions,'
    https://arxiv.org/abs/1610.02357.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, in_channels=3, in_size=(299, 299),
        num_classes=1000):
        super(Xception, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', XceptionInitBlock(
            in_channels=in_channels))
        in_channels = 64
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            for j, out_channels in enumerate(channels_per_stage):
                stage.add_module('unit{}'.format(j + 1), XceptionUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    stride=2 if j == 0 else 1, reps=2 if j == 0 else 3,
                    start_with_relu=i != 0 or j != 0, grow_first=i != len(
                    channels) - 1 or j != len(channels_per_stage) - 1))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('final_block', XceptionFinalBlock())
        self.output = nn.Linear(in_features=2048, out_features=num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class XConv2d(nn.Conv2d):
    """
    X-Convolution layer.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    groups : int, default 1
        Number of groups.
    expand_ratio : int, default 2
        Ratio of expansion.
    """

    def __init__(self, in_channels, out_channels, kernel_size, groups=1,
        expand_ratio=2, **kwargs):
        super(XConv2d, self).__init__(in_channels=in_channels, out_channels
            =out_channels, kernel_size=kernel_size, groups=groups, **kwargs)
        self.expand_ratio = expand_ratio
        if isinstance(kernel_size, int):
            kernel_size = kernel_size, kernel_size
        grouped_in_channels = in_channels // groups
        self.mask = torch.nn.Parameter(data=torch.Tensor(out_channels,
            grouped_in_channels, *kernel_size), requires_grad=False)
        self.init_parameters()

    def init_parameters(self):
        shape = self.mask.shape
        expand_size = max(shape[1] // self.expand_ratio, 1)
        self.mask[:] = 0
        for i in range(shape[0]):
            jj = torch.randperm(shape[1], device=self.mask.device)[:expand_size
                ]
            self.mask[(i), (jj), :, :] = 1

    def forward(self, input):
        masked_weight = self.weight.mul(self.mask)
        return F.conv2d(input=input, weight=masked_weight, bias=self.bias,
            stride=self.stride, padding=self.padding, dilation=self.
            dilation, groups=self.groups)


class PreXConvBlock(nn.Module):
    """
    X-Convolution block with Batch normalization and ReLU pre-activation.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    kernel_size : int or tuple/list of 2 int
        Convolution window size.
    stride : int or tuple/list of 2 int
        Strides of the convolution.
    padding : int or tuple/list of 2 int
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    bias : bool, default False
        Whether the layer uses a bias vector.
    return_preact : bool, default False
        Whether return pre-activation. It's used by PreResNet.
    activate : bool, default True
        Whether activate the convolution block.
    expand_ratio : int, default 2
        Ratio of expansion.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride,
        padding, dilation=1, bias=False, return_preact=False, activate=True,
        expand_ratio=2):
        super(PreXConvBlock, self).__init__()
        self.return_preact = return_preact
        self.activate = activate
        self.bn = nn.BatchNorm2d(num_features=in_channels)
        if self.activate:
            self.activ = nn.ReLU(inplace=True)
        self.conv = XConv2d(in_channels=in_channels, out_channels=
            out_channels, kernel_size=kernel_size, stride=stride, padding=
            padding, dilation=dilation, bias=bias, expand_ratio=expand_ratio)

    def forward(self, x):
        x = self.bn(x)
        if self.activate:
            x = self.activ(x)
        if self.return_preact:
            x_pre_activ = x
        x = self.conv(x)
        if self.return_preact:
            return x, x_pre_activ
        else:
            return x


def pre_xconv3x3_block(in_channels, out_channels, stride=1, padding=1,
    dilation=1, return_preact=False, activate=True, expand_ratio=2):
    """
    3x3 version of the pre-activated x-convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    padding : int or tuple/list of 2 int, default 1
        Padding value for convolution layer.
    dilation : int or tuple/list of 2 int, default 1
        Dilation value for convolution layer.
    return_preact : bool, default False
        Whether return pre-activation.
    activate : bool, default True
        Whether activate the convolution block.
    expand_ratio : int, default 2
        Ratio of expansion.
    """
    return PreXConvBlock(in_channels=in_channels, out_channels=out_channels,
        kernel_size=3, stride=stride, padding=padding, dilation=dilation,
        return_preact=return_preact, activate=activate, expand_ratio=
        expand_ratio)


def pre_xconv1x1_block(in_channels, out_channels, stride=1, bias=False,
    return_preact=False, activate=True, expand_ratio=2):
    """
    1x1 version of the pre-activated x-convolution block.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    stride : int or tuple/list of 2 int, default 1
        Strides of the convolution.
    bias : bool, default False
        Whether the layer uses a bias vector.
    return_preact : bool, default False
        Whether return pre-activation.
    activate : bool, default True
        Whether activate the convolution block.
    expand_ratio : int, default 2
        Ratio of expansion.
    """
    return PreXConvBlock(in_channels=in_channels, out_channels=out_channels,
        kernel_size=1, stride=stride, padding=0, bias=bias, return_preact=
        return_preact, activate=activate, expand_ratio=expand_ratio)


class XDenseUnit(nn.Module):
    """
    X-DenseNet unit.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    dropout_rate : float
        Parameter of Dropout layer. Faction of the input units to drop.
    expand_ratio : int
        Ratio of expansion.
    """

    def __init__(self, in_channels, out_channels, dropout_rate, expand_ratio):
        super(XDenseUnit, self).__init__()
        self.use_dropout = dropout_rate != 0.0
        bn_size = 4
        inc_channels = out_channels - in_channels
        mid_channels = inc_channels * bn_size
        self.conv1 = pre_xconv1x1_block(in_channels=in_channels,
            out_channels=mid_channels, expand_ratio=expand_ratio)
        self.conv2 = pre_xconv3x3_block(in_channels=mid_channels,
            out_channels=inc_channels, expand_ratio=expand_ratio)
        if self.use_dropout:
            self.dropout = nn.Dropout(p=dropout_rate)

    def forward(self, x):
        identity = x
        x = self.conv1(x)
        x = self.conv2(x)
        if self.use_dropout:
            x = self.dropout(x)
        x = torch.cat((identity, x), dim=1)
        return x


class XDenseNet(nn.Module):
    """
    X-DenseNet model from 'Deep Expander Networks: Efficient Deep Networks from Graph Theory,'
    https://arxiv.org/abs/1711.08757.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    dropout_rate : float, default 0.0
        Parameter of Dropout layer. Faction of the input units to drop.
    expand_ratio : int, default 2
        Ratio of expansion.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (224, 224)
        Spatial size of the expected input image.
    num_classes : int, default 1000
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, dropout_rate=0.0,
        expand_ratio=2, in_channels=3, in_size=(224, 224), num_classes=1000):
        super(XDenseNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        self.features = nn.Sequential()
        self.features.add_module('init_block', PreResInitBlock(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            if i != 0:
                stage.add_module('trans{}'.format(i + 1), TransitionBlock(
                    in_channels=in_channels, out_channels=in_channels // 2))
                in_channels = in_channels // 2
            for j, out_channels in enumerate(channels_per_stage):
                stage.add_module('unit{}'.format(j + 1), XDenseUnit(
                    in_channels=in_channels, out_channels=out_channels,
                    dropout_rate=dropout_rate, expand_ratio=expand_ratio))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('post_activ', PreResActivation(in_channels
            =in_channels))
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=7,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


class XDenseSimpleUnit(nn.Module):
    """
    X-DenseNet simple unit for CIFAR.

    Parameters:
    ----------
    in_channels : int
        Number of input channels.
    out_channels : int
        Number of output channels.
    dropout_rate : float
        Parameter of Dropout layer. Faction of the input units to drop.
    expand_ratio : int
        Ratio of expansion.
    """

    def __init__(self, in_channels, out_channels, dropout_rate, expand_ratio):
        super(XDenseSimpleUnit, self).__init__()
        self.use_dropout = dropout_rate != 0.0
        inc_channels = out_channels - in_channels
        self.conv = pre_xconv3x3_block(in_channels=in_channels,
            out_channels=inc_channels, expand_ratio=expand_ratio)
        if self.use_dropout:
            self.dropout = nn.Dropout(p=dropout_rate)

    def forward(self, x):
        identity = x
        x = self.conv(x)
        if self.use_dropout:
            x = self.dropout(x)
        x = torch.cat((identity, x), dim=1)
        return x


class CIFARXDenseNet(nn.Module):
    """
    X-DenseNet model for CIFAR from 'Deep Expander Networks: Efficient Deep Networks from Graph Theory,'
    https://arxiv.org/abs/1711.08757.

    Parameters:
    ----------
    channels : list of list of int
        Number of output channels for each unit.
    init_block_channels : int
        Number of output channels for the initial unit.
    bottleneck : bool
        Whether to use a bottleneck or simple block in units.
    dropout_rate : float, default 0.0
        Parameter of Dropout layer. Faction of the input units to drop.
    expand_ratio : int, default 2
        Ratio of expansion.
    in_channels : int, default 3
        Number of input channels.
    in_size : tuple of two ints, default (32, 32)
        Spatial size of the expected input image.
    num_classes : int, default 10
        Number of classification classes.
    """

    def __init__(self, channels, init_block_channels, bottleneck,
        dropout_rate=0.0, expand_ratio=2, in_channels=3, in_size=(32, 32),
        num_classes=10):
        super(CIFARXDenseNet, self).__init__()
        self.in_size = in_size
        self.num_classes = num_classes
        unit_class = XDenseUnit if bottleneck else XDenseSimpleUnit
        self.features = nn.Sequential()
        self.features.add_module('init_block', conv3x3(in_channels=
            in_channels, out_channels=init_block_channels))
        in_channels = init_block_channels
        for i, channels_per_stage in enumerate(channels):
            stage = nn.Sequential()
            if i != 0:
                stage.add_module('trans{}'.format(i + 1), TransitionBlock(
                    in_channels=in_channels, out_channels=in_channels // 2))
                in_channels = in_channels // 2
            for j, out_channels in enumerate(channels_per_stage):
                stage.add_module('unit{}'.format(j + 1), unit_class(
                    in_channels=in_channels, out_channels=out_channels,
                    dropout_rate=dropout_rate, expand_ratio=expand_ratio))
                in_channels = out_channels
            self.features.add_module('stage{}'.format(i + 1), stage)
        self.features.add_module('post_activ', PreResActivation(in_channels
            =in_channels))
        self.features.add_module('final_pool', nn.AvgPool2d(kernel_size=8,
            stride=1))
        self.output = nn.Linear(in_features=in_channels, out_features=
            num_classes)
        self._init_params()

    def _init_params(self):
        for name, module in self.named_modules():
            if isinstance(module, nn.Conv2d):
                init.kaiming_uniform_(module.weight)
                if module.bias is not None:
                    init.constant_(module.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.output(x)
        return x


LENGTH = 64


class PytorchModel(torch.nn.Module):

    def __init__(self):
        super(PytorchModel, self).__init__()
        self.bn = torch.nn.BatchNorm2d(num_features=LENGTH, eps=1e-05,
            momentum=0.9)

    def forward(self, x):
        x = self.bn(x)
        return x


class PytorchModel(torch.nn.Module):

    def __init__(self):
        super(PytorchModel, self).__init__()
        self.conv = torch.nn.Conv2d(in_channels=3, out_channels=64,
            kernel_size=7, stride=2, padding=3, bias=True)

    def forward(self, x):
        x = self.conv(x)
        return x


class PytorchModel(torch.nn.Module):

    def __init__(self):
        super(PytorchModel, self).__init__()
        self.dense = torch.nn.Linear(in_features=1024, out_features=1000,
            bias=False)

    def forward(self, x):
        x = self.dense(x)
        return x


import torch
from _paritybench_helpers import _mock_config, _mock_layer, _paritybench_base, _fails_compile

class Test_osmr_imgclsmob(_paritybench_base):
    pass
    def test_000(self):
        self._check(AlexDense(*[], **{'in_channels': 4, 'out_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_001(self):
        self._check(AlexOutputBlock(*[], **{'in_channels': 4, 'classes': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_002(self):
        self._check(AttentionRefinementModule(*[], **{'in_channels': 4, 'out_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_003(self):
        self._check(AvgPoolBranch(*[], **{'in_channels': 4, 'out_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_004(self):
        self._check(BR(*[], **{'nOut': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_005(self):
        self._check(Backbone(*[], **{}), [torch.rand([4, 3, 64, 64])], {})

    def test_006(self):
        self._check(BasicBlock(*[], **{'inplanes': 4, 'planes': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_007(self):
        self._check(BiSeNetOutput(*[], **{'in_channels': 4, 'mid_channels': 4, 'out_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_008(self):
        self._check(BranchNet(*[], **{'inplanes': 4, 'planes': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_009(self):
        self._check(C(*[], **{'nIn': 4, 'nOut': 4, 'kSize': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_010(self):
        self._check(CB(*[], **{'nIn': 4, 'nOut': 4, 'kSize': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_011(self):
        self._check(CBR(*[], **{'nIn': 4, 'nOut': 4, 'kSize': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_012(self):
        self._check(ChannelShuffle(*[], **{'channels': 4, 'groups': 1}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_013(self):
        self._check(ChannelShuffle2(*[], **{'channels': 4, 'groups': 1}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_014(self):
        self._check(ChannelSqueeze(*[], **{'channels': 4, 'groups': 1}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_015(self):
        self._check(ChannetConv(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_016(self):
        self._check(ChannetDwsConvBlock(*[], **{'in_channels': 4, 'out_channels': 4, 'stride': 1}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_017(self):
        self._check(CondenseComplexConv(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4, 'groups': 1}), [torch.rand([4, 4, 4, 4])], {})

    def test_018(self):
        self._check(CondenseInitBlock(*[], **{'in_channels': 4, 'out_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_019(self):
        self._check(CondenseLinear(*[], **{'in_features': 4, 'out_features': 4}), [torch.rand([4, 4, 4, 2])], {})

    def test_020(self):
        self._check(CondenseSimpleConv(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4, 'groups': 1}), [torch.rand([4, 4, 4, 4])], {})

    def test_021(self):
        self._check(Conv(*[], **{'inp_dim': 4, 'out_dim': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_022(self):
        self._check(Conv2d1bit(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1}), [torch.rand([4, 4, 4, 4])], {})

    def test_023(self):
        self._check(ConvBNReLU(*[], **{'in_channels': 4, 'out_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_024(self):
        self._check(ConvBlock1bit(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_025(self):
        self._check(Cpm(*[], **{'in_channels': 4, 'out_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_026(self):
        self._check(DIAAttention(*[], **{'in_x_features': 4, 'in_h_features': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_027(self):
        self._check(DIALSTMCell(*[], **{'in_x_features': 4, 'in_h_features': 4, 'num_layers': 1}), [torch.rand([4, 4]), torch.rand([4, 4]), torch.rand([4, 4])], {})

    def test_028(self):
        self._check(DPNConv(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4, 'groups': 1}), [torch.rand([4, 4, 4, 4])], {})

    def test_029(self):
        self._check(DPNInitBlock(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'padding': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_030(self):
        self._check(DPNUnit(*[], **{'in_channels': 4, 'mid_channels': 4, 'bw': 4, 'inc': 4, 'groups': 1, 'has_proj': 4, 'key_stride': 1}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_031(self):
        self._check(DRNBlock(*[], **{'in_channels': 4, 'out_channels': 4, 'stride': 1, 'dilation': 1}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_032(self):
        self._check(DRNBottleneck(*[], **{'in_channels': 4, 'out_channels': 4, 'stride': 1, 'dilation': 1}), [torch.rand([4, 4, 4, 4])], {})

    def test_033(self):
        self._check(DRNConv(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4, 'dilation': 1, 'activate': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_034(self):
        self._check(DartsConv(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_035(self):
        self._check(DilatedConv(*[], **{'inp_dim': 4, 'out_dim': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_036(self):
        self._check(DiracConv(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_037(self):
        self._check(DiracInitBlock(*[], **{'in_channels': 4, 'out_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_038(self):
        self._check(DropConvBlock(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_039(self):
        self._check(DualPathSequential(*[], **{}), [torch.rand([4, 4, 4, 4])], {})

    def test_040(self):
        self._check(DwsConv(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_041(self):
        self._check(DwsConvBlock(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4, 'activate': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_042(self):
        self._check(FeatureFusionModule(*[], **{'in_channels': 4, 'out_channels': 4}), [torch.rand([4, 1, 4, 4]), torch.rand([4, 3, 4, 4])], {})

    def test_043(self):
        self._check(FireConv(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'padding': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_044(self):
        self._check(FirstLSTMAmp(*[], **{'in_features': 4, 'out_features': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_045(self):
        self._check(Flatten(*[], **{}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_046(self):
        self._check(FractalBlock(*[], **{'in_channels': 4, 'out_channels': 4, 'num_columns': 4, 'loc_drop_prob': 4, 'dropout_prob': 0.5}), [torch.rand([4, 4, 4, 4]), torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_047(self):
        self._check(FractalUnit(*[], **{'in_channels': 4, 'out_channels': 4, 'num_columns': 4, 'loc_drop_prob': 4, 'dropout_prob': 0.5}), [torch.rand([4, 4, 4, 4]), torch.rand([4, 4, 4, 4])], {})

    def test_048(self):
        self._check(GhostHSigmoid(*[], **{}), [torch.rand([4, 4, 4, 4])], {})

    def test_049(self):
        self._check(GlobalAvgMaxPool2D(*[], **{}), [torch.rand([4, 4, 4, 4])], {})

    def test_050(self):
        self._check(HSigmoid(*[], **{}), [torch.rand([4, 4, 4, 4])], {})

    def test_051(self):
        self._check(HSwish(*[], **{}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_052(self):
        self._check(HeatmapMaxDetBlock(*[], **{}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_053(self):
        self._check(Hourglass(*[], **{'depth': 1, 'nFeat': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_054(self):
        self._check(IBN(*[], **{'channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_055(self):
        self._check(IBNConvBlock(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_056(self):
        self._check(IBNPreConvBlock(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_057(self):
        self._check(IBNbConvBlock(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_058(self):
        self._check(IBNbResInitBlock(*[], **{'in_channels': 4, 'out_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_059(self):
        self._check(IRevBottleneck(*[], **{'in_channels': 4, 'out_channels': 4, 'stride': 1, 'preactivate': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_060(self):
        self._check(IRevDualPathSequential(*[], **{}), [torch.rand([4, 4, 4, 4])], {})

    def test_061(self):
        self._check(IRevInjectivePad(*[], **{'padding': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_062(self):
        self._check(IRevMergeBlock(*[], **{}), [torch.rand([4, 4, 4, 4]), torch.rand([4, 4, 4, 4])], {})

    def test_063(self):
        self._check(IRevPostActivation(*[], **{'in_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_064(self):
        self._check(IRevSplitBlock(*[], **{}), [torch.rand([4, 4, 4, 4]), torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_065(self):
        self._check(IRevUnit(*[], **{'in_channels': 4, 'out_channels': 4, 'stride': 1, 'preactivate': 4}), [torch.rand([4, 4, 4, 4]), torch.rand([4, 4, 4, 4])], {})

    def test_066(self):
        self._check(Identity(*[], **{}), [torch.rand([4, 4, 4, 4])], {})

    def test_067(self):
        self._check(InceptConv(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_068(self):
        self._check(InitialStage(*[], **{'num_channels': 4, 'num_heatmaps': 4, 'num_pafs': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_069(self):
        self._check(InterpolationBlock(*[], **{'scale_factor': 1.0}), [torch.rand([4, 4, 4, 4])], {})

    def test_070(self):
        self._check(MEInitBlock(*[], **{'in_channels': 4, 'out_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_071(self):
        self._check(MaxPoolBranch(*[], **{}), [torch.rand([4, 4, 4, 4])], {})

    def test_072(self):
        self._check(Merge(*[], **{'x_dim': 4, 'y_dim': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_073(self):
        self._check(MixConv(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_074(self):
        self._check(MultiBlockSequential(*[], **{}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_075(self):
        self._check(MultiOutputSequential(*[], **{}), [torch.rand([4, 4, 4, 4])], {})

    def test_076(self):
        self._check(NASNetInitBlock(*[], **{'in_channels': 4, 'out_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_077(self):
        self._check(NINConv(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_078(self):
        self._check(NasAvgPoolBlock(*[], **{}), [torch.rand([4, 4, 4, 4])], {})

    def test_079(self):
        self._check(NasConv(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4, 'groups': 1}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_080(self):
        self._check(NasMaxPoolBlock(*[], **{}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_081(self):
        self._check(NasPathBlock(*[], **{'in_channels': 4, 'out_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_082(self):
        self._check(NasPathBranch(*[], **{'in_channels': 4, 'out_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_083(self):
        self._check(NormActivation(*[], **{'in_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_084(self):
        self._check(OctConv(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_085(self):
        self._check(OctConvBlock(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_086(self):
        self._check(OctResBlock(*[], **{'in_channels': 4, 'out_channels': 4, 'stride': 1}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_087(self):
        self._check(OctResBottleneck(*[], **{'in_channels': 4, 'out_channels': 4, 'stride': 1}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_088(self):
        self._check(OctResUnit(*[], **{'in_channels': 4, 'out_channels': 4, 'stride': 1}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_089(self):
        self._check(ParallelConcurent(*[], **{}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_090(self):
        self._check(ParametricSequential(*[], **{}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_091(self):
        self._check(PnasMaxPathBlock(*[], **{'in_channels': 4, 'out_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_092(self):
        self._check(PnasMaxPoolBlock(*[], **{}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_093(self):
        self._check(PolyConv(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4, 'num_blocks': 1}), [torch.rand([4, 4, 4, 4]), 0], {})

    def test_094(self):
        self._check(PoseEstimationWithMobileNet2d(*[], **{}), [torch.rand([4, 3, 64, 64])], {})

    def test_095(self):
        self._check(PostActivation(*[], **{'in_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_096(self):
        self._check(PreActivation(*[], **{'in_channels': 4, 'bn_eps': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_097(self):
        self._check(PreConvBlock(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_098(self):
        self._check(PreConvBlock1bit(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_099(self):
        self._check(PreResActivation(*[], **{'in_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_100(self):
        self._check(PreResBlock(*[], **{'in_channels': 4, 'out_channels': 4, 'stride': 1}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_101(self):
        self._check(PreResBlock1bit(*[], **{'in_channels': 4, 'out_channels': 4, 'stride': 1}), [torch.rand([4, 4, 4, 4])], {})

    def test_102(self):
        self._check(PreResInitBlock(*[], **{'in_channels': 4, 'out_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_103(self):
        self._check(PreResUnit1bit(*[], **{'in_channels': 4, 'out_channels': 4, 'stride': 1}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_104(self):
        self._check(PreXConvBlock(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_105(self):
        self._check(PyrBlock(*[], **{'in_channels': 4, 'out_channels': 4, 'stride': 1}), [torch.rand([4, 4, 4, 4])], {})

    def test_106(self):
        self._check(PyrInitBlock(*[], **{'in_channels': 4, 'out_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_107(self):
        self._check(PytorchModel(*[], **{}), [torch.rand([1024, 1024])], {})

    def test_108(self):
        self._check(RefinementStage(*[], **{'in_channels': 4, 'out_channels': 4, 'num_heatmaps': 4, 'num_pafs': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_109(self):
        self._check(RefinementStageBlock(*[], **{'in_channels': 4, 'out_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_110(self):
        self._check(RefinementStageLight(*[], **{'in_channels': 4, 'mid_channels': 4, 'out_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_111(self):
        self._check(Residual(*[], **{'ins': 4, 'outs': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_112(self):
        self._check(Resv1Block(*[], **{'inplanes': 4, 'planes': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_113(self):
        self._check(Resv2Block(*[], **{'inplanes': 4, 'planes': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_114(self):
        self._check(RevPostActivation(*[], **{'in_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_115(self):
        self._check(RevResBlock(*[], **{'in_channels': 4, 'out_channels': 4, 'stride': 1, 'preactivate': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_116(self):
        self._check(RiRFinalBlock(*[], **{}), [torch.rand([4, 4, 4, 4]), torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_117(self):
        self._check(SBmodule(*[], **{'nIn': 4, 'nOut': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_118(self):
        self._check(SEseparableCBR(*[], **{'nIn': 4, 'nOut': 4, 'kSize': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_119(self):
        self._check(SequentialConcurrent(*[], **{}), [torch.rand([4, 4, 4, 4])], {})

    def test_120(self):
        self._check(ShaConvBlock(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_121(self):
        self._check(ShakeShakeShortcut(*[], **{'in_channels': 4, 'out_channels': 4, 'stride': 1}), [torch.rand([4, 4, 4, 4])], {})

    def test_122(self):
        self._check(SimpleGroupBlock(*[], **{'channels': 4, 'multi_blocks': 1, 'groups': 1, 'dropout_rate': 0.5}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_123(self):
        self._check(SpatialGate(*[], **{}), [torch.rand([4, 4, 4, 4])], {})

    def test_124(self):
        self._check(SqueezeBlock(*[], **{'exp_size': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_125(self):
        self._check(SqueezeInitBlock(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_126(self):
        self._check(Swish(*[], **{}), [torch.rand([4, 4, 4, 4])], {})

    def test_127(self):
        self._check(VGGDense(*[], **{'in_channels': 4, 'out_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_128(self):
        self._check(VGGOutputBlock(*[], **{'in_channels': 4, 'classes': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_129(self):
        self._check(WRNBottleneck(*[], **{'in_channels': 4, 'out_channels': 4, 'stride': 1, 'width_factor': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_130(self):
        self._check(WRNConv(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4, 'stride': 1, 'padding': 4, 'activate': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_131(self):
        self._check(WRNInitBlock(*[], **{'in_channels': 4, 'out_channels': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_132(self):
        self._check(WRNUnit(*[], **{'in_channels': 4, 'out_channels': 4, 'stride': 1, 'width_factor': 4}), [torch.rand([4, 4, 4, 4])], {})

    def test_133(self):
        self._check(XConv2d(*[], **{'in_channels': 4, 'out_channels': 4, 'kernel_size': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_134(self):
        self._check(XceptionFinalBlock(*[], **{}), [torch.rand([4, 1024, 64, 64])], {})

    @_fails_compile()
    def test_135(self):
        self._check(XceptionUnit(*[], **{'in_channels': 4, 'out_channels': 4, 'stride': 1, 'reps': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_136(self):
        self._check(iSQRTCOVPool(*[], **{}), [torch.rand([4, 4, 4, 4])], {})

    def test_137(self):
        self._check(separableCBR(*[], **{'nIn': 4, 'nOut': 4, 'kSize': 4}), [torch.rand([4, 4, 4, 4])], {})

    @_fails_compile()
    def test_138(self):
        self._check(upBlock(*[], **{'in_c': 4, 'out_c': 4}), [torch.rand([4, 4, 4, 4])], {})

