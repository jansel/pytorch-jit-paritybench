import sys
_module = sys.modules[__name__]
del sys
gather_models = _module
dotav1 = _module
hrsc = _module
hrsid = _module
ssdd = _module
default_runtime = _module
schedule_1x = _module
schedule_3x = _module
schedule_40e = _module
schedule_6x = _module
cfa_r50_fpn_1x_dota_le135 = _module
cfa_r50_fpn_1x_dota_oc = _module
cfa_r50_fpn_40e_dota_oc = _module
rotated_retinanet_obb_kld_stable_convnext_adamw_fpn_1x_dota_le90 = _module
rotated_retinanet_obb_csl_gaussian_r50_fpn_fp16_1x_dota_le90 = _module
g_reppoints_r50_fpn_1x_dota_le135 = _module
gliding_vertex_r50_fpn_1x_dota_le90 = _module
rotated_retinanet_hbb_gwd_r50_fpn_1x_dota_oc = _module
rotated_retinanet_obb_gwd_r50_fpn_1x_dota_le135 = _module
rotated_retinanet_obb_gwd_r50_fpn_1x_dota_le90 = _module
r3det_kfiou_ln_r50_fpn_1x_dota_oc = _module
r3det_kfiou_ln_swin_tiny_adamw_fpn_1x_dota_ms_rr_oc = _module
r3det_kfiou_ln_swin_tiny_adamw_fpn_2x_dota_ms_rr_oc = _module
r3det_refine_kfiou_ln_r50_fpn_1x_dota_oc = _module
r3det_tiny_kfiou_ln_r50_fpn_1x_dota_oc = _module
roi_trans_kfiou_ln_r50_fpn_1x_dota_le90 = _module
roi_trans_kfiou_ln_r50_fpn_1x_dota_ms_rr_le90 = _module
roi_trans_kfiou_ln_swin_tiny_fpn_1x_dota_le90 = _module
roi_trans_kfiou_ln_swin_tiny_fpn_1x_dota_ms_rr_le90 = _module
rotated_retinanet_hbb_kfiou_r50_fpn_1x_dota_le135 = _module
rotated_retinanet_hbb_kfiou_r50_fpn_1x_dota_le90 = _module
rotated_retinanet_hbb_kfiou_r50_fpn_1x_dota_oc = _module
rotated_retinanet_obb_kfiou_r50_fpn_1x_dota_le135 = _module
rotated_retinanet_obb_kfiou_r50_fpn_1x_dota_le90 = _module
s2anet_kfiou_ln_r50_fpn_1x_dota_le135 = _module
r3det_kld_r50_fpn_1x_dota_oc = _module
r3det_kld_stable_r50_fpn_1x_dota_oc = _module
r3det_tiny_kld_r50_fpn_1x_dota_oc = _module
rotated_retinanet_hbb_kld_r50_fpn_1x_dota_oc = _module
rotated_retinanet_hbb_kld_stable_r50_fpn_1x_dota_oc = _module
rotated_retinanet_hbb_kld_stable_r50_fpn_6x_hrsc_rr_oc = _module
rotated_retinanet_obb_kld_r50_fpn_1x_dota_le135 = _module
rotated_retinanet_obb_kld_r50_fpn_1x_dota_le90 = _module
rotated_retinanet_obb_kld_stable_r50_adamw_fpn_1x_dota_le90 = _module
rotated_retinanet_obb_kld_stable_r50_fpn_1x_dota_le90 = _module
rotated_retinanet_obb_kld_stable_r50_fpn_6x_hrsc_rr_le90 = _module
oriented_rcnn_r50_fpn_1x_dota_le90 = _module
oriented_rcnn_r50_fpn_6x_hrsid_le90 = _module
oriented_rcnn_r50_fpn_6x_ssdd_le90 = _module
oriented_rcnn_r50_fpn_fp16_1x_dota_le90 = _module
oriented_rcnn_swin_tiny_fpn_1x_dota_le90 = _module
oriented_reppoints_r50_fpn_1x_dota_le135 = _module
oriented_reppoints_r50_fpn_40e_dota_ms_le135 = _module
r3det_r50_fpn_1x_dota_oc = _module
r3det_refine_r50_fpn_1x_dota_oc = _module
r3det_tiny_r50_fpn_1x_dota_oc = _module
redet_re50_refpn_1x_dota_le90 = _module
redet_re50_refpn_1x_dota_ms_rr_le90 = _module
redet_re50_refpn_3x_hrsc_le90 = _module
redet_re50_refpn_fp16_1x_dota_le90 = _module
roi_trans_r50_fpn_1x_dota_le135 = _module
roi_trans_r50_fpn_1x_dota_le90 = _module
roi_trans_r50_fpn_1x_dota_ms_le90 = _module
roi_trans_r50_fpn_1x_dota_ms_rr_le90 = _module
roi_trans_r50_fpn_1x_dota_oc = _module
roi_trans_r50_fpn_fp16_1x_dota_le90 = _module
roi_trans_swin_tiny_fpn_1x_dota_le90 = _module
r3det_atss_r50_fpn_1x_dota_oc = _module
rotated_atss_hbb_r50_fpn_1x_dota_oc = _module
rotated_atss_obb_r50_fpn_1x_dota_le135 = _module
rotated_atss_obb_r50_fpn_1x_dota_le90 = _module
rotated_faster_rcnn_r50_fpn_1x_dota_le90 = _module
rotated_fcos_csl_gaussian_r50_fpn_1x_dota_le90 = _module
rotated_fcos_kld_r50_fpn_1x_dota_le90 = _module
rotated_fcos_r50_fpn_1x_dota_le90 = _module
rotated_fcos_sep_angle_r50_fpn_1x_dota_le90 = _module
rotated_reppoints_r50_fpn_1x_dota_le135 = _module
rotated_reppoints_r50_fpn_1x_dota_oc = _module
rotated_retinanet_hbb_r50_fpn_1x_dota_le135 = _module
rotated_retinanet_hbb_r50_fpn_1x_dota_le90 = _module
rotated_retinanet_hbb_r50_fpn_1x_dota_oc = _module
rotated_retinanet_hbb_r50_fpn_6x_hrsc_rr_oc = _module
rotated_retinanet_obb_r50_fpn_1x_dota_le135 = _module
rotated_retinanet_obb_r50_fpn_1x_dota_le90 = _module
rotated_retinanet_obb_r50_fpn_1x_dota_ms_rr_le90 = _module
rotated_retinanet_obb_r50_fpn_1x_dota_oc = _module
rotated_retinanet_obb_r50_fpn_6x_hrsc_rr_le90 = _module
rotated_retinanet_obb_r50_fpn_fp16_1x_dota_le90 = _module
s2anet_r50_fpn_1x_dota_le135 = _module
s2anet_r50_fpn_3x_hrsc_le135 = _module
s2anet_r50_fpn_fp16_1x_dota_le135 = _module
sasm_reppoints_r50_fpn_1x_dota_oc = _module
huge_image_demo = _module
image_demo = _module
conf = _module
stat = _module
mmrotate = _module
apis = _module
inference = _module
train = _module
core = _module
anchor = _module
anchor_generator = _module
builder = _module
utils = _module
bbox = _module
assigners = _module
atss_kld_assigner = _module
atss_obb_assigner = _module
convex_assigner = _module
max_convex_iou_assigner = _module
sas_assigner = _module
coder = _module
angle_coder = _module
delta_midpointoffset_rbbox_coder = _module
delta_xywha_hbbox_coder = _module
delta_xywha_rbbox_coder = _module
distance_angle_point_coder = _module
gliding_vertex_coder = _module
iou_calculators = _module
rotate_iou2d_calculator = _module
samplers = _module
rotate_random_sampler = _module
transforms = _module
gmm = _module
evaluation = _module
eval_map = _module
patch = _module
merge_results = _module
split = _module
post_processing = _module
bbox_nms_rotated = _module
visualization = _module
image = _module
palette = _module
datasets = _module
dota = _module
pipelines = _module
loading = _module
sar = _module
models = _module
backbones = _module
re_resnet = _module
dense_heads = _module
csl_rotated_fcos_head = _module
csl_rotated_retina_head = _module
kfiou_odm_refine_head = _module
kfiou_rotate_retina_head = _module
kfiou_rotate_retina_refine_head = _module
odm_refine_head = _module
oriented_reppoints_head = _module
oriented_rpn_head = _module
rotated_anchor_free_head = _module
rotated_anchor_head = _module
rotated_atss_head = _module
rotated_fcos_head = _module
rotated_reppoints_head = _module
rotated_retina_head = _module
rotated_retina_refine_head = _module
rotated_rpn_head = _module
sam_reppoints_head = _module
utils = _module
detectors = _module
base = _module
gliding_vertex = _module
oriented_rcnn = _module
r3det = _module
redet = _module
roi_transformer = _module
rotate_faster_rcnn = _module
rotated_fcos = _module
rotated_reppoints = _module
rotated_retinanet = _module
s2anet = _module
single_stage = _module
two_stage = _module
utils = _module
losses = _module
convex_giou_loss = _module
gaussian_dist_loss = _module
gaussian_dist_loss_v1 = _module
kf_iou_loss = _module
kld_reppoints_loss = _module
rotated_iou_loss = _module
smooth_focal_loss = _module
spatial_border_loss = _module
necks = _module
re_fpn = _module
roi_heads = _module
bbox_heads = _module
convfc_rbbox_head = _module
gv_bbox_head = _module
rotated_bbox_head = _module
gv_ratio_roi_head = _module
oriented_standard_roi_head = _module
roi_extractors = _module
rotate_single_level_roi_extractor = _module
roi_trans_roi_head = _module
rotate_standard_roi_head = _module
enn = _module
orconv = _module
ripool = _module
collect_env = _module
compat_config = _module
logger = _module
misc = _module
setup_env = _module
version = _module
setup = _module
test_dota = _module
test_rotate = _module
test_pipelines = _module
test_rtransforms = _module
test_backbones = _module
test_rotate_anchor_head = _module
test_sam_reppoints_head = _module
test_forward = _module
test_loss = _module
test_necks = _module
test_compat_config = _module
test_misc = _module
test_overlaps = _module
test_ranchor = _module
test_rutils = _module
test_setup_env = _module
test_transformer = _module
test_version = _module
test_visualization = _module
analyze_logs = _module
benchmark = _module
confusion_matrix = _module
get_flops = _module
img_split = _module
mmrotate2torchserve = _module
mmrotate_handler = _module
browse_dataset = _module
print_config = _module
publish_model = _module
test = _module
train = _module

from _paritybench_helpers import _mock_config, patch_functional
from unittest.mock import mock_open, MagicMock
from torch.autograd import Function
from torch.nn import Module
import abc, collections, copy, enum, functools, inspect, itertools, logging, math, matplotlib, numbers, numpy, pandas, queue, random, re, scipy, sklearn, string, tensorflow, time, torch, torchaudio, torchtext, torchvision, types, typing, uuid, warnings
import numpy as np
from torch import Tensor
patch_functional()
open = mock_open()
yaml = logging = sys = argparse = MagicMock()
ArgumentParser = argparse.ArgumentParser
_global_config = args = argv = cfg = config = params = _mock_config()
argparse.ArgumentParser.return_value.parse_args.return_value = _global_config
yaml.load.return_value = _global_config
sys.argv = _global_config
__version__ = '1.0.0'
xrange = range
wraps = functools.wraps


from collections import OrderedDict


import torch


import numpy as np


import math


from math import pi


import re


import time


from collections import defaultdict


from functools import partial


import warnings


import torch.nn as nn


import torch.utils.checkpoint as cp


from torch.nn.modules.batchnorm import _BatchNorm


import copy


from inspect import signature


import torch.nn.functional as F


from torch.autograd import Function


from torch.autograd.function import once_differentiable


from copy import deepcopy


from torch import nn


from abc import ABCMeta


from torch.nn.modules import Conv2d


from torch.nn.parameter import Parameter


import torch.multiprocessing as mp


import matplotlib.pyplot as plt


from matplotlib.ticker import MultipleLocator


import torch.distributed as dist


N = 8


def build_enn_divide_feature(planes):
    """build a enn regular feature map with the specified number of channels
    divided by N."""
    assert gspace.fibergroup.order() > 0
    N = gspace.fibergroup.order()
    planes = planes / N
    planes = int(planes)
    return enn.FieldType(gspace, [gspace.regular_repr] * planes)


def build_enn_norm_layer(num_features, postfix=''):
    """build an enn normalizion layer."""
    in_type = build_enn_divide_feature(num_features)
    return 'bn' + str(postfix), enn.InnerBatchNorm(in_type)


def ennAvgPool(inplanes, kernel_size=1, stride=None, padding=0, ceil_mode=False):
    """enn Average Pooling.

    Args:
        inplanes (int): The number of input channel.
        kernel_size (int, optional): The size of kernel.
        stride (int, optional): Stride of the convolution. Default: 1.
        padding (int or tuple): Zero-padding added to both sides of the input.
            Default: 0.
        ceil_mode (bool, optional): if True, keep information in the corner of
            feature map.
    """
    in_type = build_enn_divide_feature(inplanes)
    return enn.PointwiseAvgPool(in_type, kernel_size, stride=stride, padding=padding, ceil_mode=ceil_mode)


def ennConv(inplanes, outplanes, kernel_size=3, stride=1, padding=0, groups=1, bias=False, dilation=1):
    """enn convolution.

    Args:
        in_channels (List[int]): Number of input channels per scale.
        out_channels (int): Number of output channels (used at each scale).
        kernel_size (int, optional): The size of kernel.
        stride (int, optional): Stride of the convolution. Default: 1.
        padding (int or tuple): Zero-padding added to both sides of the input.
            Default: 0.
        groups (int): Number of blocked connections from input.
            channels to output channels. Default: 1.
        bias (bool): If True, adds a learnable bias to the output.
            Default: False.
        dilation (int or tuple): Spacing between kernel elements. Default: 1.
    """
    in_type = build_enn_divide_feature(inplanes)
    out_type = build_enn_divide_feature(outplanes)
    return enn.R2Conv(in_type, out_type, kernel_size, stride=stride, padding=padding, groups=groups, bias=bias, dilation=dilation, sigma=None, frequencies_cutoff=lambda r: 3 * r)


def ennReLU(inplanes):
    """enn ReLU."""
    in_type = build_enn_divide_feature(inplanes)
    return enn.ReLU(in_type, inplace=False)


def get_expansion(block, expansion=None):
    """Get the expansion of a residual block.

    The block expansion will be obtained by the following order:

    1. If ``expansion`` is given, just return it.
    2. If ``block`` has the attribute ``expansion``, then return
       ``block.expansion``.
    3. Return the default value according the the block type:
       1 for ``BasicBlock`` and 4 for ``Bottleneck``.

    Args:
        block (class): The block class.
        expansion (int | None): The given expansion ratio.

    Returns:
        int: The expansion of the block.
    """
    if isinstance(expansion, int):
        assert expansion > 0
    elif expansion is None:
        if hasattr(block, 'expansion'):
            expansion = block.expansion
        elif issubclass(block, BasicBlock):
            expansion = 1
        elif issubclass(block, Bottleneck):
            expansion = 4
        else:
            raise TypeError(f'expansion is not specified for {block.__name__}')
    else:
        raise TypeError('expansion must be an integer or None')
    return expansion


class ResLayer(nn.Sequential):
    """ResLayer to build ReResNet style backbone.

    Args:
        block (nn.Module): Residual block used to build ResLayer.
        num_blocks (int): Number of blocks.
        in_channels (int): Input channels of this block.
        out_channels (int): Output channels of this block.
        expansion (int, optional): The expansion for BasicBlock/Bottleneck.
            If not specified, it will firstly be obtained via
            ``block.expansion``. If the block has no attribute "expansion",
            the following default values will be used: 1 for BasicBlock and
            4 for Bottleneck. Default: None.
        stride (int): stride of the first block. Default: 1.
        avg_down (bool): Use AvgPool instead of stride conv when
            downsampling in the bottleneck. Default: False
        conv_cfg (dict): dictionary to construct and config conv layer.
            Default: None
        norm_cfg (dict): dictionary to construct and config norm layer.
            Default: dict(type='BN')
    """

    def __init__(self, block, num_blocks, in_channels, out_channels, expansion=None, stride=1, avg_down=False, conv_cfg=None, norm_cfg=dict(type='BN'), **kwargs):
        self.block = block
        self.expansion = get_expansion(block, expansion)
        downsample = None
        if stride != 1 or in_channels != out_channels:
            downsample = []
            conv_stride = stride
            if avg_down and stride != 1:
                conv_stride = 1
                downsample.append(ennAvgPool(in_channels, kernel_size=stride, stride=stride, ceil_mode=True))
            downsample.extend([ennConv(in_channels, out_channels, kernel_size=1, stride=conv_stride, bias=False), build_enn_norm_layer(out_channels)[1]])
            downsample = enn.SequentialModule(*downsample)
        layers = []
        layers.append(block(in_channels=in_channels, out_channels=out_channels, expansion=self.expansion, stride=stride, downsample=downsample, conv_cfg=conv_cfg, norm_cfg=norm_cfg, **kwargs))
        in_channels = out_channels
        for _ in range(1, num_blocks):
            layers.append(block(in_channels=in_channels, out_channels=out_channels, expansion=self.expansion, stride=1, conv_cfg=conv_cfg, norm_cfg=norm_cfg, **kwargs))
        super(ResLayer, self).__init__(*layers)


class AlignConv(nn.Module):
    """Align Conv of `S2ANet`.

    Args:
        in_channels (int): Number of input channels.
        featmap_strides (list): The strides of featmap.
        kernel_size (int, optional): The size of kernel.
        stride (int, optional): Stride of the convolution. Default: None
        deform_groups (int, optional): Number of deformable group partitions.
    """

    def __init__(self, in_channels, out_channels, kernel_size=3, stride=None, deform_groups=1):
        super(AlignConv, self).__init__()
        self.kernel_size = kernel_size
        self.stride = stride
        self.deform_conv = DeformConv2d(in_channels, out_channels, kernel_size=kernel_size, padding=(kernel_size - 1) // 2, deform_groups=deform_groups)
        self.relu = nn.ReLU(inplace=True)

    def init_weights(self):
        """Initialize weights of the head."""
        normal_init(self.deform_conv, std=0.01)

    @torch.no_grad()
    def get_offset(self, anchors, featmap_size, stride):
        """Get the offset of AlignConv."""
        dtype, device = anchors.dtype, anchors.device
        feat_h, feat_w = featmap_size
        pad = (self.kernel_size - 1) // 2
        idx = torch.arange(-pad, pad + 1, dtype=dtype, device=device)
        yy, xx = torch.meshgrid(idx, idx)
        xx = xx.reshape(-1)
        yy = yy.reshape(-1)
        xc = torch.arange(0, feat_w, device=device, dtype=dtype)
        yc = torch.arange(0, feat_h, device=device, dtype=dtype)
        yc, xc = torch.meshgrid(yc, xc)
        xc = xc.reshape(-1)
        yc = yc.reshape(-1)
        x_conv = xc[:, None] + xx
        y_conv = yc[:, None] + yy
        x_ctr, y_ctr, w, h, a = torch.unbind(anchors, dim=1)
        x_ctr, y_ctr, w, h = x_ctr / stride, y_ctr / stride, w / stride, h / stride
        cos, sin = torch.cos(a), torch.sin(a)
        dw, dh = w / self.kernel_size, h / self.kernel_size
        x, y = dw[:, None] * xx, dh[:, None] * yy
        xr = cos[:, None] * x - sin[:, None] * y
        yr = sin[:, None] * x + cos[:, None] * y
        x_anchor, y_anchor = xr + x_ctr[:, None], yr + y_ctr[:, None]
        offset_x = x_anchor - x_conv
        offset_y = y_anchor - y_conv
        offset = torch.stack([offset_y, offset_x], dim=-1)
        offset = offset.reshape(anchors.size(0), -1).permute(1, 0).reshape(-1, feat_h, feat_w)
        return offset

    def forward(self, x, anchors):
        """Forward function of AlignConv."""
        anchors = anchors.reshape(x.shape[0], x.shape[2], x.shape[3], 5)
        num_imgs, H, W = anchors.shape[:3]
        offset_list = [self.get_offset(anchors[i].reshape(-1, 5), (H, W), self.stride) for i in range(num_imgs)]
        offset_tensor = torch.stack(offset_list, dim=0)
        x = self.relu(self.deform_conv(x, offset_tensor.detach()))
        return x


class AlignConvModule(nn.Module):
    """The module of AlignConv.

    Args:
        in_channels (int): Number of input channels.
        featmap_strides (list): The strides of featmap.
        align_conv_size (int): The size of align convolution.
    """

    def __init__(self, in_channels, featmap_strides, align_conv_size):
        super(AlignConvModule, self).__init__()
        self.in_channels = in_channels
        self.featmap_strides = featmap_strides
        self.align_conv_size = align_conv_size
        self._init_layers()

    def _init_layers(self):
        """Initialize layers of the head."""
        self.ac = nn.ModuleList([AlignConv(self.in_channels, self.in_channels, kernel_size=self.align_conv_size, stride=s) for s in self.featmap_strides])

    def forward(self, x, rbboxes):
        """
        Args:
            x (list[Tensor]):
                feature maps of multiple scales
            best_rbboxes (list[list[Tensor]]):
                best rbboxes of multiple scales of multiple images
        """
        mlvl_rbboxes = [torch.cat(rbbox) for rbbox in zip(*rbboxes)]
        out = []
        for x_scale, rbboxes_scale, ac_scale in zip(x, mlvl_rbboxes, self.ac):
            feat_refined_scale = ac_scale(x_scale, rbboxes_scale)
            out.append(feat_refined_scale)
        return out


class FeatureRefineModule(nn.Module):
    """Feature refine module for `R3Det`.

    Args:
        in_channels (int): Number of input channels.
        featmap_strides (list): The strides of featmap.
        conv_cfg (dict, optional): Config dict for convolution layer.
            Default: None.
        norm_cfg (dict, optional): Config dict for normalization layer.
            Default: None.
    """

    def __init__(self, in_channels, featmap_strides, conv_cfg=None, norm_cfg=None):
        super(FeatureRefineModule, self).__init__()
        self.in_channels = in_channels
        self.featmap_strides = featmap_strides
        self.conv_cfg = conv_cfg
        self.norm_cfg = norm_cfg
        self._init_layers()

    def _init_layers(self):
        """Initialize layers of feature refine module."""
        self.conv_5_1 = nn.Conv2d(in_channels=self.in_channels, out_channels=self.in_channels, kernel_size=(5, 1), stride=1, padding=(2, 0))
        self.conv_1_5 = nn.Conv2d(in_channels=self.in_channels, out_channels=self.in_channels, kernel_size=(1, 5), stride=1, padding=(0, 2))
        self.conv_1_1 = nn.Conv2d(in_channels=self.in_channels, out_channels=self.in_channels, kernel_size=1)

    def init_weights(self):
        """Initialize weights of feature refine module."""
        normal_init(self.conv_5_1, std=0.01)
        normal_init(self.conv_1_5, std=0.01)
        normal_init(self.conv_1_1, std=0.01)

    def forward(self, x, best_rbboxes):
        """
        Args:
            x (list[Tensor]):
                feature maps of multiple scales
            best_rbboxes (list[list[Tensor]]):
                best rbboxes of multiple scales of multiple images
        """
        mlvl_rbboxes = [torch.cat(best_rbbox) for best_rbbox in zip(*best_rbboxes)]
        out = []
        for x_scale, best_rbboxes_scale, fr_scale in zip(x, mlvl_rbboxes, self.featmap_strides):
            feat_scale_1 = self.conv_5_1(self.conv_1_5(x_scale))
            feat_scale_2 = self.conv_1_1(x_scale)
            feat_scale = feat_scale_1 + feat_scale_2
            feat_refined_scale = rotated_feature_align(feat_scale, best_rbboxes_scale, 1 / fr_scale)
            out.append(x_scale + feat_refined_scale)
        return out


class ConvexGIoULossFuction(Function):
    """The function of Convex GIoU loss."""

    @staticmethod
    def forward(ctx, pred, target, weight=None, reduction=None, avg_factor=None, loss_weight=1.0):
        """Forward function.

        Args:
            ctx:  {save_for_backward, convex_points_grad}
            pred (torch.Tensor): Predicted convexes.
            target (torch.Tensor): Corresponding gt convexes.
            weight (torch.Tensor, optional): The weight of loss for each
                prediction. Defaults to None.
            reduction (str, optional): The reduction method of the
            loss. Defaults to None.
            avg_factor (int, optional): Average factor that is used to average
                the loss. Defaults to None.
            loss_weight (float, optional): The weight of loss. Defaults to 1.0.
        """
        ctx.save_for_backward(pred)
        convex_gious, grad = convex_giou(pred, target)
        loss = 1 - convex_gious
        if weight is not None:
            loss = loss * weight
            grad = grad * weight.reshape(-1, 1)
        if reduction == 'sum':
            loss = loss.sum()
        elif reduction == 'mean':
            loss = loss.mean()
        unvaild_inds = torch.nonzero((grad > 1).sum(1), as_tuple=False)[:, 0]
        grad[unvaild_inds] = 1e-06
        reduce_grad = -grad / grad.size(0) * loss_weight
        ctx.convex_points_grad = reduce_grad
        return loss

    @staticmethod
    @once_differentiable
    def backward(ctx, input=None):
        """Backward function."""
        convex_points_grad = ctx.convex_points_grad
        return convex_points_grad, None, None, None, None, None


convex_giou_loss = ConvexGIoULossFuction.apply


class ConvexGIoULoss(nn.Module):
    """Convex GIoU loss.

    Computing the Convex GIoU loss between a set of predicted convexes and
    target convexes.

    Args:
        reduction (str, optional): The reduction method of the loss. Defaults
            to 'mean'.
        loss_weight (float, optional): The weight of loss. Defaults to 1.0.

    Return:
        torch.Tensor: Loss tensor.
    """

    def __init__(self, reduction='mean', loss_weight=1.0):
        super(ConvexGIoULoss, self).__init__()
        self.reduction = reduction
        self.loss_weight = loss_weight

    def forward(self, pred, target, weight=None, avg_factor=None, reduction_override=None, **kwargs):
        """Forward function.

        Args:
            pred (torch.Tensor): Predicted convexes.
            target (torch.Tensor): Corresponding gt convexes.
            weight (torch.Tensor, optional): The weight of loss for each
                prediction. Defaults to None.
            avg_factor (int, optional): Average factor that is used to average
                the loss. Defaults to None.
            reduction_override (str, optional): The reduction method used to
                override the original reduction method of the loss.
                Defaults to None.
        """
        if weight is not None and not torch.any(weight > 0):
            return (pred * weight.unsqueeze(-1)).sum()
        assert reduction_override in (None, 'none', 'mean', 'sum')
        reduction = reduction_override if reduction_override else self.reduction
        loss = self.loss_weight * convex_giou_loss(pred, target, weight, reduction, avg_factor, self.loss_weight)
        return loss


def AspectRatio(gt_rbboxes):
    """Compute the aspect ratio of all gts.

    Args:
        gt_rbboxes (torch.Tensor): Groundtruth polygons, shape (k, 8).

    Returns:
        ratios (torch.Tensor): The aspect ratio of gt_rbboxes, shape (k, 1).
    """
    pt1, pt2, pt3, pt4 = gt_rbboxes[..., :8].chunk(4, 1)
    edge1 = torch.sqrt(torch.pow(pt1[..., 0] - pt2[..., 0], 2) + torch.pow(pt1[..., 1] - pt2[..., 1], 2))
    edge2 = torch.sqrt(torch.pow(pt2[..., 0] - pt3[..., 0], 2) + torch.pow(pt2[..., 1] - pt3[..., 1], 2))
    edges = torch.stack([edge1, edge2], dim=1)
    width, _ = torch.max(edges, 1)
    height, _ = torch.min(edges, 1)
    ratios = width / height
    return ratios


class BCConvexGIoULossFuction(Function):
    """The function of BCConvex GIoU loss."""

    @staticmethod
    def forward(ctx, pred, target, weight=None, reduction=None, avg_factor=None, loss_weight=1.0):
        """Forward function.

        Args:
            ctx:  {save_for_backward, convex_points_grad}
            pred (torch.Tensor): Predicted convexes.
            target (torch.Tensor): Corresponding gt convexes.
            weight (torch.Tensor, optional): The weight of loss for each
                prediction. Defaults to None.
            reduction (str, optional): The reduction method of the
            loss. Defaults to None.
            avg_factor (int, optional): Average factor that is used to average
                the loss. Defaults to None.
            loss_weight (float, optional): The weight of loss. Defaults to 1.0.
        """
        ctx.save_for_backward(pred)
        convex_gious, grad = convex_giou(pred, target)
        pts_pred_all_dx = pred[:, 0::2]
        pts_pred_all_dy = pred[:, 1::2]
        pred_left_x_inds = pts_pred_all_dx.min(dim=1, keepdim=True)[1]
        pred_right_x_inds = pts_pred_all_dx.max(dim=1, keepdim=True)[1]
        pred_up_y_inds = pts_pred_all_dy.min(dim=1, keepdim=True)[1]
        pred_bottom_y_inds = pts_pred_all_dy.max(dim=1, keepdim=True)[1]
        pred_right_x = pts_pred_all_dx.gather(dim=1, index=pred_right_x_inds)
        pred_right_y = pts_pred_all_dy.gather(dim=1, index=pred_right_x_inds)
        pred_left_x = pts_pred_all_dx.gather(dim=1, index=pred_left_x_inds)
        pred_left_y = pts_pred_all_dy.gather(dim=1, index=pred_left_x_inds)
        pred_up_x = pts_pred_all_dx.gather(dim=1, index=pred_up_y_inds)
        pred_up_y = pts_pred_all_dy.gather(dim=1, index=pred_up_y_inds)
        pred_bottom_x = pts_pred_all_dx.gather(dim=1, index=pred_bottom_y_inds)
        pred_bottom_y = pts_pred_all_dy.gather(dim=1, index=pred_bottom_y_inds)
        pred_corners = torch.cat([pred_left_x, pred_left_y, pred_up_x, pred_up_y, pred_right_x, pred_right_y, pred_bottom_x, pred_bottom_y], dim=-1)
        pts_target_all_dx = target[:, 0::2]
        pts_target_all_dy = target[:, 1::2]
        target_left_x_inds = pts_target_all_dx.min(dim=1, keepdim=True)[1]
        target_right_x_inds = pts_target_all_dx.max(dim=1, keepdim=True)[1]
        target_up_y_inds = pts_target_all_dy.min(dim=1, keepdim=True)[1]
        target_bottom_y_inds = pts_target_all_dy.max(dim=1, keepdim=True)[1]
        target_right_x = pts_target_all_dx.gather(dim=1, index=target_right_x_inds)
        target_right_y = pts_target_all_dy.gather(dim=1, index=target_right_x_inds)
        target_left_x = pts_target_all_dx.gather(dim=1, index=target_left_x_inds)
        target_left_y = pts_target_all_dy.gather(dim=1, index=target_left_x_inds)
        target_up_x = pts_target_all_dx.gather(dim=1, index=target_up_y_inds)
        target_up_y = pts_target_all_dy.gather(dim=1, index=target_up_y_inds)
        target_bottom_x = pts_target_all_dx.gather(dim=1, index=target_bottom_y_inds)
        target_bottom_y = pts_target_all_dy.gather(dim=1, index=target_bottom_y_inds)
        target_corners = torch.cat([target_left_x, target_left_y, target_up_x, target_up_y, target_right_x, target_right_y, target_bottom_x, target_bottom_y], dim=-1)
        pts_pred_dx_mean = pts_pred_all_dx.mean(dim=1, keepdim=True).reshape(-1, 1)
        pts_pred_dy_mean = pts_pred_all_dy.mean(dim=1, keepdim=True).reshape(-1, 1)
        pts_pred_mean = torch.cat([pts_pred_dx_mean, pts_pred_dy_mean], dim=-1)
        pts_target_dx_mean = pts_target_all_dx.mean(dim=1, keepdim=True).reshape(-1, 1)
        pts_target_dy_mean = pts_target_all_dy.mean(dim=1, keepdim=True).reshape(-1, 1)
        pts_target_mean = torch.cat([pts_target_dx_mean, pts_target_dy_mean], dim=-1)
        beta = 1.0
        diff_mean = torch.abs(pts_pred_mean - pts_target_mean)
        diff_mean_loss = torch.where(diff_mean < beta, 0.5 * diff_mean * diff_mean / beta, diff_mean - 0.5 * beta)
        diff_mean_loss = diff_mean_loss.sum() / len(diff_mean_loss)
        diff_corners = torch.abs(pred_corners - target_corners)
        diff_corners_loss = torch.where(diff_corners < beta, 0.5 * diff_corners * diff_corners / beta, diff_corners - 0.5 * beta)
        diff_corners_loss = diff_corners_loss.sum() / len(diff_corners_loss)
        target_aspect = AspectRatio(target)
        smooth_loss_weight = torch.exp(-1 / 4 * target_aspect)
        loss = smooth_loss_weight * (diff_mean_loss.reshape(-1, 1) + diff_corners_loss.reshape(-1, 1)) + 1 - (1 - 2 * smooth_loss_weight) * convex_gious
        if weight is not None:
            loss = loss * weight
            grad = grad * weight.reshape(-1, 1)
        if reduction == 'sum':
            loss = loss.sum()
        elif reduction == 'mean':
            loss = loss.mean()
        unvaild_inds = torch.nonzero((grad > 1).sum(1), as_tuple=False)[:, 0]
        grad[unvaild_inds] = 1e-06
        reduce_grad = -grad / grad.size(0) * loss_weight
        ctx.convex_points_grad = reduce_grad
        return loss

    @staticmethod
    @once_differentiable
    def backward(ctx, input=None):
        """Backward function."""
        convex_points_grad = ctx.convex_points_grad
        return convex_points_grad, None, None, None, None, None


bc_convex_giou_loss = BCConvexGIoULossFuction.apply


class BCConvexGIoULoss(nn.Module):
    """BCConvex GIoU loss.

    Computing the BCConvex GIoU loss between a set of predicted convexes and
    target convexes.

    Args:
        reduction (str, optional): The reduction method of the loss. Defaults
            to 'mean'.
        loss_weight (float, optional): The weight of loss. Defaults to 1.0.

    Return:
        torch.Tensor: Loss tensor.
    """

    def __init__(self, reduction='mean', loss_weight=1.0):
        super(BCConvexGIoULoss, self).__init__()
        self.reduction = reduction
        self.loss_weight = loss_weight

    def forward(self, pred, target, weight=None, avg_factor=None, reduction_override=None, **kwargs):
        """Forward function.

        Args:
            pred (torch.Tensor): Predicted convexes.
            target (torch.Tensor): Corresponding gt convexes.
            weight (torch.Tensor, optional): The weight of loss for each
                prediction. Defaults to None.
            avg_factor (int, optional): Average factor that is used to average
                the loss. Defaults to None.
            reduction_override (str, optional): The reduction method used to
                override the original reduction method of the loss.
                Defaults to None.
        """
        if weight is not None and not torch.any(weight > 0):
            return (pred * weight.unsqueeze(-1)).sum()
        assert reduction_override in (None, 'none', 'mean', 'sum')
        reduction = reduction_override if reduction_override else self.reduction
        loss = self.loss_weight * bc_convex_giou_loss(pred, target, weight, reduction, avg_factor, self.loss_weight)
        return loss


def gwd_loss(pred, target, fun='sqrt', tau=2.0):
    """Gaussian Wasserstein distance loss.

    Args:
        pred (torch.Tensor): Predicted bboxes.
        target (torch.Tensor): Corresponding gt bboxes.
        fun (str): The function applied to distance. Defaults to 'log1p'.
        tau (float): Defaults to 1.0.

    Returns:
        loss (torch.Tensor)
    """
    mu_p, sigma_p = pred
    mu_t, sigma_t = target
    xy_distance = (mu_p - mu_t).square().sum(dim=-1)
    whr_distance = sigma_p.diagonal(dim1=-2, dim2=-1).sum(dim=-1)
    whr_distance = whr_distance + sigma_t.diagonal(dim1=-2, dim2=-1).sum(dim=-1)
    _t_tr = sigma_p.bmm(sigma_t).diagonal(dim1=-2, dim2=-1).sum(dim=-1)
    _t_det_sqrt = (sigma_p.det() * sigma_t.det()).clamp(0).sqrt()
    whr_distance += -2 * (_t_tr + 2 * _t_det_sqrt).clamp(0).sqrt()
    dis = xy_distance + whr_distance
    gwd_dis = dis.clamp(min=1e-06)
    if fun == 'sqrt':
        loss = 1 - 1 / (tau + torch.sqrt(gwd_dis))
    elif fun == 'log1p':
        loss = 1 - 1 / (tau + torch.log1p(gwd_dis))
    else:
        scale = 2 * _t_det_sqrt.sqrt().sqrt().clamp(1e-07)
        loss = torch.log1p(torch.sqrt(gwd_dis) / scale)
    return loss


class GaussianMixture:
    """Initializes the Gaussian mixture model and brings all tensors into their
    required shape.

    Args:
        n_components (int): number of components.
        n_features (int, optional): number of features.
        mu_init (torch.Tensor, optional): (T, k, d)
        var_init (torch.Tensor, optional): (T, k, d) or (T, k, d, d)
        eps (float, optional): Defaults to 1e-6.
        requires_grad (bool, optional): Defaults to False.
    """

    def __init__(self, n_components, n_features=2, mu_init=None, var_init=None, eps=1e-06, requires_grad=False):
        self.n_components = n_components
        self.n_features = n_features
        self.mu_init = mu_init
        self.var_init = var_init
        self.eps = eps
        self.lower_bound_logdet = -783.0
        self.requires_grad = requires_grad
        self.T = 1
        self.N = 9

    def _init_params(self, mu_init=None, var_init=None):
        """Initializes the parameters of Gaussian mixture model.

        Args:
            mu_init (torch.Tensor, optional): mu of Gaussian.
            var_init (torch.Tensor, optional): variance of Gaussian.
        """
        self.log_likelihood = -np.inf
        if mu_init is not None:
            self.mu_init = mu_init
        if var_init is not None:
            self.var_init = var_init
        if self.requires_grad:
            if self.mu_init is not None:
                assert torch.is_tensor(self.mu_init)
                assert self.mu_init.size() == (self.T, self.n_components, self.n_features), 'Input mu_init does not have required tensor dimensions (%i, %i, %i)' % (self.T, self.n_components, self.n_features)
                self.mu = self.mu_init.clone().requires_grad_()
            else:
                self.mu = torch.randn((self.T, self.n_components, self.n_features), requires_grad=True)
            if self.var_init is not None:
                assert torch.is_tensor(self.var_init)
                assert self.var_init.size() == (self.T, self.n_components, self.n_features, self.n_features), 'Input var_init does not have required tensor dimensions (%i, %i, %i, %i)' % (self.T, self.n_components, self.n_features, self.n_features)
                self.var = self.var_init.clone().requires_grad_()
            else:
                self.var = torch.eye(self.n_features).reshape((1, 1, self.n_features, self.n_features)).repeat(self.T, self.n_components, 1, 1).requires_grad_()
            self.pi = torch.empty((self.T, self.n_components, 1)).fill_(1.0 / self.n_components).requires_grad_()
        else:
            if self.mu_init is not None:
                assert torch.is_tensor(self.mu_init)
                assert self.mu_init.size() == (self.T, self.n_components, self.n_features), 'Input mu_init does not have required tensor dimensions (%i, %i, %i)' % (self.T, self.n_components, self.n_features)
                self.mu = self.mu_init.clone()
            else:
                self.mu = torch.randn((self.T, self.n_components, self.n_features))
            if self.var_init is not None:
                assert torch.is_tensor(self.var_init)
                assert self.var_init.size() == (self.T, self.n_components, self.n_features, self.n_features), 'Input var_init does not have required tensor dimensions (%i, %i, %i, %i)' % (self.T, self.n_components, self.n_features, self.n_features)
                self.var = self.var_init.clone()
            else:
                self.var = torch.eye(self.n_features).reshape((1, 1, self.n_features, self.n_features)).repeat(self.T, self.n_components, 1, 1)
            self.pi = torch.empty((self.T, self.n_components, 1)).fill_(1.0 / self.n_components)
        self.params_fitted = False

    def check_size(self, x):
        """Make sure that the shape of x is (T, n, 1, d).

        Args:
            x (torch.Tensor): input tensor.

        Returns:
            torch.Tensor: output tensor.
        """
        if len(x.size()) == 3:
            x = x.unsqueeze(2)
        return x

    def fit(self, x, delta=0.001, n_iter=10):
        """Fits Gaussian mixture model to the data.

        Args:
            x (torch.Tensor): input tensor.
            delta (float, optional): threshold.
            n_iter (int, optional): number of iterations.
        """
        self.T = x.size()[0]
        self.N = x.size()[1]
        select = torch.randint(self.N, size=(self.T * self.n_components,))
        mu_init = x.reshape(-1, self.n_features)[select, :].view(self.T, self.n_components, self.n_features)
        self._init_params(mu_init=mu_init)
        x = self.check_size(x)
        i = 0
        j = np.inf
        while i <= n_iter and (not torch.is_tensor(j) or (j >= delta).any()):
            log_likelihood_old = self.log_likelihood
            mu_old = self.mu
            var_old = self.var
            self.em_runner(x)
            self.log_likelihood = self.get_score(x)
            if (self.log_likelihood.abs() == float('Inf')).any() or torch.isnan(self.log_likelihood).any():
                select = torch.randint(self.N, size=(self.T * self.n_components,))
                mu_init = x.reshape(-1, self.n_features)[select, :].view(self.T, self.n_components, self.n_features)
                self._init_params(mu_init=mu_init)
            i += 1
            j = self.log_likelihood - log_likelihood_old
            if torch.is_tensor(j) and (j <= delta).any():
                t = j <= delta
                mu_old = t.float().view(self.T, 1, 1) * mu_old + (~t).float().view(self.T, 1, 1) * self.mu
                var_old = t.float().view(self.T, 1, 1, 1) * var_old + (~t).float().view(self.T, 1, 1, 1) * self.var
                self.update_mu(mu_old)
                self.update_var(var_old)
        self.params_fitted = True

    def estimate_log_prob(self, x):
        """Estimate the log-likelihood probability that samples belong to the
        k-th Gaussian.

        Args:
            x (torch.Tensor): (T, n, d) or (T, n, 1, d)

        Returns:
            torch.Tensor: log-likelihood probability that samples belong to                 the k-th Gaussian with dimensions (T, n, k, 1).
        """
        x = self.check_size(x)
        mu = self.mu
        var = self.var
        inverse_var = torch.inverse(var)
        d = x.shape[-1]
        log_2pi = d * np.log(2.0 * pi)
        det_var = torch.det(var)
        log_det = torch.log(det_var).view(self.T, 1, self.n_components, 1)
        log_det[log_det == -np.inf] = self.lower_bound_logdet
        mu = mu.unsqueeze(1)
        x_mu_T = (x - mu).unsqueeze(-2)
        x_mu = (x - mu).unsqueeze(-1)
        x_mu_T_inverse_var = x_mu_T.matmul(inverse_var.unsqueeze(1))
        x_mu_T_inverse_var_x_mu = x_mu_T_inverse_var.matmul(x_mu).squeeze(-1)
        log_p = -0.5 * (log_2pi + log_det + x_mu_T_inverse_var_x_mu)
        return log_p

    def log_resp_step(self, x):
        """Computes log-responses that indicate the (logarithmic) posterior
        belief (sometimes called responsibilities) that a data point was
        generated by one of the k mixture components. Also returns the mean of
        the mean of the logarithms of the probabilities (as is done in
        sklearn). This is the so-called expectation step of the EM-algorithm.

        Args:
            x (torch.Tensor): (T, n, d) or (T, n, 1, d)

        Returns:
            tuple:

                log_prob_norm (torch.Tensor): the mean of the mean of the                     logarithms of the probabilities.
                log_resp (torch.Tensor): log-responses that indicate the                     posterior belief.
        """
        x = self.check_size(x)
        weighted_log_prob = self.estimate_log_prob(x) + torch.log(self.pi).unsqueeze(1)
        log_prob_norm = torch.logsumexp(weighted_log_prob, dim=2, keepdim=True)
        log_resp = weighted_log_prob - log_prob_norm
        return torch.mean(log_prob_norm, dim=(1, 2)), log_resp

    def EM_step(self, x, log_resp):
        """From the log-probabilities, computes new parameters pi, mu, var
        (that maximize the log-likelihood). This is the maximization step of
        the EM-algorithm.

        Args:
            x (torch.Tensor): (T, n, d) or (T, n, 1, d)
            log_resp (torch.Tensor): (T, n, k, 1)

        Returns:
            tuple:

                pi (torch.Tensor): (T, k, 1)
                mu (torch.Tensor): (T, k, d)
                var (torch.Tensor): (T, k, d) or (T, k, d, d)
        """
        x = self.check_size(x)
        resp = torch.exp(log_resp)
        pi = torch.sum(resp, dim=1) + self.eps
        mu = torch.sum(resp * x, dim=1) / pi
        eps = torch.eye(self.n_features) * self.eps
        var = torch.sum((x - mu.unsqueeze(1)).unsqueeze(-1).matmul((x - mu.unsqueeze(1)).unsqueeze(-2)) * resp.unsqueeze(-1), dim=1) / torch.sum(resp, dim=1).unsqueeze(-1) + eps
        pi = pi / x.shape[1]
        return pi, mu, var

    def em_runner(self, x):
        """Performs one iteration of the expectation-maximization algorithm by
        calling the respective subroutines.

        Args:
            x (torch.Tensor): (n, 1, d)
        """
        _, log_resp = self.log_resp_step(x)
        pi, mu, var = self.EM_step(x, log_resp)
        self.update_pi(pi)
        self.update_mu(mu)
        self.update_var(var)

    def get_score(self, x, sum_data=True):
        """Computes the log-likelihood of the data under the model.

        Args:
            x (torch.Tensor): (T, n, 1, d)
            sum_data (bool,optional): Flag of whether to sum scores.

        Returns:
            torch.Tensor: score or per_sample_score.
        """
        weighted_log_prob = self.estimate_log_prob(x) + torch.log(self.pi).unsqueeze(1)
        per_sample_score = torch.logsumexp(weighted_log_prob, dim=2)
        if sum_data:
            return per_sample_score.sum(dim=1)
        else:
            return per_sample_score.squeeze(-1)

    def update_mu(self, mu):
        """Updates mean to the provided value.

        Args:
            mu (torch.Tensor):
        """
        assert mu.size() == (self.T, self.n_components, self.n_features), 'Input mu does not have required tensor dimensions (%i, %i, %i)' % (self.T, self.n_components, self.n_features)
        if mu.size() == (self.n_components, self.n_features):
            self.mu = mu.unsqueeze(0)
        elif mu.size() == (self.T, self.n_components, self.n_features):
            self.mu = mu.clone()

    def update_var(self, var):
        """Updates variance to the provided value.

        Args:
            var (torch.Tensor): (T, k, d) or (T, k, d, d)
        """
        assert var.size() == (self.T, self.n_components, self.n_features, self.n_features), 'Input var does not have required tensor dimensions (%i, %i, %i, %i)' % (self.T, self.n_components, self.n_features, self.n_features)
        if var.size() == (self.n_components, self.n_features, self.n_features):
            self.var = var.unsqueeze(0)
        elif var.size() == (self.T, self.n_components, self.n_features, self.n_features):
            self.var = var.clone()

    def update_pi(self, pi):
        """Updates pi to the provided value.

        Args:
            pi (torch.Tensor): (T, k, 1)
        """
        assert pi.size() == (self.T, self.n_components, 1), 'Input pi does not have required tensor dimensions (%i, %i, %i)' % (self.T, self.n_components, 1)
        self.pi = pi.clone()


def gt2gaussian(target):
    """Convert polygons to Gaussian distributions.

    Args:
        target (torch.Tensor): Polygons with shape (N, 8).

    Returns:
        dict[str, torch.Tensor]: Gaussian distributions.
    """
    L = 3
    center = torch.mean(target, dim=1)
    edge_1 = target[:, 1, :] - target[:, 0, :]
    edge_2 = target[:, 2, :] - target[:, 1, :]
    w = (edge_1 * edge_1).sum(dim=-1, keepdim=True)
    w_ = w.sqrt()
    h = (edge_2 * edge_2).sum(dim=-1, keepdim=True)
    diag = torch.cat([w, h], dim=-1).diag_embed() / (4 * L * L)
    cos_sin = edge_1 / w_
    neg = torch.tensor([[1, -1]], dtype=torch.float32)
    R = torch.stack([cos_sin * neg, cos_sin[..., [1, 0]]], dim=-2)
    return center, R.matmul(diag).matmul(R.transpose(-1, -2))


def kld_single2single(g1, g2):
    """Compute Kullback-Leibler Divergence.

    Args:
        g1 (dict[str, torch.Tensor]): Gaussian distribution 1.
        g2 (torch.Tensor): Gaussian distribution 2.

    Returns:
        torch.Tensor: Kullback-Leibler Divergence.
    """
    p_mu = g1.mu
    p_var = g1.var
    assert p_mu.dim() == 3 and p_mu.size()[1] == 1
    assert p_var.dim() == 4 and p_var.size()[1] == 1
    p_mu = p_mu.squeeze(1)
    p_var = p_var.squeeze(1)
    t_mu, t_var = g2
    delta = (p_mu - t_mu).unsqueeze(-1)
    t_inv = torch.inverse(t_var)
    term1 = delta.transpose(-1, -2).matmul(t_inv).matmul(delta).squeeze(-1)
    term2 = torch.diagonal(t_inv.matmul(p_var), dim1=-2, dim2=-1).sum(dim=-1, keepdim=True) + torch.log(torch.det(t_var) / torch.det(p_var)).reshape(-1, 1)
    return 0.5 * (term1 + term2) - 1


def postprocess(distance, fun='log1p', tau=1.0):
    """Convert distance to loss.

    Args:
        distance (torch.Tensor)
        fun (str, optional): The function applied to distance.
            Defaults to 'log1p'.
        tau (float, optional): Defaults to 1.0.

    Returns:
        loss (torch.Tensor)
    """
    if fun == 'log1p':
        distance = torch.log1p(distance)
    elif fun == 'sqrt':
        distance = torch.sqrt(distance.clamp(1e-07))
    elif fun == 'none':
        pass
    else:
        raise ValueError(f'Invalid non-linear function {fun}')
    if tau >= 1.0:
        return 1 - 1 / (tau + distance)
    else:
        return distance


def xy_stddev_pearson_2_xy_sigma(xy_stddev_pearson):
    """Convert oriented bounding box from the Pearson coordinate system to 2-D
    Gaussian distribution.

    Args:
        xy_stddev_pearson (torch.Tensor): rbboxes with shape (N, 5).

    Returns:
        xy (torch.Tensor): center point of 2-D Gaussian distribution
            with shape (N, 2).
        sigma (torch.Tensor): covariance matrix of 2-D Gaussian distribution
            with shape (N, 2, 2).
    """
    _shape = xy_stddev_pearson.shape
    assert _shape[-1] == 5
    xy = xy_stddev_pearson[..., :2]
    stddev = xy_stddev_pearson[..., 2:4]
    pearson = xy_stddev_pearson[..., 4].clamp(min=1e-07 - 1, max=1 - 1e-07)
    covar = pearson * stddev.prod(dim=-1)
    var = stddev.square()
    sigma = torch.stack((var[..., 0], covar, covar, var[..., 1]), dim=-1).reshape(_shape[:-1] + (2, 2))
    return xy, sigma


def xy_wh_r_2_xy_sigma(xywhr):
    """Convert oriented bounding box to 2-D Gaussian distribution.

    Args:
        xywhr (torch.Tensor): rbboxes with shape (N, 5).

    Returns:
        xy (torch.Tensor): center point of 2-D Gaussian distribution
            with shape (N, 2).
        sigma (torch.Tensor): covariance matrix of 2-D Gaussian distribution
            with shape (N, 2, 2).
    """
    _shape = xywhr.shape
    assert _shape[-1] == 5
    xy = xywhr[..., :2]
    wh = xywhr[..., 2:4].clamp(min=1e-07, max=10000000.0).reshape(-1, 2)
    r = xywhr[..., 4]
    cos_r = torch.cos(r)
    sin_r = torch.sin(r)
    R = torch.stack((cos_r, -sin_r, sin_r, cos_r), dim=-1).reshape(-1, 2, 2)
    S = 0.5 * torch.diag_embed(wh)
    sigma = R.bmm(S.square()).bmm(R.permute(0, 2, 1)).reshape(_shape[:-1] + (2, 2))
    return xy, sigma


def bcd_loss(pred, target, fun='log1p', tau=1.0):
    """Bhatacharyya distance loss.

    Args:
        pred (torch.Tensor): Predicted bboxes.
        target (torch.Tensor): Corresponding gt bboxes.
        fun (str): The function applied to distance. Defaults to 'log1p'.
        tau (float): Defaults to 1.0.

    Returns:
        loss (torch.Tensor)
    """
    mu_p, sigma_p = pred
    mu_t, sigma_t = target
    mu_p = mu_p.reshape(-1, 2)
    mu_t = mu_t.reshape(-1, 2)
    sigma_p = sigma_p.reshape(-1, 2, 2)
    sigma_t = sigma_t.reshape(-1, 2, 2)
    delta = (mu_p - mu_t).unsqueeze(-1)
    sigma = 0.5 * (sigma_p + sigma_t)
    sigma_inv = torch.inverse(sigma)
    term1 = torch.log(torch.det(sigma) / torch.sqrt(torch.det(sigma_t.matmul(sigma_p)))).reshape(-1, 1)
    term2 = delta.transpose(-1, -2).matmul(sigma_inv).matmul(delta).squeeze(-1)
    dis = 0.5 * term1 + 0.125 * term2
    bcd_dis = dis.clamp(min=1e-06)
    if fun == 'sqrt':
        loss = 1 - 1 / (tau + torch.sqrt(bcd_dis))
    elif fun == 'log1p':
        loss = 1 - 1 / (tau + torch.log1p(bcd_dis))
    else:
        loss = 1 - 1 / (tau + bcd_dis)
    return loss


class KFLoss(nn.Module):
    """Kalman filter based loss.

    Args:
        fun (str, optional): The function applied to distance.
            Defaults to 'log1p'.
        reduction (str, optional): The reduction method of the
            loss. Defaults to 'mean'.
        loss_weight (float, optional): The weight of loss. Defaults to 1.0.

    Returns:
        loss (torch.Tensor)
    """

    def __init__(self, fun='none', reduction='mean', loss_weight=1.0, **kwargs):
        super(KFLoss, self).__init__()
        assert reduction in ['none', 'sum', 'mean']
        assert fun in ['none', 'ln', 'exp']
        self.fun = fun
        self.reduction = reduction
        self.loss_weight = loss_weight

    def forward(self, pred, target, weight=None, avg_factor=None, pred_decode=None, targets_decode=None, reduction_override=None, **kwargs):
        """Forward function.

        Args:
            pred (torch.Tensor): Predicted convexes.
            target (torch.Tensor): Corresponding gt convexes.
            weight (torch.Tensor, optional): The weight of loss for each
                prediction. Defaults to None.
            avg_factor (int, optional): Average factor that is used to average
                the loss. Defaults to None.
            pred_decode (torch.Tensor): Predicted decode bboxes.
            targets_decode (torch.Tensor): Corresponding gt decode bboxes.
            reduction_override (str, optional): The reduction method used to
               override the original reduction method of the loss.
               Defaults to None.

        Returns:
            loss (torch.Tensor)
        """
        assert reduction_override in (None, 'none', 'mean', 'sum')
        reduction = reduction_override if reduction_override else self.reduction
        if weight is not None and not torch.any(weight > 0) and reduction != 'none':
            return (pred * weight).sum()
        if weight is not None and weight.dim() > 1:
            assert weight.shape == pred.shape
            weight = weight.mean(-1)
        return kfiou_loss(pred, target, fun=self.fun, weight=weight, avg_factor=avg_factor, pred_decode=pred_decode, targets_decode=targets_decode, reduction=reduction, **kwargs) * self.loss_weight


class KLDRepPointsLoss(nn.Module):
    """Kullback-Leibler Divergence loss for RepPoints.

    Args:
        eps (float): Defaults to 1e-6.
        reduction (str, optional): The reduction method of the
            loss. Defaults to 'mean'.
        loss_weight (float, optional): The weight of loss. Defaults to 1.0.
    """

    def __init__(self, eps=1e-06, reduction='mean', loss_weight=1.0):
        super(KLDRepPointsLoss, self).__init__()
        self.eps = eps
        self.reduction = reduction
        self.loss_weight = loss_weight

    def forward(self, pred, target, weight=None, avg_factor=None, reduction_override=None, **kwargs):
        """Forward function.

        Args:
            pred (torch.Tensor): Predicted convexes.
            target (torch.Tensor): Corresponding gt convexes.
            weight (torch.Tensor, optional): The weight of loss for each
                prediction. Defaults to None.
            avg_factor (int, optional): Average factor that is used to average
                the loss. Defaults to None.
            reduction_override (str, optional): The reduction method used to
               override the original reduction method of the loss.
               Defaults to None.

        Returns:
            loss (torch.Tensor)
        """
        if weight is not None and not torch.any(weight > 0):
            return (pred * weight.unsqueeze(-1)).sum()
        assert reduction_override in (None, 'none', 'mean', 'sum')
        reduction = reduction_override if reduction_override else self.reduction
        loss_bbox = self.loss_weight * kld_loss(pred, target, weight, eps=self.eps, reduction=reduction, avg_factor=avg_factor, **kwargs)
        return loss_bbox


class RotatedIoULoss(nn.Module):
    """RotatedIoULoss.

    Computing the IoU loss between a set of predicted rbboxes and
    target rbboxes.
    Args:
        linear (bool): If True, use linear scale of loss else determined
            by mode. Default: False.
        eps (float): Eps to avoid log(0).
        reduction (str): Options are "none", "mean" and "sum".
        loss_weight (float): Weight of loss.
        mode (str): Loss scaling mode, including "linear", "square", and "log".
            Default: 'log'
    """

    def __init__(self, linear=False, eps=1e-06, reduction='mean', loss_weight=1.0, mode='log'):
        super(RotatedIoULoss, self).__init__()
        assert mode in ['linear', 'square', 'log']
        if linear:
            mode = 'linear'
            warnings.warn('DeprecationWarning: Setting "linear=True" in IOULoss is deprecated, please use "mode=`linear`" instead.')
        self.mode = mode
        self.linear = linear
        self.eps = eps
        self.reduction = reduction
        self.loss_weight = loss_weight

    def forward(self, pred, target, weight=None, avg_factor=None, reduction_override=None, **kwargs):
        """Forward function.

        Args:
            pred (torch.Tensor): The prediction.
            target (torch.Tensor): The learning target of the prediction.
            weight (torch.Tensor, optional): The weight of loss for each
                prediction. Defaults to None.
            avg_factor (int, optional): Average factor that is used to average
                the loss. Defaults to None.
            reduction_override (str, optional): The reduction method used to
                override the original reduction method of the loss.
                Defaults to None. Options are "none", "mean" and "sum".
        """
        assert reduction_override in (None, 'none', 'mean', 'sum')
        reduction = reduction_override if reduction_override else self.reduction
        if weight is not None and not torch.any(weight > 0) and reduction != 'none':
            if pred.dim() == weight.dim() + 1:
                weight = weight.unsqueeze(1)
            return (pred * weight).sum()
        if weight is not None and weight.dim() > 1:
            assert weight.shape == pred.shape
            weight = weight.mean(-1)
        loss = self.loss_weight * rotated_iou_loss(pred, target, weight, mode=self.mode, eps=self.eps, reduction=reduction, avg_factor=avg_factor, **kwargs)
        return loss


def smooth_focal_loss(pred, target, weight=None, gamma=2.0, alpha=0.25, reduction='mean', avg_factor=None):
    """Smooth Focal Loss proposed in Circular Smooth Label (CSL).

    Args:
        pred (torch.Tensor): The prediction.
        target (torch.Tensor): The learning label of the prediction.
        weight (torch.Tensor, optional): The weight of loss for each
            prediction. Defaults to None.
        gamma (float, optional): The gamma for calculating the modulating
                factor. Defaults to 2.0.
        alpha (float, optional): A balanced form for Focal Loss.
            Defaults to 0.25.
        reduction (str, optional): The reduction method used to
            override the original reduction method of the loss.
            Options are "none", "mean" and "sum".
        avg_factor (int, optional): Average factor that is used to average
            the loss. Defaults to None.

    Returns:
        torch.Tensor: The calculated loss
    """
    pred_sigmoid = pred.sigmoid()
    target = target.type_as(pred)
    pt = (1 - pred_sigmoid) * target + pred_sigmoid * (1 - target)
    focal_weight = (alpha * target + (1 - alpha) * (1 - target)) * pt.pow(gamma)
    loss = F.binary_cross_entropy_with_logits(pred, target, reduction='none') * focal_weight
    if weight is not None:
        if weight.shape != loss.shape:
            if weight.size(0) == loss.size(0):
                weight = weight.view(-1, 1)
            else:
                assert weight.numel() == loss.numel()
                weight = weight.view(loss.size(0), -1)
        assert weight.ndim == loss.ndim
    loss = weight_reduce_loss(loss, weight, reduction, avg_factor)
    return loss


class SmoothFocalLoss(nn.Module):
    """Smooth Focal Loss. Implementation of `Circular Smooth Label (CSL).`__

    __ https://link.springer.com/chapter/10.1007/978-3-030-58598-3_40

    Args:
        gamma (float, optional): The gamma for calculating the modulating
            factor. Defaults to 2.0.
        alpha (float, optional): A balanced form for Focal Loss.
            Defaults to 0.25.
        reduction (str, optional): The method used to reduce the loss into
            a scalar. Defaults to 'mean'. Options are "none", "mean" and
            "sum".
        loss_weight (float, optional): Weight of loss. Defaults to 1.0.

    Returns:
        loss (torch.Tensor)
    """

    def __init__(self, gamma=2.0, alpha=0.25, reduction='mean', loss_weight=1.0):
        super(SmoothFocalLoss, self).__init__()
        self.gamma = gamma
        self.alpha = alpha
        self.reduction = reduction
        self.loss_weight = loss_weight

    def forward(self, pred, target, weight=None, avg_factor=None, reduction_override=None):
        """Forward function.

        Args:
            pred (torch.Tensor): The prediction.
            target (torch.Tensor): The learning label of the prediction.
            weight (torch.Tensor, optional): The weight of loss for each
                prediction. Defaults to None.
            avg_factor (int, optional): Average factor that is used to average
                the loss. Defaults to None.
            reduction_override (str, optional): The reduction method used to
                override the original reduction method of the loss.
                Options are "none", "mean" and "sum".

        Returns:
            torch.Tensor: The calculated loss
        """
        assert reduction_override in (None, 'none', 'mean', 'sum')
        reduction = reduction_override if reduction_override else self.reduction
        loss_cls = self.loss_weight * smooth_focal_loss(pred, target, weight, gamma=self.gamma, alpha=self.alpha, reduction=reduction, avg_factor=avg_factor)
        return loss_cls


def spatial_border_loss(pts, gt_bboxes):
    """The loss is used to penalize the learning points out of the assigned
    ground truth boxes (polygon by default).

    Args:
        pts (torch.Tensor): point sets with shape (N, 9*2).
        gt_bboxes (torch.Tensor): gt_bboxes with polygon form with shape(N, 8)

    Returns:
        loss (torch.Tensor)
    """
    num_gts, num_pointsets = gt_bboxes.size(0), pts.size(0)
    num_point = int(pts.size(1) / 2.0)
    loss = pts.new_zeros([0])
    if num_gts > 0:
        inside_flag_list = []
        for i in range(num_point):
            pt = pts[:, 2 * i:2 * i + 2].reshape(num_pointsets, 2).contiguous()
            inside_pt_flag = points_in_polygons(pt, gt_bboxes)
            inside_pt_flag = torch.diag(inside_pt_flag)
            inside_flag_list.append(inside_pt_flag)
        inside_flag = torch.stack(inside_flag_list, dim=1)
        pts = pts.reshape(-1, num_point, 2)
        out_border_pts = pts[torch.where(inside_flag == 0)]
        if out_border_pts.size(0) > 0:
            corr_gt_boxes = gt_bboxes[torch.where(inside_flag == 0)[0]]
            corr_gt_boxes_center_x = (corr_gt_boxes[:, 0] + corr_gt_boxes[:, 4]) / 2.0
            corr_gt_boxes_center_y = (corr_gt_boxes[:, 1] + corr_gt_boxes[:, 5]) / 2.0
            corr_gt_boxes_center = torch.stack([corr_gt_boxes_center_x, corr_gt_boxes_center_y], dim=1)
            distance_out_pts = 0.2 * ((out_border_pts - corr_gt_boxes_center) ** 2).sum(dim=1).sqrt()
            loss = distance_out_pts.sum() / out_border_pts.size(0)
    return loss


def weighted_spatial_border_loss(pts, gt_bboxes, weight, avg_factor=None):
    """Weghted spatial border loss.

    Args:
        pts (torch.Tensor): point sets with shape (N, 9*2).
        gt_bboxes (torch.Tensor): gt_bboxes with polygon form with shape(N, 8)
        weight (torch.Tensor): weights for point sets with shape (N)

    Returns:
        loss (torch.Tensor)
    """
    weight = weight.unsqueeze(dim=1).repeat(1, 4)
    assert weight.dim() == 2
    if avg_factor is None:
        avg_factor = torch.sum(weight > 0).float().item() / 4 + 1e-06
    loss = spatial_border_loss(pts, gt_bboxes)
    return torch.sum(loss)[None] / avg_factor


class SpatialBorderLoss(nn.Module):
    """Spatial Border loss for learning points in Oriented RepPoints.

    Args:
        pts (torch.Tensor): point sets with shape (N, 9*2).
        Default points number in each point set is 9.
        gt_bboxes (torch.Tensor): gt_bboxes with polygon form with shape(N, 8)

    Returns:
        loss (torch.Tensor)
    """

    def __init__(self, loss_weight=1.0):
        super(SpatialBorderLoss, self).__init__()
        self.loss_weight = loss_weight

    def forward(self, pts, gt_bboxes, weight, *args, **kwargs):
        loss = self.loss_weight * weighted_spatial_border_loss(pts, gt_bboxes, weight, *args, **kwargs)
        return loss


class ORConv2d(Conv2d):
    """Oriented 2-D convolution.

    Args:
        in_channels (List[int]): Number of input channels per scale.
        out_channels (int): Number of output channels (used at each scale).
        kernel_size (int, optional): The size of kernel.
        arf_config (tuple, optional): a tuple consist of nOrientation and
            nRotation.
        stride (int, optional): Stride of the convolution. Default: 1.
        padding (int or tuple): Zero-padding added to both sides of the input.
            Default: 0.
        dilation (int or tuple): Spacing between kernel elements. Default: 1.
        groups (int): Number of blocked connections from input.
            channels to output channels. Default: 1.
        bias (bool): If True, adds a learnable bias to the output.
            Default: False.
    """

    def __init__(self, in_channels, out_channels, kernel_size=3, arf_config=None, stride=1, padding=0, dilation=1, groups=1, bias=True):
        self.nOrientation, self.nRotation = to_2tuple(arf_config)
        assert (math.log(self.nOrientation) + 1e-05) % math.log(2) < 0.001, f'invalid nOrientation {self.nOrientation}'
        assert (math.log(self.nRotation) + 1e-05) % math.log(2) < 0.001, f'invalid nRotation {self.nRotation}'
        super(ORConv2d, self).__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias)
        self.register_buffer('indices', self.get_indices())
        self.weight = Parameter(torch.Tensor(out_channels, in_channels, self.nOrientation, *self.kernel_size))
        if bias:
            self.bias = Parameter(torch.Tensor(out_channels * self.nRotation))
        self.reset_parameters()

    def reset_parameters(self):
        """Reset the parameters of ORConv2d."""
        n = self.in_channels * self.nOrientation
        for k in self.kernel_size:
            n *= k
        self.weight.data.normal_(0, math.sqrt(2.0 / n))
        if self.bias is not None:
            self.bias.data.zero_()

    def get_indices(self):
        """Get the indices of ORConv2d."""
        kernel_indices = {(1): {(0): (1,), (45): (1,), (90): (1,), (135): (1,), (180): (1,), (225): (1,), (270): (1,), (315): (1,)}, (3): {(0): (1, 2, 3, 4, 5, 6, 7, 8, 9), (45): (2, 3, 6, 1, 5, 9, 4, 7, 8), (90): (3, 6, 9, 2, 5, 8, 1, 4, 7), (135): (6, 9, 8, 3, 5, 7, 2, 1, 4), (180): (9, 8, 7, 6, 5, 4, 3, 2, 1), (225): (8, 7, 4, 9, 5, 1, 6, 3, 2), (270): (7, 4, 1, 8, 5, 2, 9, 6, 3), (315): (4, 1, 2, 7, 5, 3, 8, 9, 6)}}
        delta_orientation = 360 / self.nOrientation
        delta_rotation = 360 / self.nRotation
        kH, kW = self.kernel_size
        indices = torch.IntTensor(self.nOrientation * kH * kW, self.nRotation)
        for i in range(0, self.nOrientation):
            for j in range(0, kH * kW):
                for k in range(0, self.nRotation):
                    angle = delta_rotation * k
                    layer = (i + math.floor(angle / delta_orientation)) % self.nOrientation
                    kernel = kernel_indices[kW][angle][j]
                    indices[i * kH * kW + j, k] = int(layer * kH * kW + kernel)
        return indices.view(self.nOrientation, kH, kW, self.nRotation)

    def rotate_arf(self):
        """Build active rotating filter module."""
        return active_rotated_filter(self.weight, self.indices)

    def forward(self, input):
        """Forward function."""
        return F.conv2d(input, self.rotate_arf(), self.bias, self.stride, self.padding, self.dilation, self.groups)

    def __repr__(self):
        arf_config = f'[{self.nOrientation}]' if self.nOrientation == self.nRotation else '[{self.nOrientation}-{self.nRotation}]'
        s = '{name}({arf_config} {in_channels}, {out_channels}, kernel_size={kernel_size}, stride={stride}'
        if self.padding != (0,) * len(self.padding):
            s += ', padding={padding}'
        if self.dilation != (1,) * len(self.dilation):
            s += ', dilation={dilation}'
        if self.output_padding != (0,) * len(self.output_padding):
            s += ', output_padding={output_padding}'
        if self.groups != 1:
            s += ', groups={groups}'
        if self.bias is None:
            s += ', bias=False'
        s += ')'
        return s.format(name=self.__class__.__name__, arf_config=arf_config, **self.__dict__)


class RotationInvariantPooling(nn.Module):
    """Rotating invariant pooling module.

    Args:
        nInputPlane (int): The number of Input plane.
        nOrientation (int, optional): The number of oriented channels.
    """

    def __init__(self, nInputPlane, nOrientation=8):
        super(RotationInvariantPooling, self).__init__()
        self.nInputPlane = nInputPlane
        self.nOrientation = nOrientation

    def forward(self, x):
        """Forward function."""
        N, c, h, w = x.size()
        x = x.view(N, -1, self.nOrientation, h, w)
        x, _ = x.max(dim=2, keepdim=False)
        return x

